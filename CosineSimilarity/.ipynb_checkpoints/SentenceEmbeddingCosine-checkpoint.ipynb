{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e655b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>SDG 1</th>\n",
       "      <th>SDG 2</th>\n",
       "      <th>SDG 3</th>\n",
       "      <th>SDG 4</th>\n",
       "      <th>SDG 5</th>\n",
       "      <th>SDG 6</th>\n",
       "      <th>SDG 7</th>\n",
       "      <th>SDG 8</th>\n",
       "      <th>SDG 9</th>\n",
       "      <th>SDG 10</th>\n",
       "      <th>SDG 11</th>\n",
       "      <th>SDG 12</th>\n",
       "      <th>SDG 13</th>\n",
       "      <th>SDG 14</th>\n",
       "      <th>SDG 15</th>\n",
       "      <th>SDG 16</th>\n",
       "      <th>SDG 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shape, Built Enviro Projects the built environ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEP 5 this course is identified by rmit univer...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comm Skills for Health Prof this course will e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SW Field Education A in this course you will u...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSC Work Integrated Learning 2 in this course ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Policy analysis for growth prospects in region...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Building an understanding of liveability acros...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Stage 2 - Latrobe Valley Smart Specialisation ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Balance Victoria:  Potential Impacts of a Form...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Development of culturing procedures and molecu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>760 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  SDG 1  SDG 2  SDG 3  \\\n",
       "0    Shape, Built Enviro Projects the built environ...    0.0    0.0    0.0   \n",
       "1    PEP 5 this course is identified by rmit univer...    0.0    0.0    1.0   \n",
       "2    Comm Skills for Health Prof this course will e...    0.0    0.0    1.0   \n",
       "3    SW Field Education A in this course you will u...    0.0    0.0    0.0   \n",
       "4    LSC Work Integrated Learning 2 in this course ...    0.0    0.0    0.0   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "755  Policy analysis for growth prospects in region...    0.0    0.0    0.0   \n",
       "756  Building an understanding of liveability acros...    0.0    0.0    0.0   \n",
       "757  Stage 2 - Latrobe Valley Smart Specialisation ...    0.0    1.0    0.0   \n",
       "758  Balance Victoria:  Potential Impacts of a Form...    0.0    0.0    0.0   \n",
       "759  Development of culturing procedures and molecu...    0.0    0.0    0.0   \n",
       "\n",
       "     SDG 4  SDG 5  SDG 6  SDG 7  SDG 8  SDG 9  SDG 10  SDG 11  SDG 12  SDG 13  \\\n",
       "0      1.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "1      1.0    0.0    0.0    0.0    1.0    0.0     1.0     0.0     0.0     0.0   \n",
       "2      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "3      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "4      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "..     ...    ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       "755    0.0    0.0    0.0    0.0    1.0    1.0     0.0     0.0     0.0     0.0   \n",
       "756    0.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "757    0.0    0.0    0.0    1.0    1.0    0.0     0.0     0.0     0.0     0.0   \n",
       "758    0.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "759    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     SDG 14  SDG 15  SDG 16  SDG 17  \n",
       "0       0.0     0.0     0.0     1.0  \n",
       "1       0.0     0.0     0.0     0.0  \n",
       "2       0.0     0.0     0.0     0.0  \n",
       "3       0.0     0.0     0.0     0.0  \n",
       "4       0.0     0.0     0.0     0.0  \n",
       "..      ...     ...     ...     ...  \n",
       "755     0.0     0.0     0.0     0.0  \n",
       "756     0.0     0.0     0.0     0.0  \n",
       "757     0.0     0.0     0.0     1.0  \n",
       "758     0.0     0.0     0.0     0.0  \n",
       "759     0.0     1.0     0.0     0.0  \n",
       "\n",
       "[760 rows x 18 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# Load SDG keywords\n",
    "with open('Data/sdg_keywords.json', 'r') as file:\n",
    "    sdg_keywords = json.load(file)\n",
    "\n",
    "# Load test dataset\n",
    "df = pd.read_csv('Data/test_large.csv')\n",
    "# df = df.sample(n=25, random_state=42)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "398e2b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class 'str'> <class 'float'>]\n",
      "760\n",
      "755\n"
     ]
    }
   ],
   "source": [
    "#Just checking data types\n",
    "unique_types = df['Text'].apply(type).unique()\n",
    "print(unique_types)\n",
    "print(len(df))\n",
    "\n",
    "# Filtering out rows where 'Text' column has a data type of float or contains NaN values\n",
    "df = df[df['Text'].apply(lambda x: not isinstance(x, float))]\n",
    "df = df.dropna(subset=['Text'])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(len(df))\n",
    "texts = df['Text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecf92d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SentenceTransformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L3-v2')\n",
    "\n",
    "# Create embeddings for text data\n",
    "texts_embeddings = model.encode(texts, convert_to_numpy=True)\n",
    "\n",
    "# Create individual embeddings for SDG keywords\n",
    "sdg_keywords_embeddings = {sdg: [(word, model.encode([word], convert_to_numpy=True)[0]) for word in words] for sdg, words in sdg_keywords.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ebea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_single_sdg(text_vector, current_sdg, threshold, top_n_keywords=5):\n",
    "    keyword_embeddings = sdg_keywords_embeddings[current_sdg]\n",
    "    individual_word_similarities = [(keyword, cosine_similarity([embedding], [text_vector])[0][0]) for keyword, embedding in keyword_embeddings]\n",
    "    individual_word_similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "    max_sim = individual_word_similarities[0][1]\n",
    "    sdg_assignment = 1 if max_sim > threshold else 0\n",
    "    top_keywords = {}\n",
    "    if sdg_assignment == 1:\n",
    "        top_keywords_for_sdg = [word[0] for word in individual_word_similarities[:top_n_keywords]]\n",
    "        top_keywords[current_sdg] = top_keywords_for_sdg\n",
    "    return sdg_assignment, top_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ae703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process texts and predict SDGs\n",
    "threshold = 0.60\n",
    "true_labels = df.drop('Text', axis=1)\n",
    "results = [{'Text': text, 'Predicted_SDGs': ''} for text in texts]\n",
    "predictions_df = pd.DataFrame({'Text': texts})\n",
    "\n",
    "for sdg in true_labels.columns:\n",
    "    if sdg not in sdg_keywords:\n",
    "        print(f\"Warning: {sdg} is not found in sdg_keywords. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    assigned_sdgs_keywords = [assign_single_sdg(text_vector, sdg, threshold) for text_vector in texts_embeddings]\n",
    "    assigned_sdgs, top_keywords_list = zip(*assigned_sdgs_keywords)\n",
    "\n",
    "    for idx, text in enumerate(texts):\n",
    "        if assigned_sdgs[idx] == 1:\n",
    "            results[idx]['Predicted_SDGs'] += sdg + ', '\n",
    "            results[idx][f'Top_Keywords_for_{sdg}'] = ', '.join(top_keywords_list[idx][sdg])\n",
    "\n",
    "    predictions_df[sdg] = assigned_sdgs\n",
    "    print(f\"Finished processing {sdg}.\")\n",
    "\n",
    "# Trim the trailing commas in 'Predicted_SDGs'\n",
    "for row in results:\n",
    "    if row['Predicted_SDGs']:\n",
    "        row['Predicted_SDGs'] = row['Predicted_SDGs'].rstrip(', ')\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.fillna(\"\")\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea184c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "for sdg in true_labels.columns:\n",
    "    if sdg in predictions_df.columns:  # Only compare if the SDG exists in the predictions\n",
    "        print(f\"Classification Report for {sdg}:\")\n",
    "        print(classification_report(true_labels[sdg], predictions_df[sdg]))\n",
    "        print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701a6d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = predictions_df.drop('Text', axis=1)\n",
    "print(classification_report(true_labels, preds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71787a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "results_df.to_csv(f\"Reports/Version4/Results.csv\")\n",
    "\n",
    "preds_df = predictions_df.drop(columns=['Text'])\n",
    "with open(\"Reports/Version4/evaluation_report.txt\", \"w\") as f:\n",
    "    # Write overall classification report for all SDGs\n",
    "    f.write(\"Overall Classification Report:\\n\")\n",
    "    f.write(classification_report(true_labels, preds_df, target_names=true_labels.columns))\n",
    "    f.write(\"------------------------------------------------------\\n\\n\")\n",
    "\n",
    "    # Write classification reports for each individual SDG\n",
    "    for sdg in true_labels.columns:\n",
    "        if sdg in preds_df.columns:  # Only compare if the SDG exists in the predictions\n",
    "            y_true = true_labels[sdg]\n",
    "            y_pred = preds_df[sdg]\n",
    "            f.write(f\"Classification Report for {sdg}:\\n\")\n",
    "            f.write(classification_report(y_true, y_pred) + \"\\n\")\n",
    "            f.write(\"------------------------------------------------------\\n\")\n",
    "\n",
    "    # Write confusion matrices for each SDG\n",
    "    f.write(\"Confusion Matrices:\\n\")\n",
    "    for sdg in true_labels.columns:\n",
    "        if sdg in preds_df.columns:  # Only compare if the SDG exists in the predictions\n",
    "            y_true = true_labels[sdg]\n",
    "            y_pred = preds_df[sdg]\n",
    "            mcm = confusion_matrix(y_true, y_pred)\n",
    "            f.write(f\"Confusion Matrix for {sdg}:\\n\")\n",
    "            f.write(str(mcm) + \"\\n\")\n",
    "            f.write(\"------------------------------------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
