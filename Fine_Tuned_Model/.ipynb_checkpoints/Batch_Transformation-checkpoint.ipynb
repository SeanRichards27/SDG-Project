{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c0b55607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- SPECIFY FILE LOCATIONS HERE -----------------\n",
    "\n",
    "# S3 paths\n",
    "s3_bucket = 'sdg-project'\n",
    "model_name = 'bal_model1'\n",
    "artifact_name = 'pytorch-training-2023-10-26-04-05-28-024'\n",
    "\n",
    "# Model location path\n",
    "s3_model_path = f's3://{s3_bucket}/models/{model_name}/artifacts/{artifact_name}/output/model.tar.gz'\n",
    "\n",
    "# Original test data path\n",
    "#test_data_path = 'data/old_data/test_course.csv'\n",
    "test_data_path = 'data/bal_test.csv'\n",
    "s3_test_data_path = f's3://{s3_bucket}/{test_data_path}'\n",
    "\n",
    "# Transformed (text only) test data path\n",
    "transformed_data_path = 'data/test_split/text_only_test.csv'\n",
    "s3_transformed_data_path = f's3://{s3_bucket}/{transformed_data_path}'\n",
    "\n",
    "# Prediction output path\n",
    "prediction_output_path = f's3://{s3_bucket}/models/{model_name}/predictions/'\n",
    "\n",
    "# Local paths\n",
    "local_tarball_path = 'model.tar.gz'\n",
    "local_test_data_path = 'Split_Data/text_only_test.csv'\n",
    "local_results_path = 'batch_results.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7d2fb405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.18.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (2.31.0)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.18.0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.18.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.18.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.18.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.18.0) (2023.5.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses->transformers==4.18.0) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses->transformers==4.18.0) (8.1.6)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses->transformers==4.18.0) (1.3.1)\n",
      "4.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.18.0\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import torch\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import transformers\n",
    "import tarfile\n",
    "\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = 'sdg-project'\n",
    "\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a111b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sdg-project/models/wed_11_10_model2/artifacts/pytorch-training-2023-10-11-11-52-51-335/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(s3_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0852a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the tarball from S3\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(s3_bucket, s3_model_path.replace(f's3://{s3_bucket}/', ''), local_tarball_path)\n",
    "\n",
    "# Extract the tarball\n",
    "with tarfile.open(local_tarball_path, 'r:gz') as tar:\n",
    "    tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b2f93eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "test_data = pd.read_csv(f's3://{s3_bucket}/{test_data_path}')\n",
    "valid_rows = test_data['Text'].apply(lambda x: isinstance(x, str))\n",
    "test_data = test_data[valid_rows]\n",
    "\n",
    "os.makedirs('Split_Data', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f9a4eed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "755\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5de4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ad10681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check 1: Verify if any row in the 'Text' column contains unexpected double quotes\n",
    "malformed_rows = test_data['Text'].str.count('\"') % 2 != 0\n",
    "if malformed_rows.sum() > 0:\n",
    "    print(f\"Warning: Found {malformed_rows.sum()} rows with unmatched double quotes!\")\n",
    "\n",
    "# Check 2: Verify if any row in the 'Text' column contains newlines \n",
    "newline_rows = test_data['Text'].str.contains('\\n')\n",
    "if newline_rows.sum() > 0:\n",
    "    print(f\"Warning: Found {newline_rows.sum()} rows with newlines!\")\n",
    "\n",
    "# Check 3: Verify if any row in the 'Text' column exceeds a certain length\n",
    "# (Useful check if there's a MaxPayloadInMB constraint as mentioned in your logs)\n",
    "max_length = 5 * 10**6  # e.g., 5MB\n",
    "long_rows = test_data['Text'].str.len() > max_length\n",
    "if long_rows.sum() > 0:\n",
    "    print(f\"Warning: Found {long_rows.sum()} rows exceeding {max_length} characters!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "effb86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle unmatched double quotes\n",
    "# Option 1: Remove rows with unmatched double quotes\n",
    "test_data = test_data[~malformed_rows]\n",
    "\n",
    "\n",
    "# Handle newlines\n",
    "# Replace newlines with spaces\n",
    "test_data['Text'] = test_data['Text'].str.replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b79428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a3cdc0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a version with only the 'Text' column and save it\n",
    "test_data[[\"Text\"]].to_csv(local_test_data_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf3b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d0e6bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the CSV\n",
    "# test_data = pd.read_csv(s3_transformed_data_path)\n",
    "\n",
    "# # Display the first few rows\n",
    "# #print(test_data.head())\n",
    "# with open(local_test_data_path, 'r') as file:\n",
    "#     content = file.read()\n",
    "#     if content.count('\"') % 2 != 0:\n",
    "#         print(\"Mismatched quotes found!\")\n",
    "#     else:\n",
    "#         print(\"Quotes seem to be okay.\")\n",
    "\n",
    "# # Check for empty or NaN rows\n",
    "# empty_rows = test_data[test_data.isnull().any(axis=1)]\n",
    "# if not empty_rows.empty:\n",
    "#     print(\"Found empty or NaN rows:\")\n",
    "#     print(empty_rows)\n",
    "# else:\n",
    "#     print(\"No empty or NaN rows found.\")\n",
    "\n",
    "# # with open(local_test_data_path, 'r') as file:\n",
    "# #     content = file.read()\n",
    "# #     line_endings = set(content.splitlines(True))\n",
    "# #     print(f\"Line endings used: {line_endings}\")\n",
    "\n",
    "# # Check if all rows have the same number of columns\n",
    "# column_counts = test_data.apply(lambda x: x.count(), axis=1)\n",
    "# if len(column_counts.unique()) > 1:\n",
    "#     print(\"Rows with varying number of columns detected!\")\n",
    "# else:\n",
    "#     print(\"All rows have the same number of columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2129778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\r\n",
      "-rw-r--r-- root/root  98841817 2023-10-11 22:47 model.pth\r\n"
     ]
    }
   ],
   "source": [
    "# Upload the text-only data to S3\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.meta.client.upload_file(local_test_data_path, s3_bucket, transformed_data_path)\n",
    "\n",
    "!tar -tzvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "da9d8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model.pth' is in the current directory\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('model.pth')\n",
    "    tar.add('requirements.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ce93be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['model.pth', 'requirements.txt']\n",
      "All necessary files are present in the model.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Extract the tarball to a temp directory\n",
    "temp_dir = 'temp_model_dir'\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "with tarfile.open(local_tarball_path, 'r:gz') as tar:\n",
    "    tar.extractall(path=temp_dir)\n",
    "\n",
    "# List contents of the extracted directory\n",
    "extracted_files = os.listdir(temp_dir)\n",
    "print(\"Extracted files:\", extracted_files)\n",
    "\n",
    "# Define the necessary files that should be present\n",
    "required_files = ['model.pth', 'requirements.txt']\n",
    "\n",
    "# Check if the necessary files are present\n",
    "all_files_present = all(file in extracted_files for file in required_files)\n",
    "\n",
    "if all_files_present:\n",
    "    print(\"All necessary files are present in the model.tar.gz.\")\n",
    "else:\n",
    "    missing_files = [file for file in required_files if file not in extracted_files]\n",
    "    print(f\"Missing files in model.tar.gz: {missing_files}\")\n",
    "    # Raise an error or handle accordingly\n",
    "    raise RuntimeError(f\"model.tar.gz is missing the following files: {missing_files}\")\n",
    "\n",
    "# Optionally, remove the temporary directory after verification\n",
    "import shutil\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6f5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "09bbe687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = 'model.tar.gz' \n",
    "model = PyTorchModel(model_data=model_location, \n",
    "                     role=role,\n",
    "                     framework_version='1.8.0',\n",
    "                     py_version='py3',\n",
    "                     entry_point='train.py',\n",
    "                     sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0a915aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Repacking model artifact (model.tar.gz), script artifact (None), and dependencies ([]) into single tar.gz file located at s3://sagemaker-ap-southeast-2-058391833268/pytorch-inference-2023-10-12-04-56-13-395/model.tar.gz. This may take some time depending on model size...\n",
      "INFO:sagemaker:Creating model with name: pytorch-inference-2023-10-12-04-56-20-275\n"
     ]
    }
   ],
   "source": [
    "transformer = model.transformer(instance_count=1,\n",
    "                                instance_type='ml.m5.xlarge',\n",
    "                                strategy='SingleRecord',\n",
    "                                assemble_with='Line',\n",
    "                                output_path=prediction_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "46e82e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: pytorch-inference-2023-10-12-04-56-21-014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34m2023-10-12 05:01:15,695 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 2998 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:15,728 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,356 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 4987601e1651435ba0251a7cbec44e5d\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,365 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,395 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,588 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,589 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,589 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,591 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,608 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,610 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,612 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]49\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,626 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,626 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,629 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,631 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,631 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,651 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,651 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,656 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,657 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,657 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,657 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,657 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,994 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:32822 \"GET /ping HTTP/1.1\" 200 77\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,997 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,120 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:32830 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,134 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,347 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,348 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.59849548339844|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,349 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.26663589477539|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,351 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,358 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14146.2265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,359 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1256.06640625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,360 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.1|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:19,283 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:19,296 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:19,311 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:19,374 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,918 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,918 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,930 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,942 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,947 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,958 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,969 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,032 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,050 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,930 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,942 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,947 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,958 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,969 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,032 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,050 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[32m2023-10-12T05:01:18.158:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,838 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,846 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,913 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,179 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,185 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,195 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,306 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,838 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,846 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,913 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,179 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,185 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,195 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,306 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,311 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,311 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,319 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,319 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,351 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,353 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,354 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,351 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,353 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,354 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,817 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,827 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,014 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,040 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,044 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,046 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,092 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,094 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,206 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,209 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,211 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,212 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,373 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,817 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,827 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,014 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,040 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,044 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,046 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,092 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,094 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,206 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,209 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,211 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,212 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,373 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,380 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,390 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,380 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,390 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,415 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,448 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,451 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,468 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,525 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,531 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,565 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,569 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,572 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,574 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,576 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,725 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,728 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,788 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,415 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,448 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,451 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,468 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,525 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,531 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,565 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,569 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,572 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,574 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,576 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,725 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,728 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,788 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,792 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,798 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,801 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,804 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:24,240 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,792 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,798 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,801 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,804 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:24,240 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,016 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,024 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,060 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,061 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,066 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,223 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,226 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,346 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,350 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,016 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,024 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,060 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,061 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,066 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,223 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,226 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,346 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,350 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,756 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,760 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,756 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,760 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,494 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,499 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,563 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,567 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,703 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,707 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,716 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,717 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,863 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,866 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,870 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,872 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,899 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,913 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,979 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,984 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,012 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,017 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,034 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,078 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,081 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,089 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,099 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,130 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,133 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,138 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,147 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,177 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,181 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,186 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,194 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,273 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,278 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,346 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,349 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,494 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,499 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,563 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,567 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,703 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,707 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,716 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,717 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,863 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,866 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,870 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,872 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,899 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,913 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,979 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,984 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,012 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,017 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,034 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,078 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,081 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,089 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,099 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,130 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,133 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,138 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,147 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,177 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,181 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,186 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,194 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,273 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,278 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,346 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,349 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,367 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,368 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,370 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,371 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,403 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,405 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,407 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,408 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,409 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,410 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,411 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,367 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,368 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,370 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,371 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,403 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,405 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,407 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,408 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,409 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,410 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,411 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,458 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,459 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,461 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,463 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,468 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,472 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,474 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,494 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,531 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,532 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,534 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,536 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,591 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,650 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,658 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,672 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,677 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,458 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,459 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,461 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,463 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,468 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,472 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,474 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,494 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,531 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,532 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,534 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,536 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,591 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,650 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,658 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,672 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,677 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,680 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,683 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,693 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,697 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,700 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,701 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,708 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,711 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,714 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,732 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,733 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,812 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,814 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,818 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,837 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,838 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,680 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,683 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,693 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,697 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,700 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,701 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,708 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,711 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,714 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,732 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,733 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,812 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,814 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,818 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,837 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,838 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,411 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,415 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,415 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,419 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,411 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,415 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,415 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,419 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,443 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,447 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,447 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,930 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,931 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,932 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,935 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,943 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,950 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,950 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,955 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,335 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,394 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,443 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,447 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,447 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,930 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,931 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,932 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,935 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,943 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,950 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,950 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,955 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,335 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,394 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:01:31,210 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:31,210 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:32,101 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.6/site-packages/transformers/models/splinter/configuration_splinter.py'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:32,101 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.6/site-packages/transformers/models/splinter/configuration_splinter.py'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:33,636 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:33,667 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:33,952 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,093 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,103 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,128 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:33,636 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:33,667 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:33,952 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,093 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,103 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,128 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,132 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,248 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,259 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,132 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,248 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,259 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,675 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,727 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,675 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,727 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,565 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,673 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,698 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,565 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,673 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,698 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,733 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,758 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,772 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,773 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,855 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,858 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,865 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,882 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,910 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,952 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,958 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,053 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,061 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,151 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,154 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,173 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,177 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,733 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,758 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,772 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,773 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,855 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,858 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,865 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,882 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,910 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,952 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,958 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,053 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,061 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,151 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,154 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,173 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,177 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,477 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,503 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,646 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,666 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,742 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,748 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,765 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,767 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,829 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,834 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,840 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,845 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,938 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,941 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,477 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,503 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,646 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,666 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,742 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,748 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,765 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,767 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,829 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,834 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,840 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,845 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,938 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,941 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,123 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,130 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,271 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,275 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,321 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,324 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,334 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,414 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,418 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,123 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,130 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,271 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,275 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,321 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,324 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,334 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,414 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,418 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,051 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,055 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,149 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,172 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,051 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,055 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,149 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,172 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,912 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,156 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,174 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,285 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,289 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,315 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,354 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,381 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,383 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,912 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,156 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,174 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,285 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,289 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,315 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,354 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,381 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,383 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:01:41,193 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,194 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,206 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,232 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,233 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,234 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,301 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,310 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,312 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,326 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,331 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,412 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,429 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,193 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,194 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,206 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,232 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,233 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,234 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,301 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,310 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,312 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,326 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,331 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,412 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,429 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,432 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,432 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,489 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,506 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,606 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,613 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,619 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,622 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,664 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,669 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,746 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,749 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,769 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,772 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,776 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,806 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,824 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,899 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,926 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,944 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,948 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,954 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,957 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,958 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,033 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,036 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,039 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,040 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,489 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,506 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,606 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,613 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,619 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,622 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,664 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,669 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,746 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,749 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,769 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,772 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,776 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,806 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,824 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,899 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,926 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,944 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,948 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,954 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,957 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,958 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,033 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,036 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,039 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,040 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,067 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,071 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,147 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,150 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,181 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,184 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,263 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,266 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,429 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,067 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,071 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,147 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,150 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,181 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,184 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,263 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,266 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,429 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,446 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,484 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,486 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,487 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,512 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,519 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,557 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,560 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,563 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,566 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,446 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,484 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,486 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,487 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,512 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,519 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,557 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,560 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,563 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,566 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,572 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,628 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,630 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,632 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,670 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,699 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,702 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,705 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,706 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,712 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,713 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,725 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,731 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,734 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,800 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,801 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,802 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,805 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,842 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,847 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,853 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,902 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,904 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,917 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,920 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,980 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,270 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,349 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,572 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,628 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,630 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,632 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,670 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,699 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,702 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,705 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,706 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,712 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,713 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,725 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,731 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,734 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,800 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,801 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,802 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,805 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,842 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,847 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,853 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,902 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,904 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,917 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,920 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,980 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,270 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,349 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,350 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,361 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,386 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,387 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,388 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,350 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,361 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,386 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,387 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,388 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,478 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,481 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,552 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,941 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:44,085 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,478 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,481 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,552 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,941 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:44,085 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:44,560 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:44,867 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:44,560 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:44,867 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:45,436 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:45,436 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:46,540 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:46,540 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:46,652 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,137 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,161 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,208 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:46,652 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,137 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,161 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,208 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,478 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,479 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,479 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/847 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,068 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|| 847/847 [00:00<00:00, 582kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,069 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,180 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/140M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,289 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 33.0k/140M [00:00<08:05, 303kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,397 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 113k/140M [00:00<04:20, 563kB/s] \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,478 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,479 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,479 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/847 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,068 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|| 847/847 [00:00<00:00, 582kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,069 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,180 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/140M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,289 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 33.0k/140M [00:00<08:05, 303kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,397 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 113k/140M [00:00<04:20, 563kB/s] \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,498 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 255k/140M [00:00<02:39, 918kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,599 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 506k/140M [00:00<01:35, 1.53MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,700 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 1.00M/140M [00:00<00:51, 2.81MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,799 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|         | 1.93M/140M [00:00<00:28, 5.13MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,901 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|         | 3.77M/140M [00:00<00:14, 9.67MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|         | 6.60M/140M [00:00<00:08, 15.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,102 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   7%|         | 9.42M/140M [00:00<00:06, 20.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,202 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|         | 12.3M/140M [00:01<00:05, 23.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,302 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|         | 15.1M/140M [00:01<00:05, 25.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,404 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|        | 17.9M/140M [00:01<00:04, 26.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,498 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 255k/140M [00:00<02:39, 918kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,599 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 506k/140M [00:00<01:35, 1.53MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,700 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 1.00M/140M [00:00<00:51, 2.81MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,799 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|         | 1.93M/140M [00:00<00:28, 5.13MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,901 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|         | 3.77M/140M [00:00<00:14, 9.67MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|         | 6.60M/140M [00:00<00:08, 15.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,102 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   7%|         | 9.42M/140M [00:00<00:06, 20.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,202 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|         | 12.3M/140M [00:01<00:05, 23.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,302 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|         | 15.1M/140M [00:01<00:05, 25.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,404 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|        | 17.9M/140M [00:01<00:04, 26.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,504 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|        | 20.5M/140M [00:01<00:04, 26.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,604 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|        | 23.3M/140M [00:01<00:04, 27.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,705 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|        | 26.1M/140M [00:01<00:04, 27.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,805 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  21%|        | 28.9M/140M [00:01<00:04, 28.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,905 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  23%|       | 31.7M/140M [00:01<00:03, 28.7MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,005 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|       | 34.5M/140M [00:01<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,106 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|       | 37.3M/140M [00:01<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,206 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|       | 40.1M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,306 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|       | 43.0M/140M [00:02<00:03, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,406 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|      | 45.8M/140M [00:02<00:03, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,504 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|        | 20.5M/140M [00:01<00:04, 26.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,604 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|        | 23.3M/140M [00:01<00:04, 27.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,705 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|        | 26.1M/140M [00:01<00:04, 27.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,805 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  21%|        | 28.9M/140M [00:01<00:04, 28.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,905 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  23%|       | 31.7M/140M [00:01<00:03, 28.7MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,005 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|       | 34.5M/140M [00:01<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,106 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|       | 37.3M/140M [00:01<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,206 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|       | 40.1M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,306 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|       | 43.0M/140M [00:02<00:03, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,406 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|      | 45.8M/140M [00:02<00:03, 29.3MB/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:01:51,511 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|    | 76.8M/140M [00:03<00:02, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,612 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  57%|    | 79.6M/140M [00:03<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,712 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|    | 82.4M/140M [00:03<00:02, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,812 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|    | 85.2M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,913 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|   | 88.0M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,013 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|   | 90.8M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,113 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|   | 93.6M/140M [00:03<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,214 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  69%|   | 96.5M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,314 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|   | 99.3M/140M [00:04<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,415 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|  | 102M/140M [00:04<00:01, 29.4MB/s] \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,511 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|    | 76.8M/140M [00:03<00:02, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,612 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  57%|    | 79.6M/140M [00:03<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,712 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|    | 82.4M/140M [00:03<00:02, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,812 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|    | 85.2M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,913 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|   | 88.0M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,013 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|   | 90.8M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,113 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|   | 93.6M/140M [00:03<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,214 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  69%|   | 96.5M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,314 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|   | 99.3M/140M [00:04<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,415 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|  | 102M/140M [00:04<00:01, 29.4MB/s] \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,515 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|  | 105M/140M [00:04<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,616 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  77%|  | 108M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,716 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|  | 111M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,817 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|  | 113M/140M [00:04<00:00, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,917 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  83%| | 116M/140M [00:04<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,017 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  85%| | 119M/140M [00:04<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,117 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  87%| | 122M/140M [00:04<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,218 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  89%| | 125M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,318 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  91%| | 127M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,419 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  93%|| 130M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,515 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|  | 105M/140M [00:04<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,616 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  77%|  | 108M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,716 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|  | 111M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,817 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|  | 113M/140M [00:04<00:00, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,917 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  83%| | 116M/140M [00:04<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,017 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  85%| | 119M/140M [00:04<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,117 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  87%| | 122M/140M [00:04<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,218 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  89%| | 125M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,318 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  91%| | 127M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,419 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  93%|| 130M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,519 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|| 133M/140M [00:05<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,619 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|| 136M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,519 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|| 133M/140M [00:05<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,619 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|| 136M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,668 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  99%|| 139M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,668 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  99%|| 139M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,283 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,284 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,284 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,286 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,286 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,283 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,284 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,284 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,286 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,286 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,444 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,444 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|| 140M/140M [00:05<00:00, 26.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,066 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.dense.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,066 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,067 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,071 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,071 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|| 140M/140M [00:05<00:00, 26.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,066 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.dense.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,066 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,067 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,071 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,071 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,657 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38914\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,658 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:39282|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,659 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:78|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,829 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39088\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,829 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:39455|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,831 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:76|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39137\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,657 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38914\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,658 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:39282|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,659 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:78|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,829 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39088\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,829 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:39455|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,831 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:76|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39137\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:39506|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:79|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,944 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39217\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,944 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:39568|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,945 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:61|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:57,188 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:57,381 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:57,383 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  88%| | 200k/226k [00:00<00:00, 1.06MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:39506|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:79|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,944 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39217\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,944 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:39568|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,945 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:61|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:57,188 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:57,381 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:57,383 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  88%| | 200k/226k [00:00<00:00, 1.06MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,626 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,626 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1966\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 40161\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1965.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26c4677a-24e0-4ad5-a2e9-aa23ba715705,timestamp:1697086918\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,628 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:38185|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,628 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,626 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,626 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1966\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 40161\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1965.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26c4677a-24e0-4ad5-a2e9-aa23ba715705,timestamp:1697086918\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,628 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:38185|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,628 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e73e9071-5549-4a50-a5b9-23995ed89a0b,timestamp:1697086921\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,796 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,796 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e73e9071-5549-4a50-a5b9-23995ed89a0b,timestamp:1697086921\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,796 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,796 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,155 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ae797469-7be7-4bde-8c80-cdad52d2a7dc,timestamp:1697086923\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,157 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,157 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,155 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ae797469-7be7-4bde-8c80-cdad52d2a7dc,timestamp:1697086923\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,157 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,157 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ad45f378-c13c-4df5-ae3c-7df5472ef98e,timestamp:1697086924\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,387 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ad45f378-c13c-4df5-ae3c-7df5472ef98e,timestamp:1697086924\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,387 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,387 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,387 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30f52137-55b9-4391-b99d-5a6dc978fa2c,timestamp:1697086925\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,655 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,655 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30f52137-55b9-4391-b99d-5a6dc978fa2c,timestamp:1697086925\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,655 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,655 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f544ee5-bd4c-44c0-a4b6-5768a19b67e4,timestamp:1697086926\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f544ee5-bd4c-44c0-a4b6-5768a19b67e4,timestamp:1697086926\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,232 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ffc4f501-d465-47dc-aa81-b64bebf90e05,timestamp:1697086928\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,232 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,232 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ffc4f501-d465-47dc-aa81-b64bebf90e05,timestamp:1697086928\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,232 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,553 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,553 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1313.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d544b1e7-0a03-44e0-a681-02665adc39d2,timestamp:1697086929\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,553 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,553 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1313.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d544b1e7-0a03-44e0-a681-02665adc39d2,timestamp:1697086929\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:02:12,625 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1753.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9cae691c-bb3b-4343-b4e2-87141dc64462,timestamp:1697086932\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,625 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1754\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1756\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,625 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1753.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9cae691c-bb3b-4343-b4e2-87141dc64462,timestamp:1697086932\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,625 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1754\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1756\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:913e15b0-634b-4d94-9fed-9e27cee2c0d8,timestamp:1697086933\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,912 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:913e15b0-634b-4d94-9fed-9e27cee2c0d8,timestamp:1697086933\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,912 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,267 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2cebb42f-dc6a-4a61-8712-62aa724f6fa4,timestamp:1697086935\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,267 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1352\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,267 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2cebb42f-dc6a-4a61-8712-62aa724f6fa4,timestamp:1697086935\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,267 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1352\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3279208c-af19-4018-8bb5-aac511e5dea0,timestamp:1697086936\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3279208c-af19-4018-8bb5-aac511e5dea0,timestamp:1697086936\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1331\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1330.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aee640fd-2324-4eb0-b221-61f171f589f0,timestamp:1697086937\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,873 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,873 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,263 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31464767456055|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.550483703613281|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12950.546875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2451.76953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1331\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1330.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aee640fd-2324-4eb0-b221-61f171f589f0,timestamp:1697086937\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,873 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,873 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,263 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31464767456055|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.550483703613281|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12950.546875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2451.76953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:644c7cc9-0e1b-4c51-8ccc-0d2ea91b2b55,timestamp:1697086939\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,135 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,135 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:644c7cc9-0e1b-4c51-8ccc-0d2ea91b2b55,timestamp:1697086939\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,135 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,135 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1378.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18388e8b-5780-478f-b2e7-dbdc8e0b7e84,timestamp:1697086940\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1378.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18388e8b-5780-478f-b2e7-dbdc8e0b7e84,timestamp:1697086940\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:02:23,195 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1381\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,195 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1384.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8722b274-8552-4ca6-a0c0-e057134578cf,timestamp:1697086943\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1387\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,195 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1381\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,195 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1384.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8722b274-8552-4ca6-a0c0-e057134578cf,timestamp:1697086943\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1387\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:da9cf7a2-b39f-4175-a110-97f0691f3f36,timestamp:1697086944\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,455 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:da9cf7a2-b39f-4175-a110-97f0691f3f36,timestamp:1697086944\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,455 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a0617a94-fb37-452c-82c3-f883c1898b36,timestamp:1697086945\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,729 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a0617a94-fb37-452c-82c3-f883c1898b36,timestamp:1697086945\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,729 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39a62958-875c-4ad2-93ba-973128af4c4f,timestamp:1697086947\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39a62958-875c-4ad2-93ba-973128af4c4f,timestamp:1697086947\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,693 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bb7d2602-6fba-43cb-ab6b-f9fe97043428,timestamp:1697086948\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,693 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1674\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,693 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bb7d2602-6fba-43cb-ab6b-f9fe97043428,timestamp:1697086948\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,693 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1674\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b54d1009-c77a-4e15-9170-469529b7a7c5,timestamp:1697086949\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,964 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,964 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b54d1009-c77a-4e15-9170-469529b7a7c5,timestamp:1697086949\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,964 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,964 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:81b93081-790c-48ff-a0d9-95eec5d35a40,timestamp:1697086951\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,235 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,235 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:81b93081-790c-48ff-a0d9-95eec5d35a40,timestamp:1697086951\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,235 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,235 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd78387c-17aa-4e06-99f0-0fc4a45a764d,timestamp:1697086953\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,858 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,858 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd78387c-17aa-4e06-99f0-0fc4a45a764d,timestamp:1697086953\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,858 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,858 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,211 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1348.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:90c67b42-581c-46dc-8f70-5fbcc7eb5cec,timestamp:1697086955\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,211 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1350\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,211 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1348.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:90c67b42-581c-46dc-8f70-5fbcc7eb5cec,timestamp:1697086955\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,211 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1350\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d3b19eab-990e-4598-b108-78dc35537579,timestamp:1697086956\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,520 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d3b19eab-990e-4598-b108-78dc35537579,timestamp:1697086956\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,520 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2d84932-42d8-4312-b292-874336eaad40,timestamp:1697086957\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2d84932-42d8-4312-b292-874336eaad40,timestamp:1697086957\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1403.68|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8d1a2842-5519-4d80-adf2-ebe3fc98e162,timestamp:1697086959\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1405\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,167 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,167 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,168 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1403.68|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8d1a2842-5519-4d80-adf2-ebe3fc98e162,timestamp:1697086959\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1405\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,167 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,167 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,168 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,423 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7bc43cb2-a01f-40ce-9901-6fb9e7f08554,timestamp:1697086960\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,423 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,423 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7bc43cb2-a01f-40ce-9901-6fb9e7f08554,timestamp:1697086960\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,423 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:97e47df2-0c88-46b2-8680-852646681a27,timestamp:1697086961\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:97e47df2-0c88-46b2-8680-852646681a27,timestamp:1697086961\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:02:43,135 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:43,135 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2191c6fd-d683-46b6-8fb9-e0ad7c9083db,timestamp:1697086963\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,135 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,135 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2191c6fd-d683-46b6-8fb9-e0ad7c9083db,timestamp:1697086963\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,699 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1560\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,699 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1559.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:495dc2a3-bc2b-4868-9960-1e4b0596ece3,timestamp:1697086964\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1561\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,699 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1560\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,699 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1559.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:495dc2a3-bc2b-4868-9960-1e4b0596ece3,timestamp:1697086964\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1561\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1411.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:35f913f9-ab74-48a7-bd92-f2ec85cecad9,timestamp:1697086966\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1413\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,118 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,118 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1411.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:35f913f9-ab74-48a7-bd92-f2ec85cecad9,timestamp:1697086966\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1413\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,118 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,118 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,408 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1aa8a5df-6c22-4223-95d3-fecd11308e08,timestamp:1697086967\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,408 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1aa8a5df-6c22-4223-95d3-fecd11308e08,timestamp:1697086967\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,674 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,674 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7422de9-0dc2-45cc-bdc4-7b69be89ef60,timestamp:1697086968\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,674 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,674 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7422de9-0dc2-45cc-bdc4-7b69be89ef60,timestamp:1697086968\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,958 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,958 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4d3a36c-428c-42d5-932a-0f0eede5b9fd,timestamp:1697086969\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,958 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,958 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4d3a36c-428c-42d5-932a-0f0eede5b9fd,timestamp:1697086969\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,286 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:56391c5a-cd03-4c20-9bf4-465afbf31a9c,timestamp:1697086971\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,286 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,286 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:56391c5a-cd03-4c20-9bf4-465afbf31a9c,timestamp:1697086971\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,286 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5644507-6303-4c66-a82e-91618f182816,timestamp:1697086972\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,551 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5644507-6303-4c66-a82e-91618f182816,timestamp:1697086972\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,551 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:02:55,049 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61f6f3ef-1a0d-4443-b75d-2fbc4abf8bc6,timestamp:1697086975\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,050 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,050 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,051 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,051 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,052 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,049 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61f6f3ef-1a0d-4443-b75d-2fbc4abf8bc6,timestamp:1697086975\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,050 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,050 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,051 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,051 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,052 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4273f14d-9fd6-461a-8fbd-d20ad8dd6498,timestamp:1697086976\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4273f14d-9fd6-461a-8fbd-d20ad8dd6498,timestamp:1697086976\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,612 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20f5e780-017c-40f9-a9fe-af7cc0f7b251,timestamp:1697086977\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,612 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20f5e780-017c-40f9-a9fe-af7cc0f7b251,timestamp:1697086977\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e0515de6-4018-4a74-9681-305fadb3f7f9,timestamp:1697086978\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e0515de6-4018-4a74-9681-305fadb3f7f9,timestamp:1697086978\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aa981c9d-6110-45b4-8e33-0a82bd522c36,timestamp:1697086980\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aa981c9d-6110-45b4-8e33-0a82bd522c36,timestamp:1697086980\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,553 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:37233442-4364-4622-af89-b9404a160222,timestamp:1697086981\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,553 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:37233442-4364-4622-af89-b9404a160222,timestamp:1697086981\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1533\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1532.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46a695c1-5c15-428f-a98e-5236f96e15f7,timestamp:1697086983\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1534\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1533\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1532.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46a695c1-5c15-428f-a98e-5236f96e15f7,timestamp:1697086983\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1534\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:21c97ded-fa82-4f2c-aa31-14016aa370f2,timestamp:1697086985\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,784 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,784 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:21c97ded-fa82-4f2c-aa31-14016aa370f2,timestamp:1697086985\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,784 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,784 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,142 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1354.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:df70ac57-eb77-4ab0-873c-f2d16a0f8d86,timestamp:1697086987\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,142 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1354.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:df70ac57-eb77-4ab0-873c-f2d16a0f8d86,timestamp:1697086987\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ddb2b55b-9efb-431f-9224-ad2f720bc35a,timestamp:1697086988\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1413\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ddb2b55b-9efb-431f-9224-ad2f720bc35a,timestamp:1697086988\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1413\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,834 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,834 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d40483ae-140a-4c43-a53d-6eb0c8565433,timestamp:1697086989\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,834 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,834 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d40483ae-140a-4c43-a53d-6eb0c8565433,timestamp:1697086989\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,291 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1449.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f60d846-4f78-40c4-9440-8460edf856b4,timestamp:1697086991\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1451\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1454\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,291 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1449.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f60d846-4f78-40c4-9440-8460edf856b4,timestamp:1697086991\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1451\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1454\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d7a92730-4cce-40ab-847a-9dc747dabd5a,timestamp:1697086992\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d7a92730-4cce-40ab-847a-9dc747dabd5a,timestamp:1697086992\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c37b31fc-6854-43b5-af3f-f79b0c1e8fba,timestamp:1697086993\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,892 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,892 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c37b31fc-6854-43b5-af3f-f79b0c1e8fba,timestamp:1697086993\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,892 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,892 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:03:16,432 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,432 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64965965-57d6-426a-aa7a-8725d9f76bbd,timestamp:1697086996\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,432 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,432 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64965965-57d6-426a-aa7a-8725d9f76bbd,timestamp:1697086996\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1331\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1330.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:096c75d8-f04b-4d14-83fa-c4070c7bbdee,timestamp:1697086997\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31452941894531|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.550601959228516|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12945.0390625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2457.24609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1331\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1330.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:096c75d8-f04b-4d14-83fa-c4070c7bbdee,timestamp:1697086997\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31452941894531|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.550601959228516|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12945.0390625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2457.24609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:054c7d79-baff-40bc-be5a-e43050e493b0,timestamp:1697086999\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:054c7d79-baff-40bc-be5a-e43050e493b0,timestamp:1697086999\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1839\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1838.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e2884bb7-b27c-4d77-bd17-71d3fe9cfa78,timestamp:1697087000\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1839\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,859 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,859 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1839\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1838.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e2884bb7-b27c-4d77-bd17-71d3fe9cfa78,timestamp:1697087000\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1839\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,859 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,859 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cd8ed9c-88a8-47c2-8df9-0ed4d626fe62,timestamp:1697087002\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cd8ed9c-88a8-47c2-8df9-0ed4d626fe62,timestamp:1697087002\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6cd6aea4-c209-4340-944d-a9689eec0c80,timestamp:1697087003\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6cd6aea4-c209-4340-944d-a9689eec0c80,timestamp:1697087003\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7f4ed6bc-e500-4246-8a92-b2f596be71d9,timestamp:1697087004\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7f4ed6bc-e500-4246-8a92-b2f596be71d9,timestamp:1697087004\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7d651406-6bc3-4419-a86f-b247c8c212c1,timestamp:1697087007\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7d651406-6bc3-4419-a86f-b247c8c212c1,timestamp:1697087007\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,438 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,438 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5534cf7-7c80-4c2b-b528-b0fcb41387ba,timestamp:1697087008\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,438 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,438 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5534cf7-7c80-4c2b-b528-b0fcb41387ba,timestamp:1697087008\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,708 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,708 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb73292a-26c5-4747-ab5a-e6e12358f0e0,timestamp:1697087009\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,708 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,708 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb73292a-26c5-4747-ab5a-e6e12358f0e0,timestamp:1697087009\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1306.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6f77d062-8fc0-4878-b479-8ac291659738,timestamp:1697087011\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1308\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1306.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6f77d062-8fc0-4878-b479-8ac291659738,timestamp:1697087011\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1308\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e08b26f-bd0f-4a47-9993-d5561808622b,timestamp:1697087012\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,283 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,283 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e08b26f-bd0f-4a47-9993-d5561808622b,timestamp:1697087012\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,283 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,283 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,585 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,585 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:275e8993-20a1-494d-b158-7691cafb55f0,timestamp:1697087013\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,585 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,585 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:275e8993-20a1-494d-b158-7691cafb55f0,timestamp:1697087013\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a5fda5a-83fe-4c85-bbc7-6c9a3262a75c,timestamp:1697087014\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a5fda5a-83fe-4c85-bbc7-6c9a3262a75c,timestamp:1697087014\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1296\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1296\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62650408-6939-40d0-b777-7b84b048ce5f,timestamp:1697087017\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62650408-6939-40d0-b777-7b84b048ce5f,timestamp:1697087017\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9ff1e9c4-97e2-4c1c-9b5e-84acabfc8005,timestamp:1697087018\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,758 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,758 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9ff1e9c4-97e2-4c1c-9b5e-84acabfc8005,timestamp:1697087018\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,758 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,758 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,026 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,026 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd3f6996-1866-4bba-b7b7-7f4e6e642a43,timestamp:1697087020\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,026 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,026 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd3f6996-1866-4bba-b7b7-7f4e6e642a43,timestamp:1697087020\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47193dfe-43e7-4ece-b792-f8378322c230,timestamp:1697087021\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47193dfe-43e7-4ece-b792-f8378322c230,timestamp:1697087021\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5ff01e4e-6651-46fc-ae81-32897b00a8af,timestamp:1697087022\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5ff01e4e-6651-46fc-ae81-32897b00a8af,timestamp:1697087022\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,979 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1332\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,979 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1331.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a94162e-283a-4670-a22a-98bd69a8e38d,timestamp:1697087023\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1333\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,979 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1332\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,979 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1331.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a94162e-283a-4670-a22a-98bd69a8e38d,timestamp:1697087023\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1333\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4063fe92-3c1b-4c98-9dbd-0c5262c089dd,timestamp:1697087025\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4063fe92-3c1b-4c98-9dbd-0c5262c089dd,timestamp:1697087025\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:03:46,594 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:46,594 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f4f96354-56b5-4ab3-bfb8-57bb4ed0c235,timestamp:1697087028\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f4f96354-56b5-4ab3-bfb8-57bb4ed0c235,timestamp:1697087028\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f323c021-9369-4051-a274-bfa076a2e032,timestamp:1697087029\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1326\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f323c021-9369-4051-a274-bfa076a2e032,timestamp:1697087029\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1326\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1490\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1489.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d5b11ba-2b59-49ad-851f-95199a9a8721,timestamp:1697087030\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1490\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1489.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d5b11ba-2b59-49ad-851f-95199a9a8721,timestamp:1697087030\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:68fdacb7-f844-48d2-9f66-cb44933fc03d,timestamp:1697087033\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:68fdacb7-f844-48d2-9f66-cb44933fc03d,timestamp:1697087033\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b551ceaf-2782-43ae-9b02-aa06a85a584c,timestamp:1697087034\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b551ceaf-2782-43ae-9b02-aa06a85a584c,timestamp:1697087034\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4583a42e-f81e-4213-916e-902d4f9ebe9d,timestamp:1697087036\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4583a42e-f81e-4213-916e-902d4f9ebe9d,timestamp:1697087036\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52165b5c-a1d7-4afb-bacf-e5b8d25095c0,timestamp:1697087037\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52165b5c-a1d7-4afb-bacf-e5b8d25095c0,timestamp:1697087037\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0379d030-987c-4ced-ad82-259e403c2682,timestamp:1697087038\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0379d030-987c-4ced-ad82-259e403c2682,timestamp:1697087038\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1367.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6ba28b69-109d-4c0e-8e5d-28416493749f,timestamp:1697087039\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1367.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6ba28b69-109d-4c0e-8e5d-28416493749f,timestamp:1697087039\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,254 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,254 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2852d59-d5a0-4f2b-86f2-4ce8b7492a04,timestamp:1697087041\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,254 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,254 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2852d59-d5a0-4f2b-86f2-4ce8b7492a04,timestamp:1697087041\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a28b2492-d1c5-4919-81ff-fbc54efecc25,timestamp:1697087044\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a28b2492-d1c5-4919-81ff-fbc54efecc25,timestamp:1697087044\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1532\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1533\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,584 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,584 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1531.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46bef51e-30e8-43f3-a57a-2507ca50b293,timestamp:1697087045\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1532\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1533\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,584 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,584 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1531.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46bef51e-30e8-43f3-a57a-2507ca50b293,timestamp:1697087045\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b67614ed-77a6-4b57-a4d7-d6d613acd1f4,timestamp:1697087047\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b67614ed-77a6-4b57-a4d7-d6d613acd1f4,timestamp:1697087047\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,580 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1359\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,580 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1358.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:acdcfd57-c095-4d09-8467-3574b80a25a6,timestamp:1697087048\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1360\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,580 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1359\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,580 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1358.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:acdcfd57-c095-4d09-8467-3574b80a25a6,timestamp:1697087048\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1360\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1364\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:222ac353-fd73-4736-995a-d2c249a9b6d7,timestamp:1697087049\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1364\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:222ac353-fd73-4736-995a-d2c249a9b6d7,timestamp:1697087049\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,333 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1382\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1381.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb4ee964-73f2-4910-b3f7-cebae218726b,timestamp:1697087051\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1383\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,333 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1382\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1381.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb4ee964-73f2-4910-b3f7-cebae218726b,timestamp:1697087051\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1383\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c67a8d69-2490-454d-9eb3-f5bb30852629,timestamp:1697087052\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c67a8d69-2490-454d-9eb3-f5bb30852629,timestamp:1697087052\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:04:15,283 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,283 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8b0f8dcb-b156-4ea4-95d4-cc03a85aa844,timestamp:1697087055\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,283 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,283 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8b0f8dcb-b156-4ea4-95d4-cc03a85aa844,timestamp:1697087055\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,941 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,941 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6603f42-7469-475d-b3db-f62232852529,timestamp:1697087056\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1655\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,941 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,941 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6603f42-7469-475d-b3db-f62232852529,timestamp:1697087056\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1655\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bd8210e-08ce-4c08-9ca5-faa4ed2cb31c,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,268 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.314414978027344|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550716400146484|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12939.50390625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2462.78125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bd8210e-08ce-4c08-9ca5-faa4ed2cb31c,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,268 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.314414978027344|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550716400146484|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12939.50390625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2462.78125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:82008115-842b-406b-9985-8e3c93aae241,timestamp:1697087059\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:82008115-842b-406b-9985-8e3c93aae241,timestamp:1697087059\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a0d4327-b248-433a-862f-99791a9a32bc,timestamp:1697087060\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a0d4327-b248-433a-862f-99791a9a32bc,timestamp:1697087060\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aa63eeba-68c0-4a30-b99d-0d15c1ba1387,timestamp:1697087061\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aa63eeba-68c0-4a30-b99d-0d15c1ba1387,timestamp:1697087061\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53b3226b-7300-4899-a8c8-7f6c2bfd7321,timestamp:1697087063\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53b3226b-7300-4899-a8c8-7f6c2bfd7321,timestamp:1697087063\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:51fc7dff-621a-4184-b61c-b4b1a125413c,timestamp:1697087065\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1350\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:51fc7dff-621a-4184-b61c-b4b1a125413c,timestamp:1697087065\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1350\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f08ed7e1-5d5d-4d04-b39a-5acec2a1bbb1,timestamp:1697087067\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,259 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f08ed7e1-5d5d-4d04-b39a-5acec2a1bbb1,timestamp:1697087067\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,259 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c54e56d-ebe0-429e-991d-490f5f34471d,timestamp:1697087068\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c54e56d-ebe0-429e-991d-490f5f34471d,timestamp:1697087068\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1883\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1882.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61c002ec-918c-483d-a6a3-28476f6cbb62,timestamp:1697087070\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1883\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1882.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61c002ec-918c-483d-a6a3-28476f6cbb62,timestamp:1697087070\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1884\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1884\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1572313f-a26b-4e3b-a71f-9c9f9cbaf301,timestamp:1697087071\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1572313f-a26b-4e3b-a71f-9c9f9cbaf301,timestamp:1697087071\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b6142e26-5d25-42de-9db0-102bf7f38869,timestamp:1697087072\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,970 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,970 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b6142e26-5d25-42de-9db0-102bf7f38869,timestamp:1697087072\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,970 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,970 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70585da8-8ca5-4da7-aeaa-fcbb1ce76576,timestamp:1697087074\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70585da8-8ca5-4da7-aeaa-fcbb1ce76576,timestamp:1697087074\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1554\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1553.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4b921df3-1d65-47fc-84df-5cfcab76c734,timestamp:1697087077\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1554\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1554\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1553.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4b921df3-1d65-47fc-84df-5cfcab76c734,timestamp:1697087077\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1554\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,250 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,250 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e5758833-0367-4c05-9c0b-ba70b4d4fc27,timestamp:1697087078\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,250 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,250 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e5758833-0367-4c05-9c0b-ba70b4d4fc27,timestamp:1697087078\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1702\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,957 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1701.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:166652cc-c9ce-47cc-af5b-5a95664559b6,timestamp:1697087079\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1704\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1702\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,957 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1701.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:166652cc-c9ce-47cc-af5b-5a95664559b6,timestamp:1697087079\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1704\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,251 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,251 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e013a874-44d2-4872-99a7-078bcf0601eb,timestamp:1697087081\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,251 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,251 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e013a874-44d2-4872-99a7-078bcf0601eb,timestamp:1697087081\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bac09dcf-3aaa-40d6-86f1-41c7568e8899,timestamp:1697087082\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bac09dcf-3aaa-40d6-86f1-41c7568e8899,timestamp:1697087082\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1295.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2937604f-b57c-48af-b74a-2f52b5577046,timestamp:1697087083\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1295.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2937604f-b57c-48af-b74a-2f52b5577046,timestamp:1697087083\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:438ec5f0-a8ba-42c4-83e8-a3c851fc0481,timestamp:1697087086\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:438ec5f0-a8ba-42c4-83e8-a3c851fc0481,timestamp:1697087086\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c6a5577f-47bf-413e-b68c-9cc4315fda59,timestamp:1697087087\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,713 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,713 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c6a5577f-47bf-413e-b68c-9cc4315fda59,timestamp:1697087087\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,713 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,713 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d53b0d5f-be66-495d-ba18-3c25d475fd5a,timestamp:1697087088\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d53b0d5f-be66-495d-ba18-3c25d475fd5a,timestamp:1697087088\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2aefad8f-10b3-4537-adf6-2f64d7abbdc7,timestamp:1697087090\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2aefad8f-10b3-4537-adf6-2f64d7abbdc7,timestamp:1697087090\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,641 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,641 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1398.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4336cf54-7f68-4ab6-8b53-d9ebd5b1f0c3,timestamp:1697087091\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1400\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,641 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,641 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1398.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4336cf54-7f68-4ab6-8b53-d9ebd5b1f0c3,timestamp:1697087091\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1400\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f85df82-7e9e-46f4-a8ba-45ccbf70805f,timestamp:1697087092\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f85df82-7e9e-46f4-a8ba-45ccbf70805f,timestamp:1697087092\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4c51d6ce-a56c-4a3f-9380-90b152a3506b,timestamp:1697087094\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4c51d6ce-a56c-4a3f-9380-90b152a3506b,timestamp:1697087094\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a829e51a-6a96-412a-af2a-c113a47ea8b3,timestamp:1697087096\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a829e51a-6a96-412a-af2a-c113a47ea8b3,timestamp:1697087096\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ed392e28-c734-480c-a624-8df107c3d004,timestamp:1697087098\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ed392e28-c734-480c-a624-8df107c3d004,timestamp:1697087098\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,659 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1366.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47e2055d-268d-4908-b45b-cc946ca3d028,timestamp:1697087099\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,659 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1366.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47e2055d-268d-4908-b45b-cc946ca3d028,timestamp:1697087099\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d984f20-b6a5-43a7-b8a0-39160a3d985e,timestamp:1697087100\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,989 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,989 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d984f20-b6a5-43a7-b8a0-39160a3d985e,timestamp:1697087100\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,989 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,989 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1455.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c7f2ebf-5ba9-4bf7-a4f3-e10eb8aca55d,timestamp:1697087102\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1455.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c7f2ebf-5ba9-4bf7-a4f3-e10eb8aca55d,timestamp:1697087102\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dfea58df-832a-44d9-8e18-32d2ad33bfc2,timestamp:1697087103\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dfea58df-832a-44d9-8e18-32d2ad33bfc2,timestamp:1697087103\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,989 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,989 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:900d333e-6eb8-4b94-a709-0085eff0b359,timestamp:1697087104\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,989 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,989 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:900d333e-6eb8-4b94-a709-0085eff0b359,timestamp:1697087104\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87e029ae-84f0-4d89-9c47-e517fa8051b4,timestamp:1697087107\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87e029ae-84f0-4d89-9c47-e517fa8051b4,timestamp:1697087107\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7d46a940-dcad-4cd7-b4df-5dfe950bce04,timestamp:1697087108\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7d46a940-dcad-4cd7-b4df-5dfe950bce04,timestamp:1697087108\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bdfd6a8-34ee-4c80-be6c-9432f9cc94a2,timestamp:1697087110\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bdfd6a8-34ee-4c80-be6c-9432f9cc94a2,timestamp:1697087110\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,294 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1225\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,294 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1225.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57624185-c39b-477b-81b8-0e471980eabf,timestamp:1697087111\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,294 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1225\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,294 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1225.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57624185-c39b-477b-81b8-0e471980eabf,timestamp:1697087111\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e9b43e1c-fe27-43e7-a148-dabdfc23a638,timestamp:1697087112\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e9b43e1c-fe27-43e7-a148-dabdfc23a638,timestamp:1697087112\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,841 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,841 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43440891-90d1-479b-ba9a-1cd2b084d265,timestamp:1697087113\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,841 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,841 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43440891-90d1-479b-ba9a-1cd2b084d265,timestamp:1697087113\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,102 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:14cf6c11-07ef-4b10-a503-da5b244afbf9,timestamp:1697087115\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,102 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,102 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:14cf6c11-07ef-4b10-a503-da5b244afbf9,timestamp:1697087115\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,102 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:05:18,011 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,011 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87faff5d-6e13-4cd1-ac7e-6223b8a2c0cf,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31429672241211|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550834655761719|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12933.3203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2468.9609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,011 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,011 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87faff5d-6e13-4cd1-ac7e-6223b8a2c0cf,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31429672241211|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550834655761719|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12933.3203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2468.9609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1291.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6a69a73b-21a9-47a5-a974-71dc7c89506c,timestamp:1697087119\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1291.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6a69a73b-21a9-47a5-a974-71dc7c89506c,timestamp:1697087119\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:09c0d51b-5e7f-4d7e-9316-137ba3b10c09,timestamp:1697087120\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,562 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,562 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:09c0d51b-5e7f-4d7e-9316-137ba3b10c09,timestamp:1697087120\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,562 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,562 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c2a20fb-2685-44ee-94f1-a955ee551abf,timestamp:1697087121\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c2a20fb-2685-44ee-94f1-a955ee551abf,timestamp:1697087121\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1556\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1555.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28b9a7fd-4dc6-4d6c-a41e-4df06aa836a0,timestamp:1697087123\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1556\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1556\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1555.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28b9a7fd-4dc6-4d6c-a41e-4df06aa836a0,timestamp:1697087123\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1556\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b798a1dd-bbab-4a13-90d5-4fbcf72f6ecb,timestamp:1697087124\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b798a1dd-bbab-4a13-90d5-4fbcf72f6ecb,timestamp:1697087124\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cd800461-d590-4aef-887b-d518d2be89f9,timestamp:1697087127\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cd800461-d590-4aef-887b-d518d2be89f9,timestamp:1697087127\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,632 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:df5ffa4b-3c99-4cff-928d-63727175335a,timestamp:1697087128\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,632 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:df5ffa4b-3c99-4cff-928d-63727175335a,timestamp:1697087128\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:74970a5a-0c86-445b-80e5-e900a4578d77,timestamp:1697087129\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:74970a5a-0c86-445b-80e5-e900a4578d77,timestamp:1697087129\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3823aebf-d2c3-4fc9-a89b-21937027c152,timestamp:1697087131\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3823aebf-d2c3-4fc9-a89b-21937027c152,timestamp:1697087131\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,414 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,414 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0dda7e6e-60eb-43bf-99b8-51135d21d184,timestamp:1697087132\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,414 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,414 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0dda7e6e-60eb-43bf-99b8-51135d21d184,timestamp:1697087132\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:253fd98d-cfda-4eca-81cf-a0e1871aee16,timestamp:1697087133\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:253fd98d-cfda-4eca-81cf-a0e1871aee16,timestamp:1697087133\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2475439d-d634-435d-bdcf-f528da7c01ab,timestamp:1697087134\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2475439d-d634-435d-bdcf-f528da7c01ab,timestamp:1697087134\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1491\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1490.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cc7ead65-b80c-447f-97bf-62888e06478a,timestamp:1697087137\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1491\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1490.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cc7ead65-b80c-447f-97bf-62888e06478a,timestamp:1697087137\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7c7ba74a-f85e-4adb-9fc7-675c72da57df,timestamp:1697087138\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7c7ba74a-f85e-4adb-9fc7-675c72da57df,timestamp:1697087138\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,219 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,219 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4ac54527-52c8-465a-b5c3-afa4369976df,timestamp:1697087140\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,219 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,219 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4ac54527-52c8-465a-b5c3-afa4369976df,timestamp:1697087140\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,491 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:03130877-ce75-4c8e-9d88-fea2fee25477,timestamp:1697087141\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,491 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:03130877-ce75-4c8e-9d88-fea2fee25477,timestamp:1697087141\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3cff1729-43ee-4aba-a346-e994f4c88c17,timestamp:1697087142\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,745 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,745 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3cff1729-43ee-4aba-a346-e994f4c88c17,timestamp:1697087142\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,745 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,745 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:74590c9c-9ab1-4e47-a458-d0d37f818eee,timestamp:1697087144\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:74590c9c-9ab1-4e47-a458-d0d37f818eee,timestamp:1697087144\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,266 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,266 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20c6a6ea-851a-4cd6-b837-e2e8d251d9b6,timestamp:1697087145\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,266 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,266 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20c6a6ea-851a-4cd6-b837-e2e8d251d9b6,timestamp:1697087145\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:410610d6-b21d-464d-b293-753cae73400c,timestamp:1697087147\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,884 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,884 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:410610d6-b21d-464d-b293-753cae73400c,timestamp:1697087147\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,884 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,884 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,293 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1406\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,293 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1406\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,293 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1405.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c43492d9-7e94-4218-a9a3-79776b909d1d,timestamp:1697087149\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1407\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,293 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1405.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c43492d9-7e94-4218-a9a3-79776b909d1d,timestamp:1697087149\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1407\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cbdf4d8b-4178-4681-af9c-4add0406478d,timestamp:1697087150\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cbdf4d8b-4178-4681-af9c-4add0406478d,timestamp:1697087150\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,820 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,820 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3b6796d3-9771-4c38-a49b-2f52388376a0,timestamp:1697087151\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,820 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,820 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3b6796d3-9771-4c38-a49b-2f52388376a0,timestamp:1697087151\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1595\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1594.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c557033e-2c9f-47c1-9934-48120d0ad935,timestamp:1697087153\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1595\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1595\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1594.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c557033e-2c9f-47c1-9934-48120d0ad935,timestamp:1697087153\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1595\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e6cbd23-38c7-4ff6-801e-b10d56ac5ac0,timestamp:1697087154\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e6cbd23-38c7-4ff6-801e-b10d56ac5ac0,timestamp:1697087154\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,010 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,010 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7ef5994-9d17-4872-9124-6e9d0200980f,timestamp:1697087156\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,010 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,010 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7ef5994-9d17-4872-9124-6e9d0200980f,timestamp:1697087156\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:05:58,667 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,667 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,667 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:638e316d-39f8-41f8-8deb-ef8aa51e3cf7,timestamp:1697087158\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,667 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:638e316d-39f8-41f8-8deb-ef8aa51e3cf7,timestamp:1697087158\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1689\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1688.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:60ee5dbf-2ada-444d-bc20-992e73662386,timestamp:1697087160\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,361 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1689\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1688.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:60ee5dbf-2ada-444d-bc20-992e73662386,timestamp:1697087160\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,361 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1492\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1492\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1491.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e2fcfe2-4a65-4880-b099-cf752bee4ba2,timestamp:1697087161\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1492\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,857 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,857 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1491.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e2fcfe2-4a65-4880-b099-cf752bee4ba2,timestamp:1697087161\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1492\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,857 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,857 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d9526c4-46a4-4717-881f-7af95fb8e454,timestamp:1697087163\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d9526c4-46a4-4717-881f-7af95fb8e454,timestamp:1697087163\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,371 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,371 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:67c64a75-fda2-4d4a-a63c-c98df908fe15,timestamp:1697087164\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,371 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,371 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:67c64a75-fda2-4d4a-a63c-c98df908fe15,timestamp:1697087164\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1688\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1688\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1687.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e58be36a-cddf-4be2-8812-d755bea14957,timestamp:1697087166\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1688\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1688\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1687.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e58be36a-cddf-4be2-8812-d755bea14957,timestamp:1697087166\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1544\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1543.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0fdd6575-8b64-41d3-9f7c-b55c2886dd16,timestamp:1697087168\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1545\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1544\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1543.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0fdd6575-8b64-41d3-9f7c-b55c2886dd16,timestamp:1697087168\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1545\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,170 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,170 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:521ae18f-c2ec-470a-ba4a-cf4655b4357a,timestamp:1697087170\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,170 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,170 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:521ae18f-c2ec-470a-ba4a-cf4655b4357a,timestamp:1697087170\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1235.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:15b488d6-e113-4358-a397-abd96fdb1a1f,timestamp:1697087171\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,413 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1235.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:15b488d6-e113-4358-a397-abd96fdb1a1f,timestamp:1697087171\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,413 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d08a14c-41bf-4bc3-b5b1-6a2cf56995fd,timestamp:1697087172\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d08a14c-41bf-4bc3-b5b1-6a2cf56995fd,timestamp:1697087172\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bfb9fc63-4733-4ab7-8f85-1580df0c187e,timestamp:1697087173\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bfb9fc63-4733-4ab7-8f85-1580df0c187e,timestamp:1697087173\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1722\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1721.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b7990fa9-8e00-4ef9-97ba-d9f13c628c59,timestamp:1697087175\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1722\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1722\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1721.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b7990fa9-8e00-4ef9-97ba-d9f13c628c59,timestamp:1697087175\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1722\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d10ff9a-7383-43a4-9a30-e59b5828a240,timestamp:1697087176\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d10ff9a-7383-43a4-9a30-e59b5828a240,timestamp:1697087176\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:06:18,336 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1472\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1472.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:de470ec2-5201-4855-92aa-05050dad5d15,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1474\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,336 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1472\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1472.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:de470ec2-5201-4855-92aa-05050dad5d15,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1474\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1339.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3a101d29-f35e-4986-b444-7183b7d90955,timestamp:1697087179\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1339.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3a101d29-f35e-4986-b444-7183b7d90955,timestamp:1697087179\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,040 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,040 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cfa154b6-0b31-4eda-95aa-409933842c26,timestamp:1697087181\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,040 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,040 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cfa154b6-0b31-4eda-95aa-409933842c26,timestamp:1697087181\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,324 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,324 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:09db7ba1-2c91-4165-a547-a5b5ad2df6a3,timestamp:1697087182\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,324 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,324 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:09db7ba1-2c91-4165-a547-a5b5ad2df6a3,timestamp:1697087182\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1315.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2978f03c-88fc-4109-b8df-980dfcfe0356,timestamp:1697087183\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1317\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1315.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2978f03c-88fc-4109-b8df-980dfcfe0356,timestamp:1697087183\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1317\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,897 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,897 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93f12080-7898-4226-a7c1-d7d5c04574e1,timestamp:1697087184\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,897 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,897 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93f12080-7898-4226-a7c1-d7d5c04574e1,timestamp:1697087184\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1355.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0afa216b-c1fa-4282-8d1c-26b2bea26b2d,timestamp:1697087186\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1355.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0afa216b-c1fa-4282-8d1c-26b2bea26b2d,timestamp:1697087186\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ff400802-1ca5-43d7-85df-a53e52d70574,timestamp:1697087187\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1417\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ff400802-1ca5-43d7-85df-a53e52d70574,timestamp:1697087187\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1417\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:354aa161-1cc9-41ef-ab45-12d6ec3fdbde,timestamp:1697087190\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:354aa161-1cc9-41ef-ab45-12d6ec3fdbde,timestamp:1697087190\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:71237a83-22c4-4b13-9c1c-65a243676544,timestamp:1697087191\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:71237a83-22c4-4b13-9c1c-65a243676544,timestamp:1697087191\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:839a07fe-0e2e-4fb5-9f01-b848cdea3973,timestamp:1697087192\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:839a07fe-0e2e-4fb5-9f01-b848cdea3973,timestamp:1697087192\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1333\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1332.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f71760ce-f17a-44bd-a1c8-11d795f1f1aa,timestamp:1697087194\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1333\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1333\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1332.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f71760ce-f17a-44bd-a1c8-11d795f1f1aa,timestamp:1697087194\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1333\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,399 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,399 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0174f78f-afa3-481f-8485-f84051362252,timestamp:1697087195\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,399 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,399 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0174f78f-afa3-481f-8485-f84051362252,timestamp:1697087195\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:42762327-9fa4-46a8-a162-c7e897db8aa3,timestamp:1697087196\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:42762327-9fa4-46a8-a162-c7e897db8aa3,timestamp:1697087196\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,919 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,919 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b9c66d45-4d32-4cd4-8279-5389340f51c0,timestamp:1697087197\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,919 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,919 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b9c66d45-4d32-4cd4-8279-5389340f51c0,timestamp:1697087197\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f1691b65-0f5c-460b-ba94-0598c1b4dac0,timestamp:1697087200\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f1691b65-0f5c-460b-ba94-0598c1b4dac0,timestamp:1697087200\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75ef51df-dcf0-43d1-a4db-0406b97b5d71,timestamp:1697087201\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,735 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,735 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75ef51df-dcf0-43d1-a4db-0406b97b5d71,timestamp:1697087201\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,735 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,735 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bbfd606d-07ea-42b1-8fd0-dec674ced1c1,timestamp:1697087203\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bbfd606d-07ea-42b1-8fd0-dec674ced1c1,timestamp:1697087203\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,347 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,347 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:688fb309-8023-45d1-9cda-4e19c63b884b,timestamp:1697087204\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,347 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,347 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:688fb309-8023-45d1-9cda-4e19c63b884b,timestamp:1697087204\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1668\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1667.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0fb00b2a-d28c-4504-b176-5bb0b2d8c764,timestamp:1697087206\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1668\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1667.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0fb00b2a-d28c-4504-b176-5bb0b2d8c764,timestamp:1697087206\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d6fd5bc-4ba6-4731-8999-9ac1b5f3c28e,timestamp:1697087207\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d6fd5bc-4ba6-4731-8999-9ac1b5f3c28e,timestamp:1697087207\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:00f7e34c-7e8e-4b52-bf1b-bcadea22d9ed,timestamp:1697087208\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,509 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:00f7e34c-7e8e-4b52-bf1b-bcadea22d9ed,timestamp:1697087208\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,509 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07eabef8-a1bc-46be-a3be-ae380bd6c00b,timestamp:1697087211\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,044 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07eabef8-a1bc-46be-a3be-ae380bd6c00b,timestamp:1697087211\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,044 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:178b172d-0cb3-4e04-af1f-acbffee422e4,timestamp:1697087212\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:178b172d-0cb3-4e04-af1f-acbffee422e4,timestamp:1697087212\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:84dc5e04-0d2f-42f4-a42e-d622d88df9c5,timestamp:1697087213\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:84dc5e04-0d2f-42f4-a42e-d622d88df9c5,timestamp:1697087213\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,429 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1712\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,429 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1712.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93f29ca5-1d45-4f51-be09-b851f71fc9e0,timestamp:1697087215\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1714\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,429 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1712\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,429 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1712.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93f29ca5-1d45-4f51-be09-b851f71fc9e0,timestamp:1697087215\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1714\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e3960bf9-62b0-4cf0-9424-f805d3f91442,timestamp:1697087216\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e3960bf9-62b0-4cf0-9424-f805d3f91442,timestamp:1697087216\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,985 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,985 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f476336b-1b88-43f2-b91d-1f0f81be152f,timestamp:1697087217\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,985 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,985 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f476336b-1b88-43f2-b91d-1f0f81be152f,timestamp:1697087217\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1389\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1388.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:82a22dd8-0a5a-41b6-bf67-950a3930eb34,timestamp:1697087219\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,379 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,379 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1389\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1388.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:82a22dd8-0a5a-41b6-bf67-950a3930eb34,timestamp:1697087219\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,379 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,379 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fa6a105a-ca68-4471-ae36-52f25288b937,timestamp:1697087221\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,947 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fa6a105a-ca68-4471-ae36-52f25288b937,timestamp:1697087221\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,947 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,407 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1459\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1457.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08a5dabb-257a-4ef9-b22e-fe8ec93584f5,timestamp:1697087223\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,407 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1459\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1457.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08a5dabb-257a-4ef9-b22e-fe8ec93584f5,timestamp:1697087223\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,649 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,649 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64eaf6c1-6d4f-40fa-b3eb-67c0bf59d129,timestamp:1697087224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,649 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,649 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64eaf6c1-6d4f-40fa-b3eb-67c0bf59d129,timestamp:1697087224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ee23da9a-c2ef-44a3-a99b-ec171ab5dd78,timestamp:1697087225\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ee23da9a-c2ef-44a3-a99b-ec171ab5dd78,timestamp:1697087225\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:343ff877-e7c1-45dd-bd3f-6e65188e1d8c,timestamp:1697087227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,293 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,293 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,294 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:343ff877-e7c1-45dd-bd3f-6e65188e1d8c,timestamp:1697087227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,293 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,293 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,294 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:449f37d7-62db-4847-bc15-9da5fc278fbc,timestamp:1697087228\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,596 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,596 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:449f37d7-62db-4847-bc15-9da5fc278fbc,timestamp:1697087228\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,596 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,596 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1434\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1433.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:515a45f9-f5ca-40ca-80ba-66c5e79ad74c,timestamp:1697087230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1435\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1434\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1433.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:515a45f9-f5ca-40ca-80ba-66c5e79ad74c,timestamp:1697087230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1435\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.92|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc19cba5-1199-48b3-bc96-db1220c188a0,timestamp:1697087232\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.92|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc19cba5-1199-48b3-bc96-db1220c188a0,timestamp:1697087232\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d986546-a74a-421e-93d6-641075a90807,timestamp:1697087233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d986546-a74a-421e-93d6-641075a90807,timestamp:1697087233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2043\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2042.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e0065064-0cd2-483c-a6c7-b62adf726f5d,timestamp:1697087235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2043\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,886 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,886 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2043\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2042.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e0065064-0cd2-483c-a6c7-b62adf726f5d,timestamp:1697087235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2043\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,886 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,886 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dad09e10-b2e6-42a4-8918-9ef18c7b50d0,timestamp:1697087237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dad09e10-b2e6-42a4-8918-9ef18c7b50d0,timestamp:1697087237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31406784057617|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551063537597656|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12931.58203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2470.734375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,381 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,381 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f5a37d20-730b-4365-90df-c5a9cc5f4eef,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31406784057617|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551063537597656|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12931.58203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2470.734375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,381 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,381 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f5a37d20-730b-4365-90df-c5a9cc5f4eef,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,637 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ad5723cb-1336-4b5a-8583-4540f53cf6a4,timestamp:1697087239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,637 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ad5723cb-1336-4b5a-8583-4540f53cf6a4,timestamp:1697087239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:07:22,392 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1459\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,392 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1458.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7cea0a04-a762-4d8e-9432-0413ebe54f7a,timestamp:1697087242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1460\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,392 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1459\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,392 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1458.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7cea0a04-a762-4d8e-9432-0413ebe54f7a,timestamp:1697087242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1460\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,672 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:634fb889-2308-4c6d-aa91-df3675dcbb50,timestamp:1697087243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,672 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:634fb889-2308-4c6d-aa91-df3675dcbb50,timestamp:1697087243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,094 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,094 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:88962e73-4677-4065-9e07-b9712f9ca1ec,timestamp:1697087245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1420\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,094 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,094 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:88962e73-4677-4065-9e07-b9712f9ca1ec,timestamp:1697087245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1420\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f6dfee2b-9a0f-4224-a487-e06c3dc2a4b1,timestamp:1697087246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,333 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,333 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f6dfee2b-9a0f-4224-a487-e06c3dc2a4b1,timestamp:1697087246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,333 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,333 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,593 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a42e0a9-e7a3-443f-b10d-171b6ae5c300,timestamp:1697087247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,593 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a42e0a9-e7a3-443f-b10d-171b6ae5c300,timestamp:1697087247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,874 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,874 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,874 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1e3b53d-32dc-41fd-b9c2-57396b00432c,timestamp:1697087248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,874 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1e3b53d-32dc-41fd-b9c2-57396b00432c,timestamp:1697087248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,151 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,151 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.93|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a20676c6-5e93-49a5-b20f-73d122368c5d,timestamp:1697087250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,151 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,151 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.93|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a20676c6-5e93-49a5-b20f-73d122368c5d,timestamp:1697087250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1233.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e04cbb22-1161-476a-80ef-2ef1064550e2,timestamp:1697087252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,929 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,929 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1233.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e04cbb22-1161-476a-80ef-2ef1064550e2,timestamp:1697087252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,929 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,929 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,276 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7109970b-98de-4a66-835c-902df819af07,timestamp:1697087254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,276 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1345\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,276 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7109970b-98de-4a66-835c-902df819af07,timestamp:1697087254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,276 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1345\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,561 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,561 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3e215b4a-ccfa-4546-a76f-c57e04f12c6a,timestamp:1697087255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,561 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,561 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3e215b4a-ccfa-4546-a76f-c57e04f12c6a,timestamp:1697087255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,901 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,901 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a8acd67-013e-4a0b-894d-7cb300c50e3f,timestamp:1697087256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,901 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,901 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a8acd67-013e-4a0b-894d-7cb300c50e3f,timestamp:1697087256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6c6025ee-6c44-4768-a3c9-99011d85e512,timestamp:1697087258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6c6025ee-6c44-4768-a3c9-99011d85e512,timestamp:1697087258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:442c184a-24a6-4d9b-8fb6-8006697c7057,timestamp:1697087259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,399 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,399 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:442c184a-24a6-4d9b-8fb6-8006697c7057,timestamp:1697087259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,399 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,399 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1474\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1473.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7cb7070a-d7ae-424f-bdaa-640d3fb9adf3,timestamp:1697087260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1474\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1473.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7cb7070a-d7ae-424f-bdaa-640d3fb9adf3,timestamp:1697087260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1475\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1475\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93b7e76b-7af2-49d5-bc00-65ac9f67d89a,timestamp:1697087263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93b7e76b-7af2-49d5-bc00-65ac9f67d89a,timestamp:1697087263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,676 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,676 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0b5b0b23-242d-4216-9214-beae053bcbd5,timestamp:1697087264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,676 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,676 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0b5b0b23-242d-4216-9214-beae053bcbd5,timestamp:1697087264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26052aee-d3a1-47f5-976b-360182caa8c3,timestamp:1697087265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26052aee-d3a1-47f5-976b-360182caa8c3,timestamp:1697087265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e8887b76-f2d4-4162-870f-88a975e8a876,timestamp:1697087267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e8887b76-f2d4-4162-870f-88a975e8a876,timestamp:1697087267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,432 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,432 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,432 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8d4431cb-0b42-43d6-86e6-2813cf935aea,timestamp:1697087268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,432 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8d4431cb-0b42-43d6-86e6-2813cf935aea,timestamp:1697087268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f994e493-563c-48b7-8c2b-4f4535b07186,timestamp:1697087269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,705 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f994e493-563c-48b7-8c2b-4f4535b07186,timestamp:1697087269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,705 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,960 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cbcb5351-4384-431c-8927-ff596f3612d0,timestamp:1697087270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,960 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cbcb5351-4384-431c-8927-ff596f3612d0,timestamp:1697087270\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93686a62-0b3d-4d8a-8709-d16a71c7ff50,timestamp:1697087274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93686a62-0b3d-4d8a-8709-d16a71c7ff50,timestamp:1697087274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:40dd77d9-4414-48d5-a521-5b6cc8a9505c,timestamp:1697087275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:40dd77d9-4414-48d5-a521-5b6cc8a9505c,timestamp:1697087275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c9d020d1-2472-443a-a1de-2e7434692c62,timestamp:1697087276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c9d020d1-2472-443a-a1de-2e7434692c62,timestamp:1697087276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5722f51b-bba8-4b9f-8092-90ab18f4829b,timestamp:1697087277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5722f51b-bba8-4b9f-8092-90ab18f4829b,timestamp:1697087277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:817eb125-6a37-4cd2-b909-eb8d17bc271b,timestamp:1697087279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:817eb125-6a37-4cd2-b909-eb8d17bc271b,timestamp:1697087279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1455.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b5591821-63d3-480a-812a-f1e882eb86f7,timestamp:1697087280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,594 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,594 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1455.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b5591821-63d3-480a-812a-f1e882eb86f7,timestamp:1697087280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,594 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,594 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,895 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,895 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a85f6e2-5ec6-42be-8e29-fa417fd496c7,timestamp:1697087281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,895 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,895 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a85f6e2-5ec6-42be-8e29-fa417fd496c7,timestamp:1697087281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1cabbc9f-d1e0-4037-9aad-5cb450734d08,timestamp:1697087284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1cabbc9f-d1e0-4037-9aad-5cb450734d08,timestamp:1697087284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,867 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,867 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6afc1a7b-5658-41c7-acae-87ff0c32eda1,timestamp:1697087286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6afc1a7b-5658-41c7-acae-87ff0c32eda1,timestamp:1697087286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7341257a-ea9d-4959-94b0-33ba3ec0709f,timestamp:1697087287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7341257a-ea9d-4959-94b0-33ba3ec0709f,timestamp:1697087287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,791 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1409\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,791 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32db5faf-0bfe-4c51-b38d-edbd63bb25c9,timestamp:1697087288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,791 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1409\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,791 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32db5faf-0bfe-4c51-b38d-edbd63bb25c9,timestamp:1697087288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,086 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6a7b13c-7d47-4472-b407-f56e6a400f75,timestamp:1697087290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,086 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6a7b13c-7d47-4472-b407-f56e6a400f75,timestamp:1697087290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,400 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1310\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,400 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1309.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53dd47f4-06a8-45b7-aa97-f4319474ba67,timestamp:1697087291\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,400 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1310\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,400 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1309.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53dd47f4-06a8-45b7-aa97-f4319474ba67,timestamp:1697087291\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1335.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2adb63c-ca04-4177-a472-f951f8425e66,timestamp:1697087292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1335.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2adb63c-ca04-4177-a472-f951f8425e66,timestamp:1697087292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:48008942-4adc-45a6-81be-ae04e6b1b587,timestamp:1697087295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,227 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:48008942-4adc-45a6-81be-ae04e6b1b587,timestamp:1697087295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,227 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2fb90fa-49ab-40ee-948e-f71c35cad704,timestamp:1697087296\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2fb90fa-49ab-40ee-948e-f71c35cad704,timestamp:1697087296\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b83580b5-c49e-47b0-903e-83be945bafe6,timestamp:1697087297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3139533996582|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551177978515625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12929.9921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2472.328125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b83580b5-c49e-47b0-903e-83be945bafe6,timestamp:1697087297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3139533996582|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551177978515625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12929.9921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2472.328125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f8df68b-f3df-4eb1-8658-51827200f89b,timestamp:1697087299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f8df68b-f3df-4eb1-8658-51827200f89b,timestamp:1697087299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1422\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1422\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1421.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d2382a2-d4d8-4798-b67e-7c4b6d027182,timestamp:1697087300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1423\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1421.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d2382a2-d4d8-4798-b67e-7c4b6d027182,timestamp:1697087300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1423\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5da786ea-6b91-4042-a7d6-760aa689fa7a,timestamp:1697087301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,834 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5da786ea-6b91-4042-a7d6-760aa689fa7a,timestamp:1697087301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,834 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,117 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:97279f2a-a4d2-4eec-89a2-028ca9b2edfd,timestamp:1697087303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,117 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:97279f2a-a4d2-4eec-89a2-028ca9b2edfd,timestamp:1697087303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:08:24,369 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:24,369 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:24,369 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:24,369 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:802d1412-dead-4f26-9902-6dca7c200e74,timestamp:1697087305\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,711 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,711 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:802d1412-dead-4f26-9902-6dca7c200e74,timestamp:1697087305\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,711 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,711 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1235.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28c835a5-0178-4d47-b997-613e8ef16a7f,timestamp:1697087306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1235.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28c835a5-0178-4d47-b997-613e8ef16a7f,timestamp:1697087306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6a7ca1d2-5c19-4b91-9cae-42097238cbfb,timestamp:1697087308\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,199 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,199 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6a7ca1d2-5c19-4b91-9cae-42097238cbfb,timestamp:1697087308\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,199 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,199 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ce5fdc2-c2a6-4b8f-8149-e6f12b7a0811,timestamp:1697087309\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ce5fdc2-c2a6-4b8f-8149-e6f12b7a0811,timestamp:1697087309\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,785 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,785 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:488392e1-1fca-457f-a666-7f1f22ef43f5,timestamp:1697087310\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,785 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,785 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:488392e1-1fca-457f-a666-7f1f22ef43f5,timestamp:1697087310\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5cab178-b4fc-41c9-ac32-52c5e39d2ddc,timestamp:1697087312\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5cab178-b4fc-41c9-ac32-52c5e39d2ddc,timestamp:1697087312\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1449\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1448.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:58ae2225-3fb9-46a4-a7e9-81e883689601,timestamp:1697087313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1449\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1449\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1448.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:58ae2225-3fb9-46a4-a7e9-81e883689601,timestamp:1697087313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1449\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1400\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1399.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:323f6e00-3f60-4742-8ff5-239e0b1d4972,timestamp:1697087316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1400\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1399.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:323f6e00-3f60-4742-8ff5-239e0b1d4972,timestamp:1697087316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1315.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a2f647e6-a285-4d0a-aacf-8d8c6e4ad1f8,timestamp:1697087317\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1315.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a2f647e6-a285-4d0a-aacf-8d8c6e4ad1f8,timestamp:1697087317\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6beccbe2-ee71-4156-8d70-541c85e7989c,timestamp:1697087318\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6beccbe2-ee71-4156-8d70-541c85e7989c,timestamp:1697087318\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,288 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1522\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,288 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1523.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1d6bd24-6b92-45c7-ba3f-7033af618574,timestamp:1697087320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1525\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,288 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1522\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,288 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1523.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1d6bd24-6b92-45c7-ba3f-7033af618574,timestamp:1697087320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1525\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb352df2-8574-4167-9141-1212baa7aac6,timestamp:1697087321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb352df2-8574-4167-9141-1212baa7aac6,timestamp:1697087321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f31629cd-94a1-4890-90a5-136b454f28c8,timestamp:1697087322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f31629cd-94a1-4890-90a5-136b454f28c8,timestamp:1697087322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,789 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,789 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1468.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:24aa4331-ad9f-498f-97ac-0303fdb019b2,timestamp:1697087324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,261 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,261 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1468.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:24aa4331-ad9f-498f-97ac-0303fdb019b2,timestamp:1697087324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,261 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,261 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:08:46,767 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,767 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32f59871-c31e-4c63-8aa8-29f41b05d2ac,timestamp:1697087326\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,767 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,767 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32f59871-c31e-4c63-8aa8-29f41b05d2ac,timestamp:1697087326\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,004 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,004 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,004 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1233.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d815ec8a-7ea8-4432-a0ba-950d6574c462,timestamp:1697087328\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,004 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1233.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d815ec8a-7ea8-4432-a0ba-950d6574c462,timestamp:1697087328\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bbb8371-7d59-4122-94d2-58922d480b6a,timestamp:1697087329\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,328 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bbb8371-7d59-4122-94d2-58922d480b6a,timestamp:1697087329\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,328 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1485.89|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c9eeba9e-4612-4331-a55f-b4560b455fce,timestamp:1697087332\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1487\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1487\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1485.89|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c9eeba9e-4612-4331-a55f-b4560b455fce,timestamp:1697087332\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1487\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1487\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1695.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39c5eecf-959a-42a9-a882-68d2f28075b1,timestamp:1697087333\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1697\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1695.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39c5eecf-959a-42a9-a882-68d2f28075b1,timestamp:1697087333\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1697\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5922b882-8535-4490-abfd-1d66444a6db5,timestamp:1697087335\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5922b882-8535-4490-abfd-1d66444a6db5,timestamp:1697087335\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d25fb1c-2600-4c8f-96ff-cf109a3895c0,timestamp:1697087336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d25fb1c-2600-4c8f-96ff-cf109a3895c0,timestamp:1697087336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1677.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:78cb888c-dd14-4f5f-8dc2-e379a03986c4,timestamp:1697087338\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1677.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:78cb888c-dd14-4f5f-8dc2-e379a03986c4,timestamp:1697087338\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:752c473c-b549-4167-b987-9f2f4bc277e3,timestamp:1697087339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,393 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,393 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:752c473c-b549-4167-b987-9f2f4bc277e3,timestamp:1697087339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,393 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,393 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1403\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1402.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a110f89-8613-4fa7-9be6-2ece2aa820a1,timestamp:1697087342\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1403\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1403\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1402.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a110f89-8613-4fa7-9be6-2ece2aa820a1,timestamp:1697087342\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1403\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:660753bd-f707-4090-ab99-e44c191133f6,timestamp:1697087343\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:660753bd-f707-4090-ab99-e44c191133f6,timestamp:1697087343\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2b188843-9f7e-4360-9c57-4f051cbd37c3,timestamp:1697087344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2b188843-9f7e-4360-9c57-4f051cbd37c3,timestamp:1697087344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1328\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1328\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:94002af5-d30e-4f83-8972-52ac5bbf869e,timestamp:1697087346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1328\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1328\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:94002af5-d30e-4f83-8972-52ac5bbf869e,timestamp:1697087346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,486 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59401937-2425-4eb1-87d8-2ce07a1ad6fe,timestamp:1697087347\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,486 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,486 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59401937-2425-4eb1-87d8-2ce07a1ad6fe,timestamp:1697087347\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,486 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,766 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,766 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:12616caf-cad2-496c-8c59-30788965f3a1,timestamp:1697087348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,766 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,766 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:12616caf-cad2-496c-8c59-30788965f3a1,timestamp:1697087348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:502dede8-f904-4f1f-9eb2-b869baabb86a,timestamp:1697087350\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:502dede8-f904-4f1f-9eb2-b869baabb86a,timestamp:1697087350\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,665 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a6861e6c-7c41-4ccb-b47a-86061c691aaf,timestamp:1697087352\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,665 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a6861e6c-7c41-4ccb-b47a-86061c691aaf,timestamp:1697087352\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ab9ed52a-224b-4f1e-82f0-cda9d183c50b,timestamp:1697087353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ab9ed52a-224b-4f1e-82f0-cda9d183c50b,timestamp:1697087353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63f313a3-2914-402f-be0c-8ee019e54733,timestamp:1697087355\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63f313a3-2914-402f-be0c-8ee019e54733,timestamp:1697087355\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6723171e-d0b5-45fc-875d-1e83ff171152,timestamp:1697087356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6723171e-d0b5-45fc-875d-1e83ff171152,timestamp:1697087356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,828 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,828 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,828 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:487d136a-ce55-4833-bd92-4cca2235fbd0,timestamp:1697087357\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313838958740234|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551292419433594|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12928.84765625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.47265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,828 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:487d136a-ce55-4833-bd92-4cca2235fbd0,timestamp:1697087357\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313838958740234|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551292419433594|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12928.84765625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.47265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08743481-147e-4dab-a9db-ce25217354e4,timestamp:1697087359\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08743481-147e-4dab-a9db-ce25217354e4,timestamp:1697087359\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e61759a2-4a61-42b6-8fda-23b52e73ad1d,timestamp:1697087360\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e61759a2-4a61-42b6-8fda-23b52e73ad1d,timestamp:1697087360\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c599f75-0495-4860-97f0-a391976b0606,timestamp:1697087361\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c599f75-0495-4860-97f0-a391976b0606,timestamp:1697087361\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1320.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb17da5f-d35f-4f5f-9cfd-befc7733a3fc,timestamp:1697087363\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1320.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb17da5f-d35f-4f5f-9cfd-befc7733a3fc,timestamp:1697087363\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,427 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,427 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aacf50f2-6a6e-42f7-bf05-df8a2b14721b,timestamp:1697087364\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,427 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,427 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aacf50f2-6a6e-42f7-bf05-df8a2b14721b,timestamp:1697087364\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1482\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b77a5f33-3f39-4583-9a97-03b28df71b51,timestamp:1697087365\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1482\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1482\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b77a5f33-3f39-4583-9a97-03b28df71b51,timestamp:1697087365\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1482\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:adf0390f-b27c-4527-a649-53af6ce93249,timestamp:1697087368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,528 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,528 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:adf0390f-b27c-4527-a649-53af6ce93249,timestamp:1697087368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,528 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,528 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,812 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,812 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0357dd78-136e-404b-96fb-1abf85d3dbb1,timestamp:1697087369\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,812 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,812 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0357dd78-136e-404b-96fb-1abf85d3dbb1,timestamp:1697087369\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c328857e-9750-412e-82f0-ad63dc5a2325,timestamp:1697087371\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c328857e-9750-412e-82f0-ad63dc5a2325,timestamp:1697087371\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,365 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,365 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55a46e0e-349c-4637-b4ae-260412fab20e,timestamp:1697087372\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,365 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,365 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55a46e0e-349c-4637-b4ae-260412fab20e,timestamp:1697087372\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,619 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a65d9790-b4df-4bde-8f66-2fd10c7a3d34,timestamp:1697087373\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,619 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a65d9790-b4df-4bde-8f66-2fd10c7a3d34,timestamp:1697087373\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,878 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,878 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,878 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7193d4c9-0e60-43f0-b576-491ecc7d760d,timestamp:1697087374\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,878 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7193d4c9-0e60-43f0-b576-491ecc7d760d,timestamp:1697087374\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,537 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,537 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ce61689-0e9b-4735-80aa-c1caf95da0e4,timestamp:1697087376\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,537 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,537 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ce61689-0e9b-4735-80aa-c1caf95da0e4,timestamp:1697087376\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:09:39,098 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,098 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9fb82536-f669-4090-b840-62ff1d3b9870,timestamp:1697087379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,098 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,098 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9fb82536-f669-4090-b840-62ff1d3b9870,timestamp:1697087379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,444 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1343\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,444 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1342.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:99124d49-de63-474d-8f70-b5ddb902b03f,timestamp:1697087380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,444 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1343\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,444 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1342.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:99124d49-de63-474d-8f70-b5ddb902b03f,timestamp:1697087380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1488\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1487.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:05eaf128-04b4-4a89-be0b-24a32b938b83,timestamp:1697087381\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1488\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1488\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1487.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:05eaf128-04b4-4a89-be0b-24a32b938b83,timestamp:1697087381\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1488\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18f10bbb-8c2b-4880-b1c6-95f43c52181c,timestamp:1697087384\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18f10bbb-8c2b-4880-b1c6-95f43c52181c,timestamp:1697087384\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5ea60c08-e114-4513-80f9-f3eb43502bed,timestamp:1697087385\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5ea60c08-e114-4513-80f9-f3eb43502bed,timestamp:1697087385\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e4a6571-5934-4be1-9463-fa67a8fb1ef3,timestamp:1697087387\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e4a6571-5934-4be1-9463-fa67a8fb1ef3,timestamp:1697087387\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,621 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1534\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1535\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1533.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dc4e0671-6054-4dbb-87f9-f6e96aa8fdcd,timestamp:1697087388\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,621 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1534\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1535\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1533.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dc4e0671-6054-4dbb-87f9-f6e96aa8fdcd,timestamp:1697087388\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,925 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,925 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d09a807-3882-4220-ae76-e39c4555b6d1,timestamp:1697087389\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,925 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,925 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d09a807-3882-4220-ae76-e39c4555b6d1,timestamp:1697087389\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b7d488c8-715a-4a47-8419-0f0102f99f0f,timestamp:1697087391\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b7d488c8-715a-4a47-8419-0f0102f99f0f,timestamp:1697087391\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ce69c5c4-9858-48b5-a61e-ca64f2d88311,timestamp:1697087392\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ce69c5c4-9858-48b5-a61e-ca64f2d88311,timestamp:1697087392\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1520.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a468dace-f466-4b22-bc28-5f1b4c41365e,timestamp:1697087393\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:54,000 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:54,000 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1520.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a468dace-f466-4b22-bc28-5f1b4c41365e,timestamp:1697087393\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:54,000 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:54,000 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ba0b091e-0942-4b8f-a891-90d28ee0c6bb,timestamp:1697087395\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ba0b091e-0942-4b8f-a891-90d28ee0c6bb,timestamp:1697087395\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1743\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1742.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c09abbae-ea29-41c5-a3b8-90217e42a579,timestamp:1697087397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1743\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1743\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1742.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c09abbae-ea29-41c5-a3b8-90217e42a579,timestamp:1697087397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1743\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,759 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1755\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,759 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1754.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63d3bc4c-6bd8-4296-b9d0-39a39ba9d934,timestamp:1697087398\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1756\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,759 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1755\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,759 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1754.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63d3bc4c-6bd8-4296-b9d0-39a39ba9d934,timestamp:1697087398\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1756\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,509 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1746\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,509 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1746.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5902549-1e4c-47ab-9b73-f0e4f5dfc7d3,timestamp:1697087400\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,509 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1746\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,509 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1746.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5902549-1e4c-47ab-9b73-f0e4f5dfc7d3,timestamp:1697087400\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1748\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1748\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.92|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ae4dafbd-3d20-4c4f-8c46-6a0f0e18583e,timestamp:1697087401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.92|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ae4dafbd-3d20-4c4f-8c46-6a0f0e18583e,timestamp:1697087401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b9d638ca-f45d-4b73-a272-c92fce7b0226,timestamp:1697087403\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b9d638ca-f45d-4b73-a272-c92fce7b0226,timestamp:1697087403\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4435ca1-d94d-4de2-9571-a19ba6ed24e8,timestamp:1697087405\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4435ca1-d94d-4de2-9571-a19ba6ed24e8,timestamp:1697087405\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7b50ce95-7d1c-49e5-802c-e791fcd2141d,timestamp:1697087406\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7b50ce95-7d1c-49e5-802c-e791fcd2141d,timestamp:1697087406\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44a841fa-676b-4f9e-9f61-0664f6133ca9,timestamp:1697087408\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,030 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44a841fa-676b-4f9e-9f61-0664f6133ca9,timestamp:1697087408\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,030 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07d377d9-15a5-4f10-bede-c7dcf73162f2,timestamp:1697087409\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07d377d9-15a5-4f10-bede-c7dcf73162f2,timestamp:1697087409\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8a7906e2-d83f-46b0-ac59-33867eb8a464,timestamp:1697087410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8a7906e2-d83f-46b0-ac59-33867eb8a464,timestamp:1697087410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,800 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,800 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a8d1018d-5410-457d-8067-f57177fe442e,timestamp:1697087411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,800 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,800 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a8d1018d-5410-457d-8067-f57177fe442e,timestamp:1697087411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1420\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1420.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e162a3cf-4023-4f53-8fe7-366a386647ba,timestamp:1697087413\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1421\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1420\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1420.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e162a3cf-4023-4f53-8fe7-366a386647ba,timestamp:1697087413\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1421\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1622\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1623\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1621.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80d44dac-c2db-4496-8412-d89a9cdf73d8,timestamp:1697087416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1622\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1623\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1621.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80d44dac-c2db-4496-8412-d89a9cdf73d8,timestamp:1697087416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ab13451-a471-4291-8790-11bf19a87b6b,timestamp:1697087417\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3137321472168|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551399230957031|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12927.2421875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2475.07421875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ab13451-a471-4291-8790-11bf19a87b6b,timestamp:1697087417\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3137321472168|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551399230957031|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12927.2421875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2475.07421875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb70cceb-d3be-471d-b12c-b977621c1854,timestamp:1697087419\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb70cceb-d3be-471d-b12c-b977621c1854,timestamp:1697087419\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5661bfc6-8721-4ae9-800d-c06a937304e6,timestamp:1697087420\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5661bfc6-8721-4ae9-800d-c06a937304e6,timestamp:1697087420\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,868 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,868 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a6179cbf-1665-4ca4-ba4d-05301693f40d,timestamp:1697087421\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,868 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,868 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a6179cbf-1665-4ca4-ba4d-05301693f40d,timestamp:1697087421\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1663\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1667.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cca0813-2a74-46d8-bac8-4cb7ecabd37c,timestamp:1697087423\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,541 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,541 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1663\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1667.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cca0813-2a74-46d8-bac8-4cb7ecabd37c,timestamp:1697087423\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,541 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,541 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:10:26,249 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,249 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:447ef808-3354-4bc1-8c03-a0b623c62b5e,timestamp:1697087426\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,249 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,249 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:447ef808-3354-4bc1-8c03-a0b623c62b5e,timestamp:1697087426\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d04cd3e2-c25a-4770-b6c4-64312b763824,timestamp:1697087427\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d04cd3e2-c25a-4770-b6c4-64312b763824,timestamp:1697087427\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,262 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1704\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,262 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1703.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a20072d7-989d-4be9-bddf-785086c7b4f6,timestamp:1697087429\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,262 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1704\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,262 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1703.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a20072d7-989d-4be9-bddf-785086c7b4f6,timestamp:1697087429\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3424fb85-72ff-47a3-89e7-7a9b21e2af9c,timestamp:1697087430\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3424fb85-72ff-47a3-89e7-7a9b21e2af9c,timestamp:1697087430\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f99e232f-7304-428b-a1eb-45af52908753,timestamp:1697087431\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f99e232f-7304-428b-a1eb-45af52908753,timestamp:1697087431\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1296\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1295.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cab78fc-e35a-4b86-b36c-0536c4b4a5eb,timestamp:1697087433\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1296\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1295.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cab78fc-e35a-4b86-b36c-0536c4b4a5eb,timestamp:1697087433\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1379.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:92266acb-4548-414c-8710-ca9419fab434,timestamp:1697087434\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,505 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,505 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1379.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:92266acb-4548-414c-8710-ca9419fab434,timestamp:1697087434\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,505 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,505 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:54873644-b0eb-445b-87f3-ffffaa978615,timestamp:1697087437\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:54873644-b0eb-445b-87f3-ffffaa978615,timestamp:1697087437\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b27ce2a1-f21c-4583-8d8f-b35d0740d996,timestamp:1697087438\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b27ce2a1-f21c-4583-8d8f-b35d0740d996,timestamp:1697087438\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6fbaaeb-26a9-419c-bed6-6f6d1b6162b7,timestamp:1697087439\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6fbaaeb-26a9-419c-bed6-6f6d1b6162b7,timestamp:1697087439\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1803\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1802.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18c15bab-61d4-4f22-ba45-11f6229629cf,timestamp:1697087441\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1803\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1803\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1802.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18c15bab-61d4-4f22-ba45-11f6229629cf,timestamp:1697087441\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1803\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,631 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,631 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd44d4c8-5de0-478a-b035-e1fece9efe80,timestamp:1697087442\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,631 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,631 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd44d4c8-5de0-478a-b035-e1fece9efe80,timestamp:1697087442\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c289b389-e40f-4d57-95cd-ddfe3922fcde,timestamp:1697087443\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c289b389-e40f-4d57-95cd-ddfe3922fcde,timestamp:1697087443\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1308\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5772989e-dd38-4c45-b7a5-0af5a317fd9a,timestamp:1697087445\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1308\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1308\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5772989e-dd38-4c45-b7a5-0af5a317fd9a,timestamp:1697087445\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1308\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5bc662e0-6f6d-424c-8726-885545a2ae49,timestamp:1697087447\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5bc662e0-6f6d-424c-8726-885545a2ae49,timestamp:1697087447\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1468.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3832670e-0f8a-45fa-95d1-eeb4a216570b,timestamp:1697087449\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1468.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3832670e-0f8a-45fa-95d1-eeb4a216570b,timestamp:1697087449\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:be4ce414-0645-4196-924e-0a7e899225c8,timestamp:1697087450\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,384 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:be4ce414-0645-4196-924e-0a7e899225c8,timestamp:1697087450\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,384 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39664c6e-30eb-4183-8814-3cf478de9a3f,timestamp:1697087451\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39664c6e-30eb-4183-8814-3cf478de9a3f,timestamp:1697087451\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d05ac8f6-8e7f-45b6-bbda-ddf113c4ccfc,timestamp:1697087452\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d05ac8f6-8e7f-45b6-bbda-ddf113c4ccfc,timestamp:1697087452\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1481\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1277e012-88fc-416f-b3e3-c018040d9929,timestamp:1697087454\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1482\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1481\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1277e012-88fc-416f-b3e3-c018040d9929,timestamp:1697087454\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1482\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,189 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,189 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a65741f3-12c5-43cf-b274-fe36679f539f,timestamp:1697087457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,189 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,189 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a65741f3-12c5-43cf-b274-fe36679f539f,timestamp:1697087457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,932 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1739\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,932 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1739.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e87533c-09ea-4f01-94ec-9d6ea0d41cb5,timestamp:1697087458\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1741\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,932 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1739\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,932 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1739.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e87533c-09ea-4f01-94ec-9d6ea0d41cb5,timestamp:1697087458\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1741\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:361a36f1-1196-4d4a-94e5-55de12caad6d,timestamp:1697087460\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:361a36f1-1196-4d4a-94e5-55de12caad6d,timestamp:1697087460\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2d16d59-be9a-4912-981a-aea56b44d3db,timestamp:1697087461\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,444 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,444 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2d16d59-be9a-4912-981a-aea56b44d3db,timestamp:1697087461\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,444 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,444 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1663\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2437b48-b45b-4f76-a151-91fb56ae7f84,timestamp:1697087463\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1663\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2437b48-b45b-4f76-a151-91fb56ae7f84,timestamp:1697087463\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,368 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,368 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:76316a78-29ad-4562-8e2f-7f5b7cc4e00a,timestamp:1697087464\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,368 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,368 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:76316a78-29ad-4562-8e2f-7f5b7cc4e00a,timestamp:1697087464\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a04a1dd-eeb1-4d5a-8774-c7903cffd71e,timestamp:1697087465\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,652 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a04a1dd-eeb1-4d5a-8774-c7903cffd71e,timestamp:1697087465\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,652 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1512\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1512.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:335e1a14-a73f-470c-af28-2ff6671cc7ae,timestamp:1697087468\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1513\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1512\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1512.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:335e1a14-a73f-470c-af28-2ff6671cc7ae,timestamp:1697087468\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1513\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1737\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1736.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59a4fd47-0c54-4302-93e4-8f8d37a93866,timestamp:1697087470\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1737\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1737\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1736.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59a4fd47-0c54-4302-93e4-8f8d37a93866,timestamp:1697087470\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1737\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,455 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:51443e7d-cf00-4ec4-ba08-2fbadb24fbcf,timestamp:1697087471\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,455 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:51443e7d-cf00-4ec4-ba08-2fbadb24fbcf,timestamp:1697087471\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1357\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55075465-2615-447e-b2a6-461c98e1375d,timestamp:1697087472\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,817 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1357\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55075465-2615-447e-b2a6-461c98e1375d,timestamp:1697087472\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,817 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,099 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7bc40ab-7f38-403b-afed-10da4ce1542b,timestamp:1697087474\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,099 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7bc40ab-7f38-403b-afed-10da4ce1542b,timestamp:1697087474\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1291.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1f506ab-dfc5-4061-9dde-b1ad377abf0d,timestamp:1697087475\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1291.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1f506ab-dfc5-4061-9dde-b1ad377abf0d,timestamp:1697087475\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,047 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1649\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,047 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d88a9f6b-9d78-4fed-bdae-1578062a00e3,timestamp:1697087477\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1651\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,047 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1649\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,047 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d88a9f6b-9d78-4fed-bdae-1578062a00e3,timestamp:1697087477\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1651\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:976a7206-477d-4bb4-9d2f-39e76891f012,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:976a7206-477d-4bb4-9d2f-39e76891f012,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:38384145-ea3a-46d5-9a0b-b1756f29f39a,timestamp:1697087479\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:38384145-ea3a-46d5-9a0b-b1756f29f39a,timestamp:1697087479\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1651\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1650.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63f62249-af29-40eb-abee-156b3c828d3c,timestamp:1697087481\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1651\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1651\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1650.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63f62249-af29-40eb-abee-156b3c828d3c,timestamp:1697087481\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1651\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1398\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,767 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1397.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c371450b-da3b-450d-8597-57c44c7762e3,timestamp:1697087482\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,767 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1398\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,767 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1397.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c371450b-da3b-450d-8597-57c44c7762e3,timestamp:1697087482\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,767 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a368034-86d4-4e20-939e-c8df657108ea,timestamp:1697087484\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a368034-86d4-4e20-939e-c8df657108ea,timestamp:1697087484\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,678 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1572\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1571.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:db689326-6aca-4769-967f-750e23fcf964,timestamp:1697087485\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1573\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,678 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1572\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1571.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:db689326-6aca-4769-967f-750e23fcf964,timestamp:1697087485\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1573\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1640\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4f700dcf-1e26-4ace-b73d-5143ac8d7dae,timestamp:1697087487\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1640\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4f700dcf-1e26-4ace-b73d-5143ac8d7dae,timestamp:1697087487\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:11:30,316 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1690\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,316 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1689.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8136bcf8-9f59-4024-8682-a1fd0df2b8d0,timestamp:1697087490\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1691\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,316 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1690\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,316 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1689.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8136bcf8-9f59-4024-8682-a1fd0df2b8d0,timestamp:1697087490\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1691\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,578 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ec55d47-39aa-4227-8457-a78565cac2ef,timestamp:1697087491\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,578 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ec55d47-39aa-4227-8457-a78565cac2ef,timestamp:1697087491\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,849 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:844b91b5-e172-4a5b-8bd9-10166a87495d,timestamp:1697087492\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,849 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:844b91b5-e172-4a5b-8bd9-10166a87495d,timestamp:1697087492\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1428\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1428\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1428\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1428\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1426.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e1d90ed4-cca6-4534-abe5-e6697f8e1543,timestamp:1697087494\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1426.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e1d90ed4-cca6-4534-abe5-e6697f8e1543,timestamp:1697087494\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,520 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a77d077-1155-4d03-b07c-712bd576c07e,timestamp:1697087495\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,520 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a77d077-1155-4d03-b07c-712bd576c07e,timestamp:1697087495\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1436\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1434.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:da1b929a-f6ba-4825-a71d-ad6fe839314f,timestamp:1697087496\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1436\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1436\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1434.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:da1b929a-f6ba-4825-a71d-ad6fe839314f,timestamp:1697087496\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1436\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1515\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1514.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5eadfa0-6cb4-417d-8c80-26adbc6e4b3a,timestamp:1697087499\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1515\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,799 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1515\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1514.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5eadfa0-6cb4-417d-8c80-26adbc6e4b3a,timestamp:1697087499\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1515\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,799 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9b8b24a2-a037-401f-b427-20175b061ab2,timestamp:1697087501\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9b8b24a2-a037-401f-b427-20175b061ab2,timestamp:1697087501\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,881 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1812\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1812.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:004cd715-8d52-45e3-918f-b2a21511e47d,timestamp:1697087502\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1814\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,881 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1812\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1812.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:004cd715-8d52-45e3-918f-b2a21511e47d,timestamp:1697087502\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1814\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1471\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1470.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2740a5e-9802-40d0-abb2-669e204d5f77,timestamp:1697087504\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1472\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1471\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1470.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2740a5e-9802-40d0-abb2-669e204d5f77,timestamp:1697087504\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1472\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1508\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1508.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:903c334a-9708-423c-8172-dae1cbfcb5f5,timestamp:1697087505\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1509\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,868 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1508\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1508.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:903c334a-9708-423c-8172-dae1cbfcb5f5,timestamp:1697087505\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1509\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,868 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a87fedfd-1f2a-4cef-b823-fc581919e9ae,timestamp:1697087507\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a87fedfd-1f2a-4cef-b823-fc581919e9ae,timestamp:1697087507\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,217 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,217 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,994 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,994 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:846cbafd-86ef-4f7c-999e-3996ffcbdb78,timestamp:1697087509\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,994 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,994 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:846cbafd-86ef-4f7c-999e-3996ffcbdb78,timestamp:1697087509\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2b73989-ece1-4c03-b9b3-f8f9281ee486,timestamp:1697087511\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2b73989-ece1-4c03-b9b3-f8f9281ee486,timestamp:1697087511\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:836a3c18-a6e0-4d64-8752-082985ab37ba,timestamp:1697087512\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:836a3c18-a6e0-4d64-8752-082985ab37ba,timestamp:1697087512\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,802 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,802 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2d69dd5-b523-4def-9def-b5029518a933,timestamp:1697087513\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,802 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,802 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2d69dd5-b523-4def-9def-b5029518a933,timestamp:1697087513\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,065 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,065 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c83509b8-7250-4f0b-8fb2-51d58ca54954,timestamp:1697087515\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,065 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,065 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c83509b8-7250-4f0b-8fb2-51d58ca54954,timestamp:1697087515\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1515\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1515.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:251eac28-1a95-4c80-a173-0d557a87f920,timestamp:1697087516\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1516\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,585 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1515\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1515.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:251eac28-1a95-4c80-a173-0d557a87f920,timestamp:1697087516\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1516\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,585 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c85b76e2-02f8-4f84-977a-fae504efdf16,timestamp:1697087517\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c85b76e2-02f8-4f84-977a-fae504efdf16,timestamp:1697087517\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fae2d710-addd-405e-8e29-1c28c5845ab9,timestamp:1697087520\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fae2d710-addd-405e-8e29-1c28c5845ab9,timestamp:1697087520\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5abde31c-d057-4489-a273-5f272744b990,timestamp:1697087521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5abde31c-d057-4489-a273-5f272744b990,timestamp:1697087521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57ebb7b6-8707-4548-9b8c-dc3d09793c5f,timestamp:1697087522\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57ebb7b6-8707-4548-9b8c-dc3d09793c5f,timestamp:1697087522\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e56612e6-b63a-42ae-9488-893207a1e0fa,timestamp:1697087524\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e56612e6-b63a-42ae-9488-893207a1e0fa,timestamp:1697087524\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d04e056b-33ea-4acb-901e-a8ffc107924c,timestamp:1697087525\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d04e056b-33ea-4acb-901e-a8ffc107924c,timestamp:1697087525\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1406\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1405.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fe4a0e4a-bfaa-4c28-8b70-d79f42603bfe,timestamp:1697087526\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1407\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1406\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1405.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fe4a0e4a-bfaa-4c28-8b70-d79f42603bfe,timestamp:1697087526\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1407\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,319 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8e07c35-dd5d-4098-921f-3ded4f9e33c9,timestamp:1697087528\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,319 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8e07c35-dd5d-4098-921f-3ded4f9e33c9,timestamp:1697087528\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:12:11,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,554 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:590a3024-2e80-4506-92eb-96f0066d0c09,timestamp:1697087531\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1341\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,554 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:590a3024-2e80-4506-92eb-96f0066d0c09,timestamp:1697087531\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1341\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1379.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd40032a-9349-43cf-a917-e814d49e948c,timestamp:1697087532\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1379.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd40032a-9349-43cf-a917-e814d49e948c,timestamp:1697087532\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1995\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1995.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:21de6077-0eee-4ab2-8196-602583987490,timestamp:1697087534\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1995\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1995\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1995.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:21de6077-0eee-4ab2-8196-602583987490,timestamp:1697087534\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1995\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1394\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c414cbb-636f-481e-ad4a-31888d84bb49,timestamp:1697087536\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1394\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c414cbb-636f-481e-ad4a-31888d84bb49,timestamp:1697087536\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,690 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:50564332-947b-453a-aa5d-9f1be7d34ea7,timestamp:1697087537\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,690 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,690 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:50564332-947b-453a-aa5d-9f1be7d34ea7,timestamp:1697087537\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,690 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,264 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313514709472656|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551616668701172|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12905.0859375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2497.24609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,264 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313514709472656|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551616668701172|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12905.0859375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2497.24609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8b5ade06-509d-427e-bc25-b00ef1edc7bd,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8b5ade06-509d-427e-bc25-b00ef1edc7bd,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:928f0286-a341-40f3-9eae-9954b003db1d,timestamp:1697087541\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:928f0286-a341-40f3-9eae-9954b003db1d,timestamp:1697087541\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8013332d-7596-441d-b86e-6c51c43b0ba1,timestamp:1697087543\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8013332d-7596-441d-b86e-6c51c43b0ba1,timestamp:1697087543\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d24447cb-2146-4fa1-8933-b629426dcc6f,timestamp:1697087544\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d24447cb-2146-4fa1-8933-b629426dcc6f,timestamp:1697087544\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,825 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7e258562-ba4c-4f1e-8989-1cd9b2ff93e1,timestamp:1697087545\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,825 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7e258562-ba4c-4f1e-8989-1cd9b2ff93e1,timestamp:1697087545\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1409\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1408.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6944f18-4017-4ce8-9126-0021f8dad61a,timestamp:1697087547\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1409\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1408.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6944f18-4017-4ce8-9126-0021f8dad61a,timestamp:1697087547\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d65941c7-797a-4f78-9b77-2df91c049ee6,timestamp:1697087548\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d65941c7-797a-4f78-9b77-2df91c049ee6,timestamp:1697087548\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f74ab2d7-3313-4b0a-9b21-0a258d59f822,timestamp:1697087550\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f74ab2d7-3313-4b0a-9b21-0a258d59f822,timestamp:1697087550\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cf420b14-7146-4276-b6eb-bd2597a0f950,timestamp:1697087552\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cf420b14-7146-4276-b6eb-bd2597a0f950,timestamp:1697087552\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4c5fd6fe-8d72-430b-b543-d93c36250dd2,timestamp:1697087553\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4c5fd6fe-8d72-430b-b543-d93c36250dd2,timestamp:1697087553\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:88ede10c-ab04-4170-8c5e-600bf788d964,timestamp:1697087555\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,227 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,227 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:88ede10c-ab04-4170-8c5e-600bf788d964,timestamp:1697087555\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,227 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,227 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f4a2af53-c07a-4e99-a4ef-5a3bfdfcaf8b,timestamp:1697087556\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f4a2af53-c07a-4e99-a4ef-5a3bfdfcaf8b,timestamp:1697087556\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1800\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1799.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9f4c7b51-8950-4a3d-bda7-cc8eaee8d3a6,timestamp:1697087558\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1800\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1800\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1799.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9f4c7b51-8950-4a3d-bda7-cc8eaee8d3a6,timestamp:1697087558\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1800\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,558 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2abda9c5-a70d-4664-a5fc-188d19915fa9,timestamp:1697087559\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,558 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2abda9c5-a70d-4664-a5fc-188d19915fa9,timestamp:1697087559\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1400.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9d59c8f1-85e5-4f2b-83c5-4a04fdff5893,timestamp:1697087562\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1400.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9d59c8f1-85e5-4f2b-83c5-4a04fdff5893,timestamp:1697087562\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,457 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,457 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e3c4a12-70df-4b23-96e4-42006b681438,timestamp:1697087563\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,457 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,457 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e3c4a12-70df-4b23-96e4-42006b681438,timestamp:1697087563\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ebc98a0d-6fcd-4e36-b993-46299f3afc29,timestamp:1697087565\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1671\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,133 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ebc98a0d-6fcd-4e36-b993-46299f3afc29,timestamp:1697087565\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1671\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,133 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55f3d7b6-ff16-4a64-9e8a-6419d19550b2,timestamp:1697087566\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55f3d7b6-ff16-4a64-9e8a-6419d19550b2,timestamp:1697087566\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1477.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7534c89-d777-4375-aba4-90ebf555b788,timestamp:1697087567\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,898 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,898 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1477.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7534c89-d777-4375-aba4-90ebf555b788,timestamp:1697087567\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,898 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,898 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1515ca1b-d654-4246-a2e8-1bcbe192586c,timestamp:1697087569\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1515ca1b-d654-4246-a2e8-1bcbe192586c,timestamp:1697087569\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1398.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a9bdcb9-9d8f-4bd2-8342-11248291de9e,timestamp:1697087570\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1398.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a9bdcb9-9d8f-4bd2-8342-11248291de9e,timestamp:1697087570\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6cbd749d-597e-4200-81fb-ff68bd0b00d1,timestamp:1697087573\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,121 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6cbd749d-597e-4200-81fb-ff68bd0b00d1,timestamp:1697087573\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,121 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75150bff-3718-4182-80ff-2da89eb262aa,timestamp:1697087574\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75150bff-3718-4182-80ff-2da89eb262aa,timestamp:1697087574\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,664 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ac178649-ede7-4e40-9b14-eb033a80c252,timestamp:1697087575\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,664 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ac178649-ede7-4e40-9b14-eb033a80c252,timestamp:1697087575\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30a705e8-5ac2-49af-9f2b-4aa211b962bc,timestamp:1697087576\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,994 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,994 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30a705e8-5ac2-49af-9f2b-4aa211b962bc,timestamp:1697087576\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,994 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,994 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:13e4455e-92ef-44ae-808b-27318969a3e8,timestamp:1697087578\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:13e4455e-92ef-44ae-808b-27318969a3e8,timestamp:1697087578\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bf197b7-980c-4ca3-b31f-6bb77e6bcf11,timestamp:1697087579\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bf197b7-980c-4ca3-b31f-6bb77e6bcf11,timestamp:1697087579\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4f9fa01c-dbdf-47db-a396-123914a77e85,timestamp:1697087580\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4f9fa01c-dbdf-47db-a396-123914a77e85,timestamp:1697087580\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:13:03,357 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2e8e185e-b5f6-4d28-9d63-65b2c44a76c4,timestamp:1697087583\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,357 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2e8e185e-b5f6-4d28-9d63-65b2c44a76c4,timestamp:1697087583\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1360\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1360\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1359.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b96a2ade-0646-47a7-b9af-c54e83c77083,timestamp:1697087584\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1361\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1359.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b96a2ade-0646-47a7-b9af-c54e83c77083,timestamp:1697087584\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1361\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:762d8cfd-7c2b-4f2c-91c7-aa9a58db4a6b,timestamp:1697087586\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:762d8cfd-7c2b-4f2c-91c7-aa9a58db4a6b,timestamp:1697087586\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,515 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1435\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1435.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:688a64a6-c708-418e-9b5f-5658899034e6,timestamp:1697087587\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1437\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,515 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1435\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1435.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:688a64a6-c708-418e-9b5f-5658899034e6,timestamp:1697087587\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1437\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:36a46d19-031d-46c6-89b3-cfb962781e41,timestamp:1697087589\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:36a46d19-031d-46c6-89b3-cfb962781e41,timestamp:1697087589\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,421 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:77818bf8-1a8d-4710-b7bf-c60427ad9d3b,timestamp:1697087590\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,421 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:77818bf8-1a8d-4710-b7bf-c60427ad9d3b,timestamp:1697087590\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a09033a-3a39-4b40-9607-523d04914212,timestamp:1697087593\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a09033a-3a39-4b40-9607-523d04914212,timestamp:1697087593\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,790 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1642\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,790 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1642.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bb930c0e-021a-4aa5-a938-b02d1f6d8e50,timestamp:1697087594\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1644\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,790 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1642\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,790 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1642.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bb930c0e-021a-4aa5-a938-b02d1f6d8e50,timestamp:1697087594\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1644\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1651.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:37d9939a-2c4d-4d63-adc7-74183d4d353f,timestamp:1697087596\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1653\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1651.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:37d9939a-2c4d-4d63-adc7-74183d4d353f,timestamp:1697087596\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1653\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7b8c7c8-f71c-4e70-b94b-d8f6da1349d2,timestamp:1697087597\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7b8c7c8-f71c-4e70-b94b-d8f6da1349d2,timestamp:1697087597\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31340408325195|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551727294921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12902.77734375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2499.51953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31340408325195|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551727294921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12902.77734375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2499.51953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,214 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1494\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1495\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1493.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7c2ed513-622f-4d66-ba71-4a406590bfb2,timestamp:1697087599\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,214 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1494\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1495\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1493.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7c2ed513-622f-4d66-ba71-4a406590bfb2,timestamp:1697087599\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,470 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,470 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aad603cf-98d1-4d05-8363-709e05398872,timestamp:1697087600\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,470 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,470 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aad603cf-98d1-4d05-8363-709e05398872,timestamp:1697087600\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30853154-295d-4ba0-8a47-ed88ca0dac1a,timestamp:1697087603\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30853154-295d-4ba0-8a47-ed88ca0dac1a,timestamp:1697087603\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,367 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44d40bb3-0fcc-4a70-86f2-4879061be501,timestamp:1697087604\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,367 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44d40bb3-0fcc-4a70-86f2-4879061be501,timestamp:1697087604\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,837 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1468\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,837 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1466.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d63dbd8c-e033-4bbb-a037-9645d8c1ba8d,timestamp:1697087605\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,837 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1468\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,837 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1466.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d63dbd8c-e033-4bbb-a037-9645d8c1ba8d,timestamp:1697087605\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1405\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1404.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e088148b-ea47-4648-a614-d87eef2c8875,timestamp:1697087607\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1405\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1405\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1404.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e088148b-ea47-4648-a614-d87eef2c8875,timestamp:1697087607\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1405\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,504 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,504 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8fa6f4c-4408-4317-a9ae-defdf4364169,timestamp:1697087608\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,504 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,504 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8fa6f4c-4408-4317-a9ae-defdf4364169,timestamp:1697087608\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1343\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c8b16c1-faef-4b3c-b287-a653650fd773,timestamp:1697087609\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1343\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c8b16c1-faef-4b3c-b287-a653650fd773,timestamp:1697087609\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,232 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,232 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1376.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:767c4801-18e5-4a96-ab51-28df7bcbc7ac,timestamp:1697087611\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1377\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,232 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,232 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1376.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:767c4801-18e5-4a96-ab51-28df7bcbc7ac,timestamp:1697087611\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1377\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e3db748-8b4d-4c6f-af89-c2300f7ef528,timestamp:1697087613\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e3db748-8b4d-4c6f-af89-c2300f7ef528,timestamp:1697087613\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d7a0058-81c4-4bba-94ff-f0dee62e3fdd,timestamp:1697087615\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d7a0058-81c4-4bba-94ff-f0dee62e3fdd,timestamp:1697087615\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e559a25b-0c4e-40da-b381-d89fd49ab3e8,timestamp:1697087616\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e559a25b-0c4e-40da-b381-d89fd49ab3e8,timestamp:1697087616\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1588\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1587.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4690e416-8e4f-4357-be20-9236e284e16c,timestamp:1697087617\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1589\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1588\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1587.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4690e416-8e4f-4357-be20-9236e284e16c,timestamp:1697087617\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1589\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1312.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bf059d92-138d-439e-a663-159b0770ef8b,timestamp:1697087619\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,263 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,263 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1312.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bf059d92-138d-439e-a663-159b0770ef8b,timestamp:1697087619\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,263 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,263 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1935\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1934.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d64b91c-b3ba-4dae-b21b-19e2f1db84c9,timestamp:1697087621\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1935\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,201 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,201 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1935\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1934.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d64b91c-b3ba-4dae-b21b-19e2f1db84c9,timestamp:1697087621\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1935\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,201 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,201 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aea18087-70a8-4e7a-a10e-646121ac5667,timestamp:1697087622\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aea18087-70a8-4e7a-a10e-646121ac5667,timestamp:1697087622\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6726b170-f56d-4d1f-b8b0-886736a0a71d,timestamp:1697087625\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6726b170-f56d-4d1f-b8b0-886736a0a71d,timestamp:1697087625\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,593 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bd60d85f-d87f-429b-b08b-fb67b0424aa3,timestamp:1697087626\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,593 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bd60d85f-d87f-429b-b08b-fb67b0424aa3,timestamp:1697087626\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1283.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c3b32279-a178-4e20-8d91-40661b283d4e,timestamp:1697087627\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1283.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c3b32279-a178-4e20-8d91-40661b283d4e,timestamp:1697087627\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c827dec4-7483-43cd-91b8-150c2174f85f,timestamp:1697087629\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,152 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,152 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c827dec4-7483-43cd-91b8-150c2174f85f,timestamp:1697087629\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,152 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,152 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7aadad20-c74e-46ab-895e-fb01dc0c68b7,timestamp:1697087630\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7aadad20-c74e-46ab-895e-fb01dc0c68b7,timestamp:1697087630\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1366\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1366.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9e24ff18-48fb-41fe-8e9b-ec310064fccf,timestamp:1697087631\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1366\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1366.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9e24ff18-48fb-41fe-8e9b-ec310064fccf,timestamp:1697087631\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,064 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,064 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08d073a7-0cf7-44ec-a145-c84c5ced67c8,timestamp:1697087633\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,064 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,064 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08d073a7-0cf7-44ec-a145-c84c5ced67c8,timestamp:1697087633\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c8265927-ece3-4057-94f9-c5a2e167ad01,timestamp:1697087635\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c8265927-ece3-4057-94f9-c5a2e167ad01,timestamp:1697087635\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:489a1884-9a05-4aab-982e-69737d7d8425,timestamp:1697087636\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:489a1884-9a05-4aab-982e-69737d7d8425,timestamp:1697087636\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44454ab6-d538-4f13-8443-e0e6cba8935f,timestamp:1697087638\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44454ab6-d538-4f13-8443-e0e6cba8935f,timestamp:1697087638\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9c5cead2-5248-4d39-83e0-54bdfea38b4a,timestamp:1697087639\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9c5cead2-5248-4d39-83e0-54bdfea38b4a,timestamp:1697087639\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,864 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64525fd5-27ef-43e0-8858-781ffb109e88,timestamp:1697087640\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,864 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64525fd5-27ef-43e0-8858-781ffb109e88,timestamp:1697087640\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:260e84ad-7729-4918-ac22-99806224721d,timestamp:1697087642\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:260e84ad-7729-4918-ac22-99806224721d,timestamp:1697087642\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,366 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2ad18248-6211-40c8-a931-63667639d134,timestamp:1697087643\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,366 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2ad18248-6211-40c8-a931-63667639d134,timestamp:1697087643\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:601c42e5-641e-4066-8c35-1816f7ab024c,timestamp:1697087645\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:601c42e5-641e-4066-8c35-1816f7ab024c,timestamp:1697087645\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,146 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,146 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b43fceba-45fe-430e-8fa2-cf7283438d3a,timestamp:1697087647\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,146 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,146 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b43fceba-45fe-430e-8fa2-cf7283438d3a,timestamp:1697087647\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:680175d1-9545-41a4-8603-09995173be3c,timestamp:1697087648\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:680175d1-9545-41a4-8603-09995173be3c,timestamp:1697087648\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd9acc98-2424-49ad-9a77-0973fda66608,timestamp:1697087649\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd9acc98-2424-49ad-9a77-0973fda66608,timestamp:1697087649\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ef9836d6-e35f-4483-89f9-2ec9a08c858b,timestamp:1697087650\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ef9836d6-e35f-4483-89f9-2ec9a08c858b,timestamp:1697087650\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,223 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,223 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ed5ba26-d3a0-4351-a6b9-90118d312cc9,timestamp:1697087652\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,223 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,223 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ed5ba26-d3a0-4351-a6b9-90118d312cc9,timestamp:1697087652\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:11c2ac82-7650-4ba2-8c86-c7d73de7163e,timestamp:1697087653\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:11c2ac82-7650-4ba2-8c86-c7d73de7163e,timestamp:1697087653\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1395\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1394.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:774cfc0a-4949-4906-bd44-e40206f9a739,timestamp:1697087656\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1396\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1395\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1394.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:774cfc0a-4949-4906-bd44-e40206f9a739,timestamp:1697087656\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1396\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1391\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1390.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a9955d7-e4f7-4afd-b9c5-ca88486eb79a,timestamp:1697087657\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1391\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1391\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1390.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a9955d7-e4f7-4afd-b9c5-ca88486eb79a,timestamp:1697087657\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1391\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31328201293945|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551849365234375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12895.953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2506.375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31328201293945|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551849365234375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12895.953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2506.375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:530d4ca4-3cbd-4dde-b777-f82da7680dec,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:530d4ca4-3cbd-4dde-b777-f82da7680dec,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:402fee51-79a5-4768-9716-ce96d01a9089,timestamp:1697087662\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:402fee51-79a5-4768-9716-ce96d01a9089,timestamp:1697087662\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:831fd025-2073-4e9e-a830-65e27faff3ac,timestamp:1697087663\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:831fd025-2073-4e9e-a830-65e27faff3ac,timestamp:1697087663\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1703\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1701.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52f6676c-04e0-455a-9abd-8f46a91c8b9d,timestamp:1697087665\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1703\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1703\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1701.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52f6676c-04e0-455a-9abd-8f46a91c8b9d,timestamp:1697087665\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1703\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1311.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6fd33f36-213d-4122-b43c-b5c790d2323c,timestamp:1697087666\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1311.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6fd33f36-213d-4122-b43c-b5c790d2323c,timestamp:1697087666\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b92f4d36-143f-4939-9f75-49b84cdab3b0,timestamp:1697087667\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,853 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,853 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b92f4d36-143f-4939-9f75-49b84cdab3b0,timestamp:1697087667\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,853 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,853 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bcf013d-1caa-41a6-846e-524acdbdd086,timestamp:1697087669\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1655\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bcf013d-1caa-41a6-846e-524acdbdd086,timestamp:1697087669\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1655\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4aacb9ae-68ec-483e-8e33-93dfd27824f5,timestamp:1697087670\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4aacb9ae-68ec-483e-8e33-93dfd27824f5,timestamp:1697087670\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:148980ea-0b72-4bb0-946c-c1fa71ea391d,timestamp:1697087672\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,044 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,044 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:148980ea-0b72-4bb0-946c-c1fa71ea391d,timestamp:1697087672\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,044 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,044 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1361\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1360.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39955fe4-4a80-4255-ab24-bfce63c4613f,timestamp:1697087673\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1361\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1361\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1360.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39955fe4-4a80-4255-ab24-bfce63c4613f,timestamp:1697087673\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1361\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5780aa96-7eb4-4ebd-8f0a-c6c83e4147e1,timestamp:1697087674\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,669 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5780aa96-7eb4-4ebd-8f0a-c6c83e4147e1,timestamp:1697087674\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,669 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d3a386d4-1128-437a-aba9-ca5186b15c38,timestamp:1697087677\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d3a386d4-1128-437a-aba9-ca5186b15c38,timestamp:1697087677\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:38c30770-debe-4401-9f0a-1f3384d4e024,timestamp:1697087678\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:38c30770-debe-4401-9f0a-1f3384d4e024,timestamp:1697087678\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1b41910e-f4e7-4fb9-a640-2f24c89e677b,timestamp:1697087679\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1b41910e-f4e7-4fb9-a640-2f24c89e677b,timestamp:1697087679\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1427\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1428\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1427.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20ad9525-3b95-4bee-ba53-ee740c5eafb3,timestamp:1697087681\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,149 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1427\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1428\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1427.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20ad9525-3b95-4bee-ba53-ee740c5eafb3,timestamp:1697087681\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,149 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8276ff3-5a3b-4296-bd76-04f289c300f3,timestamp:1697087682\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8276ff3-5a3b-4296-bd76-04f289c300f3,timestamp:1697087682\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ab7e1db-5839-4b8e-9994-f6e0a0a39903,timestamp:1697087683\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ab7e1db-5839-4b8e-9994-f6e0a0a39903,timestamp:1697087683\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d98adca8-6121-4896-b679-9496c9bba836,timestamp:1697087684\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d98adca8-6121-4896-b679-9496c9bba836,timestamp:1697087684\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,901 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4299d48-48f3-4dbe-89f1-8fcfa7208188,timestamp:1697087687\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,901 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4299d48-48f3-4dbe-89f1-8fcfa7208188,timestamp:1697087687\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a746e3d9-0250-436e-af41-ab3c6b01dbfb,timestamp:1697087689\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a746e3d9-0250-436e-af41-ab3c6b01dbfb,timestamp:1697087689\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e9c84330-7fc4-47f3-bdbb-13efdce8bacd,timestamp:1697087690\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e9c84330-7fc4-47f3-bdbb-13efdce8bacd,timestamp:1697087690\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,699 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2a2f1b5-176e-4781-a68f-74e3ddb78050,timestamp:1697087691\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,699 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2a2f1b5-176e-4781-a68f-74e3ddb78050,timestamp:1697087691\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a81c66b3-09c8-4e7c-b092-97f8ab2c8196,timestamp:1697087693\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a81c66b3-09c8-4e7c-b092-97f8ab2c8196,timestamp:1697087693\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4f71028-3ade-486e-9dec-f3e940c4074d,timestamp:1697087694\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4f71028-3ade-486e-9dec-f3e940c4074d,timestamp:1697087694\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:29fc9f6d-3d21-4e03-8e5f-4f6c82669d86,timestamp:1697087695\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:29fc9f6d-3d21-4e03-8e5f-4f6c82669d86,timestamp:1697087695\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:732b7cdc-75d7-44b3-a3a2-5965d4320686,timestamp:1697087698\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:732b7cdc-75d7-44b3-a3a2-5965d4320686,timestamp:1697087698\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70304826-7bcc-42bf-8a26-5ae35ac27d24,timestamp:1697087699\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70304826-7bcc-42bf-8a26-5ae35ac27d24,timestamp:1697087699\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c1ada6c6-3eaf-43bc-83f2-a7ee5b3fb9cb,timestamp:1697087700\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,703 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,703 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c1ada6c6-3eaf-43bc-83f2-a7ee5b3fb9cb,timestamp:1697087700\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,703 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,703 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46c64d98-60ac-4af1-8b06-7b80326fe21c,timestamp:1697087701\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46c64d98-60ac-4af1-8b06-7b80326fe21c,timestamp:1697087701\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2057\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2056.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fecac66f-ae3c-4ecf-bdeb-671492bd86fc,timestamp:1697087704\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2057\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2057\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2056.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fecac66f-ae3c-4ecf-bdeb-671492bd86fc,timestamp:1697087704\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2057\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:596dca98-e0a7-47d6-bfd2-4754014c816b,timestamp:1697087705\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1419\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:596dca98-e0a7-47d6-bfd2-4754014c816b,timestamp:1697087705\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1419\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:69ebab3d-8737-4183-a8fd-4ce28df777c7,timestamp:1697087706\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:69ebab3d-8737-4183-a8fd-4ce28df777c7,timestamp:1697087706\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:15:09,238 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,238 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.89|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9b50cb4a-be6e-46d4-9fb6-71b199cab4c8,timestamp:1697087709\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,238 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,238 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.89|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9b50cb4a-be6e-46d4-9fb6-71b199cab4c8,timestamp:1697087709\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d12e9db-e9fd-4a48-880f-c5c6648ff698,timestamp:1697087710\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d12e9db-e9fd-4a48-880f-c5c6648ff698,timestamp:1697087710\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,821 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1326\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,821 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1326\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:76f46b3a-87ef-4949-ad22-2e86dc104d8b,timestamp:1697087711\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1328\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:76f46b3a-87ef-4949-ad22-2e86dc104d8b,timestamp:1697087711\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1328\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:13,065 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:13,065 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f2670f1-4cfa-4c09-b6aa-72a602d56f55,timestamp:1697087714\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f2670f1-4cfa-4c09-b6aa-72a602d56f55,timestamp:1697087714\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,319 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,319 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,319 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,319 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:794cc8d5-a7d2-4b29-be09-a3bd9b6666e0,timestamp:1697087715\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:794cc8d5-a7d2-4b29-be09-a3bd9b6666e0,timestamp:1697087715\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:13bd5422-6a97-4e8d-88bf-8085bad63532,timestamp:1697087716\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:13bd5422-6a97-4e8d-88bf-8085bad63532,timestamp:1697087716\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1306.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8c041356-c83f-4cd9-9cae-b9dc2d3a6975,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313175201416016|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551956176757812|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12895.44921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2506.8828125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1306.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8c041356-c83f-4cd9-9cae-b9dc2d3a6975,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313175201416016|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551956176757812|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12895.44921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2506.8828125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,451 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,451 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6daca1b8-1baa-40c5-94e1-8d2ed1bb2223,timestamp:1697087719\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,451 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,451 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6daca1b8-1baa-40c5-94e1-8d2ed1bb2223,timestamp:1697087719\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1355\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1355\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1354.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a591c7e-459c-4bef-b351-c07da5066fd0,timestamp:1697087720\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1354.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a591c7e-459c-4bef-b351-c07da5066fd0,timestamp:1697087720\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8bc41ea0-b42e-4647-89db-59cc8c8be3d4,timestamp:1697087722\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8bc41ea0-b42e-4647-89db-59cc8c8be3d4,timestamp:1697087722\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bcad5ea5-593d-427f-8ac5-7a8ba1b1bb60,timestamp:1697087724\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bcad5ea5-593d-427f-8ac5-7a8ba1b1bb60,timestamp:1697087724\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d1db280-a1c6-44c0-9e5d-616e75b87b6a,timestamp:1697087725\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d1db280-a1c6-44c0-9e5d-616e75b87b6a,timestamp:1697087725\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1c19b471-520e-448d-8e57-63fc81fd9a1f,timestamp:1697087727\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1c19b471-520e-448d-8e57-63fc81fd9a1f,timestamp:1697087727\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a00e5acc-52a5-418d-8e08-f2a20856c48a,timestamp:1697087728\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a00e5acc-52a5-418d-8e08-f2a20856c48a,timestamp:1697087728\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1454\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1454.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc5e4b9b-19aa-4c59-b39a-431e0a623d93,timestamp:1697087729\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1455\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,937 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,937 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1454\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1454.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc5e4b9b-19aa-4c59-b39a-431e0a623d93,timestamp:1697087729\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1455\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,937 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,937 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18e0ddc1-2552-4af9-9cb2-65e478b0810e,timestamp:1697087731\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18e0ddc1-2552-4af9-9cb2-65e478b0810e,timestamp:1697087731\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2f772e4-30f0-43d7-a2d5-0c0779954abb,timestamp:1697087732\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2f772e4-30f0-43d7-a2d5-0c0779954abb,timestamp:1697087732\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aaf7f959-8e7b-407d-8683-ae33ce309f12,timestamp:1697087735\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aaf7f959-8e7b-407d-8683-ae33ce309f12,timestamp:1697087735\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1c61928a-b102-4dc8-870a-e8b83b494b5a,timestamp:1697087736\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1c61928a-b102-4dc8-870a-e8b83b494b5a,timestamp:1697087736\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd1135fb-ba88-4646-be26-e7ec61cbd059,timestamp:1697087737\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd1135fb-ba88-4646-be26-e7ec61cbd059,timestamp:1697087737\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7342312f-5e69-4577-b4cb-66ccf2455fc5,timestamp:1697087738\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7342312f-5e69-4577-b4cb-66ccf2455fc5,timestamp:1697087738\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5e9a3b32-a295-4e92-9827-2991fa9e8899,timestamp:1697087740\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5e9a3b32-a295-4e92-9827-2991fa9e8899,timestamp:1697087740\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18f5e570-86a5-4f09-951c-e4bd57ab6fbd,timestamp:1697087741\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18f5e570-86a5-4f09-951c-e4bd57ab6fbd,timestamp:1697087741\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1802c557-a7da-460d-a407-a45f8f44759c,timestamp:1697087742\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1802c557-a7da-460d-a407-a45f8f44759c,timestamp:1697087742\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2b745a32-7413-4cd4-8508-f81aca801844,timestamp:1697087745\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2b745a32-7413-4cd4-8508-f81aca801844,timestamp:1697087745\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c6f9288f-55e9-408d-b8a2-35c577e7e94f,timestamp:1697087746\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c6f9288f-55e9-408d-b8a2-35c577e7e94f,timestamp:1697087746\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:03713b8e-68c7-49d1-8352-0e76d9901a46,timestamp:1697087747\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:03713b8e-68c7-49d1-8352-0e76d9901a46,timestamp:1697087747\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:849cd64b-e484-4fa8-a307-a6543e7227be,timestamp:1697087749\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,073 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:849cd64b-e484-4fa8-a307-a6543e7227be,timestamp:1697087749\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,073 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ee922981-2523-4892-8db9-f7c3ddb52e4c,timestamp:1697087750\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ee922981-2523-4892-8db9-f7c3ddb52e4c,timestamp:1697087750\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1460\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1458.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:41b8f6cb-39fb-48a0-b33a-4e1fcd28c38f,timestamp:1697087751\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1460\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1460\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1458.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:41b8f6cb-39fb-48a0-b33a-4e1fcd28c38f,timestamp:1697087751\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1460\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d52df14c-a610-4662-aa8c-c31f3b2029b9,timestamp:1697087753\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d52df14c-a610-4662-aa8c-c31f3b2029b9,timestamp:1697087753\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d5d7d9d-e5ea-478c-88e8-4df3e87b49f3,timestamp:1697087755\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d5d7d9d-e5ea-478c-88e8-4df3e87b49f3,timestamp:1697087755\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87aa1c89-c73a-40f8-9de1-f375a54f9ff6,timestamp:1697087756\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,913 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87aa1c89-c73a-40f8-9de1-f375a54f9ff6,timestamp:1697087756\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,913 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dcbb0004-4492-417b-bdee-091d81ef4466,timestamp:1697087758\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dcbb0004-4492-417b-bdee-091d81ef4466,timestamp:1697087758\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e26d3741-a392-4ebe-ab02-1a664a2d98bf,timestamp:1697087759\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e26d3741-a392-4ebe-ab02-1a664a2d98bf,timestamp:1697087759\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:514abd90-b765-4974-b1c3-9e51125b7ca5,timestamp:1697087760\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:514abd90-b765-4974-b1c3-9e51125b7ca5,timestamp:1697087760\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:978bea6d-5c18-429a-a1a8-3041368caaa0,timestamp:1697087761\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,966 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:978bea6d-5c18-429a-a1a8-3041368caaa0,timestamp:1697087761\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,966 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8c803547-9fc6-4e8e-a29f-03a70be67fd6,timestamp:1697087763\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8c803547-9fc6-4e8e-a29f-03a70be67fd6,timestamp:1697087763\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e21418d7-68bf-42f4-9d9f-09c58d78064f,timestamp:1697087765\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e21418d7-68bf-42f4-9d9f-09c58d78064f,timestamp:1697087765\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,123 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:face1ea2-bfa1-47a2-add1-52616673344c,timestamp:1697087767\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,123 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:face1ea2-bfa1-47a2-add1-52616673344c,timestamp:1697087767\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,551 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1425\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1424.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7df9cb23-b67f-4c64-ad23-ffc013135573,timestamp:1697087768\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1426\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,551 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1425\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1424.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7df9cb23-b67f-4c64-ad23-ffc013135573,timestamp:1697087768\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1426\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1350.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1ffbf4f5-55db-478f-b203-59c5b7928bfa,timestamp:1697087769\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1350.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1ffbf4f5-55db-478f-b203-59c5b7928bfa,timestamp:1697087769\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1225\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47104560-fb25-4e36-8a68-cc6a39bedb25,timestamp:1697087771\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1225\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1225\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47104560-fb25-4e36-8a68-cc6a39bedb25,timestamp:1697087771\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1225\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,417 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,417 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:192af3c1-cfcb-4823-9e3b-12a1fbf2d532,timestamp:1697087772\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,417 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,417 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:192af3c1-cfcb-4823-9e3b-12a1fbf2d532,timestamp:1697087772\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a70219a9-7514-4415-9228-ae2e5d16404a,timestamp:1697087773\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a70219a9-7514-4415-9228-ae2e5d16404a,timestamp:1697087773\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6ab24567-85b7-4a0d-82e2-b2ca768adcb5,timestamp:1697087776\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6ab24567-85b7-4a0d-82e2-b2ca768adcb5,timestamp:1697087776\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70637ff3-6991-4e1f-8f3f-f8c5a2b48767,timestamp:1697087777\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70637ff3-6991-4e1f-8f3f-f8c5a2b48767,timestamp:1697087777\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,262 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31306457519531|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.552066802978516|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12895.6015625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2506.7265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,262 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31306457519531|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.552066802978516|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12895.6015625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2506.7265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:321f9b8b-c961-491d-bffe-4428bca9e10e,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:321f9b8b-c961-491d-bffe-4428bca9e10e,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:480f1d38-637f-4fdf-b3ca-5647361dd9ef,timestamp:1697087780\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:480f1d38-637f-4fdf-b3ca-5647361dd9ef,timestamp:1697087780\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a6d01cf-e3da-4abb-ab1c-2dd7476dea7a,timestamp:1697087781\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,580 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a6d01cf-e3da-4abb-ab1c-2dd7476dea7a,timestamp:1697087781\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,580 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1568\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1567.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93e03f8a-119b-40ce-a01b-b4f2daf72cfa,timestamp:1697087783\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1568\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1568\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1567.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93e03f8a-119b-40ce-a01b-b4f2daf72cfa,timestamp:1697087783\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1568\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1445\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1445\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1445.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a446f2eb-7c76-4b28-ab1e-f409cfb51432,timestamp:1697087784\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,599 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,599 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1445\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1445\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1445.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a446f2eb-7c76-4b28-ab1e-f409cfb51432,timestamp:1697087784\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,599 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,599 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1481\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bed93b21-1933-4a52-bdfb-c600241d55b7,timestamp:1697087787\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1481\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bed93b21-1933-4a52-bdfb-c600241d55b7,timestamp:1697087787\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3c7191b1-42f3-42a9-ac51-972ca2849b1c,timestamp:1697087788\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3c7191b1-42f3-42a9-ac51-972ca2849b1c,timestamp:1697087788\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ce7bf05b-a52c-476e-8895-d0e6a02a1f77,timestamp:1697087789\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ce7bf05b-a52c-476e-8895-d0e6a02a1f77,timestamp:1697087789\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,108 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e08ebfc-2f99-4498-a53a-d7b3f2b795eb,timestamp:1697087791\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,108 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e08ebfc-2f99-4498-a53a-d7b3f2b795eb,timestamp:1697087791\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1425\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1424.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:34e15a1f-17b0-4cfe-8cf0-547d65856bcd,timestamp:1697087792\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1425\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,537 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1425\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1424.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:34e15a1f-17b0-4cfe-8cf0-547d65856bcd,timestamp:1697087792\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1425\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,537 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c08a3dff-3de8-4e1c-b40b-8313616fbb7d,timestamp:1697087793\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c08a3dff-3de8-4e1c-b40b-8313616fbb7d,timestamp:1697087793\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bfcae98b-043f-41b5-adeb-25c472c5010c,timestamp:1697087795\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bfcae98b-043f-41b5-adeb-25c472c5010c,timestamp:1697087795\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:704bc68c-a5c2-4e0c-982d-bd80626a62c9,timestamp:1697087797\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:704bc68c-a5c2-4e0c-982d-bd80626a62c9,timestamp:1697087797\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1511\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1512\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1510.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a71937f9-3f49-447a-854d-96241c4111ed,timestamp:1697087799\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1511\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1512\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1510.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a71937f9-3f49-447a-854d-96241c4111ed,timestamp:1697087799\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a8494489-843d-424a-aacb-d9afe0b605a5,timestamp:1697087800\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a8494489-843d-424a-aacb-d9afe0b605a5,timestamp:1697087800\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c0fa9383-1d6d-4020-ba41-d9e90be2572c,timestamp:1697087801\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c0fa9383-1d6d-4020-ba41-d9e90be2572c,timestamp:1697087801\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:afd22c39-b6d4-4146-9111-6491fbb524ad,timestamp:1697087803\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:afd22c39-b6d4-4146-9111-6491fbb524ad,timestamp:1697087803\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80e0b67c-ddc5-4e0e-b368-c3ec31a63200,timestamp:1697087804\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,506 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,506 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80e0b67c-ddc5-4e0e-b368-c3ec31a63200,timestamp:1697087804\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,506 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,506 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1440\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1440\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1439.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bf1f39a-1922-4d5a-a78d-28f196509ceb,timestamp:1697087807\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1440\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1440\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1439.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bf1f39a-1922-4d5a-a78d-28f196509ceb,timestamp:1697087807\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:445e0b02-cb0b-4385-af0c-e58beff9be6b,timestamp:1697087808\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:445e0b02-cb0b-4385-af0c-e58beff9be6b,timestamp:1697087808\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e072487-29b6-4bad-9b1c-28e667fdab03,timestamp:1697087809\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e072487-29b6-4bad-9b1c-28e667fdab03,timestamp:1697087809\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,228 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,228 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a49ec7de-4e65-4cac-8489-f30566255b7c,timestamp:1697087811\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,228 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,228 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a49ec7de-4e65-4cac-8489-f30566255b7c,timestamp:1697087811\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28cfbbeb-a8d6-4ee3-a1e9-98440104f689,timestamp:1697087812\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28cfbbeb-a8d6-4ee3-a1e9-98440104f689,timestamp:1697087812\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,192 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,192 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f224f99-9321-459d-b0b7-705df1cecc59,timestamp:1697087814\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1659\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,192 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,192 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f224f99-9321-459d-b0b7-705df1cecc59,timestamp:1697087814\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1659\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2397e625-07b2-4f88-af12-a2d8506fcf65,timestamp:1697087815\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2397e625-07b2-4f88-af12-a2d8506fcf65,timestamp:1697087815\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dc044fd2-2112-494b-9929-7915c7eae9e0,timestamp:1697087818\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dc044fd2-2112-494b-9929-7915c7eae9e0,timestamp:1697087818\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ae8a6e7-feb4-4b3e-8c86-8e4623a0f59b,timestamp:1697087819\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ae8a6e7-feb4-4b3e-8c86-8e4623a0f59b,timestamp:1697087819\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2189573c-0273-429f-92f6-59eb3ffea5b1,timestamp:1697087820\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2189573c-0273-429f-92f6-59eb3ffea5b1,timestamp:1697087820\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fae3de92-c01f-4a57-a9da-6d18879de1fe,timestamp:1697087822\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,274 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,274 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fae3de92-c01f-4a57-a9da-6d18879de1fe,timestamp:1697087822\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,274 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,274 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0188094f-d2a8-4344-9bf6-b6e7eed8fc50,timestamp:1697087823\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0188094f-d2a8-4344-9bf6-b6e7eed8fc50,timestamp:1697087823\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,832 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:639e4dd7-4dc6-41d5-b8ee-5e6844bf1b37,timestamp:1697087824\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,832 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:639e4dd7-4dc6-41d5-b8ee-5e6844bf1b37,timestamp:1697087824\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:17:07,449 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,449 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a645f394-2695-437b-a154-39d6fd723fa1,timestamp:1697087827\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1345\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,449 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,449 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a645f394-2695-437b-a154-39d6fd723fa1,timestamp:1697087827\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1345\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,889 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1437\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a03e327-1e05-4b9d-8041-6b9cef507d01,timestamp:1697087828\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,889 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1437\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a03e327-1e05-4b9d-8041-6b9cef507d01,timestamp:1697087828\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b63982d9-ddf7-482f-8d37-e7c6bed07bf9,timestamp:1697087830\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b63982d9-ddf7-482f-8d37-e7c6bed07bf9,timestamp:1697087830\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1378.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:96b01126-28da-430d-a03d-d0138aadaf14,timestamp:1697087831\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1378.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:96b01126-28da-430d-a03d-d0138aadaf14,timestamp:1697087831\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:984895a8-24b9-4d6e-8156-3786bfa5d6f9,timestamp:1697087832\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,919 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,919 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:984895a8-24b9-4d6e-8156-3786bfa5d6f9,timestamp:1697087832\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,919 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,919 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1694\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1693.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5724ae57-05a9-44ce-9268-bb69cbce7c3a,timestamp:1697087834\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1694\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1694\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1693.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5724ae57-05a9-44ce-9268-bb69cbce7c3a,timestamp:1697087834\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1694\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:435d4ec0-63e5-4015-a929-7b1d95175c1d,timestamp:1697087837\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:435d4ec0-63e5-4015-a929-7b1d95175c1d,timestamp:1697087837\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.312950134277344|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.552181243896484|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12894.83203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2507.5|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,621 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1475\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,621 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1475.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2b258ab-85ea-43a1-91bc-81c373de1263,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1477\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.312950134277344|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.552181243896484|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12894.83203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2507.5|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,621 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1475\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,621 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1475.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2b258ab-85ea-43a1-91bc-81c373de1263,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1477\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:839af777-36eb-43ce-97c2-3d6ec86c3907,timestamp:1697087839\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:839af777-36eb-43ce-97c2-3d6ec86c3907,timestamp:1697087839\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:81fb5250-ab18-4885-a5a5-9ccc7b7809a4,timestamp:1697087841\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:81fb5250-ab18-4885-a5a5-9ccc7b7809a4,timestamp:1697087841\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:25abdb04-f861-4e91-9031-d1d9a29e26b3,timestamp:1697087842\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:25abdb04-f861-4e91-9031-d1d9a29e26b3,timestamp:1697087842\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:965acc10-b329-4de2-a10a-57f3cf103e3f,timestamp:1697087843\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:965acc10-b329-4de2-a10a-57f3cf103e3f,timestamp:1697087843\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,121 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2f6b4956-1423-4f15-a293-36b0f7cb8814,timestamp:1697087845\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,121 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2f6b4956-1423-4f15-a293-36b0f7cb8814,timestamp:1697087845\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e735cfea-deac-4a54-a5b6-e5e86c8df0f8,timestamp:1697087846\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e735cfea-deac-4a54-a5b6-e5e86c8df0f8,timestamp:1697087846\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:afe8d165-0bc4-4080-aed8-ee8bc751af5c,timestamp:1697087847\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:afe8d165-0bc4-4080-aed8-ee8bc751af5c,timestamp:1697087847\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,939 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,939 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2b01eca-0513-40d2-b619-431009b86f98,timestamp:1697087848\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,939 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,939 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2b01eca-0513-40d2-b619-431009b86f98,timestamp:1697087848\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a91177c7-e2b9-414b-86ee-51a333451c3f,timestamp:1697087850\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a91177c7-e2b9-414b-86ee-51a333451c3f,timestamp:1697087850\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08906958-c6e4-4a48-bd84-2fbb7befe05d,timestamp:1697087851\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08906958-c6e4-4a48-bd84-2fbb7befe05d,timestamp:1697087851\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,680 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,680 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5b09b1c4-7e5c-405c-a2ea-52aeaa21677a,timestamp:1697087852\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,680 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,680 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5b09b1c4-7e5c-405c-a2ea-52aeaa21677a,timestamp:1697087852\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e8cd6a3f-f16c-4177-b2d6-e3f16a52c8d7,timestamp:1697087853\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e8cd6a3f-f16c-4177-b2d6-e3f16a52c8d7,timestamp:1697087853\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc8d1bb4-92dd-4b37-90d1-04728055a328,timestamp:1697087855\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,211 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,211 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc8d1bb4-92dd-4b37-90d1-04728055a328,timestamp:1697087855\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,211 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,211 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1457.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:04b14e9b-02b0-4d0a-87e8-587a9b5ff8de,timestamp:1697087856\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1457.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:04b14e9b-02b0-4d0a-87e8-587a9b5ff8de,timestamp:1697087856\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1363\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57b3a0a8-29ae-448f-aed3-368ae6b0d31c,timestamp:1697087858\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1363\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1363\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57b3a0a8-29ae-448f-aed3-368ae6b0d31c,timestamp:1697087858\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1363\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,037 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,037 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,037 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,037 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0aefff40-a8a0-4900-bb96-bd4eddd4f392,timestamp:1697087859\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0aefff40-a8a0-4900-bb96-bd4eddd4f392,timestamp:1697087859\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:83a4fd32-e37f-4ee8-b0bc-b0c9cec651f4,timestamp:1697087860\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:83a4fd32-e37f-4ee8-b0bc-b0c9cec651f4,timestamp:1697087860\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:608d13f2-000b-4afb-9a77-246fb7e09098,timestamp:1697087863\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:608d13f2-000b-4afb-9a77-246fb7e09098,timestamp:1697087863\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:269ab13a-586c-4769-81d6-aaace2ec4921,timestamp:1697087864\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:269ab13a-586c-4769-81d6-aaace2ec4921,timestamp:1697087864\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1503\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1503\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:65b4b798-49bc-474b-828f-016d4a8fa767,timestamp:1697087865\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1503\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1503\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:65b4b798-49bc-474b-828f-016d4a8fa767,timestamp:1697087865\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1232\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:04676a2d-62ee-464a-9a13-5089ad725f82,timestamp:1697087867\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1232\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:04676a2d-62ee-464a-9a13-5089ad725f82,timestamp:1697087867\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e770adc5-ec9b-48d7-af92-6370a9cd90c9,timestamp:1697087868\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e770adc5-ec9b-48d7-af92-6370a9cd90c9,timestamp:1697087868\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:11ed91e5-37d7-4d28-8f77-ad2655b69e6a,timestamp:1697087869\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:11ed91e5-37d7-4d28-8f77-ad2655b69e6a,timestamp:1697087869\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,433 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1651\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,433 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1650.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a0c454ab-d0e7-47d6-8bab-e705d29dd805,timestamp:1697087871\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1652\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,433 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1651\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,433 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1650.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a0c454ab-d0e7-47d6-8bab-e705d29dd805,timestamp:1697087871\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1652\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:838c3bdd-83b6-4ca6-8f3e-5485004c2a5a,timestamp:1697087873\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,923 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,923 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:838c3bdd-83b6-4ca6-8f3e-5485004c2a5a,timestamp:1697087873\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,923 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,923 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1cd27295-dfed-41c2-bea1-56070aefd6ee,timestamp:1697087875\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1cd27295-dfed-41c2-bea1-56070aefd6ee,timestamp:1697087875\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9fe97bd1-e2f2-4ef6-b923-733a9005fd5c,timestamp:1697087876\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9fe97bd1-e2f2-4ef6-b923-733a9005fd5c,timestamp:1697087876\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc416bd0-9787-4a5f-82e7-4e349103aa51,timestamp:1697087877\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc416bd0-9787-4a5f-82e7-4e349103aa51,timestamp:1697087877\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:059e1c46-2765-4316-99d6-e0126faca6d2,timestamp:1697087878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:059e1c46-2765-4316-99d6-e0126faca6d2,timestamp:1697087878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f55777d7-d5ba-47b6-abc1-ff14c07132f6,timestamp:1697087880\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f55777d7-d5ba-47b6-abc1-ff14c07132f6,timestamp:1697087880\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47135382-345f-4bbe-83ae-77c1a065451c,timestamp:1697087881\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,402 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,402 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47135382-345f-4bbe-83ae-77c1a065451c,timestamp:1697087881\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,402 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,402 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59901cb1-d1de-468f-8e9d-442b6926ce9e,timestamp:1697087884\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59901cb1-d1de-468f-8e9d-442b6926ce9e,timestamp:1697087884\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07f765aa-9199-4458-9d67-1b1ceee66970,timestamp:1697087885\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07f765aa-9199-4458-9d67-1b1ceee66970,timestamp:1697087885\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d6ebe126-5b7e-47cf-b111-413304ac2ce5,timestamp:1697087886\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d6ebe126-5b7e-47cf-b111-413304ac2ce5,timestamp:1697087886\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e63f653-7797-4a8f-bc5a-2e5736230620,timestamp:1697087889\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e63f653-7797-4a8f-bc5a-2e5736230620,timestamp:1697087889\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,781 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,781 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1521.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7158761c-b7af-4cf5-9215-ca63762b94f9,timestamp:1697087890\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,781 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,781 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1521.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7158761c-b7af-4cf5-9215-ca63762b94f9,timestamp:1697087890\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,049 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ec5bda25-db88-4c67-9ab9-ecd5e96a94fe,timestamp:1697087892\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,049 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ec5bda25-db88-4c67-9ab9-ecd5e96a94fe,timestamp:1697087892\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,309 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,309 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1146140e-7853-4956-bb69-85f269ed222f,timestamp:1697087893\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,309 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,309 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1146140e-7853-4956-bb69-85f269ed222f,timestamp:1697087893\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20116023-5926-4602-b4a9-9177c12835a2,timestamp:1697087894\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20116023-5926-4602-b4a9-9177c12835a2,timestamp:1697087894\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:887386e9-6480-40aa-b288-66705318d208,timestamp:1697087895\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:887386e9-6480-40aa-b288-66705318d208,timestamp:1697087895\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d369dccd-5f0b-4e76-b738-8d6944a06ea9,timestamp:1697087897\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d369dccd-5f0b-4e76-b738-8d6944a06ea9,timestamp:1697087897\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31283187866211|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.552299499511719|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12894.546875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2507.78515625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:40e310a8-5f2b-4dea-a5b8-f1dd32baef8e,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31283187866211|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.552299499511719|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12894.546875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2507.78515625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:40e310a8-5f2b-4dea-a5b8-f1dd32baef8e,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61a40967-1a91-4d36-af51-f5b687f06d3d,timestamp:1697087899\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61a40967-1a91-4d36-af51-f5b687f06d3d,timestamp:1697087899\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c3de5c59-fae0-45ba-9334-3c1d1f47171d,timestamp:1697087901\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c3de5c59-fae0-45ba-9334-3c1d1f47171d,timestamp:1697087901\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ecddf5bb-9201-4a6a-805a-bbefa1ad7ac7,timestamp:1697087902\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ecddf5bb-9201-4a6a-805a-bbefa1ad7ac7,timestamp:1697087902\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43c6565d-5406-40a8-bd33-86e7760aa17e,timestamp:1697087905\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43c6565d-5406-40a8-bd33-86e7760aa17e,timestamp:1697087905\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:91ece376-10af-40a5-8a7d-84f63f5d9136,timestamp:1697087906\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:91ece376-10af-40a5-8a7d-84f63f5d9136,timestamp:1697087906\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1633\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1634\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1632.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:15024581-73a3-4fe5-b562-8b6bfcebe822,timestamp:1697087908\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1633\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1634\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1632.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:15024581-73a3-4fe5-b562-8b6bfcebe822,timestamp:1697087908\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1433\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1434\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,122 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,122 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1433.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e932131-2242-4c8a-894b-ba745085d2b9,timestamp:1697087911\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1433\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1434\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,122 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,122 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1433.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e932131-2242-4c8a-894b-ba745085d2b9,timestamp:1697087911\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,361 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,361 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,361 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cf585de-8d56-4853-b53b-4da6a526de1f,timestamp:1697087912\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,361 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cf585de-8d56-4853-b53b-4da6a526de1f,timestamp:1697087912\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:192a12f7-dba4-4044-ac5a-e832c8bf26b0,timestamp:1697087913\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,589 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,589 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:192a12f7-dba4-4044-ac5a-e832c8bf26b0,timestamp:1697087913\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,589 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,589 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fa0de70e-fdc0-48e5-b352-9ad96269e52f,timestamp:1697087914\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fa0de70e-fdc0-48e5-b352-9ad96269e52f,timestamp:1697087914\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:01749e53-91a5-4196-ad32-a1b5b86cf244,timestamp:1697087916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:01749e53-91a5-4196-ad32-a1b5b86cf244,timestamp:1697087916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb5cea71-6eec-466c-b8f5-2a556da38a09,timestamp:1697087917\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb5cea71-6eec-466c-b8f5-2a556da38a09,timestamp:1697087917\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bf82df74-4816-477c-87cf-6235f5869579,timestamp:1697087918\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bf82df74-4816-477c-87cf-6235f5869579,timestamp:1697087918\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d23a02eb-b2d4-4d48-83fe-31bd1fe3ba82,timestamp:1697087921\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d23a02eb-b2d4-4d48-83fe-31bd1fe3ba82,timestamp:1697087921\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c76e07b-8c9d-44d6-8dfe-6794a5568a2e,timestamp:1697087922\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,428 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,428 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c76e07b-8c9d-44d6-8dfe-6794a5568a2e,timestamp:1697087922\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,428 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,428 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:01b484a5-c989-41b9-8b69-819b15bf7b10,timestamp:1697087923\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:01b484a5-c989-41b9-8b69-819b15bf7b10,timestamp:1697087923\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:eb268527-f0d9-4503-85ff-6a8d0b05c833,timestamp:1697087924\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:eb268527-f0d9-4503-85ff-6a8d0b05c833,timestamp:1697087924\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62c870b9-1247-4052-bdb1-1abc66c587e2,timestamp:1697087926\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62c870b9-1247-4052-bdb1-1abc66c587e2,timestamp:1697087926\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m2023-10-12 05:01:15,695 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:15,695 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[35mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[35mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 2998 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:15,728 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[35mMax heap size: 2998 M\u001b[0m\n",
      "\u001b[35mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mInitial Models: model.mar\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 4\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[35mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[35mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[35mEnable metrics API: true\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:15,728 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,356 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 4987601e1651435ba0251a7cbec44e5d\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,365 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,395 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,356 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag 4987601e1651435ba0251a7cbec44e5d\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,365 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,395 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,588 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,589 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,589 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,591 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,608 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,610 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,612 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]49\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,626 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,626 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,629 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,631 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,631 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,588 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,589 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,589 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,591 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,608 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,610 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,612 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]49\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,613 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,626 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,626 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,629 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,630 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,630 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,631 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,630 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,631 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,651 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,651 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,656 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,657 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,657 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,657 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,657 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,994 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:32822 \"GET /ping HTTP/1.1\" 200 77\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:17,997 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,120 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:32830 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,134 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,347 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,348 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.59849548339844|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,349 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.26663589477539|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,351 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,358 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14146.2265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,359 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1256.06640625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:18,360 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.1|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,651 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,651 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,656 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,657 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,657 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,657 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,657 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,994 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:32822 \"GET /ping HTTP/1.1\" 200 77\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:17,997 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,120 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:32830 \"GET /execution-parameters HTTP/1.1\" 404 1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,134 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,347 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,348 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.59849548339844|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,349 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.26663589477539|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,351 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,358 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:14146.2265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,359 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1256.06640625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:18,360 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.1|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:19,283 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:19,296 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:19,311 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:19,374 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:19,283 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:19,296 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:19,311 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:19,374 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,918 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,918 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,930 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,942 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,947 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,958 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:20,969 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,032 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,050 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,930 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,942 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,947 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,958 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:20,969 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,032 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,050 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[32m2023-10-12T05:01:18.158:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,838 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,846 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:21,913 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,179 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,185 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,195 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,306 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,838 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,846 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:21,913 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,179 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,185 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,195 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,306 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,311 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,311 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,319 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,319 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,351 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,353 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,354 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,351 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,353 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,354 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,817 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:22,827 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,014 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,040 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,044 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,046 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,092 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,094 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,206 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,209 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,211 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,212 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,373 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,817 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:22,827 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,014 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,040 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,044 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,046 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,092 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,094 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,206 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,209 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,211 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,212 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,373 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,380 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,390 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,380 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,390 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,415 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,448 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,451 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,468 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,525 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,531 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,565 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,569 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,572 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,574 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,576 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,725 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,728 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,788 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,415 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,448 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,451 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,468 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,525 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,531 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,565 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,569 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,572 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,574 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,576 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,725 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,728 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,788 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,792 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,798 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,801 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:23,804 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:24,240 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,792 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,798 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,801 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:23,804 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:24,240 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,016 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,024 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,060 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,061 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,066 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,223 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,226 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,346 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,350 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,016 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,024 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,060 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,061 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,066 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,223 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,226 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,346 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,350 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,756 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:25,760 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,756 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:25,760 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,494 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,499 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,563 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,567 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,703 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,707 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,716 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,717 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,863 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,866 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,870 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,872 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,899 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,913 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,979 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:26,984 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,012 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,017 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,034 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,078 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,081 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,089 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,099 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,130 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,133 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,138 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,147 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,177 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,181 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,186 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,194 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,273 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,278 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,346 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,349 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,494 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,499 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,563 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,567 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,703 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,707 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,716 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,717 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,863 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,866 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,870 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,872 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,899 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,913 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,979 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:26,984 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,012 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,017 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,034 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,078 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,081 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,089 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,099 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,130 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,133 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,138 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,147 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,177 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,181 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,186 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,194 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,273 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,278 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,346 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,349 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,367 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,368 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,370 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,371 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,403 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,405 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,407 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,408 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,409 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,410 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,411 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,367 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,368 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,370 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,371 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,403 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,405 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,407 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,408 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,409 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,410 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,411 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,458 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,459 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,461 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,463 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,468 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,472 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,474 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,494 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,531 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,532 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,534 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,536 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,591 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,650 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,658 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,672 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,677 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,458 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,459 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,461 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,463 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,468 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,472 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,474 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,494 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,531 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,532 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,534 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,536 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,591 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,650 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,658 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,672 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,677 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,680 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,683 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,693 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,697 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,700 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,701 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,708 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,711 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,714 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,732 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,733 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,812 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,814 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,818 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,837 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:27,838 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,680 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,683 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,693 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,697 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,700 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,701 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,708 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,711 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,714 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,732 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,733 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,812 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,814 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,818 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,837 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:27,838 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,411 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,415 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,415 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,419 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,411 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,415 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,415 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,419 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,443 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,447 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,447 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,930 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,931 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,932 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,935 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,943 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,950 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,950 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:29,955 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,335 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,394 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,443 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,447 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,447 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,930 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,931 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,932 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,935 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,943 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,950 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=8dc0a322725df37303ce6e6ce73419ab15463add385a0a1a962e79015b46a71e\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,950 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:29,955 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,335 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,394 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,543 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,544 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,550 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Uninstalling packaging-20.4:\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,558 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -       Successfully uninstalled packaging-20.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,599 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,601 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,601 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:30,994 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:31,008 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:31,201 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:31,203 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:31,204 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:31,208 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:31,209 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:31,210 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,543 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,544 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,550 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Uninstalling packaging-20.4:\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,558 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -       Successfully uninstalled packaging-20.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,599 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,601 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,601 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:30,994 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:31,008 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:31,201 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:31,203 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:31,204 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:31,208 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:31,209 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:31,210 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:32,101 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.6/site-packages/transformers/models/splinter/configuration_splinter.py'\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:32,101 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: '/opt/conda/lib/python3.6/site-packages/transformers/models/splinter/configuration_splinter.py'\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:33,636 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:33,667 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:33,952 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,093 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,103 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,128 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:33,636 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:33,667 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:33,952 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,093 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,103 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,128 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,132 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,248 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,259 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,132 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,248 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,259 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,675 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:34,727 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,675 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:34,727 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,565 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,673 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,698 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,565 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,673 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,698 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,733 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,758 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,772 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,773 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,855 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,858 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,865 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,882 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,910 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,952 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:35,958 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,053 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,061 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,151 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,154 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,173 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,177 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,733 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,758 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,772 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,773 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,855 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,858 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,865 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,882 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,910 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,952 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:35,958 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,053 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,061 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,151 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,154 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,173 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,177 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,477 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,503 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,646 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,666 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,742 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,748 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,765 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,767 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,829 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,834 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,840 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,845 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,938 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:36,941 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,477 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,503 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,646 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,666 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,742 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,748 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,765 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,767 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,829 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,834 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,840 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,845 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,938 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:36,941 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,123 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,130 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,271 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,275 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,321 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,324 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,334 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,414 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:38,418 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,123 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,130 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,271 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,275 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,321 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,324 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,334 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,414 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:38,418 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,051 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,055 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,149 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,172 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,051 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,055 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,149 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,172 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,912 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:39,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,156 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,174 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,285 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,289 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,315 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,354 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,381 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,383 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,912 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:39,915 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,156 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,174 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,285 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,289 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,315 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,354 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,381 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,383 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,521 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,528 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,542 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,646 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,651 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,732 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:40,737 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,521 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,528 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,542 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,646 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,651 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,732 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:40,737 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,119 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,131 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,137 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,148 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,193 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,194 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,206 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,232 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,233 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,234 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,301 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,310 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,312 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,326 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,331 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,412 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,429 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,119 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,131 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,137 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,148 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,193 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,194 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,206 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,232 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,233 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,234 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,301 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,310 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,312 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,326 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,331 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,412 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,429 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,432 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,432 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,489 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,506 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,606 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,613 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,619 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,622 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,664 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,669 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,746 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,749 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,769 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,772 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,776 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,806 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,824 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,899 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,926 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,944 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,948 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,954 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,957 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:41,958 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,033 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,036 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,039 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,040 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,489 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,506 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,606 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,613 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,619 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,622 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,664 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,669 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,746 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,749 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,769 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,772 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,776 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,806 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,824 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,899 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,926 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,944 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,948 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,954 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,957 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:41,958 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,033 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,036 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,039 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,040 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,067 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,071 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,147 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,150 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,181 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,184 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,263 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,266 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,429 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,067 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,071 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,147 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,150 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,181 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,184 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,263 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,266 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,429 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,446 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,484 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,486 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,487 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,512 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,519 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,557 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,560 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,563 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,566 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,446 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,484 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,486 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,487 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,512 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,519 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,557 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,560 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,563 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,566 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,572 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,628 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,630 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,632 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,670 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,699 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,702 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,705 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,706 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,712 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,713 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,725 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,731 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,734 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,800 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,801 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,802 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,805 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,842 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,847 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,853 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,902 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,904 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,917 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,920 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:42,980 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,270 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,349 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,572 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,628 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,630 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,632 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,670 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,699 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,702 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,705 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,706 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,712 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,713 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,725 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,731 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,734 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,800 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,801 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,802 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,805 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,842 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,847 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,853 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,902 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,904 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,917 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,920 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:42,980 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,270 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,349 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,350 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,361 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,386 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,387 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,388 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,350 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,361 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,386 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,387 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,388 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,478 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,481 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,552 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:43,941 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:44,085 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,478 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,481 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,552 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:43,941 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:44,085 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:44,560 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:44,867 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:44,560 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:44,867 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:45,436 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:45,436 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:46,540 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:46,540 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:46,652 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,137 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,161 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,208 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:46,652 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,137 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,161 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,208 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,478 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,479 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,479 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/847 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:47,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,068 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|| 847/847 [00:00<00:00, 582kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,069 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,180 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/140M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,289 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 33.0k/140M [00:00<08:05, 303kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,397 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 113k/140M [00:00<04:20, 563kB/s] \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,478 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,479 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,479 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/847 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:47,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,068 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|| 847/847 [00:00<00:00, 582kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,069 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,180 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/140M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,289 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 33.0k/140M [00:00<08:05, 303kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,397 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 113k/140M [00:00<04:20, 563kB/s] \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,498 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 255k/140M [00:00<02:39, 918kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,599 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 506k/140M [00:00<01:35, 1.53MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,700 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 1.00M/140M [00:00<00:51, 2.81MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,799 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|         | 1.93M/140M [00:00<00:28, 5.13MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:48,901 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|         | 3.77M/140M [00:00<00:14, 9.67MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|         | 6.60M/140M [00:00<00:08, 15.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,102 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   7%|         | 9.42M/140M [00:00<00:06, 20.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,202 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|         | 12.3M/140M [00:01<00:05, 23.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,302 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|         | 15.1M/140M [00:01<00:05, 25.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,404 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|        | 17.9M/140M [00:01<00:04, 26.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,498 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 255k/140M [00:00<02:39, 918kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,599 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 506k/140M [00:00<01:35, 1.53MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,700 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 1.00M/140M [00:00<00:51, 2.81MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,799 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|         | 1.93M/140M [00:00<00:28, 5.13MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:48,901 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   3%|         | 3.77M/140M [00:00<00:14, 9.67MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,001 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   5%|         | 6.60M/140M [00:00<00:08, 15.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,102 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   7%|         | 9.42M/140M [00:00<00:06, 20.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,202 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   9%|         | 12.3M/140M [00:01<00:05, 23.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,302 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  11%|         | 15.1M/140M [00:01<00:05, 25.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,404 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  13%|        | 17.9M/140M [00:01<00:04, 26.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,504 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|        | 20.5M/140M [00:01<00:04, 26.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,604 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|        | 23.3M/140M [00:01<00:04, 27.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,705 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|        | 26.1M/140M [00:01<00:04, 27.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,805 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  21%|        | 28.9M/140M [00:01<00:04, 28.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:49,905 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  23%|       | 31.7M/140M [00:01<00:03, 28.7MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,005 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|       | 34.5M/140M [00:01<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,106 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|       | 37.3M/140M [00:01<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,206 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|       | 40.1M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,306 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|       | 43.0M/140M [00:02<00:03, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,406 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|      | 45.8M/140M [00:02<00:03, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,504 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  15%|        | 20.5M/140M [00:01<00:04, 26.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,604 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  17%|        | 23.3M/140M [00:01<00:04, 27.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,705 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  19%|        | 26.1M/140M [00:01<00:04, 27.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,805 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  21%|        | 28.9M/140M [00:01<00:04, 28.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:49,905 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  23%|       | 31.7M/140M [00:01<00:03, 28.7MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,005 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  25%|       | 34.5M/140M [00:01<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,106 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  27%|       | 37.3M/140M [00:01<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,206 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  29%|       | 40.1M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,306 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  31%|       | 43.0M/140M [00:02<00:03, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,406 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  33%|      | 45.8M/140M [00:02<00:03, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,507 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|      | 48.6M/140M [00:02<00:03, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,608 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|      | 51.4M/140M [00:02<00:03, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,708 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  39%|      | 54.3M/140M [00:02<00:03, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,808 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|      | 57.1M/140M [00:02<00:02, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:50,909 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|     | 59.9M/140M [00:02<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,009 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|     | 62.7M/140M [00:02<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,109 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|     | 65.5M/140M [00:02<00:02, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,209 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  49%|     | 68.3M/140M [00:03<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,310 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|     | 71.1M/140M [00:03<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,410 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|    | 73.9M/140M [00:03<00:02, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,507 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  35%|      | 48.6M/140M [00:02<00:03, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,608 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  37%|      | 51.4M/140M [00:02<00:03, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,708 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  39%|      | 54.3M/140M [00:02<00:03, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,808 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  41%|      | 57.1M/140M [00:02<00:02, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:50,909 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  43%|     | 59.9M/140M [00:02<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,009 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  45%|     | 62.7M/140M [00:02<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,109 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  47%|     | 65.5M/140M [00:02<00:02, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,209 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  49%|     | 68.3M/140M [00:03<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,310 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  51%|     | 71.1M/140M [00:03<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,410 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  53%|    | 73.9M/140M [00:03<00:02, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,511 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|    | 76.8M/140M [00:03<00:02, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,612 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  57%|    | 79.6M/140M [00:03<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,712 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|    | 82.4M/140M [00:03<00:02, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,812 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|    | 85.2M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:51,913 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|   | 88.0M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,013 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|   | 90.8M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,113 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|   | 93.6M/140M [00:03<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,214 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  69%|   | 96.5M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,314 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|   | 99.3M/140M [00:04<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,415 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|  | 102M/140M [00:04<00:01, 29.4MB/s] \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,511 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  55%|    | 76.8M/140M [00:03<00:02, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,612 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  57%|    | 79.6M/140M [00:03<00:02, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,712 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  59%|    | 82.4M/140M [00:03<00:02, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,812 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  61%|    | 85.2M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:51,913 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  63%|   | 88.0M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,013 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  65%|   | 90.8M/140M [00:03<00:01, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,113 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  67%|   | 93.6M/140M [00:03<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,214 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  69%|   | 96.5M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,314 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  71%|   | 99.3M/140M [00:04<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,415 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  73%|  | 102M/140M [00:04<00:01, 29.4MB/s] \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,515 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|  | 105M/140M [00:04<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,616 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  77%|  | 108M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,716 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|  | 111M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,817 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|  | 113M/140M [00:04<00:00, 29.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:52,917 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  83%| | 116M/140M [00:04<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,017 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  85%| | 119M/140M [00:04<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,117 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  87%| | 122M/140M [00:04<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,218 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  89%| | 125M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,318 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  91%| | 127M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,419 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  93%|| 130M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,515 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  75%|  | 105M/140M [00:04<00:01, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,616 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  77%|  | 108M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,716 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  79%|  | 111M/140M [00:04<00:01, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,817 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  81%|  | 113M/140M [00:04<00:00, 29.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:52,917 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  83%| | 116M/140M [00:04<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,017 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  85%| | 119M/140M [00:04<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,117 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  87%| | 122M/140M [00:04<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,218 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  89%| | 125M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,318 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  91%| | 127M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,419 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  93%|| 130M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,519 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|| 133M/140M [00:05<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,619 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|| 136M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,519 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  95%|| 133M/140M [00:05<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,619 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  97%|| 136M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:53,668 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  99%|| 139M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:53,668 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  99%|| 139M/140M [00:05<00:00, 29.4MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,283 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,284 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,284 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,286 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,286 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,283 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,284 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,284 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,286 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,286 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,444 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,444 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|| 140M/140M [00:05<00:00, 26.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,066 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.dense.weight']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,066 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,067 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,071 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,071 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,445 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|| 140M/140M [00:05<00:00, 26.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:55,791 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,066 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.dense.weight']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,066 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,067 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,071 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,071 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,657 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38914\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,658 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:39282|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,659 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:78|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,829 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39088\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,829 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:39455|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,831 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:76|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39137\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,657 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38914\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,658 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:39282|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,659 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:78|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,829 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39088\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,829 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:39455|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,831 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:76|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39137\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:39506|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:79|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,944 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39217\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,944 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:39568|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:56,945 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:61|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:57,188 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:57,381 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:57,383 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  88%| | 200k/226k [00:00<00:00, 1.06MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:39506|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,883 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:79|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,944 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39217\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,944 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:39568|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:56,945 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:61|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:57,188 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:57,381 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:57,383 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  88%| | 200k/226k [00:00<00:00, 1.06MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,626 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,626 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1966\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 40161\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1965.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26c4677a-24e0-4ad5-a2e9-aa23ba715705,timestamp:1697086918\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,628 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:38185|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:01:58,628 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,626 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,626 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1966\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 40161\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,627 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1965.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26c4677a-24e0-4ad5-a2e9-aa23ba715705,timestamp:1697086918\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,628 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:38185|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:01:58,628 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:00,453 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1771\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:00,453 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:00,454 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1773\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:00,454 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:00,454 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1770.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7e4ac9fb-242a-46aa-b399-74e7119e3084,timestamp:1697086920\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:00,455 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:00,455 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:00,453 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1771\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:00,453 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:00,454 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1773\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:00,454 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:00,454 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1770.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7e4ac9fb-242a-46aa-b399-74e7119e3084,timestamp:1697086920\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:00,455 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:00,455 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e73e9071-5549-4a50-a5b9-23995ed89a0b,timestamp:1697086921\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,796 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:01,796 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e73e9071-5549-4a50-a5b9-23995ed89a0b,timestamp:1697086921\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,795 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,796 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:01,796 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,155 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ae797469-7be7-4bde-8c80-cdad52d2a7dc,timestamp:1697086923\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,157 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:03,157 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,155 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ae797469-7be7-4bde-8c80-cdad52d2a7dc,timestamp:1697086923\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,156 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,157 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:03,157 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ad45f378-c13c-4df5-ae3c-7df5472ef98e,timestamp:1697086924\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,387 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ad45f378-c13c-4df5-ae3c-7df5472ef98e,timestamp:1697086924\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,386 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,387 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:04,387 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:04,387 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30f52137-55b9-4391-b99d-5a6dc978fa2c,timestamp:1697086925\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,655 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:05,655 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30f52137-55b9-4391-b99d-5a6dc978fa2c,timestamp:1697086925\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,654 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,655 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:05,655 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f544ee5-bd4c-44c0-a4b6-5768a19b67e4,timestamp:1697086926\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f544ee5-bd4c-44c0-a4b6-5768a19b67e4,timestamp:1697086926\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:06,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,924 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:06,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,232 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ffc4f501-d465-47dc-aa81-b64bebf90e05,timestamp:1697086928\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,232 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,232 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ffc4f501-d465-47dc-aa81-b64bebf90e05,timestamp:1697086928\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,232 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:08,233 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,553 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,553 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1313.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d544b1e7-0a03-44e0-a681-02665adc39d2,timestamp:1697086929\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,553 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,553 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:09,552 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1313.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d544b1e7-0a03-44e0-a681-02665adc39d2,timestamp:1697086929\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:10,865 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cdf4960-d35f-4366-a7ff-1b6d269301a1,timestamp:1697086930\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:10,865 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:10,866 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:10,866 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:10,866 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:10,866 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:10,865 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cdf4960-d35f-4366-a7ff-1b6d269301a1,timestamp:1697086930\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:10,865 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:10,866 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:10,866 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:10,866 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:10,866 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,625 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1753.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9cae691c-bb3b-4343-b4e2-87141dc64462,timestamp:1697086932\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,625 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1754\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1756\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,625 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1753.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9cae691c-bb3b-4343-b4e2-87141dc64462,timestamp:1697086932\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,625 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1754\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1756\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:12,626 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:913e15b0-634b-4d94-9fed-9e27cee2c0d8,timestamp:1697086933\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:13,912 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:913e15b0-634b-4d94-9fed-9e27cee2c0d8,timestamp:1697086933\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,911 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:13,912 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,267 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2cebb42f-dc6a-4a61-8712-62aa724f6fa4,timestamp:1697086935\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,267 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1352\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,267 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2cebb42f-dc6a-4a61-8712-62aa724f6fa4,timestamp:1697086935\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,267 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1352\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:15,268 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3279208c-af19-4018-8bb5-aac511e5dea0,timestamp:1697086936\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3279208c-af19-4018-8bb5-aac511e5dea0,timestamp:1697086936\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:16,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1331\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1330.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aee640fd-2324-4eb0-b221-61f171f589f0,timestamp:1697086937\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,873 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:17,873 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,263 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31464767456055|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.550483703613281|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12950.546875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2451.76953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1331\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1330.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aee640fd-2324-4eb0-b221-61f171f589f0,timestamp:1697086937\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,872 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,873 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:17,873 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,263 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31464767456055|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.550483703613281|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12950.546875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2451.76953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:18,264 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086938\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:644c7cc9-0e1b-4c51-8ccc-0d2ea91b2b55,timestamp:1697086939\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,135 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:19,135 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:644c7cc9-0e1b-4c51-8ccc-0d2ea91b2b55,timestamp:1697086939\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,134 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,135 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:19,135 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1378.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18388e8b-5780-478f-b2e7-dbdc8e0b7e84,timestamp:1697086940\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1378.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18388e8b-5780-478f-b2e7-dbdc8e0b7e84,timestamp:1697086940\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,518 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:20,519 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:21,804 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:21,804 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9244bdb9-fb96-4724-8730-7d83543f02a4,timestamp:1697086941\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:21,805 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:21,805 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:21,804 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:21,804 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9244bdb9-fb96-4724-8730-7d83543f02a4,timestamp:1697086941\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:21,805 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:21,805 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:21,805 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:21,805 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:21,805 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:21,805 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,195 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1381\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,195 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1384.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8722b274-8552-4ca6-a0c0-e057134578cf,timestamp:1697086943\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1387\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,195 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1381\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,195 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1384.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8722b274-8552-4ca6-a0c0-e057134578cf,timestamp:1697086943\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1387\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:23,196 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:da9cf7a2-b39f-4175-a110-97f0691f3f36,timestamp:1697086944\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:24,455 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:da9cf7a2-b39f-4175-a110-97f0691f3f36,timestamp:1697086944\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,454 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:24,455 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a0617a94-fb37-452c-82c3-f883c1898b36,timestamp:1697086945\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:25,729 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a0617a94-fb37-452c-82c3-f883c1898b36,timestamp:1697086945\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,728 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:25,729 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39a62958-875c-4ad2-93ba-973128af4c4f,timestamp:1697086947\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39a62958-875c-4ad2-93ba-973128af4c4f,timestamp:1697086947\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:27,015 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,693 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bb7d2602-6fba-43cb-ab6b-f9fe97043428,timestamp:1697086948\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,693 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1674\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,693 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bb7d2602-6fba-43cb-ab6b-f9fe97043428,timestamp:1697086948\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,693 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1674\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:28,694 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b54d1009-c77a-4e15-9170-469529b7a7c5,timestamp:1697086949\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,964 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:29,964 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,963 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b54d1009-c77a-4e15-9170-469529b7a7c5,timestamp:1697086949\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,964 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:29,964 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:81b93081-790c-48ff-a0d9-95eec5d35a40,timestamp:1697086951\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,235 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:31,235 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:81b93081-790c-48ff-a0d9-95eec5d35a40,timestamp:1697086951\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,234 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,235 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:31,235 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0cfeb9be-9858-4af7-b27f-171a2b95c4d6,timestamp:1697086952\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0cfeb9be-9858-4af7-b27f-171a2b95c4d6,timestamp:1697086952\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:32,561 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd78387c-17aa-4e06-99f0-0fc4a45a764d,timestamp:1697086953\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,858 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:33,858 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd78387c-17aa-4e06-99f0-0fc4a45a764d,timestamp:1697086953\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,857 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,858 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:33,858 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,211 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1348.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:90c67b42-581c-46dc-8f70-5fbcc7eb5cec,timestamp:1697086955\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,211 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1350\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,211 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1348.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:90c67b42-581c-46dc-8f70-5fbcc7eb5cec,timestamp:1697086955\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,211 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1350\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:35,212 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d3b19eab-990e-4598-b108-78dc35537579,timestamp:1697086956\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:36,520 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d3b19eab-990e-4598-b108-78dc35537579,timestamp:1697086956\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,519 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:36,520 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2d84932-42d8-4312-b292-874336eaad40,timestamp:1697086957\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2d84932-42d8-4312-b292-874336eaad40,timestamp:1697086957\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:37,757 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1403.68|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8d1a2842-5519-4d80-adf2-ebe3fc98e162,timestamp:1697086959\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1405\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,167 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,167 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:39,168 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1403.68|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8d1a2842-5519-4d80-adf2-ebe3fc98e162,timestamp:1697086959\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1405\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,167 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,167 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:39,168 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,423 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7bc43cb2-a01f-40ce-9901-6fb9e7f08554,timestamp:1697086960\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,423 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,423 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7bc43cb2-a01f-40ce-9901-6fb9e7f08554,timestamp:1697086960\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,423 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:40,424 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:97e47df2-0c88-46b2-8680-852646681a27,timestamp:1697086961\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:97e47df2-0c88-46b2-8680-852646681a27,timestamp:1697086961\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:41,692 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1438\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:43,135 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:43,135 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2191c6fd-d683-46b6-8fb9-e0ad7c9083db,timestamp:1697086963\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1438\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,135 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,135 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:43,134 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2191c6fd-d683-46b6-8fb9-e0ad7c9083db,timestamp:1697086963\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,699 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1560\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,699 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1559.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:495dc2a3-bc2b-4868-9960-1e4b0596ece3,timestamp:1697086964\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1561\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,699 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1560\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,699 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1559.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:495dc2a3-bc2b-4868-9960-1e4b0596ece3,timestamp:1697086964\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1561\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:44,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1411.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:35f913f9-ab74-48a7-bd92-f2ec85cecad9,timestamp:1697086966\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1413\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,118 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:46,118 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1411.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:35f913f9-ab74-48a7-bd92-f2ec85cecad9,timestamp:1697086966\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1413\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,117 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,118 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:46,118 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,408 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1aa8a5df-6c22-4223-95d3-fecd11308e08,timestamp:1697086967\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,408 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1aa8a5df-6c22-4223-95d3-fecd11308e08,timestamp:1697086967\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:47,409 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,674 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:48,674 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7422de9-0dc2-45cc-bdc4-7b69be89ef60,timestamp:1697086968\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,674 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,675 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:48,674 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7422de9-0dc2-45cc-bdc4-7b69be89ef60,timestamp:1697086968\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,958 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:49,958 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4d3a36c-428c-42d5-932a-0f0eede5b9fd,timestamp:1697086969\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,958 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,959 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:49,958 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4d3a36c-428c-42d5-932a-0f0eede5b9fd,timestamp:1697086969\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,286 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:56391c5a-cd03-4c20-9bf4-465afbf31a9c,timestamp:1697086971\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,286 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,286 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:56391c5a-cd03-4c20-9bf4-465afbf31a9c,timestamp:1697086971\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,286 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:51,287 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5644507-6303-4c66-a82e-91618f182816,timestamp:1697086972\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:52,551 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5644507-6303-4c66-a82e-91618f182816,timestamp:1697086972\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,550 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:52,551 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:53,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:00def3c6-cd4b-4fed-98e9-fc67b94e0519,timestamp:1697086973\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:53,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1232\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:53,788 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:53,788 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:53,788 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:53,788 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:53,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:00def3c6-cd4b-4fed-98e9-fc67b94e0519,timestamp:1697086973\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:53,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1232\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:53,788 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:53,788 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:53,788 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:53,788 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,049 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61f6f3ef-1a0d-4443-b75d-2fbc4abf8bc6,timestamp:1697086975\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,050 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,050 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,051 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,051 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:55,052 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,049 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61f6f3ef-1a0d-4443-b75d-2fbc4abf8bc6,timestamp:1697086975\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,050 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,050 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,051 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,051 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:55,052 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4273f14d-9fd6-461a-8fbd-d20ad8dd6498,timestamp:1697086976\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4273f14d-9fd6-461a-8fbd-d20ad8dd6498,timestamp:1697086976\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:56,331 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,612 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20f5e780-017c-40f9-a9fe-af7cc0f7b251,timestamp:1697086977\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,612 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20f5e780-017c-40f9-a9fe-af7cc0f7b251,timestamp:1697086977\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:57,613 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e0515de6-4018-4a74-9681-305fadb3f7f9,timestamp:1697086978\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e0515de6-4018-4a74-9681-305fadb3f7f9,timestamp:1697086978\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:02:58,942 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aa981c9d-6110-45b4-8e33-0a82bd522c36,timestamp:1697086980\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aa981c9d-6110-45b4-8e33-0a82bd522c36,timestamp:1697086980\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:00,247 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,553 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:37233442-4364-4622-af89-b9404a160222,timestamp:1697086981\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,553 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:37233442-4364-4622-af89-b9404a160222,timestamp:1697086981\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:01,554 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1533\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1532.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46a695c1-5c15-428f-a98e-5236f96e15f7,timestamp:1697086983\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1534\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1533\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1532.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46a695c1-5c15-428f-a98e-5236f96e15f7,timestamp:1697086983\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1534\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:03,092 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1399.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:96e02498-9488-42e2-b199-dd86f3d94cd1,timestamp:1697086984\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1399.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:96e02498-9488-42e2-b199-dd86f3d94cd1,timestamp:1697086984\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:04,497 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:21c97ded-fa82-4f2c-aa31-14016aa370f2,timestamp:1697086985\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,784 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:05,784 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:21c97ded-fa82-4f2c-aa31-14016aa370f2,timestamp:1697086985\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,783 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,784 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:05,784 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,142 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1354.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:df70ac57-eb77-4ab0-873c-f2d16a0f8d86,timestamp:1697086987\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,142 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1354.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:df70ac57-eb77-4ab0-873c-f2d16a0f8d86,timestamp:1697086987\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:07,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ddb2b55b-9efb-431f-9224-ad2f720bc35a,timestamp:1697086988\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1413\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:08,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ddb2b55b-9efb-431f-9224-ad2f720bc35a,timestamp:1697086988\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1413\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,560 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:08,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,834 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:09,834 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d40483ae-140a-4c43-a53d-6eb0c8565433,timestamp:1697086989\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,834 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,835 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:09,834 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d40483ae-140a-4c43-a53d-6eb0c8565433,timestamp:1697086989\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,291 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1449.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f60d846-4f78-40c4-9440-8460edf856b4,timestamp:1697086991\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1451\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1454\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,291 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1449.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f60d846-4f78-40c4-9440-8460edf856b4,timestamp:1697086991\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1451\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1454\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:11,292 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d7a92730-4cce-40ab-847a-9dc747dabd5a,timestamp:1697086992\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d7a92730-4cce-40ab-847a-9dc747dabd5a,timestamp:1697086992\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:12,568 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c37b31fc-6854-43b5-af3f-f79b0c1e8fba,timestamp:1697086993\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,892 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:13,892 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c37b31fc-6854-43b5-af3f-f79b0c1e8fba,timestamp:1697086993\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,891 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,892 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:13,892 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:73f912ba-e740-4723-a3e5-efb146caf4d7,timestamp:1697086995\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:73f912ba-e740-4723-a3e5-efb146caf4d7,timestamp:1697086995\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:15,156 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,432 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,432 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64965965-57d6-426a-aa7a-8725d9f76bbd,timestamp:1697086996\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,432 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,432 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64965965-57d6-426a-aa7a-8725d9f76bbd,timestamp:1697086996\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:16,433 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1331\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1330.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:096c75d8-f04b-4d14-83fa-c4070c7bbdee,timestamp:1697086997\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31452941894531|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.550601959228516|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12945.0390625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2457.24609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1331\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1330.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:096c75d8-f04b-4d14-83fa-c4070c7bbdee,timestamp:1697086997\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:17,768 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31452941894531|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.550601959228516|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12945.0390625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2457.24609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:18,265 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697086998\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:054c7d79-baff-40bc-be5a-e43050e493b0,timestamp:1697086999\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:054c7d79-baff-40bc-be5a-e43050e493b0,timestamp:1697086999\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:19,015 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1839\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1838.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e2884bb7-b27c-4d77-bd17-71d3fe9cfa78,timestamp:1697087000\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1839\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,859 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:20,859 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1839\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1838.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e2884bb7-b27c-4d77-bd17-71d3fe9cfa78,timestamp:1697087000\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1839\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,858 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,859 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:20,859 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cd8ed9c-88a8-47c2-8df9-0ed4d626fe62,timestamp:1697087002\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cd8ed9c-88a8-47c2-8df9-0ed4d626fe62,timestamp:1697087002\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:22,114 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6cd6aea4-c209-4340-944d-a9689eec0c80,timestamp:1697087003\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6cd6aea4-c209-4340-944d-a9689eec0c80,timestamp:1697087003\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:23,360 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7f4ed6bc-e500-4246-8a92-b2f596be71d9,timestamp:1697087004\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7f4ed6bc-e500-4246-8a92-b2f596be71d9,timestamp:1697087004\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:24,625 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,881 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,881 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26e0cd3e-ddfd-469d-9ade-0019ea298f04,timestamp:1697087005\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,881 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,881 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26e0cd3e-ddfd-469d-9ade-0019ea298f04,timestamp:1697087005\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:25,882 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7d651406-6bc3-4419-a86f-b247c8c212c1,timestamp:1697087007\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7d651406-6bc3-4419-a86f-b247c8c212c1,timestamp:1697087007\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:27,157 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,438 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,438 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5534cf7-7c80-4c2b-b528-b0fcb41387ba,timestamp:1697087008\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,438 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,438 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5534cf7-7c80-4c2b-b528-b0fcb41387ba,timestamp:1697087008\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:28,439 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,708 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,708 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb73292a-26c5-4747-ab5a-e6e12358f0e0,timestamp:1697087009\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,708 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,708 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb73292a-26c5-4747-ab5a-e6e12358f0e0,timestamp:1697087009\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:29,709 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1306.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6f77d062-8fc0-4878-b479-8ac291659738,timestamp:1697087011\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1308\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1306.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6f77d062-8fc0-4878-b479-8ac291659738,timestamp:1697087011\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1308\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:31,020 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e08b26f-bd0f-4a47-9993-d5561808622b,timestamp:1697087012\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,283 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:32,283 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e08b26f-bd0f-4a47-9993-d5561808622b,timestamp:1697087012\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,282 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,283 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:32,283 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,585 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,585 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:275e8993-20a1-494d-b158-7691cafb55f0,timestamp:1697087013\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,585 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,585 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:275e8993-20a1-494d-b158-7691cafb55f0,timestamp:1697087013\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:33,586 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a5fda5a-83fe-4c85-bbc7-6c9a3262a75c,timestamp:1697087014\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a5fda5a-83fe-4c85-bbc7-6c9a3262a75c,timestamp:1697087014\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1296\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1296\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:34,885 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:36,190 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:36,190 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4b5f219e-faac-4700-b95e-43e57333608e,timestamp:1697087016\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:36,190 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:36,190 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:36,190 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4b5f219e-faac-4700-b95e-43e57333608e,timestamp:1697087016\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:36,190 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:36,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62650408-6939-40d0-b777-7b84b048ce5f,timestamp:1697087017\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62650408-6939-40d0-b777-7b84b048ce5f,timestamp:1697087017\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:37,510 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9ff1e9c4-97e2-4c1c-9b5e-84acabfc8005,timestamp:1697087018\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,758 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:38,758 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9ff1e9c4-97e2-4c1c-9b5e-84acabfc8005,timestamp:1697087018\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,757 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,758 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:38,758 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,026 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,026 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd3f6996-1866-4bba-b7b7-7f4e6e642a43,timestamp:1697087020\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,026 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,026 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd3f6996-1866-4bba-b7b7-7f4e6e642a43,timestamp:1697087020\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:40,027 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47193dfe-43e7-4ece-b792-f8378322c230,timestamp:1697087021\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47193dfe-43e7-4ece-b792-f8378322c230,timestamp:1697087021\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,298 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:41,299 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5ff01e4e-6651-46fc-ae81-32897b00a8af,timestamp:1697087022\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5ff01e4e-6651-46fc-ae81-32897b00a8af,timestamp:1697087022\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:42,643 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,979 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1332\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,979 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1331.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a94162e-283a-4670-a22a-98bd69a8e38d,timestamp:1697087023\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1333\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,979 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1332\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,979 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1331.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a94162e-283a-4670-a22a-98bd69a8e38d,timestamp:1697087023\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1333\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:43,980 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4063fe92-3c1b-4c98-9dbd-0c5262c089dd,timestamp:1697087025\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4063fe92-3c1b-4c98-9dbd-0c5262c089dd,timestamp:1697087025\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:45,332 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:46,592 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aff652b8-6be1-4ac6-b5ba-d0394ae923a1,timestamp:1697087026\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:46,592 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:46,593 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:46,593 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:46,593 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:46,594 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:46,592 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aff652b8-6be1-4ac6-b5ba-d0394ae923a1,timestamp:1697087026\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:46,592 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:46,593 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:46,593 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:46,593 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:46,594 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f4f96354-56b5-4ab3-bfb8-57bb4ed0c235,timestamp:1697087028\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f4f96354-56b5-4ab3-bfb8-57bb4ed0c235,timestamp:1697087028\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:48,007 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f323c021-9369-4051-a274-bfa076a2e032,timestamp:1697087029\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1326\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f323c021-9369-4051-a274-bfa076a2e032,timestamp:1697087029\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1326\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:49,337 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1490\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1489.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d5b11ba-2b59-49ad-851f-95199a9a8721,timestamp:1697087030\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1490\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1489.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d5b11ba-2b59-49ad-851f-95199a9a8721,timestamp:1697087030\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,831 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:50,832 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:52,102 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:52,102 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c36a6f5b-286e-4bb9-80e4-7f1d8a18ec4a,timestamp:1697087032\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:52,102 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:52,103 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:52,103 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:52,103 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:52,102 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:52,102 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c36a6f5b-286e-4bb9-80e4-7f1d8a18ec4a,timestamp:1697087032\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:52,102 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:52,103 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:52,103 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:52,103 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:68fdacb7-f844-48d2-9f66-cb44933fc03d,timestamp:1697087033\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:68fdacb7-f844-48d2-9f66-cb44933fc03d,timestamp:1697087033\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:53,460 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b551ceaf-2782-43ae-9b02-aa06a85a584c,timestamp:1697087034\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:54,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b551ceaf-2782-43ae-9b02-aa06a85a584c,timestamp:1697087034\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4583a42e-f81e-4213-916e-902d4f9ebe9d,timestamp:1697087036\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,008 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:56,007 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4583a42e-f81e-4213-916e-902d4f9ebe9d,timestamp:1697087036\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52165b5c-a1d7-4afb-bacf-e5b8d25095c0,timestamp:1697087037\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52165b5c-a1d7-4afb-bacf-e5b8d25095c0,timestamp:1697087037\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:57,313 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0379d030-987c-4ced-ad82-259e403c2682,timestamp:1697087038\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0379d030-987c-4ced-ad82-259e403c2682,timestamp:1697087038\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:58,609 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1367.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6ba28b69-109d-4c0e-8e5d-28416493749f,timestamp:1697087039\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,981 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1367.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6ba28b69-109d-4c0e-8e5d-28416493749f,timestamp:1697087039\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:03:59,982 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,254 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,254 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2852d59-d5a0-4f2b-86f2-4ce8b7492a04,timestamp:1697087041\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,254 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,254 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2852d59-d5a0-4f2b-86f2-4ce8b7492a04,timestamp:1697087041\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:01,255 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1505\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1504.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bc095e1-d8cd-47c1-8c52-4d716eb48827,timestamp:1697087042\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1506\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1505\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1504.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bc095e1-d8cd-47c1-8c52-4d716eb48827,timestamp:1697087042\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1506\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:02,765 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:02,764 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:02,765 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a28b2492-d1c5-4919-81ff-fbc54efecc25,timestamp:1697087044\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a28b2492-d1c5-4919-81ff-fbc54efecc25,timestamp:1697087044\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:04,047 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1532\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1533\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,584 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,584 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1531.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46bef51e-30e8-43f3-a57a-2507ca50b293,timestamp:1697087045\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1532\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1533\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,584 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,584 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:05,583 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1531.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46bef51e-30e8-43f3-a57a-2507ca50b293,timestamp:1697087045\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b67614ed-77a6-4b57-a4d7-d6d613acd1f4,timestamp:1697087047\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:07,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b67614ed-77a6-4b57-a4d7-d6d613acd1f4,timestamp:1697087047\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,217 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:07,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,580 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1359\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,580 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1358.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:acdcfd57-c095-4d09-8467-3574b80a25a6,timestamp:1697087048\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1360\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,580 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1359\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,580 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1358.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:acdcfd57-c095-4d09-8467-3574b80a25a6,timestamp:1697087048\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1360\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:08,581 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1364\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:222ac353-fd73-4736-995a-d2c249a9b6d7,timestamp:1697087049\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1364\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:222ac353-fd73-4736-995a-d2c249a9b6d7,timestamp:1697087049\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:09,948 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,333 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1382\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1381.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb4ee964-73f2-4910-b3f7-cebae218726b,timestamp:1697087051\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1383\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,333 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1382\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1381.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb4ee964-73f2-4910-b3f7-cebae218726b,timestamp:1697087051\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1383\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:11,334 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c67a8d69-2490-454d-9eb3-f5bb30852629,timestamp:1697087052\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c67a8d69-2490-454d-9eb3-f5bb30852629,timestamp:1697087052\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:12,610 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:13,900 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:13,900 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7e5f22b-3a2c-4117-8519-a321fb2e639e,timestamp:1697087053\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:13,901 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:13,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:13,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:13,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:13,900 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:13,900 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7e5f22b-3a2c-4117-8519-a321fb2e639e,timestamp:1697087053\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:13,901 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:13,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:13,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:13,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,283 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,283 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8b0f8dcb-b156-4ea4-95d4-cc03a85aa844,timestamp:1697087055\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,283 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,283 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8b0f8dcb-b156-4ea4-95d4-cc03a85aa844,timestamp:1697087055\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:15,284 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,941 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,941 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6603f42-7469-475d-b3db-f62232852529,timestamp:1697087056\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1655\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,941 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,941 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6603f42-7469-475d-b3db-f62232852529,timestamp:1697087056\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1655\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:16,942 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bd8210e-08ce-4c08-9ca5-faa4ed2cb31c,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,268 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.314414978027344|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550716400146484|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12939.50390625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2462.78125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bd8210e-08ce-4c08-9ca5-faa4ed2cb31c,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,191 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,192 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,268 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.314414978027344|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550716400146484|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12939.50390625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2462.78125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:18,269 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.7|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087058\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:82008115-842b-406b-9985-8e3c93aae241,timestamp:1697087059\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:82008115-842b-406b-9985-8e3c93aae241,timestamp:1697087059\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:19,451 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a0d4327-b248-433a-862f-99791a9a32bc,timestamp:1697087060\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a0d4327-b248-433a-862f-99791a9a32bc,timestamp:1697087060\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:20,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aa63eeba-68c0-4a30-b99d-0d15c1ba1387,timestamp:1697087061\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aa63eeba-68c0-4a30-b99d-0d15c1ba1387,timestamp:1697087061\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:21,987 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53b3226b-7300-4899-a8c8-7f6c2bfd7321,timestamp:1697087063\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53b3226b-7300-4899-a8c8-7f6c2bfd7321,timestamp:1697087063\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:23,325 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1311.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d70ad142-83f9-4144-84e6-7291d79ad087,timestamp:1697087064\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1311.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d70ad142-83f9-4144-84e6-7291d79ad087,timestamp:1697087064\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:24,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:51fc7dff-621a-4184-b61c-b4b1a125413c,timestamp:1697087065\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1350\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:51fc7dff-621a-4184-b61c-b4b1a125413c,timestamp:1697087065\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1350\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:25,996 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f08ed7e1-5d5d-4d04-b39a-5acec2a1bbb1,timestamp:1697087067\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:27,259 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f08ed7e1-5d5d-4d04-b39a-5acec2a1bbb1,timestamp:1697087067\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:27,259 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c54e56d-ebe0-429e-991d-490f5f34471d,timestamp:1697087068\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:28,532 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c54e56d-ebe0-429e-991d-490f5f34471d,timestamp:1697087068\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1883\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1882.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61c002ec-918c-483d-a6a3-28476f6cbb62,timestamp:1697087070\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1883\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1882.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61c002ec-918c-483d-a6a3-28476f6cbb62,timestamp:1697087070\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1884\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1884\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:30,419 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1572313f-a26b-4e3b-a71f-9c9f9cbaf301,timestamp:1697087071\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1572313f-a26b-4e3b-a71f-9c9f9cbaf301,timestamp:1697087071\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:31,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b6142e26-5d25-42de-9db0-102bf7f38869,timestamp:1697087072\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,970 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:32,970 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b6142e26-5d25-42de-9db0-102bf7f38869,timestamp:1697087072\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,969 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,970 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:32,970 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70585da8-8ca5-4da7-aeaa-fcbb1ce76576,timestamp:1697087074\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70585da8-8ca5-4da7-aeaa-fcbb1ce76576,timestamp:1697087074\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:34,224 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52f8dec4-ea4f-4e0e-ae26-b5802392a20b,timestamp:1697087075\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52f8dec4-ea4f-4e0e-ae26-b5802392a20b,timestamp:1697087075\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:35,460 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1554\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1553.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4b921df3-1d65-47fc-84df-5cfcab76c734,timestamp:1697087077\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1554\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1554\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1553.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4b921df3-1d65-47fc-84df-5cfcab76c734,timestamp:1697087077\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,017 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1554\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:37,018 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,250 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,250 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e5758833-0367-4c05-9c0b-ba70b4d4fc27,timestamp:1697087078\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,250 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,250 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e5758833-0367-4c05-9c0b-ba70b4d4fc27,timestamp:1697087078\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:38,251 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1702\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,957 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1701.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:166652cc-c9ce-47cc-af5b-5a95664559b6,timestamp:1697087079\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1704\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1702\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,957 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1701.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:166652cc-c9ce-47cc-af5b-5a95664559b6,timestamp:1697087079\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1704\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:39,958 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,251 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,251 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e013a874-44d2-4872-99a7-078bcf0601eb,timestamp:1697087081\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,251 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,251 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e013a874-44d2-4872-99a7-078bcf0601eb,timestamp:1697087081\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:41,252 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bac09dcf-3aaa-40d6-86f1-41c7568e8899,timestamp:1697087082\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bac09dcf-3aaa-40d6-86f1-41c7568e8899,timestamp:1697087082\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:42,576 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1295.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2937604f-b57c-48af-b74a-2f52b5577046,timestamp:1697087083\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1295.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2937604f-b57c-48af-b74a-2f52b5577046,timestamp:1697087083\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:43,878 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44baee47-7c02-431d-8c30-bbff3c6e2a1c,timestamp:1697087085\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44baee47-7c02-431d-8c30-bbff3c6e2a1c,timestamp:1697087085\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:45,141 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:438ec5f0-a8ba-42c4-83e8-a3c851fc0481,timestamp:1697087086\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:438ec5f0-a8ba-42c4-83e8-a3c851fc0481,timestamp:1697087086\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:46,408 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c6a5577f-47bf-413e-b68c-9cc4315fda59,timestamp:1697087087\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,713 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:47,713 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c6a5577f-47bf-413e-b68c-9cc4315fda59,timestamp:1697087087\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,712 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,713 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:47,713 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d53b0d5f-be66-495d-ba18-3c25d475fd5a,timestamp:1697087088\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d53b0d5f-be66-495d-ba18-3c25d475fd5a,timestamp:1697087088\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:48,988 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2aefad8f-10b3-4537-adf6-2f64d7abbdc7,timestamp:1697087090\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2aefad8f-10b3-4537-adf6-2f64d7abbdc7,timestamp:1697087090\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:50,238 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,641 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,641 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1398.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4336cf54-7f68-4ab6-8b53-d9ebd5b1f0c3,timestamp:1697087091\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1400\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,641 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,641 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1398.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4336cf54-7f68-4ab6-8b53-d9ebd5b1f0c3,timestamp:1697087091\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1400\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:51,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f85df82-7e9e-46f4-a8ba-45ccbf70805f,timestamp:1697087092\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f85df82-7e9e-46f4-a8ba-45ccbf70805f,timestamp:1697087092\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:52,912 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4c51d6ce-a56c-4a3f-9380-90b152a3506b,timestamp:1697087094\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4c51d6ce-a56c-4a3f-9380-90b152a3506b,timestamp:1697087094\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:54,177 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1510\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1509.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ebb4e3d-98e9-4523-9e82-7700c65f01fb,timestamp:1697087095\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1511\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1510\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1509.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ebb4e3d-98e9-4523-9e82-7700c65f01fb,timestamp:1697087095\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1511\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:55,691 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a829e51a-6a96-412a-af2a-c113a47ea8b3,timestamp:1697087096\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a829e51a-6a96-412a-af2a-c113a47ea8b3,timestamp:1697087096\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:56,992 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ed392e28-c734-480c-a624-8df107c3d004,timestamp:1697087098\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ed392e28-c734-480c-a624-8df107c3d004,timestamp:1697087098\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:58,289 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,659 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1366.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47e2055d-268d-4908-b45b-cc946ca3d028,timestamp:1697087099\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,659 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1366.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47e2055d-268d-4908-b45b-cc946ca3d028,timestamp:1697087099\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:04:59,660 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d984f20-b6a5-43a7-b8a0-39160a3d985e,timestamp:1697087100\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,989 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:00,989 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d984f20-b6a5-43a7-b8a0-39160a3d985e,timestamp:1697087100\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,988 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,989 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:00,989 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1455.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c7f2ebf-5ba9-4bf7-a4f3-e10eb8aca55d,timestamp:1697087102\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1455.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c7f2ebf-5ba9-4bf7-a4f3-e10eb8aca55d,timestamp:1697087102\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:02,449 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dfea58df-832a-44d9-8e18-32d2ad33bfc2,timestamp:1697087103\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dfea58df-832a-44d9-8e18-32d2ad33bfc2,timestamp:1697087103\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:03,704 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,989 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,989 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:900d333e-6eb8-4b94-a709-0085eff0b359,timestamp:1697087104\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,989 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,989 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:900d333e-6eb8-4b94-a709-0085eff0b359,timestamp:1697087104\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:04,990 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:520c631d-78e0-48c6-8bad-91570498607e,timestamp:1697087106\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:520c631d-78e0-48c6-8bad-91570498607e,timestamp:1697087106\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:06,259 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87e029ae-84f0-4d89-9c47-e517fa8051b4,timestamp:1697087107\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87e029ae-84f0-4d89-9c47-e517fa8051b4,timestamp:1697087107\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:07,537 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7d46a940-dcad-4cd7-b4df-5dfe950bce04,timestamp:1697087108\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7d46a940-dcad-4cd7-b4df-5dfe950bce04,timestamp:1697087108\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:08,788 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bdfd6a8-34ee-4c80-be6c-9432f9cc94a2,timestamp:1697087110\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bdfd6a8-34ee-4c80-be6c-9432f9cc94a2,timestamp:1697087110\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:10,065 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,294 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1225\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,294 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1225.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57624185-c39b-477b-81b8-0e471980eabf,timestamp:1697087111\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,294 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1225\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,294 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1225.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57624185-c39b-477b-81b8-0e471980eabf,timestamp:1697087111\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:11,295 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e9b43e1c-fe27-43e7-a148-dabdfc23a638,timestamp:1697087112\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e9b43e1c-fe27-43e7-a148-dabdfc23a638,timestamp:1697087112\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:12,571 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,841 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,841 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43440891-90d1-479b-ba9a-1cd2b084d265,timestamp:1697087113\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,841 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,841 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43440891-90d1-479b-ba9a-1cd2b084d265,timestamp:1697087113\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:13,842 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,102 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:14cf6c11-07ef-4b10-a503-da5b244afbf9,timestamp:1697087115\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,102 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,102 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:14cf6c11-07ef-4b10-a503-da5b244afbf9,timestamp:1697087115\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,102 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:15,103 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:16,359 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:16,359 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:382cc830-538e-4a0d-b4dc-e6f287028fb8,timestamp:1697087116\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:16,360 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:16,360 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:16,360 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:16,360 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:16,359 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:16,359 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:382cc830-538e-4a0d-b4dc-e6f287028fb8,timestamp:1697087116\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:16,360 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:16,360 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:16,360 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:16,360 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,011 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,011 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87faff5d-6e13-4cd1-ac7e-6223b8a2c0cf,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31429672241211|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550834655761719|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12933.3203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2468.9609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,011 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,011 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87faff5d-6e13-4cd1-ac7e-6223b8a2c0cf,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,012 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31429672241211|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550834655761719|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12933.3203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2468.9609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087118\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1291.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6a69a73b-21a9-47a5-a974-71dc7c89506c,timestamp:1697087119\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1291.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6a69a73b-21a9-47a5-a974-71dc7c89506c,timestamp:1697087119\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:19,307 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:09c0d51b-5e7f-4d7e-9316-137ba3b10c09,timestamp:1697087120\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,562 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:20,562 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:09c0d51b-5e7f-4d7e-9316-137ba3b10c09,timestamp:1697087120\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,561 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,562 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:20,562 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c2a20fb-2685-44ee-94f1-a955ee551abf,timestamp:1697087121\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c2a20fb-2685-44ee-94f1-a955ee551abf,timestamp:1697087121\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:21,976 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1556\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1555.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28b9a7fd-4dc6-4d6c-a41e-4df06aa836a0,timestamp:1697087123\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1556\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1556\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1555.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28b9a7fd-4dc6-4d6c-a41e-4df06aa836a0,timestamp:1697087123\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1556\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:23,536 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b798a1dd-bbab-4a13-90d5-4fbcf72f6ecb,timestamp:1697087124\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b798a1dd-bbab-4a13-90d5-4fbcf72f6ecb,timestamp:1697087124\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,796 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:24,797 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26e23365-af7c-4210-b22b-a4fe48d32aae,timestamp:1697087126\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26e23365-af7c-4210-b22b-a4fe48d32aae,timestamp:1697087126\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:26,039 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cd800461-d590-4aef-887b-d518d2be89f9,timestamp:1697087127\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cd800461-d590-4aef-887b-d518d2be89f9,timestamp:1697087127\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:27,345 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:28,632 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:df5ffa4b-3c99-4cff-928d-63727175335a,timestamp:1697087128\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,631 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:28,632 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:df5ffa4b-3c99-4cff-928d-63727175335a,timestamp:1697087128\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:74970a5a-0c86-445b-80e5-e900a4578d77,timestamp:1697087129\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:29,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:74970a5a-0c86-445b-80e5-e900a4578d77,timestamp:1697087129\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,906 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:29,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3823aebf-d2c3-4fc9-a89b-21937027c152,timestamp:1697087131\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3823aebf-d2c3-4fc9-a89b-21937027c152,timestamp:1697087131\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:31,164 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,414 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,414 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0dda7e6e-60eb-43bf-99b8-51135d21d184,timestamp:1697087132\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,414 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,414 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0dda7e6e-60eb-43bf-99b8-51135d21d184,timestamp:1697087132\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:32,415 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:253fd98d-cfda-4eca-81cf-a0e1871aee16,timestamp:1697087133\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:253fd98d-cfda-4eca-81cf-a0e1871aee16,timestamp:1697087133\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:33,673 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2475439d-d634-435d-bdcf-f528da7c01ab,timestamp:1697087134\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2475439d-d634-435d-bdcf-f528da7c01ab,timestamp:1697087134\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:34,951 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c06cbbcf-c95f-4faa-bd29-6acff233ec92,timestamp:1697087136\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c06cbbcf-c95f-4faa-bd29-6acff233ec92,timestamp:1697087136\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:36,193 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1491\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1490.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cc7ead65-b80c-447f-97bf-62888e06478a,timestamp:1697087137\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1491\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1490.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cc7ead65-b80c-447f-97bf-62888e06478a,timestamp:1697087137\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:37,687 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7c7ba74a-f85e-4adb-9fc7-675c72da57df,timestamp:1697087138\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7c7ba74a-f85e-4adb-9fc7-675c72da57df,timestamp:1697087138\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,960 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:38,961 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,219 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,219 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4ac54527-52c8-465a-b5c3-afa4369976df,timestamp:1697087140\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,219 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,219 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4ac54527-52c8-465a-b5c3-afa4369976df,timestamp:1697087140\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:40,220 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,491 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:03130877-ce75-4c8e-9d88-fea2fee25477,timestamp:1697087141\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,491 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:03130877-ce75-4c8e-9d88-fea2fee25477,timestamp:1697087141\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:41,492 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3cff1729-43ee-4aba-a346-e994f4c88c17,timestamp:1697087142\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,745 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:42,745 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3cff1729-43ee-4aba-a346-e994f4c88c17,timestamp:1697087142\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,744 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,745 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:42,745 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:74590c9c-9ab1-4e47-a458-d0d37f818eee,timestamp:1697087144\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:74590c9c-9ab1-4e47-a458-d0d37f818eee,timestamp:1697087144\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:44,014 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,266 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,266 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20c6a6ea-851a-4cd6-b837-e2e8d251d9b6,timestamp:1697087145\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,266 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,266 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20c6a6ea-851a-4cd6-b837-e2e8d251d9b6,timestamp:1697087145\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:45,267 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1283.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a715e75c-6df3-45fb-9be0-48bc000b7e68,timestamp:1697087146\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1283.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a715e75c-6df3-45fb-9be0-48bc000b7e68,timestamp:1697087146\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:46,555 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:410610d6-b21d-464d-b293-753cae73400c,timestamp:1697087147\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,884 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:47,884 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:410610d6-b21d-464d-b293-753cae73400c,timestamp:1697087147\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,883 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,884 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:47,884 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,293 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1406\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,293 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1406\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,293 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1405.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c43492d9-7e94-4218-a9a3-79776b909d1d,timestamp:1697087149\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1407\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,293 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1405.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c43492d9-7e94-4218-a9a3-79776b909d1d,timestamp:1697087149\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1407\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:49,294 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cbdf4d8b-4178-4681-af9c-4add0406478d,timestamp:1697087150\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cbdf4d8b-4178-4681-af9c-4add0406478d,timestamp:1697087150\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:50,542 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,820 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,820 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3b6796d3-9771-4c38-a49b-2f52388376a0,timestamp:1697087151\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,820 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,820 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3b6796d3-9771-4c38-a49b-2f52388376a0,timestamp:1697087151\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:51,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1595\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1594.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c557033e-2c9f-47c1-9934-48120d0ad935,timestamp:1697087153\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1595\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1595\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1594.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c557033e-2c9f-47c1-9934-48120d0ad935,timestamp:1697087153\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1595\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:53,419 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e6cbd23-38c7-4ff6-801e-b10d56ac5ac0,timestamp:1697087154\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e6cbd23-38c7-4ff6-801e-b10d56ac5ac0,timestamp:1697087154\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:54,711 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,010 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,010 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7ef5994-9d17-4872-9124-6e9d0200980f,timestamp:1697087156\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,010 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,010 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7ef5994-9d17-4872-9124-6e9d0200980f,timestamp:1697087156\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:56,011 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1346.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c1d4910b-4966-4284-bb8b-704a83e8ab73,timestamp:1697087157\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1346.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c1d4910b-4966-4284-bb8b-704a83e8ab73,timestamp:1697087157\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:57,362 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,667 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,667 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,667 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:638e316d-39f8-41f8-8deb-ef8aa51e3cf7,timestamp:1697087158\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,667 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:638e316d-39f8-41f8-8deb-ef8aa51e3cf7,timestamp:1697087158\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:05:58,668 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1689\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1688.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:60ee5dbf-2ada-444d-bc20-992e73662386,timestamp:1697087160\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:00,361 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1689\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1688.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:60ee5dbf-2ada-444d-bc20-992e73662386,timestamp:1697087160\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,360 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:00,361 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1492\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1492\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1491.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e2fcfe2-4a65-4880-b099-cf752bee4ba2,timestamp:1697087161\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1492\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,857 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:01,857 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1491.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e2fcfe2-4a65-4880-b099-cf752bee4ba2,timestamp:1697087161\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1492\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,856 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,857 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:01,857 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d9526c4-46a4-4717-881f-7af95fb8e454,timestamp:1697087163\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d9526c4-46a4-4717-881f-7af95fb8e454,timestamp:1697087163\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:03,126 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,371 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,371 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:67c64a75-fda2-4d4a-a63c-c98df908fe15,timestamp:1697087164\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,371 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,371 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:67c64a75-fda2-4d4a-a63c-c98df908fe15,timestamp:1697087164\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:04,372 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1688\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1688\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1687.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e58be36a-cddf-4be2-8812-d755bea14957,timestamp:1697087166\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1688\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1688\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,063 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1687.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e58be36a-cddf-4be2-8812-d755bea14957,timestamp:1697087166\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:06,064 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:098e5bac-cd1f-4935-9996-d61e103a373c,timestamp:1697087167\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:098e5bac-cd1f-4935-9996-d61e103a373c,timestamp:1697087167\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:07,311 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1544\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1543.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0fdd6575-8b64-41d3-9f7c-b55c2886dd16,timestamp:1697087168\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1545\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1544\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1543.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0fdd6575-8b64-41d3-9f7c-b55c2886dd16,timestamp:1697087168\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1545\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:08,859 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,170 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,170 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:521ae18f-c2ec-470a-ba4a-cf4655b4357a,timestamp:1697087170\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,170 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,170 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:521ae18f-c2ec-470a-ba4a-cf4655b4357a,timestamp:1697087170\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:10,171 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1235.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:15b488d6-e113-4358-a397-abd96fdb1a1f,timestamp:1697087171\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:11,413 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1235.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:15b488d6-e113-4358-a397-abd96fdb1a1f,timestamp:1697087171\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,412 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:11,413 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d08a14c-41bf-4bc3-b5b1-6a2cf56995fd,timestamp:1697087172\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d08a14c-41bf-4bc3-b5b1-6a2cf56995fd,timestamp:1697087172\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:12,706 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bfb9fc63-4733-4ab7-8f85-1580df0c187e,timestamp:1697087173\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bfb9fc63-4733-4ab7-8f85-1580df0c187e,timestamp:1697087173\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:13,971 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1722\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1721.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b7990fa9-8e00-4ef9-97ba-d9f13c628c59,timestamp:1697087175\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1722\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1722\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1721.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b7990fa9-8e00-4ef9-97ba-d9f13c628c59,timestamp:1697087175\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1722\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:15,697 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d10ff9a-7383-43a4-9a30-e59b5828a240,timestamp:1697087176\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d10ff9a-7383-43a4-9a30-e59b5828a240,timestamp:1697087176\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:16,937 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,334 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,334 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31418991088867|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,335 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550941467285156|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,335 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,335 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12926.96875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,335 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2475.31640625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,336 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1472\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1472.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:de470ec2-5201-4855-92aa-05050dad5d15,timestamp:1697087178\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1474\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,334 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,334 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31418991088867|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,335 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.550941467285156|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,335 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,335 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12926.96875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,335 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2475.31640625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,336 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1472\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1472.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:de470ec2-5201-4855-92aa-05050dad5d15,timestamp:1697087178\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1474\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:18,414 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1339.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3a101d29-f35e-4986-b444-7183b7d90955,timestamp:1697087179\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1339.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3a101d29-f35e-4986-b444-7183b7d90955,timestamp:1697087179\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:19,757 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,040 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,040 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cfa154b6-0b31-4eda-95aa-409933842c26,timestamp:1697087181\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,040 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,040 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cfa154b6-0b31-4eda-95aa-409933842c26,timestamp:1697087181\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:21,041 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,324 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,324 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:09db7ba1-2c91-4165-a547-a5b5ad2df6a3,timestamp:1697087182\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,324 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,324 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:09db7ba1-2c91-4165-a547-a5b5ad2df6a3,timestamp:1697087182\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:22,325 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1315.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2978f03c-88fc-4109-b8df-980dfcfe0356,timestamp:1697087183\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1317\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1315.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2978f03c-88fc-4109-b8df-980dfcfe0356,timestamp:1697087183\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1317\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:23,644 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,897 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,897 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93f12080-7898-4226-a7c1-d7d5c04574e1,timestamp:1697087184\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,897 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,897 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93f12080-7898-4226-a7c1-d7d5c04574e1,timestamp:1697087184\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:24,898 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1355.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0afa216b-c1fa-4282-8d1c-26b2bea26b2d,timestamp:1697087186\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1355.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0afa216b-c1fa-4282-8d1c-26b2bea26b2d,timestamp:1697087186\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:26,257 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ff400802-1ca5-43d7-85df-a53e52d70574,timestamp:1697087187\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1417\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ff400802-1ca5-43d7-85df-a53e52d70574,timestamp:1697087187\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1417\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:27,677 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:28,924 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:28,924 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:00564eb1-3d98-4d65-8e78-86aa391298ea,timestamp:1697087188\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:28,924 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:28,924 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:28,926 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:28,926 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:28,924 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:28,924 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:00564eb1-3d98-4d65-8e78-86aa391298ea,timestamp:1697087188\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:28,924 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:28,924 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:28,926 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:28,926 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:354aa161-1cc9-41ef-ab45-12d6ec3fdbde,timestamp:1697087190\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:354aa161-1cc9-41ef-ab45-12d6ec3fdbde,timestamp:1697087190\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:30,185 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:71237a83-22c4-4b13-9c1c-65a243676544,timestamp:1697087191\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:71237a83-22c4-4b13-9c1c-65a243676544,timestamp:1697087191\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:31,427 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:839a07fe-0e2e-4fb5-9f01-b848cdea3973,timestamp:1697087192\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:839a07fe-0e2e-4fb5-9f01-b848cdea3973,timestamp:1697087192\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:32,684 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1333\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1332.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f71760ce-f17a-44bd-a1c8-11d795f1f1aa,timestamp:1697087194\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1333\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1333\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1332.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f71760ce-f17a-44bd-a1c8-11d795f1f1aa,timestamp:1697087194\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,020 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1333\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:34,021 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,399 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,399 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0174f78f-afa3-481f-8485-f84051362252,timestamp:1697087195\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,399 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,399 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0174f78f-afa3-481f-8485-f84051362252,timestamp:1697087195\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:35,400 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:42762327-9fa4-46a8-a162-c7e897db8aa3,timestamp:1697087196\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:42762327-9fa4-46a8-a162-c7e897db8aa3,timestamp:1697087196\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:36,654 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,919 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,919 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b9c66d45-4d32-4cd4-8279-5389340f51c0,timestamp:1697087197\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,919 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,919 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b9c66d45-4d32-4cd4-8279-5389340f51c0,timestamp:1697087197\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:37,920 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:39,201 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:39,201 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f639ad39-fa46-49d1-b009-7fb66523e10d,timestamp:1697087199\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:39,201 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:39,202 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:39,202 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:39,202 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:39,201 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:39,201 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f639ad39-fa46-49d1-b009-7fb66523e10d,timestamp:1697087199\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:39,201 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:39,202 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:39,202 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:39,202 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f1691b65-0f5c-460b-ba94-0598c1b4dac0,timestamp:1697087200\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f1691b65-0f5c-460b-ba94-0598c1b4dac0,timestamp:1697087200\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:40,470 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75ef51df-dcf0-43d1-a4db-0406b97b5d71,timestamp:1697087201\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,735 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:41,735 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75ef51df-dcf0-43d1-a4db-0406b97b5d71,timestamp:1697087201\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,734 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,735 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:41,735 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bbfd606d-07ea-42b1-8fd0-dec674ced1c1,timestamp:1697087203\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bbfd606d-07ea-42b1-8fd0-dec674ced1c1,timestamp:1697087203\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,028 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:43,029 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,347 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,347 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:688fb309-8023-45d1-9cda-4e19c63b884b,timestamp:1697087204\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,347 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,347 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:688fb309-8023-45d1-9cda-4e19c63b884b,timestamp:1697087204\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:44,348 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1668\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1667.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0fb00b2a-d28c-4504-b176-5bb0b2d8c764,timestamp:1697087206\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1668\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1667.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0fb00b2a-d28c-4504-b176-5bb0b2d8c764,timestamp:1697087206\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:46,019 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d6fd5bc-4ba6-4731-8999-9ac1b5f3c28e,timestamp:1697087207\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d6fd5bc-4ba6-4731-8999-9ac1b5f3c28e,timestamp:1697087207\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:47,260 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:00f7e34c-7e8e-4b52-bf1b-bcadea22d9ed,timestamp:1697087208\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:48,509 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:00f7e34c-7e8e-4b52-bf1b-bcadea22d9ed,timestamp:1697087208\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,508 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:48,509 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:92fac5a5-9adb-4dca-8789-e571c265af46,timestamp:1697087209\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:49,760 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:92fac5a5-9adb-4dca-8789-e571c265af46,timestamp:1697087209\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:49,759 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:49,760 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07eabef8-a1bc-46be-a3be-ae380bd6c00b,timestamp:1697087211\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:51,044 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07eabef8-a1bc-46be-a3be-ae380bd6c00b,timestamp:1697087211\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,043 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:51,044 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:178b172d-0cb3-4e04-af1f-acbffee422e4,timestamp:1697087212\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:178b172d-0cb3-4e04-af1f-acbffee422e4,timestamp:1697087212\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:52,330 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:84dc5e04-0d2f-42f4-a42e-d622d88df9c5,timestamp:1697087213\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:84dc5e04-0d2f-42f4-a42e-d622d88df9c5,timestamp:1697087213\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:53,712 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,429 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1712\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,429 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1712.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93f29ca5-1d45-4f51-be09-b851f71fc9e0,timestamp:1697087215\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1714\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,429 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1712\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,429 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1712.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93f29ca5-1d45-4f51-be09-b851f71fc9e0,timestamp:1697087215\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1714\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:55,430 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e3960bf9-62b0-4cf0-9424-f805d3f91442,timestamp:1697087216\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:56,695 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e3960bf9-62b0-4cf0-9424-f805d3f91442,timestamp:1697087216\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,985 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,985 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f476336b-1b88-43f2-b91d-1f0f81be152f,timestamp:1697087217\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,985 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,985 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f476336b-1b88-43f2-b91d-1f0f81be152f,timestamp:1697087217\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:57,986 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1389\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1388.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:82a22dd8-0a5a-41b6-bf67-950a3930eb34,timestamp:1697087219\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,379 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:06:59,379 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1389\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1388.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:82a22dd8-0a5a-41b6-bf67-950a3930eb34,timestamp:1697087219\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,378 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,379 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:06:59,379 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:00,681 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:00,681 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:56cc9699-60e8-40a5-b276-b7d6dd5fbb35,timestamp:1697087220\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:00,682 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:00,682 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:00,682 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:00,682 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:00,681 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:00,681 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:56cc9699-60e8-40a5-b276-b7d6dd5fbb35,timestamp:1697087220\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:00,682 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:00,682 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:00,682 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:00,682 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fa6a105a-ca68-4471-ae36-52f25288b937,timestamp:1697087221\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:01,947 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fa6a105a-ca68-4471-ae36-52f25288b937,timestamp:1697087221\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,946 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:01,947 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,407 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1459\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1457.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08a5dabb-257a-4ef9-b22e-fe8ec93584f5,timestamp:1697087223\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,407 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1459\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:03,408 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1457.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08a5dabb-257a-4ef9-b22e-fe8ec93584f5,timestamp:1697087223\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,649 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:04,649 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64eaf6c1-6d4f-40fa-b3eb-67c0bf59d129,timestamp:1697087224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,649 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,650 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:04,649 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64eaf6c1-6d4f-40fa-b3eb-67c0bf59d129,timestamp:1697087224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ee23da9a-c2ef-44a3-a99b-ec171ab5dd78,timestamp:1697087225\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ee23da9a-c2ef-44a3-a99b-ec171ab5dd78,timestamp:1697087225\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:05,949 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:343ff877-e7c1-45dd-bd3f-6e65188e1d8c,timestamp:1697087227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,293 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,293 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:07,294 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:343ff877-e7c1-45dd-bd3f-6e65188e1d8c,timestamp:1697087227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,292 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,293 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,293 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:07,294 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:449f37d7-62db-4847-bc15-9da5fc278fbc,timestamp:1697087228\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,596 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:08,596 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:449f37d7-62db-4847-bc15-9da5fc278fbc,timestamp:1697087228\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,595 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,596 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:08,596 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1434\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1433.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:515a45f9-f5ca-40ca-80ba-66c5e79ad74c,timestamp:1697087230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1435\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1434\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1433.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:515a45f9-f5ca-40ca-80ba-66c5e79ad74c,timestamp:1697087230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1435\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:10,033 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:11,312 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:11,312 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:080e1906-99ee-4025-bfb5-38f6e2456426,timestamp:1697087231\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:11,312 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:11,312 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:11,313 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:11,313 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:11,312 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:11,312 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:080e1906-99ee-4025-bfb5-38f6e2456426,timestamp:1697087231\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:11,312 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:11,312 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:11,313 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:11,313 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.92|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc19cba5-1199-48b3-bc96-db1220c188a0,timestamp:1697087232\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.92|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc19cba5-1199-48b3-bc96-db1220c188a0,timestamp:1697087232\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:12,552 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d986546-a74a-421e-93d6-641075a90807,timestamp:1697087233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d986546-a74a-421e-93d6-641075a90807,timestamp:1697087233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:13,838 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2043\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2042.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e0065064-0cd2-483c-a6c7-b62adf726f5d,timestamp:1697087235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2043\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,886 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:15,886 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2043\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2042.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e0065064-0cd2-483c-a6c7-b62adf726f5d,timestamp:1697087235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2043\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,885 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,886 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:15,886 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dad09e10-b2e6-42a4-8918-9ef18c7b50d0,timestamp:1697087237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dad09e10-b2e6-42a4-8918-9ef18c7b50d0,timestamp:1697087237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:17,132 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31406784057617|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551063537597656|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12931.58203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2470.734375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,381 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,381 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f5a37d20-730b-4365-90df-c5a9cc5f4eef,timestamp:1697087238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31406784057617|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551063537597656|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12931.58203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2470.734375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,381 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,381 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f5a37d20-730b-4365-90df-c5a9cc5f4eef,timestamp:1697087238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:18,382 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,637 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ad5723cb-1336-4b5a-8583-4540f53cf6a4,timestamp:1697087239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,637 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ad5723cb-1336-4b5a-8583-4540f53cf6a4,timestamp:1697087239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:19,638 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:92bb3877-099e-4827-8e8e-0998a622a07c,timestamp:1697087240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:20,930 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:92bb3877-099e-4827-8e8e-0998a622a07c,timestamp:1697087240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,392 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1459\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,392 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1458.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7cea0a04-a762-4d8e-9432-0413ebe54f7a,timestamp:1697087242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1460\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,392 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1459\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,392 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1458.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7cea0a04-a762-4d8e-9432-0413ebe54f7a,timestamp:1697087242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1460\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:22,393 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,672 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:634fb889-2308-4c6d-aa91-df3675dcbb50,timestamp:1697087243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,672 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:634fb889-2308-4c6d-aa91-df3675dcbb50,timestamp:1697087243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:23,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,094 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,094 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:88962e73-4677-4065-9e07-b9712f9ca1ec,timestamp:1697087245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1420\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,094 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,094 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:88962e73-4677-4065-9e07-b9712f9ca1ec,timestamp:1697087245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1420\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:25,096 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f6dfee2b-9a0f-4224-a487-e06c3dc2a4b1,timestamp:1697087246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,333 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:26,333 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f6dfee2b-9a0f-4224-a487-e06c3dc2a4b1,timestamp:1697087246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,332 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,333 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:26,333 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,593 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a42e0a9-e7a3-443f-b10d-171b6ae5c300,timestamp:1697087247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,593 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a42e0a9-e7a3-443f-b10d-171b6ae5c300,timestamp:1697087247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:27,594 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,874 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,874 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,874 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1e3b53d-32dc-41fd-b9c2-57396b00432c,timestamp:1697087248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,874 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1e3b53d-32dc-41fd-b9c2-57396b00432c,timestamp:1697087248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:28,875 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,151 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,151 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.93|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a20676c6-5e93-49a5-b20f-73d122368c5d,timestamp:1697087250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,151 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,151 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.93|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a20676c6-5e93-49a5-b20f-73d122368c5d,timestamp:1697087250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:30,154 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1532\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1530.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c75e4810-216e-4b0d-89d9-ebe9dc7f5703,timestamp:1697087251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1532\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1532\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1530.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c75e4810-216e-4b0d-89d9-ebe9dc7f5703,timestamp:1697087251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1532\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:31,690 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1233.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e04cbb22-1161-476a-80ef-2ef1064550e2,timestamp:1697087252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,929 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:32,929 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1233.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e04cbb22-1161-476a-80ef-2ef1064550e2,timestamp:1697087252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,928 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,929 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:32,929 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,276 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7109970b-98de-4a66-835c-902df819af07,timestamp:1697087254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,276 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1345\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,276 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7109970b-98de-4a66-835c-902df819af07,timestamp:1697087254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,276 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1345\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:34,277 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,561 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,561 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3e215b4a-ccfa-4546-a76f-c57e04f12c6a,timestamp:1697087255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,561 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,561 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3e215b4a-ccfa-4546-a76f-c57e04f12c6a,timestamp:1697087255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:35,562 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,901 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,901 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a8acd67-013e-4a0b-894d-7cb300c50e3f,timestamp:1697087256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,901 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,901 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a8acd67-013e-4a0b-894d-7cb300c50e3f,timestamp:1697087256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:36,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6c6025ee-6c44-4768-a3c9-99011d85e512,timestamp:1697087258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6c6025ee-6c44-4768-a3c9-99011d85e512,timestamp:1697087258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:38,152 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:442c184a-24a6-4d9b-8fb6-8006697c7057,timestamp:1697087259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,399 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:39,399 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:442c184a-24a6-4d9b-8fb6-8006697c7057,timestamp:1697087259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,398 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,399 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:39,399 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1474\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1473.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7cb7070a-d7ae-424f-bdaa-640d3fb9adf3,timestamp:1697087260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1474\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1473.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7cb7070a-d7ae-424f-bdaa-640d3fb9adf3,timestamp:1697087260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1475\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1475\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:40,879 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:42,162 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:42,162 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a61870c2-9587-4ea2-abb7-ddc022099334,timestamp:1697087262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:42,162 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:42,162 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a61870c2-9587-4ea2-abb7-ddc022099334,timestamp:1697087262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:42,163 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93b7e76b-7af2-49d5-bc00-65ac9f67d89a,timestamp:1697087263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93b7e76b-7af2-49d5-bc00-65ac9f67d89a,timestamp:1697087263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,431 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:43,432 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,676 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,676 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0b5b0b23-242d-4216-9214-beae053bcbd5,timestamp:1697087264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,676 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,676 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0b5b0b23-242d-4216-9214-beae053bcbd5,timestamp:1697087264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:44,677 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26052aee-d3a1-47f5-976b-360182caa8c3,timestamp:1697087265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26052aee-d3a1-47f5-976b-360182caa8c3,timestamp:1697087265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:45,909 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e8887b76-f2d4-4162-870f-88a975e8a876,timestamp:1697087267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e8887b76-f2d4-4162-870f-88a975e8a876,timestamp:1697087267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:47,206 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,432 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,432 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,432 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8d4431cb-0b42-43d6-86e6-2813cf935aea,timestamp:1697087268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,432 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8d4431cb-0b42-43d6-86e6-2813cf935aea,timestamp:1697087268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:48,433 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f994e493-563c-48b7-8c2b-4f4535b07186,timestamp:1697087269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:49,705 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f994e493-563c-48b7-8c2b-4f4535b07186,timestamp:1697087269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,704 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:49,705 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,960 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cbcb5351-4384-431c-8927-ff596f3612d0,timestamp:1697087270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,960 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:50,959 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cbcb5351-4384-431c-8927-ff596f3612d0,timestamp:1697087270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1672\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c4312a0c-ea0d-42cf-92f9-2b97c1eef92c,timestamp:1697087272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1672\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1672\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c4312a0c-ea0d-42cf-92f9-2b97c1eef92c,timestamp:1697087272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1672\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:52,635 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93686a62-0b3d-4d8a-8709-d16a71c7ff50,timestamp:1697087274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93686a62-0b3d-4d8a-8709-d16a71c7ff50,timestamp:1697087274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:54,054 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:40dd77d9-4414-48d5-a521-5b6cc8a9505c,timestamp:1697087275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:40dd77d9-4414-48d5-a521-5b6cc8a9505c,timestamp:1697087275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:55,313 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c9d020d1-2472-443a-a1de-2e7434692c62,timestamp:1697087276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c9d020d1-2472-443a-a1de-2e7434692c62,timestamp:1697087276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:56,591 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5722f51b-bba8-4b9f-8092-90ab18f4829b,timestamp:1697087277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5722f51b-bba8-4b9f-8092-90ab18f4829b,timestamp:1697087277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:57,839 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:817eb125-6a37-4cd2-b909-eb8d17bc271b,timestamp:1697087279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:817eb125-6a37-4cd2-b909-eb8d17bc271b,timestamp:1697087279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:07:59,133 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1455.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b5591821-63d3-480a-812a-f1e882eb86f7,timestamp:1697087280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,594 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:00,594 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1455.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b5591821-63d3-480a-812a-f1e882eb86f7,timestamp:1697087280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,593 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,594 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:00,594 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,895 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,895 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a85f6e2-5ec6-42be-8e29-fa417fd496c7,timestamp:1697087281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,895 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,895 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a85f6e2-5ec6-42be-8e29-fa417fd496c7,timestamp:1697087281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:01,896 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1683\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1682.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6655f9a0-7e4b-4fd8-9faa-29f2867eb1ff,timestamp:1697087283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1684\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1683\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1682.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6655f9a0-7e4b-4fd8-9faa-29f2867eb1ff,timestamp:1697087283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1684\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:03,582 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1cabbc9f-d1e0-4037-9aad-5cb450734d08,timestamp:1697087284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1cabbc9f-d1e0-4037-9aad-5cb450734d08,timestamp:1697087284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:04,867 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,866 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:04,867 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6afc1a7b-5658-41c7-acae-87ff0c32eda1,timestamp:1697087286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6afc1a7b-5658-41c7-acae-87ff0c32eda1,timestamp:1697087286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:06,107 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7341257a-ea9d-4959-94b0-33ba3ec0709f,timestamp:1697087287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7341257a-ea9d-4959-94b0-33ba3ec0709f,timestamp:1697087287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:07,378 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,791 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1409\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,791 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32db5faf-0bfe-4c51-b38d-edbd63bb25c9,timestamp:1697087288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,791 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1409\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,791 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32db5faf-0bfe-4c51-b38d-edbd63bb25c9,timestamp:1697087288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:08,792 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,086 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6a7b13c-7d47-4472-b407-f56e6a400f75,timestamp:1697087290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,086 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6a7b13c-7d47-4472-b407-f56e6a400f75,timestamp:1697087290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:10,087 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,400 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1310\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,400 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1309.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53dd47f4-06a8-45b7-aa97-f4319474ba67,timestamp:1697087291\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,400 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1310\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,400 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1309.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53dd47f4-06a8-45b7-aa97-f4319474ba67,timestamp:1697087291\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:11,401 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1335.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2adb63c-ca04-4177-a472-f951f8425e66,timestamp:1697087292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1335.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2adb63c-ca04-4177-a472-f951f8425e66,timestamp:1697087292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:12,740 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:065b7fc7-8719-4c51-89b0-646f491e1cf9,timestamp:1697087293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:13,971 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:065b7fc7-8719-4c51-89b0-646f491e1cf9,timestamp:1697087293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:13,970 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:13,971 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:48008942-4adc-45a6-81be-ae04e6b1b587,timestamp:1697087295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:15,227 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:48008942-4adc-45a6-81be-ae04e6b1b587,timestamp:1697087295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,226 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:15,227 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2fb90fa-49ab-40ee-948e-f71c35cad704,timestamp:1697087296\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2fb90fa-49ab-40ee-948e-f71c35cad704,timestamp:1697087296\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:16,575 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b83580b5-c49e-47b0-903e-83be945bafe6,timestamp:1697087297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3139533996582|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551177978515625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12929.9921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2472.328125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b83580b5-c49e-47b0-903e-83be945bafe6,timestamp:1697087297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:17,818 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3139533996582|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551177978515625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12929.9921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2472.328125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f8df68b-f3df-4eb1-8658-51827200f89b,timestamp:1697087299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f8df68b-f3df-4eb1-8658-51827200f89b,timestamp:1697087299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,079 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:19,080 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1422\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1422\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1421.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d2382a2-d4d8-4798-b67e-7c4b6d027182,timestamp:1697087300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1423\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1421.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d2382a2-d4d8-4798-b67e-7c4b6d027182,timestamp:1697087300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1423\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:20,505 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5da786ea-6b91-4042-a7d6-760aa689fa7a,timestamp:1697087301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:21,834 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5da786ea-6b91-4042-a7d6-760aa689fa7a,timestamp:1697087301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,833 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:21,834 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,117 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:97279f2a-a4d2-4eec-89a2-028ca9b2edfd,timestamp:1697087303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,117 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:97279f2a-a4d2-4eec-89a2-028ca9b2edfd,timestamp:1697087303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:23,118 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:24,368 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:24,368 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ff553d6a-bc97-447a-9ea9-e42575a2388d,timestamp:1697087304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:24,368 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:24,368 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:24,369 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:24,369 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:24,368 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:24,368 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ff553d6a-bc97-447a-9ea9-e42575a2388d,timestamp:1697087304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:24,368 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:24,368 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:24,369 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:24,369 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:802d1412-dead-4f26-9902-6dca7c200e74,timestamp:1697087305\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,711 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:25,711 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:802d1412-dead-4f26-9902-6dca7c200e74,timestamp:1697087305\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,710 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,711 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:25,711 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1235.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28c835a5-0178-4d47-b997-613e8ef16a7f,timestamp:1697087306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1235.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28c835a5-0178-4d47-b997-613e8ef16a7f,timestamp:1697087306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:26,950 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6a7ca1d2-5c19-4b91-9cae-42097238cbfb,timestamp:1697087308\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,199 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:28,199 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6a7ca1d2-5c19-4b91-9cae-42097238cbfb,timestamp:1697087308\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,199 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:28,199 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ce5fdc2-c2a6-4b8f-8149-e6f12b7a0811,timestamp:1697087309\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ce5fdc2-c2a6-4b8f-8149-e6f12b7a0811,timestamp:1697087309\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:29,522 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,785 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,785 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:488392e1-1fca-457f-a666-7f1f22ef43f5,timestamp:1697087310\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,785 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,785 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:488392e1-1fca-457f-a666-7f1f22ef43f5,timestamp:1697087310\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:30,786 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5cab178-b4fc-41c9-ac32-52c5e39d2ddc,timestamp:1697087312\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5cab178-b4fc-41c9-ac32-52c5e39d2ddc,timestamp:1697087312\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:32,046 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1449\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1448.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:58ae2225-3fb9-46a4-a7e9-81e883689601,timestamp:1697087313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1449\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1449\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1448.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:58ae2225-3fb9-46a4-a7e9-81e883689601,timestamp:1697087313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1449\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:33,498 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:34,762 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:34,762 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2d5c6e47-3a65-4467-8f9a-9bb4ce3836cb,timestamp:1697087314\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:34,763 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:34,763 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:34,763 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:34,763 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:34,762 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:34,762 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2d5c6e47-3a65-4467-8f9a-9bb4ce3836cb,timestamp:1697087314\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:34,763 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:34,763 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:34,763 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:34,763 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1400\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1399.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:323f6e00-3f60-4742-8ff5-239e0b1d4972,timestamp:1697087316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1400\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1399.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:323f6e00-3f60-4742-8ff5-239e0b1d4972,timestamp:1697087316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:36,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1315.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a2f647e6-a285-4d0a-aacf-8d8c6e4ad1f8,timestamp:1697087317\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1315\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1315.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a2f647e6-a285-4d0a-aacf-8d8c6e4ad1f8,timestamp:1697087317\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:37,484 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6beccbe2-ee71-4156-8d70-541c85e7989c,timestamp:1697087318\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:38,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6beccbe2-ee71-4156-8d70-541c85e7989c,timestamp:1697087318\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,756 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:38,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,288 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1522\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,288 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1523.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1d6bd24-6b92-45c7-ba3f-7033af618574,timestamp:1697087320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1525\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,288 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1522\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,288 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1523.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1d6bd24-6b92-45c7-ba3f-7033af618574,timestamp:1697087320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1525\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:40,289 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb352df2-8574-4167-9141-1212baa7aac6,timestamp:1697087321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb352df2-8574-4167-9141-1212baa7aac6,timestamp:1697087321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:41,541 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f31629cd-94a1-4890-90a5-136b454f28c8,timestamp:1697087322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f31629cd-94a1-4890-90a5-136b454f28c8,timestamp:1697087322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:42,789 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,788 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:42,789 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1468.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:24aa4331-ad9f-498f-97ac-0303fdb019b2,timestamp:1697087324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,261 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:44,261 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1468.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:24aa4331-ad9f-498f-97ac-0303fdb019b2,timestamp:1697087324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,260 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,261 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:44,261 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:eca75bf7-aa32-4858-8723-4c191c05f2bd,timestamp:1697087325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:eca75bf7-aa32-4858-8723-4c191c05f2bd,timestamp:1697087325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:45,507 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,767 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,767 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32f59871-c31e-4c63-8aa8-29f41b05d2ac,timestamp:1697087326\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,767 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,767 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32f59871-c31e-4c63-8aa8-29f41b05d2ac,timestamp:1697087326\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:46,768 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,004 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,004 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,004 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1233.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d815ec8a-7ea8-4432-a0ba-950d6574c462,timestamp:1697087328\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,004 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1233.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d815ec8a-7ea8-4432-a0ba-950d6574c462,timestamp:1697087328\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:48,005 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bbb8371-7d59-4122-94d2-58922d480b6a,timestamp:1697087329\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:49,328 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bbb8371-7d59-4122-94d2-58922d480b6a,timestamp:1697087329\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,327 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:49,328 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ac90c42e-688c-49b2-bdf3-42c5e546c8eb,timestamp:1697087330\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ac90c42e-688c-49b2-bdf3-42c5e546c8eb,timestamp:1697087330\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:50,620 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1485.89|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c9eeba9e-4612-4331-a55f-b4560b455fce,timestamp:1697087332\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1487\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1487\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1485.89|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c9eeba9e-4612-4331-a55f-b4560b455fce,timestamp:1697087332\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1487\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1487\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:52,110 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1695.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39c5eecf-959a-42a9-a882-68d2f28075b1,timestamp:1697087333\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1697\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1695.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39c5eecf-959a-42a9-a882-68d2f28075b1,timestamp:1697087333\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1697\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:53,810 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5922b882-8535-4490-abfd-1d66444a6db5,timestamp:1697087335\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5922b882-8535-4490-abfd-1d66444a6db5,timestamp:1697087335\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,137 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:55,138 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d25fb1c-2600-4c8f-96ff-cf109a3895c0,timestamp:1697087336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d25fb1c-2600-4c8f-96ff-cf109a3895c0,timestamp:1697087336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:56,410 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1677.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:78cb888c-dd14-4f5f-8dc2-e379a03986c4,timestamp:1697087338\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1677.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:78cb888c-dd14-4f5f-8dc2-e379a03986c4,timestamp:1697087338\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:58,091 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:752c473c-b549-4167-b987-9f2f4bc277e3,timestamp:1697087339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,393 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:08:59,393 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:752c473c-b549-4167-b987-9f2f4bc277e3,timestamp:1697087339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,392 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,393 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:08:59,393 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:00,889 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1493\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:00,889 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1493.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43e1c95a-f85a-4b00-8485-d43057bc3c79,timestamp:1697087340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:00,890 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1495\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:00,890 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:00,890 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:00,890 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:00,889 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1493\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:00,889 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1493.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43e1c95a-f85a-4b00-8485-d43057bc3c79,timestamp:1697087340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:00,890 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1495\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:00,890 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:00,890 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:00,890 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1403\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1402.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a110f89-8613-4fa7-9be6-2ece2aa820a1,timestamp:1697087342\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1403\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1403\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1402.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a110f89-8613-4fa7-9be6-2ece2aa820a1,timestamp:1697087342\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1403\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:02,296 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:660753bd-f707-4090-ab99-e44c191133f6,timestamp:1697087343\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:660753bd-f707-4090-ab99-e44c191133f6,timestamp:1697087343\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:03,639 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2b188843-9f7e-4360-9c57-4f051cbd37c3,timestamp:1697087344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:04,883 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2b188843-9f7e-4360-9c57-4f051cbd37c3,timestamp:1697087344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1328\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1328\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:94002af5-d30e-4f83-8972-52ac5bbf869e,timestamp:1697087346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1328\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1328\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:94002af5-d30e-4f83-8972-52ac5bbf869e,timestamp:1697087346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:06,214 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,486 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59401937-2425-4eb1-87d8-2ce07a1ad6fe,timestamp:1697087347\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:07,486 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,485 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,486 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59401937-2425-4eb1-87d8-2ce07a1ad6fe,timestamp:1697087347\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:07,486 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,766 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,766 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:12616caf-cad2-496c-8c59-30788965f3a1,timestamp:1697087348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,766 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,766 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:12616caf-cad2-496c-8c59-30788965f3a1,timestamp:1697087348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:08,767 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:502dede8-f904-4f1f-9eb2-b869baabb86a,timestamp:1697087350\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:502dede8-f904-4f1f-9eb2-b869baabb86a,timestamp:1697087350\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:10,109 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8796976e-161d-4e79-8167-98dfbab97238,timestamp:1697087351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8796976e-161d-4e79-8167-98dfbab97238,timestamp:1697087351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:11,389 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,665 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a6861e6c-7c41-4ccb-b47a-86061c691aaf,timestamp:1697087352\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,665 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:12,666 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a6861e6c-7c41-4ccb-b47a-86061c691aaf,timestamp:1697087352\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ab9ed52a-224b-4f1e-82f0-cda9d183c50b,timestamp:1697087353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ab9ed52a-224b-4f1e-82f0-cda9d183c50b,timestamp:1697087353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:13,922 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63f313a3-2914-402f-be0c-8ee019e54733,timestamp:1697087355\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63f313a3-2914-402f-be0c-8ee019e54733,timestamp:1697087355\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:15,179 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6723171e-d0b5-45fc-875d-1e83ff171152,timestamp:1697087356\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6723171e-d0b5-45fc-875d-1e83ff171152,timestamp:1697087356\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,475 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:16,476 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,828 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,828 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,828 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:487d136a-ce55-4833-bd92-4cca2235fbd0,timestamp:1697087357\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313838958740234|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551292419433594|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12928.84765625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.47265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,828 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:487d136a-ce55-4833-bd92-4cca2235fbd0,timestamp:1697087357\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:17,829 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313838958740234|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551292419433594|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12928.84765625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.47265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08743481-147e-4dab-a9db-ce25217354e4,timestamp:1697087359\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08743481-147e-4dab-a9db-ce25217354e4,timestamp:1697087359\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:19,138 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e61759a2-4a61-42b6-8fda-23b52e73ad1d,timestamp:1697087360\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e61759a2-4a61-42b6-8fda-23b52e73ad1d,timestamp:1697087360\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:20,549 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c599f75-0495-4860-97f0-a391976b0606,timestamp:1697087361\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c599f75-0495-4860-97f0-a391976b0606,timestamp:1697087361\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:21,853 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1320.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb17da5f-d35f-4f5f-9cfd-befc7733a3fc,timestamp:1697087363\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1320.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb17da5f-d35f-4f5f-9cfd-befc7733a3fc,timestamp:1697087363\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:23,177 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,427 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,427 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aacf50f2-6a6e-42f7-bf05-df8a2b14721b,timestamp:1697087364\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,427 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,427 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aacf50f2-6a6e-42f7-bf05-df8a2b14721b,timestamp:1697087364\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:24,428 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1482\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b77a5f33-3f39-4583-9a97-03b28df71b51,timestamp:1697087365\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1482\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1482\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b77a5f33-3f39-4583-9a97-03b28df71b51,timestamp:1697087365\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1482\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:25,912 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:27,288 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1373\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:27,288 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1372.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:31f37291-cc89-4c3e-a527-c149622a0277,timestamp:1697087367\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:27,289 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1374\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:27,289 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:27,289 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:27,289 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:27,288 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1373\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:27,288 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1372.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:31f37291-cc89-4c3e-a527-c149622a0277,timestamp:1697087367\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:27,289 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1374\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:27,289 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:27,289 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:27,289 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:adf0390f-b27c-4527-a649-53af6ce93249,timestamp:1697087368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,528 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:28,528 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:adf0390f-b27c-4527-a649-53af6ce93249,timestamp:1697087368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,527 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,528 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:28,528 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,812 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,812 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0357dd78-136e-404b-96fb-1abf85d3dbb1,timestamp:1697087369\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,812 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,812 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0357dd78-136e-404b-96fb-1abf85d3dbb1,timestamp:1697087369\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:29,813 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c328857e-9750-412e-82f0-ad63dc5a2325,timestamp:1697087371\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c328857e-9750-412e-82f0-ad63dc5a2325,timestamp:1697087371\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:31,058 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,365 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,365 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55a46e0e-349c-4637-b4ae-260412fab20e,timestamp:1697087372\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,365 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,365 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55a46e0e-349c-4637-b4ae-260412fab20e,timestamp:1697087372\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:32,366 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,619 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a65d9790-b4df-4bde-8f66-2fd10c7a3d34,timestamp:1697087373\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,619 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a65d9790-b4df-4bde-8f66-2fd10c7a3d34,timestamp:1697087373\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:33,620 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,878 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,878 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,878 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7193d4c9-0e60-43f0-b576-491ecc7d760d,timestamp:1697087374\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,878 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7193d4c9-0e60-43f0-b576-491ecc7d760d,timestamp:1697087374\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:34,879 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,537 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,537 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ce61689-0e9b-4735-80aa-c1caf95da0e4,timestamp:1697087376\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,537 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,537 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ce61689-0e9b-4735-80aa-c1caf95da0e4,timestamp:1697087376\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:36,538 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:37,829 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:37,829 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9e5b360c-5113-4481-a8f3-feaf5cdbe46f,timestamp:1697087377\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:37,829 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:37,829 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:37,830 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:37,830 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:37,829 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:37,829 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9e5b360c-5113-4481-a8f3-feaf5cdbe46f,timestamp:1697087377\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:37,829 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:37,829 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:37,830 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:37,830 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,098 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,098 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9fb82536-f669-4090-b840-62ff1d3b9870,timestamp:1697087379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,098 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,098 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9fb82536-f669-4090-b840-62ff1d3b9870,timestamp:1697087379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:39,099 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,444 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1343\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,444 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1342.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:99124d49-de63-474d-8f70-b5ddb902b03f,timestamp:1697087380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,444 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1343\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,444 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1342.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:99124d49-de63-474d-8f70-b5ddb902b03f,timestamp:1697087380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:40,445 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1488\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1487.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:05eaf128-04b4-4a89-be0b-24a32b938b83,timestamp:1697087381\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1488\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1488\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1487.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:05eaf128-04b4-4a89-be0b-24a32b938b83,timestamp:1697087381\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1488\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:41,936 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.93|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32c88843-0ab7-483b-a873-dbb405c92f2f,timestamp:1697087383\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.93|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:32c88843-0ab7-483b-a873-dbb405c92f2f,timestamp:1697087383\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:43,248 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18f10bbb-8c2b-4880-b1c6-95f43c52181c,timestamp:1697087384\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18f10bbb-8c2b-4880-b1c6-95f43c52181c,timestamp:1697087384\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:44,546 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5ea60c08-e114-4513-80f9-f3eb43502bed,timestamp:1697087385\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5ea60c08-e114-4513-80f9-f3eb43502bed,timestamp:1697087385\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:45,814 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e4a6571-5934-4be1-9463-fa67a8fb1ef3,timestamp:1697087387\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e4a6571-5934-4be1-9463-fa67a8fb1ef3,timestamp:1697087387\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,084 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:47,085 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,621 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1534\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1535\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1533.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dc4e0671-6054-4dbb-87f9-f6e96aa8fdcd,timestamp:1697087388\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,621 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1534\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1535\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:48,624 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1533.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dc4e0671-6054-4dbb-87f9-f6e96aa8fdcd,timestamp:1697087388\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,925 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,925 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d09a807-3882-4220-ae76-e39c4555b6d1,timestamp:1697087389\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,925 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,925 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d09a807-3882-4220-ae76-e39c4555b6d1,timestamp:1697087389\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:49,926 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b7d488c8-715a-4a47-8419-0f0102f99f0f,timestamp:1697087391\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.57|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b7d488c8-715a-4a47-8419-0f0102f99f0f,timestamp:1697087391\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:51,209 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ce69c5c4-9858-48b5-a61e-ca64f2d88311,timestamp:1697087392\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ce69c5c4-9858-48b5-a61e-ca64f2d88311,timestamp:1697087392\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:52,475 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1520.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a468dace-f466-4b22-bc28-5f1b4c41365e,timestamp:1697087393\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:54,000 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:54,000 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1520.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a468dace-f466-4b22-bc28-5f1b4c41365e,timestamp:1697087393\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:53,999 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:54,000 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:54,000 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ba0b091e-0942-4b8f-a891-90d28ee0c6bb,timestamp:1697087395\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ba0b091e-0942-4b8f-a891-90d28ee0c6bb,timestamp:1697087395\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:55,255 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1743\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1742.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c09abbae-ea29-41c5-a3b8-90217e42a579,timestamp:1697087397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1743\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1743\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1742.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c09abbae-ea29-41c5-a3b8-90217e42a579,timestamp:1697087397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1743\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:57,001 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,759 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1755\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,759 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1754.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63d3bc4c-6bd8-4296-b9d0-39a39ba9d934,timestamp:1697087398\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1756\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,759 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1755\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,759 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1754.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63d3bc4c-6bd8-4296-b9d0-39a39ba9d934,timestamp:1697087398\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1756\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:09:58,760 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,509 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1746\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,509 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1746.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5902549-1e4c-47ab-9b73-f0e4f5dfc7d3,timestamp:1697087400\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,509 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1746\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,509 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1746.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5902549-1e4c-47ab-9b73-f0e4f5dfc7d3,timestamp:1697087400\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1748\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1748\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:00,510 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.92|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ae4dafbd-3d20-4c4f-8c46-6a0f0e18583e,timestamp:1697087401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.92|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ae4dafbd-3d20-4c4f-8c46-6a0f0e18583e,timestamp:1697087401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:01,756 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b9d638ca-f45d-4b73-a272-c92fce7b0226,timestamp:1697087403\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b9d638ca-f45d-4b73-a272-c92fce7b0226,timestamp:1697087403\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:03,019 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:04,279 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:04,279 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd10d674-2403-4150-a81f-1b1276416990,timestamp:1697087404\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:04,280 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:04,280 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:04,280 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:04,280 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:04,279 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:04,279 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd10d674-2403-4150-a81f-1b1276416990,timestamp:1697087404\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:04,280 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:04,280 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:04,280 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:04,280 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4435ca1-d94d-4de2-9571-a19ba6ed24e8,timestamp:1697087405\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4435ca1-d94d-4de2-9571-a19ba6ed24e8,timestamp:1697087405\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:05,538 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7b50ce95-7d1c-49e5-802c-e791fcd2141d,timestamp:1697087406\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7b50ce95-7d1c-49e5-802c-e791fcd2141d,timestamp:1697087406\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:06,787 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44a841fa-676b-4f9e-9f61-0664f6133ca9,timestamp:1697087408\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:08,030 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44a841fa-676b-4f9e-9f61-0664f6133ca9,timestamp:1697087408\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,029 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:08,030 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07d377d9-15a5-4f10-bede-c7dcf73162f2,timestamp:1697087409\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07d377d9-15a5-4f10-bede-c7dcf73162f2,timestamp:1697087409\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:09,294 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8a7906e2-d83f-46b0-ac59-33867eb8a464,timestamp:1697087410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8a7906e2-d83f-46b0-ac59-33867eb8a464,timestamp:1697087410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:10,545 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,800 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,800 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a8d1018d-5410-457d-8067-f57177fe442e,timestamp:1697087411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,800 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,800 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a8d1018d-5410-457d-8067-f57177fe442e,timestamp:1697087411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:11,801 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1420\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1420.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e162a3cf-4023-4f53-8fe7-366a386647ba,timestamp:1697087413\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1421\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1420\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1420.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e162a3cf-4023-4f53-8fe7-366a386647ba,timestamp:1697087413\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1421\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:13,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1727.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:451c77f4-67c8-464e-967d-b449f065ce71,timestamp:1697087414\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1727.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:451c77f4-67c8-464e-967d-b449f065ce71,timestamp:1697087414\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:14,955 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1622\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1623\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1621.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80d44dac-c2db-4496-8412-d89a9cdf73d8,timestamp:1697087416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1622\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1623\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1621.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80d44dac-c2db-4496-8412-d89a9cdf73d8,timestamp:1697087416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:16,581 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ab13451-a471-4291-8790-11bf19a87b6b,timestamp:1697087417\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3137321472168|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551399230957031|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12927.2421875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2475.07421875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3ab13451-a471-4291-8790-11bf19a87b6b,timestamp:1697087417\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:17,849 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3137321472168|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551399230957031|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12927.2421875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2475.07421875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb70cceb-d3be-471d-b12c-b977621c1854,timestamp:1697087419\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb70cceb-d3be-471d-b12c-b977621c1854,timestamp:1697087419\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:19,263 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5661bfc6-8721-4ae9-800d-c06a937304e6,timestamp:1697087420\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5661bfc6-8721-4ae9-800d-c06a937304e6,timestamp:1697087420\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:20,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,868 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,868 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a6179cbf-1665-4ca4-ba4d-05301693f40d,timestamp:1697087421\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,868 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,868 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a6179cbf-1665-4ca4-ba4d-05301693f40d,timestamp:1697087421\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:21,869 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1663\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1667.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cca0813-2a74-46d8-bac8-4cb7ecabd37c,timestamp:1697087423\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,541 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:23,541 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1663\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1667.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cca0813-2a74-46d8-bac8-4cb7ecabd37c,timestamp:1697087423\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,540 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,541 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:23,541 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:703c9e47-366a-4b3f-933a-4a96e7a1451d,timestamp:1697087424\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1416\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:703c9e47-366a-4b3f-933a-4a96e7a1451d,timestamp:1697087424\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1416\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:24,960 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,249 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,249 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:447ef808-3354-4bc1-8c03-a0b623c62b5e,timestamp:1697087426\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,249 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,249 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:447ef808-3354-4bc1-8c03-a0b623c62b5e,timestamp:1697087426\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:26,250 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d04cd3e2-c25a-4770-b6c4-64312b763824,timestamp:1697087427\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1301.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d04cd3e2-c25a-4770-b6c4-64312b763824,timestamp:1697087427\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1302\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:27,555 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,262 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1704\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,262 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1703.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a20072d7-989d-4be9-bddf-785086c7b4f6,timestamp:1697087429\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,262 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1704\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,262 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1703.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a20072d7-989d-4be9-bddf-785086c7b4f6,timestamp:1697087429\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:29,263 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3424fb85-72ff-47a3-89e7-7a9b21e2af9c,timestamp:1697087430\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3424fb85-72ff-47a3-89e7-7a9b21e2af9c,timestamp:1697087430\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:30,546 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f99e232f-7304-428b-a1eb-45af52908753,timestamp:1697087431\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f99e232f-7304-428b-a1eb-45af52908753,timestamp:1697087431\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:31,821 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1296\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1295.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cab78fc-e35a-4b86-b36c-0536c4b4a5eb,timestamp:1697087433\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1296\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1295.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cab78fc-e35a-4b86-b36c-0536c4b4a5eb,timestamp:1697087433\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1297\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:33,121 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1379.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:92266acb-4548-414c-8710-ca9419fab434,timestamp:1697087434\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,505 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:34,505 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1379.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:92266acb-4548-414c-8710-ca9419fab434,timestamp:1697087434\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,504 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,505 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:34,505 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62984b53-053f-4c14-9c20-008dfd54d184,timestamp:1697087435\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62984b53-053f-4c14-9c20-008dfd54d184,timestamp:1697087435\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:35,759 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:54873644-b0eb-445b-87f3-ffffaa978615,timestamp:1697087437\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:37,027 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:54873644-b0eb-445b-87f3-ffffaa978615,timestamp:1697087437\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b27ce2a1-f21c-4583-8d8f-b35d0740d996,timestamp:1697087438\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b27ce2a1-f21c-4583-8d8f-b35d0740d996,timestamp:1697087438\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:38,305 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6fbaaeb-26a9-419c-bed6-6f6d1b6162b7,timestamp:1697087439\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6fbaaeb-26a9-419c-bed6-6f6d1b6162b7,timestamp:1697087439\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:39,550 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1803\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1802.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18c15bab-61d4-4f22-ba45-11f6229629cf,timestamp:1697087441\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1803\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1803\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1802.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18c15bab-61d4-4f22-ba45-11f6229629cf,timestamp:1697087441\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1803\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:41,356 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,631 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,631 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd44d4c8-5de0-478a-b035-e1fece9efe80,timestamp:1697087442\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,631 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,631 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd44d4c8-5de0-478a-b035-e1fece9efe80,timestamp:1697087442\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:42,632 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c289b389-e40f-4d57-95cd-ddfe3922fcde,timestamp:1697087443\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c289b389-e40f-4d57-95cd-ddfe3922fcde,timestamp:1697087443\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:43,876 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1308\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5772989e-dd38-4c45-b7a5-0af5a317fd9a,timestamp:1697087445\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1308\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1308\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1307.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5772989e-dd38-4c45-b7a5-0af5a317fd9a,timestamp:1697087445\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1308\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:45,187 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b6a3206c-8a68-4810-9612-5ab276c7adb1,timestamp:1697087446\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b6a3206c-8a68-4810-9612-5ab276c7adb1,timestamp:1697087446\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:46,437 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5bc662e0-6f6d-424c-8726-885545a2ae49,timestamp:1697087447\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5bc662e0-6f6d-424c-8726-885545a2ae49,timestamp:1697087447\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:47,678 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1468.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3832670e-0f8a-45fa-95d1-eeb4a216570b,timestamp:1697087449\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1468.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3832670e-0f8a-45fa-95d1-eeb4a216570b,timestamp:1697087449\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:49,151 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:be4ce414-0645-4196-924e-0a7e899225c8,timestamp:1697087450\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:50,384 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:be4ce414-0645-4196-924e-0a7e899225c8,timestamp:1697087450\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,383 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:50,384 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39664c6e-30eb-4183-8814-3cf478de9a3f,timestamp:1697087451\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39664c6e-30eb-4183-8814-3cf478de9a3f,timestamp:1697087451\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:51,621 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d05ac8f6-8e7f-45b6-bbda-ddf113c4ccfc,timestamp:1697087452\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d05ac8f6-8e7f-45b6-bbda-ddf113c4ccfc,timestamp:1697087452\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:52,880 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1481\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1277e012-88fc-416f-b3e3-c018040d9929,timestamp:1697087454\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1482\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1481\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1277e012-88fc-416f-b3e3-c018040d9929,timestamp:1697087454\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1482\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:54,364 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1520.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:214b2cce-d3ab-4af4-ab90-5488cfa962fa,timestamp:1697087455\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1520.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:214b2cce-d3ab-4af4-ab90-5488cfa962fa,timestamp:1697087455\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:55,888 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,189 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,189 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a65741f3-12c5-43cf-b274-fe36679f539f,timestamp:1697087457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,189 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,189 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a65741f3-12c5-43cf-b274-fe36679f539f,timestamp:1697087457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:57,190 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,932 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1739\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,932 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1739.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e87533c-09ea-4f01-94ec-9d6ea0d41cb5,timestamp:1697087458\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1741\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,932 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1739\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,932 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1739.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e87533c-09ea-4f01-94ec-9d6ea0d41cb5,timestamp:1697087458\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1741\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:10:58,933 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:361a36f1-1196-4d4a-94e5-55de12caad6d,timestamp:1697087460\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:361a36f1-1196-4d4a-94e5-55de12caad6d,timestamp:1697087460\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:00,181 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2d16d59-be9a-4912-981a-aea56b44d3db,timestamp:1697087461\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,444 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:01,444 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2d16d59-be9a-4912-981a-aea56b44d3db,timestamp:1697087461\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,443 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,444 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:01,444 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1663\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2437b48-b45b-4f76-a151-91fb56ae7f84,timestamp:1697087463\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1663\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2437b48-b45b-4f76-a151-91fb56ae7f84,timestamp:1697087463\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:03,109 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,368 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,368 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:76316a78-29ad-4562-8e2f-7f5b7cc4e00a,timestamp:1697087464\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,368 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,368 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:76316a78-29ad-4562-8e2f-7f5b7cc4e00a,timestamp:1697087464\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:04,369 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a04a1dd-eeb1-4d5a-8774-c7903cffd71e,timestamp:1697087465\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:05,652 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a04a1dd-eeb1-4d5a-8774-c7903cffd71e,timestamp:1697087465\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,651 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:05,652 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1283.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:347d8ed5-d1d2-4fb8-8ecf-9af13203781a,timestamp:1697087466\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1283.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:347d8ed5-d1d2-4fb8-8ecf-9af13203781a,timestamp:1697087466\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:06,939 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1512\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1512.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:335e1a14-a73f-470c-af28-2ff6671cc7ae,timestamp:1697087468\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1513\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1512\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1512.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:335e1a14-a73f-470c-af28-2ff6671cc7ae,timestamp:1697087468\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,454 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1513\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:08,455 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1737\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1736.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59a4fd47-0c54-4302-93e4-8f8d37a93866,timestamp:1697087470\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1737\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1737\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1736.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59a4fd47-0c54-4302-93e4-8f8d37a93866,timestamp:1697087470\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1737\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:10,194 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,455 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:51443e7d-cf00-4ec4-ba08-2fbadb24fbcf,timestamp:1697087471\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,455 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:51443e7d-cf00-4ec4-ba08-2fbadb24fbcf,timestamp:1697087471\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:11,456 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1357\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55075465-2615-447e-b2a6-461c98e1375d,timestamp:1697087472\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:12,817 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1357\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55075465-2615-447e-b2a6-461c98e1375d,timestamp:1697087472\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,816 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:12,817 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,099 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7bc40ab-7f38-403b-afed-10da4ce1542b,timestamp:1697087474\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,099 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7bc40ab-7f38-403b-afed-10da4ce1542b,timestamp:1697087474\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:14,100 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1291.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1f506ab-dfc5-4061-9dde-b1ad377abf0d,timestamp:1697087475\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1291.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a1f506ab-dfc5-4061-9dde-b1ad377abf0d,timestamp:1697087475\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,394 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:15,395 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,047 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1649\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,047 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d88a9f6b-9d78-4fed-bdae-1578062a00e3,timestamp:1697087477\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1651\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,047 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1649\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,047 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d88a9f6b-9d78-4fed-bdae-1578062a00e3,timestamp:1697087477\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1651\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:17,048 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31362533569336|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551506042480469|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12926.99609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2475.3203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:976a7206-477d-4bb4-9d2f-39e76891f012,timestamp:1697087478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31362533569336|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551506042480469|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12926.99609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2475.3203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,264 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:976a7206-477d-4bb4-9d2f-39e76891f012,timestamp:1697087478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,448 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:18,449 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:38384145-ea3a-46d5-9a0b-b1756f29f39a,timestamp:1697087479\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:38384145-ea3a-46d5-9a0b-b1756f29f39a,timestamp:1697087479\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:19,711 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1651\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1650.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63f62249-af29-40eb-abee-156b3c828d3c,timestamp:1697087481\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1651\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1651\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1650.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:63f62249-af29-40eb-abee-156b3c828d3c,timestamp:1697087481\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1651\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:21,365 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1398\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,767 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1397.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c371450b-da3b-450d-8597-57c44c7762e3,timestamp:1697087482\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:22,767 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1398\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,767 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1397.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c371450b-da3b-450d-8597-57c44c7762e3,timestamp:1697087482\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,766 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:22,767 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a368034-86d4-4e20-939e-c8df657108ea,timestamp:1697087484\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0a368034-86d4-4e20-939e-c8df657108ea,timestamp:1697087484\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:24,103 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,678 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1572\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1571.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:db689326-6aca-4769-967f-750e23fcf964,timestamp:1697087485\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1573\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,678 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1572\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1571.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:db689326-6aca-4769-967f-750e23fcf964,timestamp:1697087485\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1573\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:25,679 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1640\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4f700dcf-1e26-4ace-b73d-5143ac8d7dae,timestamp:1697087487\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1640\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4f700dcf-1e26-4ace-b73d-5143ac8d7dae,timestamp:1697087487\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:27,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:196b23c0-c7b4-465b-8e33-6a69b8ce0c90,timestamp:1697087488\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:196b23c0-c7b4-465b-8e33-6a69b8ce0c90,timestamp:1697087488\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:28,623 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,316 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1690\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,316 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1689.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8136bcf8-9f59-4024-8682-a1fd0df2b8d0,timestamp:1697087490\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1691\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,316 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1690\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,316 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1689.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8136bcf8-9f59-4024-8682-a1fd0df2b8d0,timestamp:1697087490\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1691\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:30,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,578 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ec55d47-39aa-4227-8457-a78565cac2ef,timestamp:1697087491\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,578 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ec55d47-39aa-4227-8457-a78565cac2ef,timestamp:1697087491\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:31,579 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,849 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:844b91b5-e172-4a5b-8bd9-10166a87495d,timestamp:1697087492\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,849 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:844b91b5-e172-4a5b-8bd9-10166a87495d,timestamp:1697087492\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:32,850 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1428\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1428\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1428\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1428\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1426.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e1d90ed4-cca6-4534-abe5-e6697f8e1543,timestamp:1697087494\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1426.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e1d90ed4-cca6-4534-abe5-e6697f8e1543,timestamp:1697087494\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:34,281 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,520 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a77d077-1155-4d03-b07c-712bd576c07e,timestamp:1697087495\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,520 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5a77d077-1155-4d03-b07c-712bd576c07e,timestamp:1697087495\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:35,521 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1436\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1434.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:da1b929a-f6ba-4825-a71d-ad6fe839314f,timestamp:1697087496\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1436\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1436\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1434.78|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:da1b929a-f6ba-4825-a71d-ad6fe839314f,timestamp:1697087496\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1436\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:36,959 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1318\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1317.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c07d97b-3727-4fc0-a913-d64a762b152c,timestamp:1697087498\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1318\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1317.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c07d97b-3727-4fc0-a913-d64a762b152c,timestamp:1697087498\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:38,280 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1515\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1514.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5eadfa0-6cb4-417d-8c80-26adbc6e4b3a,timestamp:1697087499\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1515\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:39,799 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1515\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1514.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d5eadfa0-6cb4-417d-8c80-26adbc6e4b3a,timestamp:1697087499\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1515\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:39,799 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9b8b24a2-a037-401f-b427-20175b061ab2,timestamp:1697087501\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9b8b24a2-a037-401f-b427-20175b061ab2,timestamp:1697087501\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:41,066 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,881 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1812\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1812.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:004cd715-8d52-45e3-918f-b2a21511e47d,timestamp:1697087502\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1814\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,881 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1812\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1812.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:004cd715-8d52-45e3-918f-b2a21511e47d,timestamp:1697087502\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1814\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:42,882 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1471\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1470.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2740a5e-9802-40d0-abb2-669e204d5f77,timestamp:1697087504\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1472\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1471\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1470.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2740a5e-9802-40d0-abb2-669e204d5f77,timestamp:1697087504\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1472\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:44,356 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1508\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1508.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:903c334a-9708-423c-8172-dae1cbfcb5f5,timestamp:1697087505\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1509\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:45,868 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1508\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1508.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:903c334a-9708-423c-8172-dae1cbfcb5f5,timestamp:1697087505\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1509\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,867 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:45,868 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a87fedfd-1f2a-4cef-b823-fc581919e9ae,timestamp:1697087507\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a87fedfd-1f2a-4cef-b823-fc581919e9ae,timestamp:1697087507\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1346\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:47,217 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1346\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,216 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:47,217 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:48,668 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1449\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:48,668 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1448.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cbcf31d-27a9-4fad-a54a-16ed3578beba,timestamp:1697087508\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1450\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:48,668 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1449\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:48,668 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1448.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5cbcf31d-27a9-4fad-a54a-16ed3578beba,timestamp:1697087508\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1450\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:48,669 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,994 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,994 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:846cbafd-86ef-4f7c-999e-3996ffcbdb78,timestamp:1697087509\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,994 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,994 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:49,993 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:846cbafd-86ef-4f7c-999e-3996ffcbdb78,timestamp:1697087509\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2b73989-ece1-4c03-b9b3-f8f9281ee486,timestamp:1697087511\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2b73989-ece1-4c03-b9b3-f8f9281ee486,timestamp:1697087511\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:51,284 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:836a3c18-a6e0-4d64-8752-082985ab37ba,timestamp:1697087512\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:836a3c18-a6e0-4d64-8752-082985ab37ba,timestamp:1697087512\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:52,538 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,802 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,802 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2d69dd5-b523-4def-9def-b5029518a933,timestamp:1697087513\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,802 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,802 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2d69dd5-b523-4def-9def-b5029518a933,timestamp:1697087513\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:53,803 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,065 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,065 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c83509b8-7250-4f0b-8fb2-51d58ca54954,timestamp:1697087515\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,065 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,065 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c83509b8-7250-4f0b-8fb2-51d58ca54954,timestamp:1697087515\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:55,066 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1515\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1515.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:251eac28-1a95-4c80-a173-0d557a87f920,timestamp:1697087516\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1516\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:56,585 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1515\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1515.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:251eac28-1a95-4c80-a173-0d557a87f920,timestamp:1697087516\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1516\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,584 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:56,585 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c85b76e2-02f8-4f84-977a-fae504efdf16,timestamp:1697087517\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c85b76e2-02f8-4f84-977a-fae504efdf16,timestamp:1697087517\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:57,874 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:59,110 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:59,110 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d1583cf-c03d-4d2f-8698-228eeccedb18,timestamp:1697087519\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:59,111 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:59,111 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:59,111 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:11:59,111 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:59,110 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:59,110 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d1583cf-c03d-4d2f-8698-228eeccedb18,timestamp:1697087519\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:59,111 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:59,111 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:59,111 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:11:59,111 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fae2d710-addd-405e-8e29-1c28c5845ab9,timestamp:1697087520\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.84|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fae2d710-addd-405e-8e29-1c28c5845ab9,timestamp:1697087520\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:00,357 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5abde31c-d057-4489-a273-5f272744b990,timestamp:1697087521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5abde31c-d057-4489-a273-5f272744b990,timestamp:1697087521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:01,663 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57ebb7b6-8707-4548-9b8c-dc3d09793c5f,timestamp:1697087522\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57ebb7b6-8707-4548-9b8c-dc3d09793c5f,timestamp:1697087522\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:02,945 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e56612e6-b63a-42ae-9488-893207a1e0fa,timestamp:1697087524\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e56612e6-b63a-42ae-9488-893207a1e0fa,timestamp:1697087524\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:04,234 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d04e056b-33ea-4acb-901e-a8ffc107924c,timestamp:1697087525\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d04e056b-33ea-4acb-901e-a8ffc107924c,timestamp:1697087525\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:05,528 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1406\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1405.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fe4a0e4a-bfaa-4c28-8b70-d79f42603bfe,timestamp:1697087526\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1407\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1406\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1405.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fe4a0e4a-bfaa-4c28-8b70-d79f42603bfe,timestamp:1697087526\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1407\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:06,938 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,319 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8e07c35-dd5d-4098-921f-3ded4f9e33c9,timestamp:1697087528\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,319 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1377.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8e07c35-dd5d-4098-921f-3ded4f9e33c9,timestamp:1697087528\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:08,320 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1888\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1887.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f7b60541-49b7-487a-9965-0d7e01aeef15,timestamp:1697087530\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1888\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1888\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1887.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f7b60541-49b7-487a-9965-0d7e01aeef15,timestamp:1697087530\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1888\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:10,211 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,554 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:590a3024-2e80-4506-92eb-96f0066d0c09,timestamp:1697087531\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1341\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,554 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1339\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,554 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:590a3024-2e80-4506-92eb-96f0066d0c09,timestamp:1697087531\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1341\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:11,555 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1379.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd40032a-9349-43cf-a917-e814d49e948c,timestamp:1697087532\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1379.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd40032a-9349-43cf-a917-e814d49e948c,timestamp:1697087532\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1380\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:12,938 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1995\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1995.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:21de6077-0eee-4ab2-8196-602583987490,timestamp:1697087534\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1995\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1995\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1995.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:21de6077-0eee-4ab2-8196-602583987490,timestamp:1697087534\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,936 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1995\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:14,937 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1394\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c414cbb-636f-481e-ad4a-31888d84bb49,timestamp:1697087536\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1394\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c414cbb-636f-481e-ad4a-31888d84bb49,timestamp:1697087536\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:16,333 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,690 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:50564332-947b-453a-aa5d-9f1be7d34ea7,timestamp:1697087537\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,690 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,690 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:50564332-947b-453a-aa5d-9f1be7d34ea7,timestamp:1697087537\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,690 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:17,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,264 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313514709472656|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551616668701172|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12905.0859375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2497.24609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:17,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,264 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313514709472656|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551616668701172|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12905.0859375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2497.24609375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8b5ade06-509d-427e-bc25-b00ef1edc7bd,timestamp:1697087538\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8b5ade06-509d-427e-bc25-b00ef1edc7bd,timestamp:1697087538\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:18,976 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:20,611 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:20,611 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:553b3636-fc2a-4956-8cb3-b393115dfc1b,timestamp:1697087540\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:20,612 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:20,612 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:20,612 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:20,612 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:20,611 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:20,611 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:553b3636-fc2a-4956-8cb3-b393115dfc1b,timestamp:1697087540\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:20,612 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:20,612 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:20,612 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:20,612 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:928f0286-a341-40f3-9eae-9954b003db1d,timestamp:1697087541\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:928f0286-a341-40f3-9eae-9954b003db1d,timestamp:1697087541\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:21,880 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8013332d-7596-441d-b86e-6c51c43b0ba1,timestamp:1697087543\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1334\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1333.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8013332d-7596-441d-b86e-6c51c43b0ba1,timestamp:1697087543\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:23,217 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d24447cb-2146-4fa1-8933-b629426dcc6f,timestamp:1697087544\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d24447cb-2146-4fa1-8933-b629426dcc6f,timestamp:1697087544\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1325\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:24,545 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,825 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7e258562-ba4c-4f1e-8989-1cd9b2ff93e1,timestamp:1697087545\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,825 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7e258562-ba4c-4f1e-8989-1cd9b2ff93e1,timestamp:1697087545\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:25,826 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1409\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1408.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6944f18-4017-4ce8-9126-0021f8dad61a,timestamp:1697087547\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1409\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1408.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e6944f18-4017-4ce8-9126-0021f8dad61a,timestamp:1697087547\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:27,238 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d65941c7-797a-4f78-9b77-2df91c049ee6,timestamp:1697087548\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d65941c7-797a-4f78-9b77-2df91c049ee6,timestamp:1697087548\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:28,522 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f74ab2d7-3313-4b0a-9b21-0a258d59f822,timestamp:1697087550\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f74ab2d7-3313-4b0a-9b21-0a258d59f822,timestamp:1697087550\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:30,164 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd9281e7-dfa6-4c41-9f5d-c9e012bc91e8,timestamp:1697087551\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd9281e7-dfa6-4c41-9f5d-c9e012bc91e8,timestamp:1697087551\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:31,442 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cf420b14-7146-4276-b6eb-bd2597a0f950,timestamp:1697087552\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cf420b14-7146-4276-b6eb-bd2597a0f950,timestamp:1697087552\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:32,696 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4c5fd6fe-8d72-430b-b543-d93c36250dd2,timestamp:1697087553\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4c5fd6fe-8d72-430b-b543-d93c36250dd2,timestamp:1697087553\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:33,943 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:88ede10c-ab04-4170-8c5e-600bf788d964,timestamp:1697087555\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,227 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:35,227 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:88ede10c-ab04-4170-8c5e-600bf788d964,timestamp:1697087555\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,226 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,227 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:35,227 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f4a2af53-c07a-4e99-a4ef-5a3bfdfcaf8b,timestamp:1697087556\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f4a2af53-c07a-4e99-a4ef-5a3bfdfcaf8b,timestamp:1697087556\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:36,490 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1800\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1799.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9f4c7b51-8950-4a3d-bda7-cc8eaee8d3a6,timestamp:1697087558\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1800\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1800\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1799.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9f4c7b51-8950-4a3d-bda7-cc8eaee8d3a6,timestamp:1697087558\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1800\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:38,293 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,558 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2abda9c5-a70d-4664-a5fc-188d19915fa9,timestamp:1697087559\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,558 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2abda9c5-a70d-4664-a5fc-188d19915fa9,timestamp:1697087559\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:39,559 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:40,796 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:40,796 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80a42c5b-1d76-476e-8062-d9967eb334e9,timestamp:1697087560\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:40,796 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:40,797 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:40,797 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:40,797 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:40,796 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:40,796 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80a42c5b-1d76-476e-8062-d9967eb334e9,timestamp:1697087560\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:40,796 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:40,797 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:40,797 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:40,797 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1400.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9d59c8f1-85e5-4f2b-83c5-4a04fdff5893,timestamp:1697087562\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1400.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9d59c8f1-85e5-4f2b-83c5-4a04fdff5893,timestamp:1697087562\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1401\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:42,200 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,457 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,457 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e3c4a12-70df-4b23-96e4-42006b681438,timestamp:1697087563\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,457 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,457 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e3c4a12-70df-4b23-96e4-42006b681438,timestamp:1697087563\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:43,458 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ebc98a0d-6fcd-4e36-b993-46299f3afc29,timestamp:1697087565\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1671\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:45,133 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ebc98a0d-6fcd-4e36-b993-46299f3afc29,timestamp:1697087565\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1671\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,132 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:45,133 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55f3d7b6-ff16-4a64-9e8a-6419d19550b2,timestamp:1697087566\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1280.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:55f3d7b6-ff16-4a64-9e8a-6419d19550b2,timestamp:1697087566\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1281\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:46,416 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1477.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7534c89-d777-4375-aba4-90ebf555b788,timestamp:1697087567\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1478\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,898 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:47,898 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1477.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a7534c89-d777-4375-aba4-90ebf555b788,timestamp:1697087567\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1478\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,897 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,898 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:47,898 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1515ca1b-d654-4246-a2e8-1bcbe192586c,timestamp:1697087569\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:49,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,165 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1515ca1b-d654-4246-a2e8-1bcbe192586c,timestamp:1697087569\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:49,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1398.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a9bdcb9-9d8f-4bd2-8342-11248291de9e,timestamp:1697087570\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1398.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a9bdcb9-9d8f-4bd2-8342-11248291de9e,timestamp:1697087570\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:50,567 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:51,856 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:51,856 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:51,856 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:176f2612-2967-4fa2-aa58-9b359e764ab3,timestamp:1697087571\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:51,856 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:51,857 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:51,857 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:51,856 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:51,856 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:51,856 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:176f2612-2967-4fa2-aa58-9b359e764ab3,timestamp:1697087571\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:51,856 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:51,857 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:51,857 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6cbd749d-597e-4200-81fb-ff68bd0b00d1,timestamp:1697087573\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:53,121 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6cbd749d-597e-4200-81fb-ff68bd0b00d1,timestamp:1697087573\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,120 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:53,121 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75150bff-3718-4182-80ff-2da89eb262aa,timestamp:1697087574\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:54,371 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75150bff-3718-4182-80ff-2da89eb262aa,timestamp:1697087574\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,664 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ac178649-ede7-4e40-9b14-eb033a80c252,timestamp:1697087575\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,664 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ac178649-ede7-4e40-9b14-eb033a80c252,timestamp:1697087575\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:55,665 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30a705e8-5ac2-49af-9f2b-4aa211b962bc,timestamp:1697087576\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,994 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:56,994 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30a705e8-5ac2-49af-9f2b-4aa211b962bc,timestamp:1697087576\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,992 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,994 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:56,994 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:13e4455e-92ef-44ae-808b-27318969a3e8,timestamp:1697087578\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:13e4455e-92ef-44ae-808b-27318969a3e8,timestamp:1697087578\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:58,317 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bf197b7-980c-4ca3-b31f-6bb77e6bcf11,timestamp:1697087579\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bf197b7-980c-4ca3-b31f-6bb77e6bcf11,timestamp:1697087579\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:12:59,577 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4f9fa01c-dbdf-47db-a396-123914a77e85,timestamp:1697087580\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4f9fa01c-dbdf-47db-a396-123914a77e85,timestamp:1697087580\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:00,818 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a5357d90-09c1-434a-982b-5ec2499a8072,timestamp:1697087582\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a5357d90-09c1-434a-982b-5ec2499a8072,timestamp:1697087582\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:02,095 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,357 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2e8e185e-b5f6-4d28-9d63-65b2c44a76c4,timestamp:1697087583\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,357 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2e8e185e-b5f6-4d28-9d63-65b2c44a76c4,timestamp:1697087583\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:03,358 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1360\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1360\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1359.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b96a2ade-0646-47a7-b9af-c54e83c77083,timestamp:1697087584\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1361\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1359.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b96a2ade-0646-47a7-b9af-c54e83c77083,timestamp:1697087584\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1361\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:04,721 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:762d8cfd-7c2b-4f2c-91c7-aa9a58db4a6b,timestamp:1697087586\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:762d8cfd-7c2b-4f2c-91c7-aa9a58db4a6b,timestamp:1697087586\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:06,077 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,515 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1435\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1435.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:688a64a6-c708-418e-9b5f-5658899034e6,timestamp:1697087587\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1437\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,515 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1435\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1435.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:688a64a6-c708-418e-9b5f-5658899034e6,timestamp:1697087587\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1437\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:07,516 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:36a46d19-031d-46c6-89b3-cfb962781e41,timestamp:1697087589\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:36a46d19-031d-46c6-89b3-cfb962781e41,timestamp:1697087589\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:09,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,421 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:77818bf8-1a8d-4710-b7bf-c60427ad9d3b,timestamp:1697087590\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,421 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:77818bf8-1a8d-4710-b7bf-c60427ad9d3b,timestamp:1697087590\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:10,422 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1411.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75914ee4-39b2-44e0-9070-e9057d04ba0a,timestamp:1697087591\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1412\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1411.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:75914ee4-39b2-44e0-9070-e9057d04ba0a,timestamp:1697087591\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1412\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:11,837 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:11,836 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:11,837 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a09033a-3a39-4b40-9607-523d04914212,timestamp:1697087593\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a09033a-3a39-4b40-9607-523d04914212,timestamp:1697087593\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:13,145 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,790 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1642\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,790 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1642.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bb930c0e-021a-4aa5-a938-b02d1f6d8e50,timestamp:1697087594\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1644\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,790 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1642\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,790 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1642.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bb930c0e-021a-4aa5-a938-b02d1f6d8e50,timestamp:1697087594\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1644\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:14,791 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1651.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:37d9939a-2c4d-4d63-adc7-74183d4d353f,timestamp:1697087596\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1653\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1651.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:37d9939a-2c4d-4d63-adc7-74183d4d353f,timestamp:1697087596\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1653\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:16,447 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7b8c7c8-f71c-4e70-b94b-d8f6da1349d2,timestamp:1697087597\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c7b8c7c8-f71c-4e70-b94b-d8f6da1349d2,timestamp:1697087597\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,715 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:17,716 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31340408325195|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551727294921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12902.77734375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2499.51953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31340408325195|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551727294921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12902.77734375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2499.51953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:18,265 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087598\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,214 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1494\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1495\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1493.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7c2ed513-622f-4d66-ba71-4a406590bfb2,timestamp:1697087599\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,214 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1494\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1495\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,214 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1493.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7c2ed513-622f-4d66-ba71-4a406590bfb2,timestamp:1697087599\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:19,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,470 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,470 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aad603cf-98d1-4d05-8363-709e05398872,timestamp:1697087600\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,470 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,470 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aad603cf-98d1-4d05-8363-709e05398872,timestamp:1697087600\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:20,471 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:21,808 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6acbb341-c741-4f96-94dd-da60dcaeb15e,timestamp:1697087601\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:21,808 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6acbb341-c741-4f96-94dd-da60dcaeb15e,timestamp:1697087601\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:21,809 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30853154-295d-4ba0-8a47-ed88ca0dac1a,timestamp:1697087603\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:30853154-295d-4ba0-8a47-ed88ca0dac1a,timestamp:1697087603\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:23,089 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:24,367 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44d40bb3-0fcc-4a70-86f2-4879061be501,timestamp:1697087604\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1274\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,366 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:24,367 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44d40bb3-0fcc-4a70-86f2-4879061be501,timestamp:1697087604\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,837 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1468\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,837 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1466.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d63dbd8c-e033-4bbb-a037-9645d8c1ba8d,timestamp:1697087605\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,837 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1468\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,837 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1466.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d63dbd8c-e033-4bbb-a037-9645d8c1ba8d,timestamp:1697087605\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1469\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:25,838 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1405\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1404.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e088148b-ea47-4648-a614-d87eef2c8875,timestamp:1697087607\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1405\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1405\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1404.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e088148b-ea47-4648-a614-d87eef2c8875,timestamp:1697087607\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1405\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:27,246 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,504 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,504 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8fa6f4c-4408-4317-a9ae-defdf4364169,timestamp:1697087608\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,504 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,504 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8fa6f4c-4408-4317-a9ae-defdf4364169,timestamp:1697087608\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:28,505 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1343\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c8b16c1-faef-4b3c-b287-a653650fd773,timestamp:1697087609\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1343\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.0|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0c8b16c1-faef-4b3c-b287-a653650fd773,timestamp:1697087609\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:29,852 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,232 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,232 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1376.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:767c4801-18e5-4a96-ab51-28df7bcbc7ac,timestamp:1697087611\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1377\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,232 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,232 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1376.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:767c4801-18e5-4a96-ab51-28df7bcbc7ac,timestamp:1697087611\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1377\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:31,233 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53bbb5e5-2f61-4dda-9b22-f19118dd9616,timestamp:1697087612\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:53bbb5e5-2f61-4dda-9b22-f19118dd9616,timestamp:1697087612\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:32,497 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e3db748-8b4d-4c6f-af89-c2300f7ef528,timestamp:1697087613\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6e3db748-8b4d-4c6f-af89-c2300f7ef528,timestamp:1697087613\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:33,761 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d7a0058-81c4-4bba-94ff-f0dee62e3fdd,timestamp:1697087615\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d7a0058-81c4-4bba-94ff-f0dee62e3fdd,timestamp:1697087615\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:35,032 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e559a25b-0c4e-40da-b381-d89fd49ab3e8,timestamp:1697087616\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,354 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e559a25b-0c4e-40da-b381-d89fd49ab3e8,timestamp:1697087616\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:36,355 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1588\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1587.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4690e416-8e4f-4357-be20-9236e284e16c,timestamp:1697087617\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1589\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1588\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1587.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4690e416-8e4f-4357-be20-9236e284e16c,timestamp:1697087617\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1589\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:37,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1312.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bf059d92-138d-439e-a663-159b0770ef8b,timestamp:1697087619\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,263 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:39,263 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1312.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bf059d92-138d-439e-a663-159b0770ef8b,timestamp:1697087619\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,262 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,263 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:39,263 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1935\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1934.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d64b91c-b3ba-4dae-b21b-19e2f1db84c9,timestamp:1697087621\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1935\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,201 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:41,201 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1935\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1934.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5d64b91c-b3ba-4dae-b21b-19e2f1db84c9,timestamp:1697087621\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1935\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,200 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,201 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:41,201 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aea18087-70a8-4e7a-a10e-646121ac5667,timestamp:1697087622\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aea18087-70a8-4e7a-a10e-646121ac5667,timestamp:1697087622\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1235\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:42,438 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:44,068 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:44,068 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1626.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:eb1908c3-42db-4cd5-97ce-59743d4c939d,timestamp:1697087624\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:44,068 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1627\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:44,069 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:44,069 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:44,069 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:44,068 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:44,068 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1626.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:eb1908c3-42db-4cd5-97ce-59743d4c939d,timestamp:1697087624\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:44,068 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1627\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:44,069 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:44,069 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:44,069 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6726b170-f56d-4d1f-b8b0-886736a0a71d,timestamp:1697087625\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.33|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6726b170-f56d-4d1f-b8b0-886736a0a71d,timestamp:1697087625\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:45,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,593 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bd60d85f-d87f-429b-b08b-fb67b0424aa3,timestamp:1697087626\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,593 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bd60d85f-d87f-429b-b08b-fb67b0424aa3,timestamp:1697087626\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:46,594 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1283.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c3b32279-a178-4e20-8d91-40661b283d4e,timestamp:1697087627\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1283.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c3b32279-a178-4e20-8d91-40661b283d4e,timestamp:1697087627\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:47,881 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c827dec4-7483-43cd-91b8-150c2174f85f,timestamp:1697087629\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,152 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:49,152 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c827dec4-7483-43cd-91b8-150c2174f85f,timestamp:1697087629\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,151 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,152 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:49,152 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7aadad20-c74e-46ab-895e-fb01dc0c68b7,timestamp:1697087630\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.34|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7aadad20-c74e-46ab-895e-fb01dc0c68b7,timestamp:1697087630\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:50,423 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1366\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1366.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9e24ff18-48fb-41fe-8e9b-ec310064fccf,timestamp:1697087631\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1366\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1366.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9e24ff18-48fb-41fe-8e9b-ec310064fccf,timestamp:1697087631\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1368\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:51,793 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,064 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,064 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08d073a7-0cf7-44ec-a145-c84c5ced67c8,timestamp:1697087633\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,064 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,064 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08d073a7-0cf7-44ec-a145-c84c5ced67c8,timestamp:1697087633\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:53,066 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:682e5ded-4272-499c-ad5b-2d24b0c85939,timestamp:1697087634\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:682e5ded-4272-499c-ad5b-2d24b0c85939,timestamp:1697087634\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:54,374 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1354\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c8265927-ece3-4057-94f9-c5a2e167ad01,timestamp:1697087635\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1354\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c8265927-ece3-4057-94f9-c5a2e167ad01,timestamp:1697087635\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:55,730 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:489a1884-9a05-4aab-982e-69737d7d8425,timestamp:1697087636\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:489a1884-9a05-4aab-982e-69737d7d8425,timestamp:1697087636\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:56,985 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44454ab6-d538-4f13-8443-e0e6cba8935f,timestamp:1697087638\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:44454ab6-d538-4f13-8443-e0e6cba8935f,timestamp:1697087638\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:58,276 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9c5cead2-5248-4d39-83e0-54bdfea38b4a,timestamp:1697087639\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:13:59,512 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9c5cead2-5248-4d39-83e0-54bdfea38b4a,timestamp:1697087639\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,864 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64525fd5-27ef-43e0-8858-781ffb109e88,timestamp:1697087640\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,864 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:64525fd5-27ef-43e0-8858-781ffb109e88,timestamp:1697087640\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:00,865 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:260e84ad-7729-4918-ac22-99806224721d,timestamp:1697087642\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.01|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:260e84ad-7729-4918-ac22-99806224721d,timestamp:1697087642\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:02,117 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,366 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2ad18248-6211-40c8-a931-63667639d134,timestamp:1697087643\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,366 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2ad18248-6211-40c8-a931-63667639d134,timestamp:1697087643\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:03,367 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4ae1e87a-6476-4bc4-be73-4070595722fa,timestamp:1697087644\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4ae1e87a-6476-4bc4-be73-4070595722fa,timestamp:1697087644\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:04,622 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:601c42e5-641e-4066-8c35-1816f7ab024c,timestamp:1697087645\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:601c42e5-641e-4066-8c35-1816f7ab024c,timestamp:1697087645\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:05,864 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,146 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,146 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b43fceba-45fe-430e-8fa2-cf7283438d3a,timestamp:1697087647\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,146 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,146 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b43fceba-45fe-430e-8fa2-cf7283438d3a,timestamp:1697087647\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:07,147 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:680175d1-9545-41a4-8603-09995173be3c,timestamp:1697087648\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:680175d1-9545-41a4-8603-09995173be3c,timestamp:1697087648\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:08,408 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd9acc98-2424-49ad-9a77-0973fda66608,timestamp:1697087649\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fd9acc98-2424-49ad-9a77-0973fda66608,timestamp:1697087649\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:09,677 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ef9836d6-e35f-4483-89f9-2ec9a08c858b,timestamp:1697087650\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ef9836d6-e35f-4483-89f9-2ec9a08c858b,timestamp:1697087650\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:10,953 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,223 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,223 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ed5ba26-d3a0-4351-a6b9-90118d312cc9,timestamp:1697087652\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,223 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,223 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ed5ba26-d3a0-4351-a6b9-90118d312cc9,timestamp:1697087652\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:12,224 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:11c2ac82-7650-4ba2-8c86-c7d73de7163e,timestamp:1697087653\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:11c2ac82-7650-4ba2-8c86-c7d73de7163e,timestamp:1697087653\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:13,529 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61c62420-f599-4432-87a7-ace326cad0ce,timestamp:1697087654\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61c62420-f599-4432-87a7-ace326cad0ce,timestamp:1697087654\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:14,808 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1395\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1394.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:774cfc0a-4949-4906-bd44-e40206f9a739,timestamp:1697087656\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1396\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1395\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1394.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:774cfc0a-4949-4906-bd44-e40206f9a739,timestamp:1697087656\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1396\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:16,206 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1391\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1390.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a9955d7-e4f7-4afd-b9c5-ca88486eb79a,timestamp:1697087657\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1391\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1391\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1390.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7a9955d7-e4f7-4afd-b9c5-ca88486eb79a,timestamp:1697087657\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1391\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:17,600 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31328201293945|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551849365234375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12895.953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2506.375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31328201293945|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551849365234375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12895.953125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2506.375|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,270 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:530d4ca4-3cbd-4dde-b777-f82da7680dec,timestamp:1697087658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:18,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:530d4ca4-3cbd-4dde-b777-f82da7680dec,timestamp:1697087658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,901 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:18,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:20,991 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2087\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:20,991 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2086.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ec1f25dc-bb83-4fd2-a8de-dc175874dfdb,timestamp:1697087660\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:20,991 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2087\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:20,993 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:20,993 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:20,993 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:20,991 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2087\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:20,991 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2086.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ec1f25dc-bb83-4fd2-a8de-dc175874dfdb,timestamp:1697087660\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:20,991 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2087\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:20,993 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:20,993 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:20,993 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:402fee51-79a5-4768-9716-ce96d01a9089,timestamp:1697087662\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:402fee51-79a5-4768-9716-ce96d01a9089,timestamp:1697087662\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:22,257 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:831fd025-2073-4e9e-a830-65e27faff3ac,timestamp:1697087663\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:831fd025-2073-4e9e-a830-65e27faff3ac,timestamp:1697087663\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:23,547 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1703\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1701.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52f6676c-04e0-455a-9abd-8f46a91c8b9d,timestamp:1697087665\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1703\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1703\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1701.64|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:52f6676c-04e0-455a-9abd-8f46a91c8b9d,timestamp:1697087665\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1703\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:25,252 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1311.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6fd33f36-213d-4122-b43c-b5c790d2323c,timestamp:1697087666\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1313\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1311.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6fd33f36-213d-4122-b43c-b5c790d2323c,timestamp:1697087666\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:26,567 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b92f4d36-143f-4939-9f75-49b84cdab3b0,timestamp:1697087667\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,853 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:27,853 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b92f4d36-143f-4939-9f75-49b84cdab3b0,timestamp:1697087667\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,852 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,853 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:27,853 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bcf013d-1caa-41a6-846e-524acdbdd086,timestamp:1697087669\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1655\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2bcf013d-1caa-41a6-846e-524acdbdd086,timestamp:1697087669\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,510 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1655\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:29,511 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4aacb9ae-68ec-483e-8e33-93dfd27824f5,timestamp:1697087670\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.97|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4aacb9ae-68ec-483e-8e33-93dfd27824f5,timestamp:1697087670\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:30,768 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:148980ea-0b72-4bb0-946c-c1fa71ea391d,timestamp:1697087672\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,044 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:32,044 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:148980ea-0b72-4bb0-946c-c1fa71ea391d,timestamp:1697087672\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,043 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,044 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:32,044 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1361\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1360.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39955fe4-4a80-4255-ab24-bfce63c4613f,timestamp:1697087673\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1361\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1361\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1360.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:39955fe4-4a80-4255-ab24-bfce63c4613f,timestamp:1697087673\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1361\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:33,407 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5780aa96-7eb4-4ebd-8f0a-c6c83e4147e1,timestamp:1697087674\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:34,669 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5780aa96-7eb4-4ebd-8f0a-c6c83e4147e1,timestamp:1697087674\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,668 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:34,669 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:602e198f-bc36-4af5-a9c8-bbbe86a34c1b,timestamp:1697087675\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:602e198f-bc36-4af5-a9c8-bbbe86a34c1b,timestamp:1697087675\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:35,922 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d3a386d4-1128-437a-aba9-ca5186b15c38,timestamp:1697087677\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d3a386d4-1128-437a-aba9-ca5186b15c38,timestamp:1697087677\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:37,169 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:38c30770-debe-4401-9f0a-1f3384d4e024,timestamp:1697087678\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:38c30770-debe-4401-9f0a-1f3384d4e024,timestamp:1697087678\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:38,427 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1b41910e-f4e7-4fb9-a640-2f24c89e677b,timestamp:1697087679\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1288.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1b41910e-f4e7-4fb9-a640-2f24c89e677b,timestamp:1697087679\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:39,718 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1427\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1428\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1427.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20ad9525-3b95-4bee-ba53-ee740c5eafb3,timestamp:1697087681\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:41,149 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1427\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1428\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1427.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20ad9525-3b95-4bee-ba53-ee740c5eafb3,timestamp:1697087681\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,148 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:41,149 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8276ff3-5a3b-4296-bd76-04f289c300f3,timestamp:1697087682\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f8276ff3-5a3b-4296-bd76-04f289c300f3,timestamp:1697087682\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:42,392 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ab7e1db-5839-4b8e-9994-f6e0a0a39903,timestamp:1697087683\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.54|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ab7e1db-5839-4b8e-9994-f6e0a0a39903,timestamp:1697087683\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:43,718 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d98adca8-6121-4896-b679-9496c9bba836,timestamp:1697087684\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d98adca8-6121-4896-b679-9496c9bba836,timestamp:1697087684\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:44,970 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1550\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1550\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1549.68|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c7f3e84-1bac-4f95-85f3-e721cddfb4fd,timestamp:1697087686\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1550\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1550\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1549.68|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2c7f3e84-1bac-4f95-85f3-e721cddfb4fd,timestamp:1697087686\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:46,523 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,901 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4299d48-48f3-4dbe-89f1-8fcfa7208188,timestamp:1697087687\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,901 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4299d48-48f3-4dbe-89f1-8fcfa7208188,timestamp:1697087687\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:47,902 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a746e3d9-0250-436e-af41-ab3c6b01dbfb,timestamp:1697087689\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,165 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a746e3d9-0250-436e-af41-ab3c6b01dbfb,timestamp:1697087689\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:49,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e9c84330-7fc4-47f3-bdbb-13efdce8bacd,timestamp:1697087690\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e9c84330-7fc4-47f3-bdbb-13efdce8bacd,timestamp:1697087690\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:50,429 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,699 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2a2f1b5-176e-4781-a68f-74e3ddb78050,timestamp:1697087691\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,699 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f2a2f1b5-176e-4781-a68f-74e3ddb78050,timestamp:1697087691\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:51,700 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a81c66b3-09c8-4e7c-b092-97f8ab2c8196,timestamp:1697087693\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a81c66b3-09c8-4e7c-b092-97f8ab2c8196,timestamp:1697087693\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:53,003 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4f71028-3ade-486e-9dec-f3e940c4074d,timestamp:1697087694\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1238.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a4f71028-3ade-486e-9dec-f3e940c4074d,timestamp:1697087694\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:54,245 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:29fc9f6d-3d21-4e03-8e5f-4f6c82669d86,timestamp:1697087695\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1272.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:29fc9f6d-3d21-4e03-8e5f-4f6c82669d86,timestamp:1697087695\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:55,521 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5683d1eb-7f60-4663-a129-c27c65b79fc8,timestamp:1697087696\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1410\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5683d1eb-7f60-4663-a129-c27c65b79fc8,timestamp:1697087696\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:56,934 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:732b7cdc-75d7-44b3-a3a2-5965d4320686,timestamp:1697087698\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:732b7cdc-75d7-44b3-a3a2-5965d4320686,timestamp:1697087698\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:58,180 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70304826-7bcc-42bf-8a26-5ae35ac27d24,timestamp:1697087699\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70304826-7bcc-42bf-8a26-5ae35ac27d24,timestamp:1697087699\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:14:59,458 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c1ada6c6-3eaf-43bc-83f2-a7ee5b3fb9cb,timestamp:1697087700\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,703 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:00,703 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.42|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c1ada6c6-3eaf-43bc-83f2-a7ee5b3fb9cb,timestamp:1697087700\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,702 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,703 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:00,703 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46c64d98-60ac-4af1-8b06-7b80326fe21c,timestamp:1697087701\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.25|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:46c64d98-60ac-4af1-8b06-7b80326fe21c,timestamp:1697087701\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,949 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:01,951 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2057\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2056.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fecac66f-ae3c-4ecf-bdeb-671492bd86fc,timestamp:1697087704\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2057\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2057\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2056.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fecac66f-ae3c-4ecf-bdeb-671492bd86fc,timestamp:1697087704\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 2057\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:04,011 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:596dca98-e0a7-47d6-bfd2-4754014c816b,timestamp:1697087705\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1419\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1418\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:596dca98-e0a7-47d6-bfd2-4754014c816b,timestamp:1697087705\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1419\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:05,432 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:69ebab3d-8737-4183-a8fd-4ce28df777c7,timestamp:1697087706\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:69ebab3d-8737-4183-a8fd-4ce28df777c7,timestamp:1697087706\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:06,690 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:07,955 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:07,955 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:07,955 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.93|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fed48f0c-8380-4228-a5d1-8b15d6815032,timestamp:1697087707\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:07,957 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:07,957 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:07,957 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:07,955 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:07,955 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:07,955 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.93|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fed48f0c-8380-4228-a5d1-8b15d6815032,timestamp:1697087707\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:07,957 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:07,957 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:07,957 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,238 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:09,238 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.89|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9b50cb4a-be6e-46d4-9fb6-71b199cab4c8,timestamp:1697087709\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,238 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,239 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:09,238 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.89|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9b50cb4a-be6e-46d4-9fb6-71b199cab4c8,timestamp:1697087709\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d12e9db-e9fd-4a48-880f-c5c6648ff698,timestamp:1697087710\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0d12e9db-e9fd-4a48-880f-c5c6648ff698,timestamp:1697087710\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:10,492 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,821 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1326\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,821 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1326\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:76f46b3a-87ef-4949-ad22-2e86dc104d8b,timestamp:1697087711\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1328\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:76f46b3a-87ef-4949-ad22-2e86dc104d8b,timestamp:1697087711\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1328\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:11,822 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:13,063 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:13,063 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:13,063 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:13,063 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26ee0199-df41-4fdc-961a-7f596526ee10,timestamp:1697087713\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:13,065 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:13,065 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:13,063 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:13,063 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:13,063 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:13,063 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.96|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:26ee0199-df41-4fdc-961a-7f596526ee10,timestamp:1697087713\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:13,065 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:13,065 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f2670f1-4cfa-4c09-b6aa-72a602d56f55,timestamp:1697087714\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f2670f1-4cfa-4c09-b6aa-72a602d56f55,timestamp:1697087714\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,319 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:14,319 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,318 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,319 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:14,319 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:794cc8d5-a7d2-4b29-be09-a3bd9b6666e0,timestamp:1697087715\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:794cc8d5-a7d2-4b29-be09-a3bd9b6666e0,timestamp:1697087715\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:15,607 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:13bd5422-6a97-4e8d-88bf-8085bad63532,timestamp:1697087716\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:13bd5422-6a97-4e8d-88bf-8085bad63532,timestamp:1697087716\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:16,880 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1306.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8c041356-c83f-4cd9-9cae-b9dc2d3a6975,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313175201416016|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551956176757812|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12895.44921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2506.8828125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1306.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8c041356-c83f-4cd9-9cae-b9dc2d3a6975,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,190 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,191 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.313175201416016|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.551956176757812|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12895.44921875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2506.8828125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:18,263 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087718\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,451 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,451 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6daca1b8-1baa-40c5-94e1-8d2ed1bb2223,timestamp:1697087719\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,451 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,451 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6daca1b8-1baa-40c5-94e1-8d2ed1bb2223,timestamp:1697087719\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:19,452 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1355\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1355\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1354.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a591c7e-459c-4bef-b351-c07da5066fd0,timestamp:1697087720\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1354.04|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a591c7e-459c-4bef-b351-c07da5066fd0,timestamp:1697087720\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:20,809 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8bc41ea0-b42e-4647-89db-59cc8c8be3d4,timestamp:1697087722\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8bc41ea0-b42e-4647-89db-59cc8c8be3d4,timestamp:1697087722\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:22,066 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:23,416 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59370783-feb1-4804-b441-911404c364b9,timestamp:1697087723\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:23,416 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59370783-feb1-4804-b441-911404c364b9,timestamp:1697087723\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:23,417 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bcad5ea5-593d-427f-8ac5-7a8ba1b1bb60,timestamp:1697087724\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bcad5ea5-593d-427f-8ac5-7a8ba1b1bb60,timestamp:1697087724\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,669 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:24,670 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d1db280-a1c6-44c0-9e5d-616e75b87b6a,timestamp:1697087725\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:25,949 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d1db280-a1c6-44c0-9e5d-616e75b87b6a,timestamp:1697087725\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1c19b471-520e-448d-8e57-63fc81fd9a1f,timestamp:1697087727\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1c19b471-520e-448d-8e57-63fc81fd9a1f,timestamp:1697087727\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:27,218 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a00e5acc-52a5-418d-8e08-f2a20856c48a,timestamp:1697087728\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a00e5acc-52a5-418d-8e08-f2a20856c48a,timestamp:1697087728\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:28,479 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1454\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1454.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc5e4b9b-19aa-4c59-b39a-431e0a623d93,timestamp:1697087729\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1455\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,937 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:29,937 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1454\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1454.37|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc5e4b9b-19aa-4c59-b39a-431e0a623d93,timestamp:1697087729\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1455\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,936 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,937 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:29,937 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18e0ddc1-2552-4af9-9cb2-65e478b0810e,timestamp:1697087731\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18e0ddc1-2552-4af9-9cb2-65e478b0810e,timestamp:1697087731\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:31,183 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2f772e4-30f0-43d7-a2d5-0c0779954abb,timestamp:1697087732\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d2f772e4-30f0-43d7-a2d5-0c0779954abb,timestamp:1697087732\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:32,446 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:33,842 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:33,842 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:86b47f29-31b3-4917-aa9d-9f9a417b54c5,timestamp:1697087733\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:33,843 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1394\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:33,843 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:33,843 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:33,843 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:33,842 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:33,842 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:86b47f29-31b3-4917-aa9d-9f9a417b54c5,timestamp:1697087733\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:33,843 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1394\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:33,843 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:33,843 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:33,843 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aaf7f959-8e7b-407d-8683-ae33ce309f12,timestamp:1697087735\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aaf7f959-8e7b-407d-8683-ae33ce309f12,timestamp:1697087735\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:35,116 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1c61928a-b102-4dc8-870a-e8b83b494b5a,timestamp:1697087736\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1c61928a-b102-4dc8-870a-e8b83b494b5a,timestamp:1697087736\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:36,381 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd1135fb-ba88-4646-be26-e7ec61cbd059,timestamp:1697087737\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dd1135fb-ba88-4646-be26-e7ec61cbd059,timestamp:1697087737\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:37,639 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7342312f-5e69-4577-b4cb-66ccf2455fc5,timestamp:1697087738\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7342312f-5e69-4577-b4cb-66ccf2455fc5,timestamp:1697087738\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:38,902 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5e9a3b32-a295-4e92-9827-2991fa9e8899,timestamp:1697087740\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5e9a3b32-a295-4e92-9827-2991fa9e8899,timestamp:1697087740\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:40,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18f5e570-86a5-4f09-951c-e4bd57ab6fbd,timestamp:1697087741\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:41,467 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.82|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:18f5e570-86a5-4f09-951c-e4bd57ab6fbd,timestamp:1697087741\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1802c557-a7da-460d-a407-a45f8f44759c,timestamp:1697087742\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1802c557-a7da-460d-a407-a45f8f44759c,timestamp:1697087742\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:42,756 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1231\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2f0a65c-5020-49c0-a333-ac52e7418cca,timestamp:1697087743\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1231\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:43,989 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b2f0a65c-5020-49c0-a333-ac52e7418cca,timestamp:1697087743\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2b745a32-7413-4cd4-8508-f81aca801844,timestamp:1697087745\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2b745a32-7413-4cd4-8508-f81aca801844,timestamp:1697087745\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:45,255 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c6f9288f-55e9-408d-b8a2-35c577e7e94f,timestamp:1697087746\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.62|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c6f9288f-55e9-408d-b8a2-35c577e7e94f,timestamp:1697087746\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:46,524 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:03713b8e-68c7-49d1-8352-0e76d9901a46,timestamp:1697087747\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:03713b8e-68c7-49d1-8352-0e76d9901a46,timestamp:1697087747\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:47,798 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:849cd64b-e484-4fa8-a307-a6543e7227be,timestamp:1697087749\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:49,073 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:849cd64b-e484-4fa8-a307-a6543e7227be,timestamp:1697087749\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,072 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:49,073 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ee922981-2523-4892-8db9-f7c3ddb52e4c,timestamp:1697087750\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1323\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1323.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ee922981-2523-4892-8db9-f7c3ddb52e4c,timestamp:1697087750\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:50,399 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1460\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1458.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:41b8f6cb-39fb-48a0-b33a-4e1fcd28c38f,timestamp:1697087751\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1460\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1460\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1458.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:41b8f6cb-39fb-48a0-b33a-4e1fcd28c38f,timestamp:1697087751\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1460\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:51,861 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d52df14c-a610-4662-aa8c-c31f3b2029b9,timestamp:1697087753\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.59|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d52df14c-a610-4662-aa8c-c31f3b2029b9,timestamp:1697087753\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:53,133 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4fd746b9-f3a6-4cfd-8377-e2c04d8eaba1,timestamp:1697087754\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.71|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4fd746b9-f3a6-4cfd-8377-e2c04d8eaba1,timestamp:1697087754\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:54,387 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d5d7d9d-e5ea-478c-88e8-4df3e87b49f3,timestamp:1697087755\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:55,652 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4d5d7d9d-e5ea-478c-88e8-4df3e87b49f3,timestamp:1697087755\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87aa1c89-c73a-40f8-9de1-f375a54f9ff6,timestamp:1697087756\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:56,913 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:87aa1c89-c73a-40f8-9de1-f375a54f9ff6,timestamp:1697087756\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,912 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:56,913 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dcbb0004-4492-417b-bdee-091d81ef4466,timestamp:1697087758\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dcbb0004-4492-417b-bdee-091d81ef4466,timestamp:1697087758\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:58,178 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e26d3741-a392-4ebe-ab02-1a664a2d98bf,timestamp:1697087759\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e26d3741-a392-4ebe-ab02-1a664a2d98bf,timestamp:1697087759\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:15:59,412 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:514abd90-b765-4974-b1c3-9e51125b7ca5,timestamp:1697087760\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.41|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:514abd90-b765-4974-b1c3-9e51125b7ca5,timestamp:1697087760\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:00,702 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:978bea6d-5c18-429a-a1a8-3041368caaa0,timestamp:1697087761\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:01,966 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:978bea6d-5c18-429a-a1a8-3041368caaa0,timestamp:1697087761\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,965 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:01,966 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8c803547-9fc6-4e8e-a29f-03a70be67fd6,timestamp:1697087763\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8c803547-9fc6-4e8e-a29f-03a70be67fd6,timestamp:1697087763\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:03,237 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7676ae57-1d0d-4c9c-8f42-a57d205c2c7e,timestamp:1697087764\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1318.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7676ae57-1d0d-4c9c-8f42-a57d205c2c7e,timestamp:1697087764\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:04,559 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e21418d7-68bf-42f4-9d9f-09c58d78064f,timestamp:1697087765\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e21418d7-68bf-42f4-9d9f-09c58d78064f,timestamp:1697087765\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:05,859 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,123 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:face1ea2-bfa1-47a2-add1-52616673344c,timestamp:1697087767\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,123 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:07,124 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:face1ea2-bfa1-47a2-add1-52616673344c,timestamp:1697087767\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,551 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1425\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1424.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7df9cb23-b67f-4c64-ad23-ffc013135573,timestamp:1697087768\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1426\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,551 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1425\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1424.77|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7df9cb23-b67f-4c64-ad23-ffc013135573,timestamp:1697087768\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1426\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:08,552 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1350.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1ffbf4f5-55db-478f-b203-59c5b7928bfa,timestamp:1697087769\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:09,905 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1350.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1ffbf4f5-55db-478f-b203-59c5b7928bfa,timestamp:1697087769\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1225\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47104560-fb25-4e36-8a68-cc6a39bedb25,timestamp:1697087771\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1225\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1225\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47104560-fb25-4e36-8a68-cc6a39bedb25,timestamp:1697087771\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1225\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:11,132 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,417 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,417 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:192af3c1-cfcb-4823-9e3b-12a1fbf2d532,timestamp:1697087772\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,417 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,417 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.7|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:192af3c1-cfcb-4823-9e3b-12a1fbf2d532,timestamp:1697087772\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:12,418 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a70219a9-7514-4415-9228-ae2e5d16404a,timestamp:1697087773\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a70219a9-7514-4415-9228-ae2e5d16404a,timestamp:1697087773\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:13,695 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:14,961 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aef72dd4-2a35-4328-96d2-2eb981967089,timestamp:1697087774\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:14,961 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.85|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:aef72dd4-2a35-4328-96d2-2eb981967089,timestamp:1697087774\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:14,962 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6ab24567-85b7-4a0d-82e2-b2ca768adcb5,timestamp:1697087776\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.46|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6ab24567-85b7-4a0d-82e2-b2ca768adcb5,timestamp:1697087776\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:16,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70637ff3-6991-4e1f-8f3f-f8c5a2b48767,timestamp:1697087777\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:17,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:70637ff3-6991-4e1f-8f3f-f8c5a2b48767,timestamp:1697087777\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,262 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31306457519531|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.552066802978516|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12895.6015625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2506.7265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,262 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31306457519531|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.552066802978516|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12895.6015625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2506.7265625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:321f9b8b-c961-491d-bffe-4428bca9e10e,timestamp:1697087778\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1411\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1410.74|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:321f9b8b-c961-491d-bffe-4428bca9e10e,timestamp:1697087778\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:18,927 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:480f1d38-637f-4fdf-b3ca-5647361dd9ef,timestamp:1697087780\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:480f1d38-637f-4fdf-b3ca-5647361dd9ef,timestamp:1697087780\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:20,288 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a6d01cf-e3da-4abb-ab1c-2dd7476dea7a,timestamp:1697087781\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:21,580 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9a6d01cf-e3da-4abb-ab1c-2dd7476dea7a,timestamp:1697087781\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,579 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:21,580 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1568\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1567.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93e03f8a-119b-40ce-a01b-b4f2daf72cfa,timestamp:1697087783\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1568\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1568\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1567.79|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:93e03f8a-119b-40ce-a01b-b4f2daf72cfa,timestamp:1697087783\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1568\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:23,150 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1445\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1445\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1445.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a446f2eb-7c76-4b28-ab1e-f409cfb51432,timestamp:1697087784\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,599 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:24,599 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1445\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1445\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1445.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a446f2eb-7c76-4b28-ab1e-f409cfb51432,timestamp:1697087784\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,598 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,599 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:24,599 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb0edf88-774e-4798-811d-27ec1fd4740a,timestamp:1697087785\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fb0edf88-774e-4798-811d-27ec1fd4740a,timestamp:1697087785\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:25,876 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1481\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bed93b21-1933-4a52-bdfb-c600241d55b7,timestamp:1697087787\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1481\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1480.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bed93b21-1933-4a52-bdfb-c600241d55b7,timestamp:1697087787\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:27,359 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3c7191b1-42f3-42a9-ac51-972ca2849b1c,timestamp:1697087788\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.27|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3c7191b1-42f3-42a9-ac51-972ca2849b1c,timestamp:1697087788\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:28,620 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ce7bf05b-a52c-476e-8895-d0e6a02a1f77,timestamp:1697087789\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ce7bf05b-a52c-476e-8895-d0e6a02a1f77,timestamp:1697087789\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:29,852 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,108 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e08ebfc-2f99-4498-a53a-d7b3f2b795eb,timestamp:1697087791\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,108 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e08ebfc-2f99-4498-a53a-d7b3f2b795eb,timestamp:1697087791\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:31,109 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1425\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1424.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:34e15a1f-17b0-4cfe-8cf0-547d65856bcd,timestamp:1697087792\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1425\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:32,537 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1425\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1424.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:34e15a1f-17b0-4cfe-8cf0-547d65856bcd,timestamp:1697087792\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1425\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,536 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:32,537 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c08a3dff-3de8-4e1c-b40b-8313616fbb7d,timestamp:1697087793\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1279.51|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c08a3dff-3de8-4e1c-b40b-8313616fbb7d,timestamp:1697087793\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:33,819 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bfcae98b-043f-41b5-adeb-25c472c5010c,timestamp:1697087795\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bfcae98b-043f-41b5-adeb-25c472c5010c,timestamp:1697087795\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:35,088 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ec3f651c-09a7-45d8-aa71-533340e740dd,timestamp:1697087796\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.11|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ec3f651c-09a7-45d8-aa71-533340e740dd,timestamp:1697087796\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:36,344 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:704bc68c-a5c2-4e0c-982d-bd80626a62c9,timestamp:1697087797\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1252\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:37,598 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.13|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:704bc68c-a5c2-4e0c-982d-bd80626a62c9,timestamp:1697087797\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1511\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1512\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1510.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a71937f9-3f49-447a-854d-96241c4111ed,timestamp:1697087799\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1511\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1512\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1510.86|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a71937f9-3f49-447a-854d-96241c4111ed,timestamp:1697087799\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:39,112 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a8494489-843d-424a-aacb-d9afe0b605a5,timestamp:1697087800\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a8494489-843d-424a-aacb-d9afe0b605a5,timestamp:1697087800\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:40,385 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c0fa9383-1d6d-4020-ba41-d9e90be2572c,timestamp:1697087801\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c0fa9383-1d6d-4020-ba41-d9e90be2572c,timestamp:1697087801\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:41,625 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:afd22c39-b6d4-4146-9111-6491fbb524ad,timestamp:1697087803\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:afd22c39-b6d4-4146-9111-6491fbb524ad,timestamp:1697087803\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:43,259 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80e0b67c-ddc5-4e0e-b368-c3ec31a63200,timestamp:1697087804\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,506 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:44,506 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:80e0b67c-ddc5-4e0e-b368-c3ec31a63200,timestamp:1697087804\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,505 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,506 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:44,506 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:45,920 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:45,920 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1412\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:45,920 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1412.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:35013152-0541-4e39-89d0-ed5f0b704c9b,timestamp:1697087805\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:45,920 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:45,921 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:45,921 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:45,920 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1412\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:45,920 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1412\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:45,920 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1412.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:35013152-0541-4e39-89d0-ed5f0b704c9b,timestamp:1697087805\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:45,920 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:45,921 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:45,921 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1440\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1440\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1439.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bf1f39a-1922-4d5a-a78d-28f196509ceb,timestamp:1697087807\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1440\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1440\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:47,363 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1439.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4bf1f39a-1922-4d5a-a78d-28f196509ceb,timestamp:1697087807\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:445e0b02-cb0b-4385-af0c-e58beff9be6b,timestamp:1697087808\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1349\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,716 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:48,715 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.02|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:445e0b02-cb0b-4385-af0c-e58beff9be6b,timestamp:1697087808\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e072487-29b6-4bad-9b1c-28e667fdab03,timestamp:1697087809\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.69|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e072487-29b6-4bad-9b1c-28e667fdab03,timestamp:1697087809\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,978 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:49,979 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,228 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,228 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a49ec7de-4e65-4cac-8489-f30566255b7c,timestamp:1697087811\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,228 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,228 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a49ec7de-4e65-4cac-8489-f30566255b7c,timestamp:1697087811\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:51,229 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28cfbbeb-a8d6-4ee3-a1e9-98440104f689,timestamp:1697087812\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1300.1|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:28cfbbeb-a8d6-4ee3-a1e9-98440104f689,timestamp:1697087812\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:52,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,192 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,192 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f224f99-9321-459d-b0b7-705df1cecc59,timestamp:1697087814\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1659\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,192 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,192 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5f224f99-9321-459d-b0b7-705df1cecc59,timestamp:1697087814\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1659\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:54,193 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2397e625-07b2-4f88-af12-a2d8506fcf65,timestamp:1697087815\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2397e625-07b2-4f88-af12-a2d8506fcf65,timestamp:1697087815\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:55,499 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3caf8264-39e7-448b-83ae-e93bf423d240,timestamp:1697087816\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.32|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:3caf8264-39e7-448b-83ae-e93bf423d240,timestamp:1697087816\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:56,778 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dc044fd2-2112-494b-9929-7915c7eae9e0,timestamp:1697087818\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.56|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dc044fd2-2112-494b-9929-7915c7eae9e0,timestamp:1697087818\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:58,440 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ae8a6e7-feb4-4b3e-8c86-8e4623a0f59b,timestamp:1697087819\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.06|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8ae8a6e7-feb4-4b3e-8c86-8e4623a0f59b,timestamp:1697087819\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:16:59,728 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2189573c-0273-429f-92f6-59eb3ffea5b1,timestamp:1697087820\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.94|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2189573c-0273-429f-92f6-59eb3ffea5b1,timestamp:1697087820\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:00,995 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fae3de92-c01f-4a57-a9da-6d18879de1fe,timestamp:1697087822\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,274 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:02,274 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fae3de92-c01f-4a57-a9da-6d18879de1fe,timestamp:1697087822\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,273 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,274 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:02,274 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0188094f-d2a8-4344-9bf6-b6e7eed8fc50,timestamp:1697087823\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0188094f-d2a8-4344-9bf6-b6e7eed8fc50,timestamp:1697087823\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:03,545 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,832 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1284\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:639e4dd7-4dc6-41d5-b8ee-5e6844bf1b37,timestamp:1697087824\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,832 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1284\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1285\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:04,833 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.17|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:639e4dd7-4dc6-41d5-b8ee-5e6844bf1b37,timestamp:1697087824\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:06,102 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:06,102 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:41f033f4-300d-4254-9094-efc10ce12127,timestamp:1697087826\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:06,103 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:06,103 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:06,103 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:06,103 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:06,102 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:06,102 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:41f033f4-300d-4254-9094-efc10ce12127,timestamp:1697087826\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:06,103 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:06,103 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:06,103 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:06,103 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,449 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1344\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,449 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a645f394-2695-437b-a154-39d6fd723fa1,timestamp:1697087827\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1345\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,449 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1344\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,449 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1343.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a645f394-2695-437b-a154-39d6fd723fa1,timestamp:1697087827\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1345\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:07,450 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,889 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1437\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a03e327-1e05-4b9d-8041-6b9cef507d01,timestamp:1697087828\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,889 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1437\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.81|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4a03e327-1e05-4b9d-8041-6b9cef507d01,timestamp:1697087828\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:08,890 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b63982d9-ddf7-482f-8d37-e7c6bed07bf9,timestamp:1697087830\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b63982d9-ddf7-482f-8d37-e7c6bed07bf9,timestamp:1697087830\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:10,230 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1378.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:96b01126-28da-430d-a03d-d0138aadaf14,timestamp:1697087831\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1378\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1379\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1378.16|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:96b01126-28da-430d-a03d-d0138aadaf14,timestamp:1697087831\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:11,611 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:984895a8-24b9-4d6e-8156-3786bfa5d6f9,timestamp:1697087832\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,919 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:12,919 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,918 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:984895a8-24b9-4d6e-8156-3786bfa5d6f9,timestamp:1697087832\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,919 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:12,919 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1694\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1693.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5724ae57-05a9-44ce-9268-bb69cbce7c3a,timestamp:1697087834\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1694\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1694\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1693.35|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5724ae57-05a9-44ce-9268-bb69cbce7c3a,timestamp:1697087834\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1694\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:14,615 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:15,897 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dfe00375-2e62-443c-8de7-e9c09807a650,timestamp:1697087835\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:15,897 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:15,896 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:dfe00375-2e62-443c-8de7-e9c09807a650,timestamp:1697087835\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:435d4ec0-63e5-4015-a929-7b1d95175c1d,timestamp:1697087837\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.6|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:435d4ec0-63e5-4015-a929-7b1d95175c1d,timestamp:1697087837\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:17,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.312950134277344|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.552181243896484|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12894.83203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2507.5|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,621 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1475\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,621 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1475.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2b258ab-85ea-43a1-91bc-81c373de1263,timestamp:1697087838\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1477\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.312950134277344|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.552181243896484|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,262 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12894.83203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2507.5|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,263 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,621 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1475\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,621 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1475.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2b258ab-85ea-43a1-91bc-81c373de1263,timestamp:1697087838\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1477\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:18,622 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:839af777-36eb-43ce-97c2-3d6ec86c3907,timestamp:1697087839\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.66|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:839af777-36eb-43ce-97c2-3d6ec86c3907,timestamp:1697087839\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:19,917 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:81fb5250-ab18-4885-a5a5-9ccc7b7809a4,timestamp:1697087841\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1293\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:81fb5250-ab18-4885-a5a5-9ccc7b7809a4,timestamp:1697087841\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:21,213 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:25abdb04-f861-4e91-9031-d1d9a29e26b3,timestamp:1697087842\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,567 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1348\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,567 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1347.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:25abdb04-f861-4e91-9031-d1d9a29e26b3,timestamp:1697087842\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:22,568 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:965acc10-b329-4de2-a10a-57f3cf103e3f,timestamp:1697087843\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:965acc10-b329-4de2-a10a-57f3cf103e3f,timestamp:1697087843\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:23,799 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,121 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2f6b4956-1423-4f15-a293-36b0f7cb8814,timestamp:1697087845\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,121 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1319\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1320\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.26|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:2f6b4956-1423-4f15-a293-36b0f7cb8814,timestamp:1697087845\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:25,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e735cfea-deac-4a54-a5b6-e5e86c8df0f8,timestamp:1697087846\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.72|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e735cfea-deac-4a54-a5b6-e5e86c8df0f8,timestamp:1697087846\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,407 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:26,408 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:afe8d165-0bc4-4080-aed8-ee8bc751af5c,timestamp:1697087847\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:afe8d165-0bc4-4080-aed8-ee8bc751af5c,timestamp:1697087847\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:27,674 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,939 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,939 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2b01eca-0513-40d2-b619-431009b86f98,timestamp:1697087848\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,939 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,939 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.73|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c2b01eca-0513-40d2-b619-431009b86f98,timestamp:1697087848\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:28,940 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a91177c7-e2b9-414b-86ee-51a333451c3f,timestamp:1697087850\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.05|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a91177c7-e2b9-414b-86ee-51a333451c3f,timestamp:1697087850\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:30,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08906958-c6e4-4a48-bd84-2fbb7befe05d,timestamp:1697087851\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.43|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:08906958-c6e4-4a48-bd84-2fbb7befe05d,timestamp:1697087851\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:31,427 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,680 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,680 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5b09b1c4-7e5c-405c-a2ea-52aeaa21677a,timestamp:1697087852\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,680 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,680 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:32,679 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5b09b1c4-7e5c-405c-a2ea-52aeaa21677a,timestamp:1697087852\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e8cd6a3f-f16c-4177-b2d6-e3f16a52c8d7,timestamp:1697087853\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.44|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e8cd6a3f-f16c-4177-b2d6-e3f16a52c8d7,timestamp:1697087853\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:33,959 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc8d1bb4-92dd-4b37-90d1-04728055a328,timestamp:1697087855\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,211 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:35,211 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1248.09|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc8d1bb4-92dd-4b37-90d1-04728055a328,timestamp:1697087855\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,210 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,211 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:35,211 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1457.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:04b14e9b-02b0-4d0a-87e8-587a9b5ff8de,timestamp:1697087856\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1457\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,671 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:36,670 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1457.14|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:04b14e9b-02b0-4d0a-87e8-587a9b5ff8de,timestamp:1697087856\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1363\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57b3a0a8-29ae-448f-aed3-368ae6b0d31c,timestamp:1697087858\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1363\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1363\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:57b3a0a8-29ae-448f-aed3-368ae6b0d31c,timestamp:1697087858\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1363\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,036 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,037 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:38,037 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,037 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:38,037 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0aefff40-a8a0-4900-bb96-bd4eddd4f392,timestamp:1697087859\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0aefff40-a8a0-4900-bb96-bd4eddd4f392,timestamp:1697087859\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:39,292 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:83a4fd32-e37f-4ee8-b0bc-b0c9cec651f4,timestamp:1697087860\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.61|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:83a4fd32-e37f-4ee8-b0bc-b0c9cec651f4,timestamp:1697087860\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:40,601 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1295\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1a86764a-38c5-46aa-8942-c90a34c4c79b,timestamp:1697087861\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1295\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1a86764a-38c5-46aa-8942-c90a34c4c79b,timestamp:1697087861\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:41,898 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:608d13f2-000b-4afb-9a77-246fb7e09098,timestamp:1697087863\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.28|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:608d13f2-000b-4afb-9a77-246fb7e09098,timestamp:1697087863\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:43,143 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:269ab13a-586c-4769-81d6-aaace2ec4921,timestamp:1697087864\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:269ab13a-586c-4769-81d6-aaace2ec4921,timestamp:1697087864\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,449 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:44,450 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1503\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1503\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:65b4b798-49bc-474b-828f-016d4a8fa767,timestamp:1697087865\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1503\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1503\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.55|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:65b4b798-49bc-474b-828f-016d4a8fa767,timestamp:1697087865\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:45,955 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1232\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:04676a2d-62ee-464a-9a13-5089ad725f82,timestamp:1697087867\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1232\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1233\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:04676a2d-62ee-464a-9a13-5089ad725f82,timestamp:1697087867\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:47,190 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e770adc5-ec9b-48d7-af92-6370a9cd90c9,timestamp:1697087868\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.65|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:e770adc5-ec9b-48d7-af92-6370a9cd90c9,timestamp:1697087868\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:48,491 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:11ed91e5-37d7-4d28-8f77-ad2655b69e6a,timestamp:1697087869\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.98|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:11ed91e5-37d7-4d28-8f77-ad2655b69e6a,timestamp:1697087869\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:49,780 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,433 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1651\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,433 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1650.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a0c454ab-d0e7-47d6-8bab-e705d29dd805,timestamp:1697087871\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1652\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,433 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1651\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,433 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1650.76|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a0c454ab-d0e7-47d6-8bab-e705d29dd805,timestamp:1697087871\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1652\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:51,434 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1223\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b1c9678c-7aa1-4188-9803-65af967e7dcd,timestamp:1697087872\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1223\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1223\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:52,659 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1222.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:b1c9678c-7aa1-4188-9803-65af967e7dcd,timestamp:1697087872\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:838c3bdd-83b6-4ca6-8f3e-5485004c2a5a,timestamp:1697087873\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,923 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:53,923 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:838c3bdd-83b6-4ca6-8f3e-5485004c2a5a,timestamp:1697087873\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,922 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,923 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:53,923 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1cd27295-dfed-41c2-bea1-56070aefd6ee,timestamp:1697087875\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.23|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1cd27295-dfed-41c2-bea1-56070aefd6ee,timestamp:1697087875\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,172 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:55,173 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9fe97bd1-e2f2-4ef6-b923-733a9005fd5c,timestamp:1697087876\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.31|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:9fe97bd1-e2f2-4ef6-b923-733a9005fd5c,timestamp:1697087876\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:56,421 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc416bd0-9787-4a5f-82e7-4e349103aa51,timestamp:1697087877\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.08|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fc416bd0-9787-4a5f-82e7-4e349103aa51,timestamp:1697087877\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:57,661 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:059e1c46-2765-4316-99d6-e0126faca6d2,timestamp:1697087878\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:059e1c46-2765-4316-99d6-e0126faca6d2,timestamp:1697087878\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:17:58,903 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f55777d7-d5ba-47b6-abc1-ff14c07132f6,timestamp:1697087880\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.99|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:f55777d7-d5ba-47b6-abc1-ff14c07132f6,timestamp:1697087880\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:00,144 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47135382-345f-4bbe-83ae-77c1a065451c,timestamp:1697087881\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,402 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:01,402 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.4|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:47135382-345f-4bbe-83ae-77c1a065451c,timestamp:1697087881\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,401 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,402 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:01,402 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1528\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1528\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1530\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1529.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a21218ea-a3c3-4c91-b5ce-b23812d66ed1,timestamp:1697087882\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:02,936 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1530\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1529.47|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:a21218ea-a3c3-4c91-b5ce-b23812d66ed1,timestamp:1697087882\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:02,934 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:02,936 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59901cb1-d1de-468f-8e9d-442b6926ce9e,timestamp:1697087884\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.91|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:59901cb1-d1de-468f-8e9d-442b6926ce9e,timestamp:1697087884\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:04,155 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07f765aa-9199-4458-9d67-1b1ceee66970,timestamp:1697087885\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.63|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:07f765aa-9199-4458-9d67-1b1ceee66970,timestamp:1697087885\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:05,376 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d6ebe126-5b7e-47cf-b111-413304ac2ce5,timestamp:1697087886\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.2|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d6ebe126-5b7e-47cf-b111-413304ac2ce5,timestamp:1697087886\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:06,647 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:08,002 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:08,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d26038d-71a4-47f4-b25a-14ceb9f95028,timestamp:1697087888\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:08,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:08,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:08,004 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:08,004 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:08,002 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:08,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1352.22|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:6d26038d-71a4-47f4-b25a-14ceb9f95028,timestamp:1697087888\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:08,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:08,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:08,004 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:08,004 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e63f653-7797-4a8f-bc5a-2e5736230620,timestamp:1697087889\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.8|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:8e63f653-7797-4a8f-bc5a-2e5736230620,timestamp:1697087889\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:09,256 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,781 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:10,781 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1521.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7158761c-b7af-4cf5-9215-ca63762b94f9,timestamp:1697087890\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1521\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,780 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,781 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:10,781 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1521.12|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:7158761c-b7af-4cf5-9215-ca63762b94f9,timestamp:1697087890\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,049 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ec5bda25-db88-4c67-9ab9-ecd5e96a94fe,timestamp:1697087892\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,049 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.19|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ec5bda25-db88-4c67-9ab9-ecd5e96a94fe,timestamp:1697087892\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:12,050 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,309 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:13,309 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1146140e-7853-4956-bb69-85f269ed222f,timestamp:1697087893\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,308 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,309 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:13,309 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.52|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:1146140e-7853-4956-bb69-85f269ed222f,timestamp:1697087893\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20116023-5926-4602-b4a9-9177c12835a2,timestamp:1697087894\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.67|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:20116023-5926-4602-b4a9-9177c12835a2,timestamp:1697087894\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:14,564 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1263\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:887386e9-6480-40aa-b288-66705318d208,timestamp:1697087895\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.75|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:887386e9-6480-40aa-b288-66705318d208,timestamp:1697087895\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:15,829 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d369dccd-5f0b-4e76-b738-8d6944a06ea9,timestamp:1697087897\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1397\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.15|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d369dccd-5f0b-4e76-b738-8d6944a06ea9,timestamp:1697087897\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1397\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:17,228 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31283187866211|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.552299499511719|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12894.546875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2507.78515625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:40e310a8-5f2b-4dea-a5b8-f1dd32baef8e,timestamp:1697087898\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31283187866211|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.552299499511719|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12894.546875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2507.78515625|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.3|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:40e310a8-5f2b-4dea-a5b8-f1dd32baef8e,timestamp:1697087898\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:18,483 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61a40967-1a91-4d36-af51-f5b687f06d3d,timestamp:1697087899\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.45|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:61a40967-1a91-4d36-af51-f5b687f06d3d,timestamp:1697087899\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:19,893 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c3de5c59-fae0-45ba-9334-3c1d1f47171d,timestamp:1697087901\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1375\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.88|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:c3de5c59-fae0-45ba-9334-3c1d1f47171d,timestamp:1697087901\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:21,270 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ecddf5bb-9201-4a6a-805a-bbefa1ad7ac7,timestamp:1697087902\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.39|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:ecddf5bb-9201-4a6a-805a-bbefa1ad7ac7,timestamp:1697087902\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:22,512 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1419\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1418.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f08957b-1d61-4fea-904a-86049ec05cce,timestamp:1697087903\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1420\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1419\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1418.9|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0f08957b-1d61-4fea-904a-86049ec05cce,timestamp:1697087903\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1420\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:23,934 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43c6565d-5406-40a8-bd33-86e7760aa17e,timestamp:1697087905\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1229\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1228.87|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:43c6565d-5406-40a8-bd33-86e7760aa17e,timestamp:1697087905\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:25,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:91ece376-10af-40a5-8a7d-84f63f5d9136,timestamp:1697087906\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.18|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:91ece376-10af-40a5-8a7d-84f63f5d9136,timestamp:1697087906\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:26,392 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1633\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1634\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1632.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:15024581-73a3-4fe5-b562-8b6bfcebe822,timestamp:1697087908\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1633\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1634\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1632.5|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:15024581-73a3-4fe5-b562-8b6bfcebe822,timestamp:1697087908\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:28,028 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:29,684 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:29,684 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1654\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:29,684 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:759a3846-ae09-4914-8122-adfc191cfce1,timestamp:1697087909\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:29,684 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:29,685 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:29,685 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:29,684 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:29,684 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1654\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:29,684 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.38|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:759a3846-ae09-4914-8122-adfc191cfce1,timestamp:1697087909\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:29,684 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:29,685 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:29,685 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1433\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1434\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,122 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,122 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1433.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e932131-2242-4c8a-894b-ba745085d2b9,timestamp:1697087911\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1433\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1434\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,122 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,122 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:31,121 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1433.07|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:0e932131-2242-4c8a-894b-ba745085d2b9,timestamp:1697087911\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,361 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,361 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1237\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1238\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,362 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:32,361 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cf585de-8d56-4853-b53b-4da6a526de1f,timestamp:1697087912\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:32,361 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1236.53|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:4cf585de-8d56-4853-b53b-4da6a526de1f,timestamp:1697087912\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:192a12f7-dba4-4044-ac5a-e832c8bf26b0,timestamp:1697087913\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,589 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:33,589 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1223.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:192a12f7-dba4-4044-ac5a-e832c8bf26b0,timestamp:1697087913\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1224\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,588 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,589 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:33,589 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fa0de70e-fdc0-48e5-b352-9ad96269e52f,timestamp:1697087914\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.03|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:fa0de70e-fdc0-48e5-b352-9ad96269e52f,timestamp:1697087914\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:34,877 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:01749e53-91a5-4196-ad32-a1b5b86cf244,timestamp:1697087916\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.21|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:01749e53-91a5-4196-ad32-a1b5b86cf244,timestamp:1697087916\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:36,129 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb5cea71-6eec-466c-b8f5-2a556da38a09,timestamp:1697087917\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1232.58|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:cb5cea71-6eec-466c-b8f5-2a556da38a09,timestamp:1697087917\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1234\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:37,365 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bf82df74-4816-477c-87cf-6235f5869579,timestamp:1697087918\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:38,657 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.29|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bf82df74-4816-477c-87cf-6235f5869579,timestamp:1697087918\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:39,886 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:39,886 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bcbf15e9-4cd4-4ff9-8b55-4714ece36215,timestamp:1697087919\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:39,887 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:39,887 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:39,887 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:39,887 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:39,886 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:39,886 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.36|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:bcbf15e9-4cd4-4ff9-8b55-4714ece36215,timestamp:1697087919\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:39,887 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:39,887 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:39,887 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:39,887 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d23a02eb-b2d4-4d48-83fe-31bd1fe3ba82,timestamp:1697087921\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1276.24|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:d23a02eb-b2d4-4d48-83fe-31bd1fe3ba82,timestamp:1697087921\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:41,166 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c76e07b-8c9d-44d6-8dfe-6794a5568a2e,timestamp:1697087922\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,428 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:42,428 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.48|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:5c76e07b-8c9d-44d6-8dfe-6794a5568a2e,timestamp:1697087922\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,427 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,428 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:42,428 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:01b484a5-c989-41b9-8b69-819b15bf7b10,timestamp:1697087923\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.49|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:01b484a5-c989-41b9-8b69-819b15bf7b10,timestamp:1697087923\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1250\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:43,680 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:eb268527-f0d9-4503-85ff-6a8d0b05c833,timestamp:1697087924\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1264\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1262.95|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:eb268527-f0d9-4503-85ff-6a8d0b05c833,timestamp:1697087924\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:44,946 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62c870b9-1247-4052-bdb1-1abc66c587e2,timestamp:1697087926\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.83|#ModelName:model,Level:Model|#hostname:f63bd019f9a1,requestID:62c870b9-1247-4052-bdb1-1abc66c587e2,timestamp:1697087926\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,176 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:32834 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-12 05:18:46,178 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:f63bd019f9a1,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[34m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31275939941406|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[34m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.552371978759766|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[34m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[34m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12894.51171875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[34m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2507.8203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[34m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[35m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[35m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31275939941406|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[35m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.552371978759766|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[35m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[35m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12894.51171875|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[35m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2507.8203125|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n",
      "\u001b[35m2023-10-12 05:19:18,262 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:f63bd019f9a1,timestamp:1697087958\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(s3_transformed_data_path, content_type='text/csv', split_type='Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "ad06ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3://sdg-project/models/wed_11_10_model2/predictions/text_only_test.csv.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "17a45809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-4.270998001098633</td>\n",
       "      <td>-6.140826</td>\n",
       "      <td>-3.422785</td>\n",
       "      <td>-1.137548</td>\n",
       "      <td>-4.993106</td>\n",
       "      <td>-3.442444</td>\n",
       "      <td>-4.832201</td>\n",
       "      <td>-3.683327</td>\n",
       "      <td>-1.343551</td>\n",
       "      <td>-3.774554</td>\n",
       "      <td>0.926038</td>\n",
       "      <td>-1.925127</td>\n",
       "      <td>-2.908843</td>\n",
       "      <td>-4.544350</td>\n",
       "      <td>-1.899872</td>\n",
       "      <td>-3.410835</td>\n",
       "      <td>-2.411789894104004]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-5.848301410675049</td>\n",
       "      <td>-7.694501</td>\n",
       "      <td>-0.159220</td>\n",
       "      <td>1.981066</td>\n",
       "      <td>-4.448861</td>\n",
       "      <td>-8.172045</td>\n",
       "      <td>-11.084715</td>\n",
       "      <td>-3.452756</td>\n",
       "      <td>-3.501133</td>\n",
       "      <td>-1.667075</td>\n",
       "      <td>-5.852106</td>\n",
       "      <td>-4.678514</td>\n",
       "      <td>-10.637145</td>\n",
       "      <td>-9.910326</td>\n",
       "      <td>-9.117752</td>\n",
       "      <td>-3.291785</td>\n",
       "      <td>-4.90162992477417]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-5.789789199829102</td>\n",
       "      <td>-7.394329</td>\n",
       "      <td>2.935072</td>\n",
       "      <td>-1.214556</td>\n",
       "      <td>-2.341746</td>\n",
       "      <td>-8.950772</td>\n",
       "      <td>-12.110457</td>\n",
       "      <td>-3.822001</td>\n",
       "      <td>-4.482407</td>\n",
       "      <td>-3.098956</td>\n",
       "      <td>-8.922877</td>\n",
       "      <td>-6.285747</td>\n",
       "      <td>-9.838937</td>\n",
       "      <td>-11.839506</td>\n",
       "      <td>-9.058368</td>\n",
       "      <td>-3.282862</td>\n",
       "      <td>-4.235047817230225]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-4.9356889724731445</td>\n",
       "      <td>-6.481263</td>\n",
       "      <td>-4.515436</td>\n",
       "      <td>2.087620</td>\n",
       "      <td>-3.992867</td>\n",
       "      <td>-7.666789</td>\n",
       "      <td>-7.991266</td>\n",
       "      <td>-1.401051</td>\n",
       "      <td>-1.966472</td>\n",
       "      <td>-1.595049</td>\n",
       "      <td>-4.414520</td>\n",
       "      <td>-1.926782</td>\n",
       "      <td>-7.380291</td>\n",
       "      <td>-8.540653</td>\n",
       "      <td>-5.733332</td>\n",
       "      <td>-1.476458</td>\n",
       "      <td>-3.2427642345428467]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-5.735708236694336</td>\n",
       "      <td>-6.663088</td>\n",
       "      <td>-4.139130</td>\n",
       "      <td>3.826489</td>\n",
       "      <td>-4.076541</td>\n",
       "      <td>-7.167147</td>\n",
       "      <td>-8.256342</td>\n",
       "      <td>-2.179849</td>\n",
       "      <td>-2.394229</td>\n",
       "      <td>-2.160081</td>\n",
       "      <td>-4.248709</td>\n",
       "      <td>-2.717120</td>\n",
       "      <td>-7.647140</td>\n",
       "      <td>-8.255084</td>\n",
       "      <td>-5.520392</td>\n",
       "      <td>-3.645286</td>\n",
       "      <td>-3.113049030303955]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3         4         5   \\\n",
       "0   [[-4.270998001098633 -6.140826 -3.422785 -1.137548 -4.993106 -3.442444   \n",
       "1   [[-5.848301410675049 -7.694501 -0.159220  1.981066 -4.448861 -8.172045   \n",
       "2   [[-5.789789199829102 -7.394329  2.935072 -1.214556 -2.341746 -8.950772   \n",
       "3  [[-4.9356889724731445 -6.481263 -4.515436  2.087620 -3.992867 -7.666789   \n",
       "4   [[-5.735708236694336 -6.663088 -4.139130  3.826489 -4.076541 -7.167147   \n",
       "\n",
       "          6         7         8         9         10        11         12  \\\n",
       "0  -4.832201 -3.683327 -1.343551 -3.774554  0.926038 -1.925127  -2.908843   \n",
       "1 -11.084715 -3.452756 -3.501133 -1.667075 -5.852106 -4.678514 -10.637145   \n",
       "2 -12.110457 -3.822001 -4.482407 -3.098956 -8.922877 -6.285747  -9.838937   \n",
       "3  -7.991266 -1.401051 -1.966472 -1.595049 -4.414520 -1.926782  -7.380291   \n",
       "4  -8.256342 -2.179849 -2.394229 -2.160081 -4.248709 -2.717120  -7.647140   \n",
       "\n",
       "          13        14        15                      16  \n",
       "0  -4.544350 -1.899872 -3.410835    -2.411789894104004]]  \n",
       "1  -9.910326 -9.117752 -3.291785     -4.90162992477417]]  \n",
       "2 -11.839506 -9.058368 -3.282862    -4.235047817230225]]  \n",
       "3  -8.540653 -5.733332 -1.476458   -3.2427642345428467]]  \n",
       "4  -8.255084 -5.520392 -3.645286    -3.113049030303955]]  "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_key = os.path.join(prediction_output_path, 'text_only_test.csv.out')\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(s3_bucket, 'models/wed_11_10_model2/predictions/text_only_test.csv.out', local_results_path)\n",
    "\n",
    "results = pd.read_csv(local_results_path, header=None)\n",
    "print(results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "214cb99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21916/2297004454.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  results[0] = results[0].str.replace(\"\\\\[\\\\[\", \"\").str.replace(\"\\\\]\\\\]\", \"\").astype(float)\n",
      "/tmp/ipykernel_21916/2297004454.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  results[16] = results[16].str.replace(\"\\\\[\\\\[\", \"\").str.replace(\"\\\\]\\\\]\", \"\").astype(float)\n"
     ]
    }
   ],
   "source": [
    "results[0] = results[0].str.replace(\"\\\\[\\\\[\", \"\").str.replace(\"\\\\]\\\\]\", \"\").astype(float)\n",
    "results[16] = results[16].str.replace(\"\\\\[\\\\[\", \"\").str.replace(\"\\\\]\\\\]\", \"\").astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9244cfd",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "886d4c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.270998</td>\n",
       "      <td>-6.140826</td>\n",
       "      <td>-3.422785</td>\n",
       "      <td>-1.137548</td>\n",
       "      <td>-4.993106</td>\n",
       "      <td>-3.442444</td>\n",
       "      <td>-4.832201</td>\n",
       "      <td>-3.683327</td>\n",
       "      <td>-1.343551</td>\n",
       "      <td>-3.774554</td>\n",
       "      <td>0.926038</td>\n",
       "      <td>-1.925127</td>\n",
       "      <td>-2.908843</td>\n",
       "      <td>-4.544350</td>\n",
       "      <td>-1.899872</td>\n",
       "      <td>-3.410835</td>\n",
       "      <td>-2.411790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.848301</td>\n",
       "      <td>-7.694501</td>\n",
       "      <td>-0.159220</td>\n",
       "      <td>1.981066</td>\n",
       "      <td>-4.448861</td>\n",
       "      <td>-8.172045</td>\n",
       "      <td>-11.084715</td>\n",
       "      <td>-3.452756</td>\n",
       "      <td>-3.501133</td>\n",
       "      <td>-1.667075</td>\n",
       "      <td>-5.852106</td>\n",
       "      <td>-4.678514</td>\n",
       "      <td>-10.637145</td>\n",
       "      <td>-9.910326</td>\n",
       "      <td>-9.117752</td>\n",
       "      <td>-3.291785</td>\n",
       "      <td>-4.901630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.789789</td>\n",
       "      <td>-7.394329</td>\n",
       "      <td>2.935072</td>\n",
       "      <td>-1.214556</td>\n",
       "      <td>-2.341746</td>\n",
       "      <td>-8.950772</td>\n",
       "      <td>-12.110457</td>\n",
       "      <td>-3.822001</td>\n",
       "      <td>-4.482407</td>\n",
       "      <td>-3.098956</td>\n",
       "      <td>-8.922877</td>\n",
       "      <td>-6.285747</td>\n",
       "      <td>-9.838937</td>\n",
       "      <td>-11.839506</td>\n",
       "      <td>-9.058368</td>\n",
       "      <td>-3.282862</td>\n",
       "      <td>-4.235048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.935689</td>\n",
       "      <td>-6.481263</td>\n",
       "      <td>-4.515436</td>\n",
       "      <td>2.087620</td>\n",
       "      <td>-3.992867</td>\n",
       "      <td>-7.666789</td>\n",
       "      <td>-7.991266</td>\n",
       "      <td>-1.401051</td>\n",
       "      <td>-1.966472</td>\n",
       "      <td>-1.595049</td>\n",
       "      <td>-4.414520</td>\n",
       "      <td>-1.926782</td>\n",
       "      <td>-7.380291</td>\n",
       "      <td>-8.540653</td>\n",
       "      <td>-5.733332</td>\n",
       "      <td>-1.476458</td>\n",
       "      <td>-3.242764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.735708</td>\n",
       "      <td>-6.663088</td>\n",
       "      <td>-4.139130</td>\n",
       "      <td>3.826489</td>\n",
       "      <td>-4.076541</td>\n",
       "      <td>-7.167147</td>\n",
       "      <td>-8.256342</td>\n",
       "      <td>-2.179849</td>\n",
       "      <td>-2.394229</td>\n",
       "      <td>-2.160081</td>\n",
       "      <td>-4.248709</td>\n",
       "      <td>-2.717120</td>\n",
       "      <td>-7.647140</td>\n",
       "      <td>-8.255084</td>\n",
       "      <td>-5.520392</td>\n",
       "      <td>-3.645286</td>\n",
       "      <td>-3.113049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>-1.518640</td>\n",
       "      <td>-1.942758</td>\n",
       "      <td>-4.211230</td>\n",
       "      <td>-2.794740</td>\n",
       "      <td>-4.028202</td>\n",
       "      <td>-6.250086</td>\n",
       "      <td>-4.349785</td>\n",
       "      <td>-0.293048</td>\n",
       "      <td>-1.563194</td>\n",
       "      <td>-0.192099</td>\n",
       "      <td>-0.690579</td>\n",
       "      <td>-2.498062</td>\n",
       "      <td>-1.015582</td>\n",
       "      <td>-4.154838</td>\n",
       "      <td>-3.202207</td>\n",
       "      <td>-3.129446</td>\n",
       "      <td>0.664385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>-2.370497</td>\n",
       "      <td>-3.798846</td>\n",
       "      <td>-2.180281</td>\n",
       "      <td>-2.071616</td>\n",
       "      <td>-3.462643</td>\n",
       "      <td>-5.673448</td>\n",
       "      <td>-7.664162</td>\n",
       "      <td>-2.669059</td>\n",
       "      <td>-2.580239</td>\n",
       "      <td>-0.888325</td>\n",
       "      <td>0.373463</td>\n",
       "      <td>-2.566797</td>\n",
       "      <td>-3.347715</td>\n",
       "      <td>-5.871198</td>\n",
       "      <td>-2.982738</td>\n",
       "      <td>-2.372128</td>\n",
       "      <td>0.207170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>-4.369191</td>\n",
       "      <td>-4.026463</td>\n",
       "      <td>-4.622212</td>\n",
       "      <td>-2.828323</td>\n",
       "      <td>-5.149218</td>\n",
       "      <td>-5.011086</td>\n",
       "      <td>-2.072423</td>\n",
       "      <td>-1.328905</td>\n",
       "      <td>-0.530117</td>\n",
       "      <td>-2.227530</td>\n",
       "      <td>-0.719165</td>\n",
       "      <td>-1.443109</td>\n",
       "      <td>-1.362124</td>\n",
       "      <td>-4.677969</td>\n",
       "      <td>-3.523318</td>\n",
       "      <td>-2.637180</td>\n",
       "      <td>-0.113555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>-3.533185</td>\n",
       "      <td>-5.472704</td>\n",
       "      <td>-4.073373</td>\n",
       "      <td>-2.706575</td>\n",
       "      <td>-4.915079</td>\n",
       "      <td>-5.592053</td>\n",
       "      <td>-5.090914</td>\n",
       "      <td>-3.327760</td>\n",
       "      <td>-2.891698</td>\n",
       "      <td>-1.107020</td>\n",
       "      <td>2.137478</td>\n",
       "      <td>-3.795199</td>\n",
       "      <td>-3.516480</td>\n",
       "      <td>-4.636741</td>\n",
       "      <td>-2.668087</td>\n",
       "      <td>-2.456976</td>\n",
       "      <td>-1.349399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>-6.948833</td>\n",
       "      <td>-3.677510</td>\n",
       "      <td>-2.077859</td>\n",
       "      <td>-7.503377</td>\n",
       "      <td>-9.220508</td>\n",
       "      <td>-0.183736</td>\n",
       "      <td>-5.122853</td>\n",
       "      <td>-5.323886</td>\n",
       "      <td>-3.782949</td>\n",
       "      <td>-8.196939</td>\n",
       "      <td>-3.291480</td>\n",
       "      <td>-3.424778</td>\n",
       "      <td>-2.654635</td>\n",
       "      <td>0.980708</td>\n",
       "      <td>0.412666</td>\n",
       "      <td>-5.467304</td>\n",
       "      <td>-3.296790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5          6   \\\n",
       "0   -4.270998 -6.140826 -3.422785 -1.137548 -4.993106 -3.442444  -4.832201   \n",
       "1   -5.848301 -7.694501 -0.159220  1.981066 -4.448861 -8.172045 -11.084715   \n",
       "2   -5.789789 -7.394329  2.935072 -1.214556 -2.341746 -8.950772 -12.110457   \n",
       "3   -4.935689 -6.481263 -4.515436  2.087620 -3.992867 -7.666789  -7.991266   \n",
       "4   -5.735708 -6.663088 -4.139130  3.826489 -4.076541 -7.167147  -8.256342   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "747 -1.518640 -1.942758 -4.211230 -2.794740 -4.028202 -6.250086  -4.349785   \n",
       "748 -2.370497 -3.798846 -2.180281 -2.071616 -3.462643 -5.673448  -7.664162   \n",
       "749 -4.369191 -4.026463 -4.622212 -2.828323 -5.149218 -5.011086  -2.072423   \n",
       "750 -3.533185 -5.472704 -4.073373 -2.706575 -4.915079 -5.592053  -5.090914   \n",
       "751 -6.948833 -3.677510 -2.077859 -7.503377 -9.220508 -0.183736  -5.122853   \n",
       "\n",
       "           7         8         9         10        11         12         13  \\\n",
       "0   -3.683327 -1.343551 -3.774554  0.926038 -1.925127  -2.908843  -4.544350   \n",
       "1   -3.452756 -3.501133 -1.667075 -5.852106 -4.678514 -10.637145  -9.910326   \n",
       "2   -3.822001 -4.482407 -3.098956 -8.922877 -6.285747  -9.838937 -11.839506   \n",
       "3   -1.401051 -1.966472 -1.595049 -4.414520 -1.926782  -7.380291  -8.540653   \n",
       "4   -2.179849 -2.394229 -2.160081 -4.248709 -2.717120  -7.647140  -8.255084   \n",
       "..        ...       ...       ...       ...       ...        ...        ...   \n",
       "747 -0.293048 -1.563194 -0.192099 -0.690579 -2.498062  -1.015582  -4.154838   \n",
       "748 -2.669059 -2.580239 -0.888325  0.373463 -2.566797  -3.347715  -5.871198   \n",
       "749 -1.328905 -0.530117 -2.227530 -0.719165 -1.443109  -1.362124  -4.677969   \n",
       "750 -3.327760 -2.891698 -1.107020  2.137478 -3.795199  -3.516480  -4.636741   \n",
       "751 -5.323886 -3.782949 -8.196939 -3.291480 -3.424778  -2.654635   0.980708   \n",
       "\n",
       "           14        15        16  \n",
       "0   -1.899872 -3.410835 -2.411790  \n",
       "1   -9.117752 -3.291785 -4.901630  \n",
       "2   -9.058368 -3.282862 -4.235048  \n",
       "3   -5.733332 -1.476458 -3.242764  \n",
       "4   -5.520392 -3.645286 -3.113049  \n",
       "..        ...       ...       ...  \n",
       "747 -3.202207 -3.129446  0.664385  \n",
       "748 -2.982738 -2.372128  0.207170  \n",
       "749 -3.523318 -2.637180 -0.113555  \n",
       "750 -2.668087 -2.456976 -1.349399  \n",
       "751  0.412666 -5.467304 -3.296790  \n",
       "\n",
       "[752 rows x 17 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the content from the file\n",
    "with open(local_results_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Process each line to remove the outer brackets and split numbers\n",
    "processed_lines = [list(map(float, line.strip()[2:-2].split(','))) for line in lines]\n",
    "\n",
    "# Convert the processed data into a dataframe\n",
    "results_df = pd.DataFrame(processed_lines)\n",
    "\n",
    "# print(results_df.shape)\n",
    "# print(results_df.head())\n",
    "\n",
    "#processed_lines\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7f5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eee1d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total non-float values: 0\n"
     ]
    }
   ],
   "source": [
    "# def is_not_float(value):\n",
    "#     try:\n",
    "#         float(value)\n",
    "#         return False\n",
    "#     except ValueError:\n",
    "#         return True\n",
    "\n",
    "# non_float_mask = results_df.applymap(is_not_float)\n",
    "# non_float_counts = non_float_mask.sum().sum()\n",
    "# print(f\"Total non-float values: {non_float_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65083af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: could not convert string to float: '[[-4.270998001098633'\n",
      "Problematic values in column 0: ['[[-4.270998001098633' '[[-5.848301410675049' '[[-3.6253974437713623'\n",
      " '[[-5.789789199829102' '[[-4.9356889724731445' '[[-4.165139198303223'\n",
      " '[[-5.735708236694336' '[[-4.352252006530762' '[[-7.999675750732422'\n",
      " '[[-6.6009602546691895' '[[-5.733427047729492' '[[-1.9372594356536865'\n",
      " '[[-3.4978535175323486' '[[-3.7069549560546875' '[[-3.7345829010009766'\n",
      " '[[-1.9820735454559326' '[[-6.994397163391113' '[[-2.0526175498962402'\n",
      " '[[-6.503925323486328' '[[-6.751236915588379' '[[-6.309639930725098'\n",
      " '[[-6.890380859375' '[[-3.9773223400115967' '[[-5.833578109741211'\n",
      " '[[-0.6642332673072815' '[[-4.762781143188477' '[[-4.65572452545166'\n",
      " '[[-4.783189296722412' '[[-4.987717628479004' '[[-4.2865519523620605'\n",
      " '[[-2.311419725418091' '[[-6.700862884521484' '[[-4.510231971740723'\n",
      " '[[-4.784397602081299' '[[-3.649338483810425' '[[-8.45500373840332'\n",
      " '[[-4.41664457321167' '[[-7.919408321380615' '[[-4.279530048370361'\n",
      " '[[-6.4008612632751465' '[[-7.768404960632324' '[[-3.017246723175049'\n",
      " '[[-4.791778087615967' '[[-7.279993057250977' '[[-5.430228233337402'\n",
      " '[[-3.846734046936035' '[[-4.479381084442139' '[[-5.389325141906738'\n",
      " '[[-5.995251178741455' '[[-4.722029685974121' '[[-4.107876300811768'\n",
      " '[[-2.7630510330200195' '[[-4.634404182434082' '[[-7.99796199798584'\n",
      " '[[-4.861922264099121' '[[-7.345458030700684' '[[-4.459059715270996'\n",
      " '[[-3.8399007320404053' '[[-4.537997722625732' '[[-1.7690033912658691'\n",
      " '[[-3.9344658851623535' '[[-3.4597928524017334' '[[-5.870385646820068'\n",
      " '[[-8.29948902130127' '[[-2.4515902996063232' '[[-1.368767499923706'\n",
      " '[[-5.237713813781738' '[[-2.7439992427825928' '[[-5.61875581741333'\n",
      " '[[-6.692437648773193' '[[-5.1142449378967285' '[[-2.17236328125'\n",
      " '[[-5.692722797393799' '[[-6.572370529174805' '[[-1.4175344705581665'\n",
      " '[[-4.7130351066589355' '[[-6.419593334197998' '[[-1.6166529655456543'\n",
      " '[[-6.631838798522949' '[[-6.498128890991211' '[[0.07610491663217545'\n",
      " '[[-3.526338815689087' '[[-4.736580848693848' '[[-5.8521270751953125'\n",
      " '[[-5.123577117919922' '[[-7.083866119384766' '[[-6.172067165374756'\n",
      " '[[-5.817145347595215' '[[-3.7486612796783447' '[[-6.82302188873291'\n",
      " '[[-2.962092399597168' '[[-2.0126824378967285' '[[-6.057424545288086'\n",
      " '[[-6.477544784545898' '[[-4.837697505950928' '[[-5.366683006286621'\n",
      " '[[-3.1899237632751465' '[[-4.090327739715576' '[[-5.591009140014648'\n",
      " '[[-4.2640204429626465' '[[-5.32175350189209' '[[-5.710052490234375'\n",
      " '[[-5.587062358856201' '[[-3.7767555713653564' '[[-8.431769371032715'\n",
      " '[[-5.467952251434326' '[[-2.091221332550049' '[[-4.450705528259277'\n",
      " '[[-6.665023326873779' '[[-7.0799174308776855' '[[-5.718772888183594'\n",
      " '[[-3.9141433238983154' '[[-3.7481908798217773' '[[-4.816321849822998'\n",
      " '[[-4.280367374420166' '[[0.9280763268470764' '[[-6.477004528045654'\n",
      " '[[-4.974255561828613' '[[-4.773140907287598' '[[-5.046452522277832'\n",
      " '[[-1.700165033340454' '[[-3.9124836921691895' '[[-3.3591508865356445'\n",
      " '[[-6.996191024780273' '[[-5.343505859375' '[[-5.380788803100586'\n",
      " '[[-6.370486259460449' '[[-2.91574764251709' '[[-4.710172176361084'\n",
      " '[[-5.569311141967773' '[[-4.160952091217041' '[[-4.875958442687988'\n",
      " '[[-2.0132479667663574' '[[-8.64792537689209' '[[-4.119390964508057'\n",
      " '[[-4.365232944488525' '[[-5.0460052490234375' '[[-7.004826545715332'\n",
      " '[[-5.548510551452637' '[[-5.041693687438965' '[[-4.740142822265625'\n",
      " '[[-4.692351818084717' '[[-1.878982663154602' '[[-4.6676177978515625'\n",
      " '[[-4.241215705871582' '[[-3.62968111038208' '[[-2.9548678398132324'\n",
      " '[[-5.605595111846924' '[[-3.2311835289001465' '[[-5.939365386962891'\n",
      " '[[-8.940662384033203' '[[-6.273449897766113' '[[-3.775285482406616'\n",
      " '[[-5.973952293395996' '[[-0.8098955154418945' '[[-3.5686731338500977'\n",
      " '[[-3.714031219482422' '[[-0.9034291505813599' '[[-5.714405059814453'\n",
      " '[[-6.0754241943359375' '[[-5.1328277587890625' '[[-5.379660606384277'\n",
      " '[[-5.787384510040283' '[[-4.448546409606934' '[[-1.4407403469085693'\n",
      " '[[-3.2012155055999756' '[[-6.5137739181518555' '[[-4.679378986358643'\n",
      " '[[-3.6754343509674072' '[[-4.003420352935791' '[[-5.7266340255737305'\n",
      " '[[-8.587189674377441' '[[-7.672964572906494' '[[-7.611868381500244'\n",
      " '[[-6.487873554229736' '[[-5.301342964172363' '[[-3.3126723766326904'\n",
      " '[[-5.968382835388184' '[[-4.007821559906006' '[[-2.335181474685669'\n",
      " '[[-2.3653345108032227' '[[-5.9046149253845215' '[[-5.0061869621276855'\n",
      " '[[-4.8347697257995605' '[[-6.1842803955078125' '[[-2.953808546066284'\n",
      " '[[-5.854979515075684' '[[-6.801987171173096' '[[-6.563516139984131'\n",
      " '[[-1.3828668594360352' '[[-5.5038838386535645' '[[-5.40177583694458'\n",
      " '[[-6.483630180358887' '[[-6.982141971588135' '[[-7.168542385101318'\n",
      " '[[-2.5040948390960693' '[[-6.672826766967773' '[[-5.659997463226318'\n",
      " '[[-5.558443069458008' '[[-1.3902666568756104' '[[-7.608665943145752'\n",
      " '[[-5.425466060638428' '[[-6.708422660827637' '[[-5.56894063949585'\n",
      " '[[-2.941833734512329' '[[-6.347183704376221' '[[-6.006344318389893'\n",
      " '[[-3.8046019077301025' '[[-6.56972074508667' '[[-3.565425157546997'\n",
      " '[[-3.4408464431762695' '[[-1.0765087604522705' '[[-4.361710548400879'\n",
      " '[[-3.9646124839782715' '[[-5.222179889678955' '[[-4.40587043762207'\n",
      " '[[-2.912177801132202' '[[-6.016870975494385' '[[-3.361686944961548'\n",
      " '[[-5.734943866729736' '[[-5.604926586151123' '[[-3.48110032081604'\n",
      " '[[-2.357630968093872' '[[-4.118932723999023' '[[-4.143310070037842'\n",
      " '[[-7.801636695861816' '[[-5.505824565887451' '[[0.8643921613693237'\n",
      " '[[-3.113901138305664' '[[-4.944943428039551' '[[-6.021580219268799'\n",
      " '[[-3.797197103500366' '[[-6.600115776062012' '[[-6.63611364364624'\n",
      " '[[-5.6557512283325195' '[[-4.145737648010254' '[[-4.805609703063965'\n",
      " '[[-5.541276454925537' '[[-6.478823661804199' '[[-5.375845909118652'\n",
      " '[[-4.061093807220459' '[[-6.179139137268066' '[[-5.307809829711914'\n",
      " '[[-5.487459182739258' '[[-6.994748115539551' '[[-4.619502067565918'\n",
      " '[[-3.651249647140503' '[[-1.9259825944900513' '[[-4.6077470779418945'\n",
      " '[[-6.165499210357666' '[[-2.3225879669189453' '[[-6.689328193664551'\n",
      " '[[-6.339290618896484' '[[-7.813665866851807' '[[-6.010757923126221'\n",
      " '[[-5.066398620605469' '[[-3.466932535171509' '[[-7.379141807556152'\n",
      " '[[-5.313528537750244' '[[-4.692902565002441' '[[-2.961777687072754'\n",
      " '[[-6.19164514541626' '[[-2.2033956050872803' '[[0.14547301828861237'\n",
      " '[[-5.510660648345947' '[[-3.653075933456421' '[[-8.550785064697266'\n",
      " '[[-4.631887912750244' '[[-3.1264631748199463' '[[-5.630372047424316'\n",
      " '[[-3.782899856567383' '[[-5.387683868408203' '[[-5.896790504455566'\n",
      " '[[-5.988796234130859' '[[-2.4586880207061768' '[[-2.5005266666412354'\n",
      " '[[-3.625706195831299' '[[-5.961203575134277' '[[-6.94019889831543'\n",
      " '[[-0.5808588266372681' '[[-5.255492687225342' '[[-2.6192739009857178'\n",
      " '[[-7.455284118652344' '[[-6.271507740020752' '[[-5.806990623474121'\n",
      " '[[-2.6612603664398193' '[[-9.529141426086426' '[[-4.78518533706665'\n",
      " '[[-3.7911272048950195' '[[-7.15983772277832' '[[-7.83031702041626'\n",
      " '[[-5.825016021728516' '[[-6.101943492889404' '[[-3.9908387660980225'\n",
      " '[[-8.684142112731934' '[[0.4238269031047821' '[[-7.620768070220947'\n",
      " '[[-4.780109882354736' '[[-5.936419486999512' '[[-5.703969955444336'\n",
      " '[[-4.823014259338379' '[[-4.79155158996582' '[[-5.587526321411133'\n",
      " '[[-6.187087535858154' '[[-5.167657852172852' '[[-8.95258903503418'\n",
      " '[[-6.231843948364258' '[[-5.781871318817139' '[[-8.001091957092285'\n",
      " '[[-4.631852149963379' '[[-5.57232666015625' '[[-5.108728408813477'\n",
      " '[[-1.4166083335876465' '[[-3.7572693824768066' '[[-5.3421783447265625'\n",
      " '[[-5.946556091308594' '[[-5.117170333862305' '[[-2.7476699352264404'\n",
      " '[[-5.847308158874512' '[[-9.116772651672363' '[[-5.797512531280518'\n",
      " '[[-8.261754989624023' '[[-5.3266096115112305' '[[-4.386322975158691'\n",
      " '[[-2.995614528656006' '[[-6.731037616729736' '[[-7.707945823669434'\n",
      " '[[-6.550980091094971' '[[-4.897706031799316' '[[-4.016783237457275'\n",
      " '[[-6.119298934936523' '[[-5.5898213386535645' '[[-4.227860450744629'\n",
      " '[[-5.321651458740234' '[[-2.534195899963379' '[[-2.728288173675537'\n",
      " '[[-5.114403247833252' '[[-4.455225944519043' '[[-5.4297356605529785'\n",
      " '[[-5.140987873077393' '[[-5.77651309967041' '[[-5.889935493469238'\n",
      " '[[-6.3275628089904785' '[[-4.966085433959961' '[[-5.545265197753906'\n",
      " '[[-1.1682554483413696' '[[-3.5361883640289307' '[[-3.5492329597473145'\n",
      " '[[-3.5784647464752197' '[[-3.1947519779205322' '[[-9.055496215820312'\n",
      " '[[-4.348100185394287' '[[-1.5010576248168945' '[[-3.0636627674102783'\n",
      " '[[-3.335378885269165' '[[-4.390470504760742' '[[-4.493508338928223'\n",
      " '[[-6.1434478759765625' '[[-2.3342015743255615' '[[-5.718344688415527'\n",
      " '[[-5.729135513305664' '[[-5.994870185852051' '[[-3.8849709033966064'\n",
      " '[[-3.2785871028900146' '[[-5.580801486968994' '[[-4.560722827911377'\n",
      " '[[-5.7806572914123535' '[[-5.754079818725586' '[[-4.305576801300049'\n",
      " '[[-5.361231327056885' '[[-7.063699722290039' '[[-4.96148681640625'\n",
      " '[[-3.817495107650757' '[[-3.966622829437256' '[[-4.425762176513672'\n",
      " '[[-6.719507217407227' '[[-3.15559458732605' '[[-4.428043365478516'\n",
      " '[[-3.8854284286499023' '[[-4.738144397735596' '[[-5.530954360961914'\n",
      " '[[-3.3426952362060547' '[[-4.652134418487549' '[[-4.610793113708496'\n",
      " '[[-7.742284297943115' '[[-6.31239652633667' '[[-3.870204448699951'\n",
      " '[[-5.765317916870117' '[[-8.70518684387207' '[[-6.626724720001221'\n",
      " '[[-5.995110511779785' '[[-6.76685905456543' '[[-4.826569080352783'\n",
      " '[[-5.556296348571777' '[[-7.22824239730835' '[[-3.082526445388794'\n",
      " '[[-2.7107951641082764' '[[-1.3860024213790894' '[[-6.852410793304443'\n",
      " '[[-4.160278797149658' '[[-7.687325477600098' '[[-5.318034648895264'\n",
      " '[[-6.708049297332764' '[[-3.453803539276123' '[[-7.236001968383789'\n",
      " '[[-8.375969886779785' '[[-6.079710483551025' '[[-2.397895574569702'\n",
      " '[[-6.191354274749756' '[[-5.644113540649414' '[[-5.801248073577881'\n",
      " '[[-5.535896301269531' '[[-3.767343521118164' '[[-4.704610824584961'\n",
      " '[[-5.469988822937012' '[[-6.033780097961426' '[[-2.8845698833465576'\n",
      " '[[-5.280240535736084' '[[-3.3217873573303223' '[[-6.607647895812988'\n",
      " '[[-4.512389183044434' '[[-7.345453262329102' '[[-4.797182559967041'\n",
      " '[[-2.57914137840271' '[[-5.973613262176514' '[[-2.600466012954712'\n",
      " '[[-4.597878456115723' '[[-8.671058654785156' '[[-8.744098663330078'\n",
      " '[[-7.291845321655273' '[[0.422991007566452' '[[-6.225528717041016'\n",
      " '[[-4.6409382820129395' '[[-2.3431005477905273' '[[-5.9334330558776855'\n",
      " '[[-6.689553737640381' '[[-5.787444591522217' '[[-6.369288921356201'\n",
      " '[[-5.484178066253662' '[[-3.7551658153533936' '[[-5.966455459594727'\n",
      " '[[-2.9316165447235107' '[[-5.033529281616211' '[[-5.907320976257324'\n",
      " '[[-4.991513252258301' '[[-4.724883079528809' '[[-5.763137340545654'\n",
      " '[[-2.919759750366211' '[[-6.472010135650635' '[[-8.673083305358887']\n",
      "Problematic values in column 16: [' -2.411789894104004]]' ' -4.90162992477417]]' ' -4.285671234130859]]'\n",
      " ' -4.235047817230225]]' ' -3.2427642345428467]]' ' -3.1834208965301514]]'\n",
      " ' -3.113049030303955]]' ' -5.068012714385986]]' ' -3.7628467082977295]]'\n",
      " ' -4.706387519836426]]' ' -4.4276838302612305]]' ' -3.95478892326355]]'\n",
      " ' -1.9074912071228027]]' ' -5.069089889526367]]' ' -1.8667556047439575]]'\n",
      " ' -1.2592673301696777]]' ' -3.984602212905884]]' ' -3.385497570037842]]'\n",
      " ' -4.081240177154541]]' ' -4.9255805015563965]]' ' -2.654729127883911]]'\n",
      " ' -3.4753079414367676]]' ' -2.338461399078369]]' ' -4.31494140625]]'\n",
      " ' -2.0936338901519775]]' ' -3.2603821754455566]]' ' -2.501283645629883]]'\n",
      " ' -3.870305061340332]]' ' -4.8662824630737305]]' ' -2.7935330867767334]]'\n",
      " ' -2.5155093669891357]]' ' -5.215130805969238]]' ' -5.423437595367432]]'\n",
      " ' -2.3286850452423096]]' ' -0.9817500114440918]]'\n",
      " ' -5.3355326652526855]]' ' -2.741992473602295]]' ' -4.61313533782959]]'\n",
      " ' -3.4939823150634766]]' ' -2.037372350692749]]' ' -4.603734493255615]]'\n",
      " ' -2.0427141189575195]]' ' -2.4466452598571777]]' ' -6.751229763031006]]'\n",
      " ' -3.0755820274353027]]' ' -2.2106170654296875]]'\n",
      " ' -4.0190815925598145]]' ' -1.643007755279541]]' ' -4.21401309967041]]'\n",
      " ' -3.8679087162017822]]' ' -1.4555035829544067]]'\n",
      " ' -0.5862162709236145]]' ' -3.9358880519866943]]' ' -5.800942420959473]]'\n",
      " ' -3.8259599208831787]]' ' -3.286799907684326]]' ' -4.181628704071045]]'\n",
      " ' -3.066842555999756]]' ' -1.7833938598632812]]' ' -0.9616491198539734]]'\n",
      " ' -1.1686904430389404]]' ' -2.9391181468963623]]' ' -5.507752895355225]]'\n",
      " ' -6.386477470397949]]' ' -3.10770583152771]]' ' -1.731967568397522]]'\n",
      " ' -2.009371519088745]]' ' -2.1743180751800537]]' ' -2.7778496742248535]]'\n",
      " ' -5.8499321937561035]]' ' -3.825944662094116]]' ' -0.6319689750671387]]'\n",
      " ' -3.4515957832336426]]' ' -3.685096263885498]]' ' -2.3808722496032715]]'\n",
      " ' -3.9543254375457764]]' ' -4.844970226287842]]' ' -3.616299629211426]]'\n",
      " ' -3.4867794513702393]]' ' -3.0850257873535156]]'\n",
      " ' -1.5023407936096191]]' ' -1.8204143047332764]]' ' -2.492077350616455]]'\n",
      " ' -3.846574306488037]]' ' -2.8019683361053467]]' ' -4.111722469329834]]'\n",
      " ' -3.1864829063415527]]' ' -3.1667072772979736]]'\n",
      " ' -1.8923120498657227]]' ' -5.414554119110107]]' ' -3.2389299869537354]]'\n",
      " ' -1.9756557941436768]]' ' -3.008629322052002]]' ' -5.777274131774902]]'\n",
      " ' -1.8324323892593384]]' ' -2.3243815898895264]]'\n",
      " ' -2.1848278045654297]]' ' -2.5174407958984375]]' ' -1.596683382987976]]'\n",
      " ' -2.997745990753174]]' ' -3.572429656982422]]' ' -4.215400218963623]]'\n",
      " ' -4.2247090339660645]]' ' -2.568106174468994]]' ' -5.431025981903076]]'\n",
      " ' -3.5495288372039795]]' ' -3.206819772720337]]' ' -4.368980884552002]]'\n",
      " ' -4.350738525390625]]' ' -5.083254814147949]]' ' -2.7178165912628174]]'\n",
      " ' -2.275135040283203]]' ' -1.3044532537460327]]' ' -3.9445908069610596]]'\n",
      " ' -0.36066997051239014]]' ' 0.5571898221969604]]'\n",
      " ' -2.8305583000183105]]' ' -2.206820011138916]]' ' -1.0165029764175415]]'\n",
      " ' -3.5855979919433594]]' ' -0.7546042203903198]]'\n",
      " ' -3.5691070556640625]]' ' -2.6818695068359375]]' ' -4.565008163452148]]'\n",
      " ' -1.6426657438278198]]' ' -2.7152981758117676]]'\n",
      " ' -2.2112817764282227]]' ' -0.9858162999153137]]' ' -2.201411008834839]]'\n",
      " ' -2.8077738285064697]]' ' -3.188744306564331]]' ' -1.6604137420654297]]'\n",
      " ' 0.5933783650398254]]' ' -4.997603893280029]]' ' -3.2111096382141113]]'\n",
      " ' -3.790771722793579]]' ' -4.235046863555908]]' ' -3.6604182720184326]]'\n",
      " ' -3.348104476928711]]' ' -3.4219675064086914]]' ' -3.842773675918579]]'\n",
      " ' -1.59884512424469]]' ' -0.00011832825839519501]]'\n",
      " ' -2.995797872543335]]' ' -3.8438351154327393]]' ' -1.8729968070983887]]'\n",
      " ' -0.5599997639656067]]' ' -3.6102993488311768]]' ' -2.29268217086792]]'\n",
      " ' -4.5227837562561035]]' ' -4.004417896270752]]' ' -3.8073413372039795]]'\n",
      " ' -2.4989278316497803]]' ' -3.7453672885894775]]'\n",
      " ' -0.24009059369564056]]' ' -5.109797954559326]]' ' -2.359685182571411]]'\n",
      " ' -3.736198663711548]]' ' -3.2041149139404297]]' ' -2.688418388366699]]'\n",
      " ' -3.5791780948638916]]' ' -2.267134666442871]]' ' -1.9989018440246582]]'\n",
      " ' -0.6588733196258545]]' ' -1.867866039276123]]' ' -4.017880439758301]]'\n",
      " ' -2.6203911304473877]]' ' -4.36458158493042]]' ' -3.542682409286499]]'\n",
      " ' -3.2635838985443115]]' ' -3.293215274810791]]' ' -4.655296325683594]]'\n",
      " ' -4.517385482788086]]' ' -4.712741851806641]]' ' -4.030580043792725]]'\n",
      " ' -3.2601988315582275]]' ' -2.146728992462158]]' ' -2.7488927841186523]]'\n",
      " ' -3.39298152923584]]' ' -1.0263843536376953]]' ' -1.6598838567733765]]'\n",
      " ' -3.648145914077759]]' ' -4.275416374206543]]' ' -1.4077532291412354]]'\n",
      " ' -3.0134496688842773]]' ' -2.8423330783843994]]' ' -2.01196026802063]]'\n",
      " ' -3.628089666366577]]' ' -3.4144582748413086]]'\n",
      " ' -0.27613791823387146]]' ' -3.750725746154785]]' ' -2.684837818145752]]'\n",
      " ' -3.686220407485962]]' ' -4.545592308044434]]' ' -4.856088161468506]]'\n",
      " ' -4.173131942749023]]' ' -4.434253215789795]]' ' -3.250117301940918]]'\n",
      " ' -3.923464775085449]]' ' -1.4078480005264282]]' ' -3.31941294670105]]'\n",
      " ' -3.2948367595672607]]' ' -2.498900890350342]]' ' -3.27038311958313]]'\n",
      " ' -0.030868813395500183]]' ' -2.474393606185913]]'\n",
      " ' -7.124360084533691]]' ' -3.2834203243255615]]' ' -4.686707019805908]]'\n",
      " ' -2.7114803791046143]]' ' -3.1825952529907227]]'\n",
      " ' -2.0882186889648438]]' ' -5.292680740356445]]' ' -3.275984048843384]]'\n",
      " ' -2.452791929244995]]' ' -3.9688005447387695]]' ' 0.22207574546337128]]'\n",
      " ' -1.5545053482055664]]' ' -4.585343837738037]]' ' -3.6080520153045654]]'\n",
      " ' -4.962360382080078]]' ' -4.1783766746521]]' ' -2.0025060176849365]]'\n",
      " ' -1.154394268989563]]' ' -1.3027116060256958]]' ' -3.85491681098938]]'\n",
      " ' -2.0364115238189697]]' ' -2.7451295852661133]]' ' 0.3367653489112854]]'\n",
      " ' -0.8370624780654907]]' ' -2.4203593730926514]]'\n",
      " ' -1.1042166948318481]]' ' -3.4636905193328857]]' ' -4.570224285125732]]'\n",
      " ' -2.3416693210601807]]' ' -4.119032859802246]]' ' -2.2301013469696045]]'\n",
      " ' -4.374665260314941]]' ' -4.642807960510254]]' ' -3.228518009185791]]'\n",
      " ' -3.0981533527374268]]' ' -3.9750218391418457]]'\n",
      " ' -3.8516807556152344]]' ' -2.167846918106079]]' ' -4.098718643188477]]'\n",
      " ' -3.8681564331054688]]' ' -0.8198809027671814]]'\n",
      " ' -0.8106769919395447]]' ' -2.8663361072540283]]' ' -3.336184501647949]]'\n",
      " ' -4.3904829025268555]]' ' -4.262539863586426]]' ' -3.468301773071289]]'\n",
      " ' -6.008208751678467]]' ' -3.831693649291992]]' ' -1.0837435722351074]]'\n",
      " ' -1.8366765975952148]]' ' -4.923182964324951]]' ' -5.298861503601074]]'\n",
      " ' -4.7211761474609375]]' ' 0.13960571587085724]]' ' -4.684608459472656]]'\n",
      " ' -2.754545211791992]]' ' -0.26065608859062195]]'\n",
      " ' -1.5221480131149292]]' ' -0.011447612196207047]]'\n",
      " ' -3.7710256576538086]]' ' -1.6181762218475342]]' ' -4.80336856842041]]'\n",
      " ' -3.085770606994629]]' ' -2.649907350540161]]' ' -2.583897352218628]]'\n",
      " ' -3.6814939975738525]]' ' -3.403106451034546]]' ' -1.99936842918396]]'\n",
      " ' -2.079286575317383]]' ' -4.005592346191406]]' ' -2.409872055053711]]'\n",
      " ' -3.7286834716796875]]' ' -1.5825005769729614]]'\n",
      " ' -4.8425750732421875]]' ' -0.5083723068237305]]' ' -4.027437210083008]]'\n",
      " ' -2.7276971340179443]]' ' -4.38789176940918]]' ' -4.206116199493408]]'\n",
      " ' -7.066463947296143]]' ' -3.2375354766845703]]' ' -1.1227929592132568]]'\n",
      " ' -5.050883769989014]]' ' -5.188840389251709]]' ' -3.005007028579712]]'\n",
      " ' -4.561613082885742]]' ' -5.190718650817871]]' ' -4.679150104522705]]'\n",
      " ' -1.7742793560028076]]' ' -4.372599124908447]]' ' -1.0380381345748901]]'\n",
      " ' -4.733107089996338]]' ' -2.9967126846313477]]' ' -1.846756935119629]]'\n",
      " ' -1.990729570388794]]' ' -1.5336322784423828]]' ' -4.156888961791992]]'\n",
      " ' -1.864392876625061]]' ' -5.000377178192139]]' ' -2.943495750427246]]'\n",
      " ' -3.3661065101623535]]' ' -4.259222030639648]]' ' -3.985671043395996]]'\n",
      " ' -5.688442230224609]]' ' -3.80098295211792]]' ' -1.549653172492981]]'\n",
      " ' -4.894168853759766]]' ' -2.8517932891845703]]' ' -3.7830467224121094]]'\n",
      " ' -4.764583587646484]]' ' -2.5323569774627686]]' ' -2.195155620574951]]'\n",
      " ' -6.169323921203613]]' ' -5.577847003936768]]' ' -3.61602783203125]]'\n",
      " ' -1.5229777097702026]]' ' -4.7752156257629395]]'\n",
      " ' -2.6215920448303223]]' ' -2.4635164737701416]]' ' -4.732386112213135]]'\n",
      " ' -5.407302379608154]]' ' -4.114917278289795]]' ' -4.049795627593994]]'\n",
      " ' -4.250216484069824]]' ' -4.332235336303711]]' ' -5.922981262207031]]'\n",
      " ' -2.557770013809204]]' ' -2.5445809364318848]]' ' -1.2971346378326416]]'\n",
      " ' -2.4107730388641357]]' ' -1.496495246887207]]' ' -2.9963207244873047]]'\n",
      " ' -3.126842975616455]]' ' -5.999183177947998]]' ' -4.705254077911377]]'\n",
      " ' -4.426768779754639]]' ' -3.6955490112304688]]' ' -3.344949245452881]]'\n",
      " ' -0.5292964577674866]]' ' -3.612473726272583]]' ' 0.35578811168670654]]'\n",
      " ' -1.0447230339050293]]' ' -1.2989423274993896]]' ' -4.800961971282959]]'\n",
      " ' -1.784598708152771]]' ' -3.1876373291015625]]' ' -2.1558330059051514]]'\n",
      " ' -1.3308693170547485]]' ' -4.950798034667969]]' ' -4.438485145568848]]'\n",
      " ' -2.640958070755005]]' ' -4.097568511962891]]' ' -3.0741896629333496]]'\n",
      " ' -5.318958759307861]]' ' -2.989046335220337]]' ' -3.0019383430480957]]'\n",
      " ' -0.7098928689956665]]' ' -5.121471405029297]]' ' -3.9984841346740723]]'\n",
      " ' -3.245696783065796]]' ' -4.360482692718506]]' ' -2.2319133281707764]]'\n",
      " ' -2.3954546451568604]]' ' -4.519279479980469]]' ' -4.9908366203308105]]'\n",
      " ' -4.840426445007324]]' ' -3.26540470123291]]' ' -4.558743953704834]]'\n",
      " ' -4.7465128898620605]]' ' -4.016281604766846]]' ' -5.132882118225098]]'\n",
      " ' -3.2739005088806152]]' ' -0.7887281179428101]]'\n",
      " ' -3.6827712059020996]]' ' -4.10449743270874]]' ' -3.7071645259857178]]'\n",
      " ' -3.0699503421783447]]' ' -4.443276882171631]]' ' -3.665156602859497]]'\n",
      " ' -2.241121768951416]]' ' -1.8066513538360596]]' ' -6.658191680908203]]'\n",
      " ' -4.766071319580078]]' ' -4.480902671813965]]' ' -4.678241729736328]]'\n",
      " ' -2.6836140155792236]]' ' -3.368800163269043]]' ' -5.07719612121582]]'\n",
      " ' -3.7572076320648193]]' ' -1.5032709836959839]]'\n",
      " ' -1.5593903064727783]]' ' -4.296601295471191]]' ' -2.7493486404418945]]'\n",
      " ' -7.5750813484191895]]' ' -3.70607590675354]]' ' -3.439490795135498]]'\n",
      " ' -0.05410213768482208]]' ' -5.20222806930542]]' ' -5.91343355178833]]'\n",
      " ' -5.6220293045043945]]' ' -0.35088759660720825]]'\n",
      " ' -4.699073314666748]]' ' -3.9134132862091064]]' ' -1.9231369495391846]]'\n",
      " ' -3.364075183868408]]' ' -3.260552167892456]]' ' -4.843420028686523]]'\n",
      " ' -3.090649127960205]]' ' -3.910783529281616]]' ' -2.591770887374878]]'\n",
      " ' -3.0365824699401855]]' ' -1.311159372329712]]' ' -4.405313491821289]]'\n",
      " ' -1.6301437616348267]]' ' -3.9103829860687256]]'\n",
      " ' -3.8664395809173584]]' ' -2.7294392585754395]]' ' -2.960381269454956]]'\n",
      " ' -2.7181293964385986]]' ' -2.3668439388275146]]'\n",
      " ' -3.9513604640960693]]' ' -4.137397766113281]]' ' -4.974609375]]'\n",
      " ' -1.7924796342849731]]' ' -3.157588243484497]]' ' -1.8431823253631592]]'\n",
      " ' -2.4162099361419678]]' ' -3.1252596378326416]]' ' -4.185220718383789]]'\n",
      " ' -4.157343864440918]]' ' -4.33369779586792]]' ' -5.8868088722229]]'\n",
      " ' -2.2471160888671875]]' ' -3.434082269668579]]' ' -0.7572959661483765]]'\n",
      " ' -3.2689461708068848]]' ' -3.0942022800445557]]' ' -4.592566967010498]]'\n",
      " ' -3.8006174564361572]]' ' -3.5147039890289307]]' ' -4.149692535400391]]'\n",
      " ' -3.01823353767395]]' ' -5.183454513549805]]']\n"
     ]
    }
   ],
   "source": [
    "# def is_float(value):\n",
    "#     \"\"\"Check if the value can be converted to float\"\"\"\n",
    "#     try:\n",
    "#         float(value)\n",
    "#         return True\n",
    "#     except:\n",
    "#         return False\n",
    "\n",
    "# # Now proceed to convert and check for problematic values\n",
    "# try:\n",
    "#     results[0] = results[0].astype(float)\n",
    "#     results[16] = results[16].astype(float)\n",
    "# except ValueError as e:\n",
    "#     print(f\"ValueError: {e}\")\n",
    "#     problematic_values_0 = results[~results[0].apply(lambda x: is_float(x))][0]\n",
    "#     problematic_values_16 = results[~results[16].apply(lambda x: is_float(x))][16]\n",
    "#     print(\"Problematic values in column 0:\", problematic_values_0.unique())\n",
    "#     print(\"Problematic values in column 16:\", problematic_values_16.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ddea1117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "13    float64\n",
      "14    float64\n",
      "15    float64\n",
      "16    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results.dtypes)\n",
    "# 1. Convert raw scores to probabilities using the sigmoid function.\n",
    "probabilities = 1 / (1 + np.exp(-results.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a00ee6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013775</td>\n",
       "      <td>0.002149</td>\n",
       "      <td>0.031591</td>\n",
       "      <td>0.242771</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.030995</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>0.206927</td>\n",
       "      <td>0.022433</td>\n",
       "      <td>0.716271</td>\n",
       "      <td>0.127291</td>\n",
       "      <td>0.051718</td>\n",
       "      <td>0.010515</td>\n",
       "      <td>0.130123</td>\n",
       "      <td>0.031959</td>\n",
       "      <td>0.082278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.460279</td>\n",
       "      <td>0.878795</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>0.029280</td>\n",
       "      <td>0.158814</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.009207</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.035854</td>\n",
       "      <td>0.007380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003049</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.949553</td>\n",
       "      <td>0.228896</td>\n",
       "      <td>0.087724</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.021415</td>\n",
       "      <td>0.011180</td>\n",
       "      <td>0.043150</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.036164</td>\n",
       "      <td>0.014272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.889694</td>\n",
       "      <td>0.018113</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.197649</td>\n",
       "      <td>0.122768</td>\n",
       "      <td>0.168675</td>\n",
       "      <td>0.011956</td>\n",
       "      <td>0.127107</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.185963</td>\n",
       "      <td>0.037588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.015687</td>\n",
       "      <td>0.978679</td>\n",
       "      <td>0.016683</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.101575</td>\n",
       "      <td>0.083614</td>\n",
       "      <td>0.103393</td>\n",
       "      <td>0.014082</td>\n",
       "      <td>0.061971</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.042572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.179662</td>\n",
       "      <td>0.125345</td>\n",
       "      <td>0.014611</td>\n",
       "      <td>0.057609</td>\n",
       "      <td>0.017495</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.427258</td>\n",
       "      <td>0.173189</td>\n",
       "      <td>0.452122</td>\n",
       "      <td>0.333904</td>\n",
       "      <td>0.075994</td>\n",
       "      <td>0.265889</td>\n",
       "      <td>0.015446</td>\n",
       "      <td>0.039083</td>\n",
       "      <td>0.041909</td>\n",
       "      <td>0.660245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.085450</td>\n",
       "      <td>0.021906</td>\n",
       "      <td>0.101535</td>\n",
       "      <td>0.111886</td>\n",
       "      <td>0.030394</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.064824</td>\n",
       "      <td>0.070421</td>\n",
       "      <td>0.291456</td>\n",
       "      <td>0.592295</td>\n",
       "      <td>0.071306</td>\n",
       "      <td>0.033970</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.048212</td>\n",
       "      <td>0.085323</td>\n",
       "      <td>0.551608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.012503</td>\n",
       "      <td>0.017525</td>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.055813</td>\n",
       "      <td>0.005770</td>\n",
       "      <td>0.006620</td>\n",
       "      <td>0.111806</td>\n",
       "      <td>0.209341</td>\n",
       "      <td>0.370490</td>\n",
       "      <td>0.097305</td>\n",
       "      <td>0.327577</td>\n",
       "      <td>0.191064</td>\n",
       "      <td>0.203895</td>\n",
       "      <td>0.009212</td>\n",
       "      <td>0.028656</td>\n",
       "      <td>0.066784</td>\n",
       "      <td>0.471642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>0.028383</td>\n",
       "      <td>0.004182</td>\n",
       "      <td>0.016735</td>\n",
       "      <td>0.062586</td>\n",
       "      <td>0.007282</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.006115</td>\n",
       "      <td>0.034631</td>\n",
       "      <td>0.052565</td>\n",
       "      <td>0.248427</td>\n",
       "      <td>0.894493</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>0.028847</td>\n",
       "      <td>0.009596</td>\n",
       "      <td>0.064883</td>\n",
       "      <td>0.078930</td>\n",
       "      <td>0.205969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.024662</td>\n",
       "      <td>0.111267</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.454195</td>\n",
       "      <td>0.005924</td>\n",
       "      <td>0.004850</td>\n",
       "      <td>0.022249</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.035865</td>\n",
       "      <td>0.031530</td>\n",
       "      <td>0.065704</td>\n",
       "      <td>0.727249</td>\n",
       "      <td>0.601727</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.035681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.013775  0.002149  0.031591  0.242771  0.006739  0.030995  0.007906   \n",
       "1    0.002876  0.000455  0.460279  0.878795  0.011557  0.000282  0.000015   \n",
       "2    0.003049  0.000614  0.949553  0.228896  0.087724  0.000130  0.000006   \n",
       "3    0.007134  0.001530  0.010820  0.889694  0.018113  0.000468  0.000338   \n",
       "4    0.003218  0.001276  0.015687  0.978679  0.016683  0.000771  0.000260   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "747  0.179662  0.125345  0.014611  0.057609  0.017495  0.001927  0.012745   \n",
       "748  0.085450  0.021906  0.101535  0.111886  0.030394  0.003424  0.000469   \n",
       "749  0.012503  0.017525  0.009735  0.055813  0.005770  0.006620  0.111806   \n",
       "750  0.028383  0.004182  0.016735  0.062586  0.007282  0.003714  0.006115   \n",
       "751  0.000959  0.024662  0.111267  0.000551  0.000099  0.454195  0.005924   \n",
       "\n",
       "           7         8         9         10        11        12        13  \\\n",
       "0    0.024523  0.206927  0.022433  0.716271  0.127291  0.051718  0.010515   \n",
       "1    0.030687  0.029280  0.158814  0.002866  0.009207  0.000024  0.000050   \n",
       "2    0.021415  0.011180  0.043150  0.000133  0.001859  0.000053  0.000007   \n",
       "3    0.197649  0.122768  0.168675  0.011956  0.127107  0.000623  0.000195   \n",
       "4    0.101575  0.083614  0.103393  0.014082  0.061971  0.000477  0.000260   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "747  0.427258  0.173189  0.452122  0.333904  0.075994  0.265889  0.015446   \n",
       "748  0.064824  0.070421  0.291456  0.592295  0.071306  0.033970  0.002812   \n",
       "749  0.209341  0.370490  0.097305  0.327577  0.191064  0.203895  0.009212   \n",
       "750  0.034631  0.052565  0.248427  0.894493  0.021984  0.028847  0.009596   \n",
       "751  0.004850  0.022249  0.000275  0.035865  0.031530  0.065704  0.727249   \n",
       "\n",
       "           14        15        16  \n",
       "0    0.130123  0.031959  0.082278  \n",
       "1    0.000110  0.035854  0.007380  \n",
       "2    0.000116  0.036164  0.014272  \n",
       "3    0.003226  0.185963  0.037588  \n",
       "4    0.003988  0.025449  0.042572  \n",
       "..        ...       ...       ...  \n",
       "747  0.039083  0.041909  0.660245  \n",
       "748  0.048212  0.085323  0.551608  \n",
       "749  0.028656  0.066784  0.471642  \n",
       "750  0.064883  0.078930  0.205969  \n",
       "751  0.601727  0.004205  0.035681  \n",
       "\n",
       "[752 rows x 17 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = 1 / (1 + np.exp(-results.values))\n",
    "probs = pd.DataFrame(probabilities)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "628203c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of true_labels: (752, 18)\n",
      "Shape of binary_predictions: (752, 17)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of true_labels:\", true_labels.shape)\n",
    "print(\"Shape of binary_predictions:\", binary_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1ad229e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>SDG 1</th>\n",
       "      <th>SDG 2</th>\n",
       "      <th>SDG 3</th>\n",
       "      <th>SDG 4</th>\n",
       "      <th>SDG 5</th>\n",
       "      <th>SDG 6</th>\n",
       "      <th>SDG 7</th>\n",
       "      <th>SDG 8</th>\n",
       "      <th>SDG 9</th>\n",
       "      <th>SDG 10</th>\n",
       "      <th>SDG 11</th>\n",
       "      <th>SDG 12</th>\n",
       "      <th>SDG 13</th>\n",
       "      <th>SDG 14</th>\n",
       "      <th>SDG 15</th>\n",
       "      <th>SDG 16</th>\n",
       "      <th>SDG 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shape, Built Enviro Projects the built environ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEP 5 this course is identified by rmit univer...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comm Skills for Health Prof this course will e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SW Field Education A in this course you will u...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSC Work Integrated Learning 2 in this course ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Policy analysis for growth prospects in region...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Building an understanding of liveability acros...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Stage 2 - Latrobe Valley Smart Specialisation ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Balance Victoria: Potential Impacts of a Form...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Development of culturing procedures and molecu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  SDG 1  SDG 2  SDG 3  \\\n",
       "0    Shape, Built Enviro Projects the built environ...    0.0    0.0    0.0   \n",
       "1    PEP 5 this course is identified by rmit univer...    0.0    0.0    1.0   \n",
       "2    Comm Skills for Health Prof this course will e...    0.0    0.0    1.0   \n",
       "3    SW Field Education A in this course you will u...    0.0    0.0    0.0   \n",
       "4    LSC Work Integrated Learning 2 in this course ...    0.0    0.0    0.0   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "755  Policy analysis for growth prospects in region...    0.0    0.0    0.0   \n",
       "756  Building an understanding of liveability acros...    0.0    0.0    0.0   \n",
       "757  Stage 2 - Latrobe Valley Smart Specialisation ...    0.0    1.0    0.0   \n",
       "758  Balance Victoria: Potential Impacts of a Form...    0.0    0.0    0.0   \n",
       "759  Development of culturing procedures and molecu...    0.0    0.0    0.0   \n",
       "\n",
       "     SDG 4  SDG 5  SDG 6  SDG 7  SDG 8  SDG 9  SDG 10  SDG 11  SDG 12  SDG 13  \\\n",
       "0      1.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "1      1.0    0.0    0.0    0.0    1.0    0.0     1.0     0.0     0.0     0.0   \n",
       "2      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "3      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "4      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "..     ...    ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       "755    0.0    0.0    0.0    0.0    1.0    1.0     0.0     0.0     0.0     0.0   \n",
       "756    0.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "757    0.0    0.0    0.0    1.0    1.0    0.0     0.0     0.0     0.0     0.0   \n",
       "758    0.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "759    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     SDG 14  SDG 15  SDG 16  SDG 17  \n",
       "0       0.0     0.0     0.0     1.0  \n",
       "1       0.0     0.0     0.0     0.0  \n",
       "2       0.0     0.0     0.0     0.0  \n",
       "3       0.0     0.0     0.0     0.0  \n",
       "4       0.0     0.0     0.0     0.0  \n",
       "..      ...     ...     ...     ...  \n",
       "755     0.0     0.0     0.0     0.0  \n",
       "756     0.0     0.0     0.0     0.0  \n",
       "757     0.0     0.0     0.0     1.0  \n",
       "758     0.0     0.0     0.0     0.0  \n",
       "759     0.0     1.0     0.0     0.0  \n",
       "\n",
       "[752 rows x 18 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "2d14a9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(752, 17)\n",
      "Overall Accuracy: 0.3245\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SDG 1       0.50      0.14      0.21        22\n",
      "       SDG 2       0.64      0.24      0.35        29\n",
      "       SDG 3       0.89      0.55      0.68       179\n",
      "       SDG 4       0.67      0.62      0.65       210\n",
      "       SDG 5       0.59      0.28      0.38        36\n",
      "       SDG 6       0.85      0.61      0.71        38\n",
      "       SDG 7       0.58      0.49      0.53        39\n",
      "       SDG 8       0.62      0.09      0.15       115\n",
      "       SDG 9       0.55      0.36      0.43       118\n",
      "      SDG 10       0.65      0.12      0.20       108\n",
      "      SDG 11       0.72      0.47      0.57        99\n",
      "      SDG 12       0.64      0.39      0.48       106\n",
      "      SDG 13       0.47      0.17      0.25        47\n",
      "      SDG 14       0.55      0.23      0.32        26\n",
      "      SDG 15       0.78      0.42      0.55        50\n",
      "      SDG 16       0.83      0.50      0.62       140\n",
      "      SDG 17       0.38      0.18      0.24        66\n",
      "\n",
      "   micro avg       0.69      0.39      0.50      1428\n",
      "   macro avg       0.64      0.34      0.43      1428\n",
      "weighted avg       0.68      0.39      0.48      1428\n",
      " samples avg       0.60      0.50      0.52      1428\n",
      "\n",
      "Confusion matrix for SDG 1:\n",
      "[[727   3]\n",
      " [ 19   3]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 2:\n",
      "[[719   4]\n",
      " [ 22   7]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 3:\n",
      "[[561  12]\n",
      " [ 81  98]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 4:\n",
      "[[477  65]\n",
      " [ 79 131]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 5:\n",
      "[[709   7]\n",
      " [ 26  10]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 6:\n",
      "[[710   4]\n",
      " [ 15  23]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 7:\n",
      "[[699  14]\n",
      " [ 20  19]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 8:\n",
      "[[631   6]\n",
      " [105  10]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 9:\n",
      "[[600  34]\n",
      " [ 76  42]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 10:\n",
      "[[637   7]\n",
      " [ 95  13]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 11:\n",
      "[[635  18]\n",
      " [ 52  47]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 12:\n",
      "[[623  23]\n",
      " [ 65  41]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 13:\n",
      "[[696   9]\n",
      " [ 39   8]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 14:\n",
      "[[721   5]\n",
      " [ 20   6]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 15:\n",
      "[[696   6]\n",
      " [ 29  21]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 16:\n",
      "[[598  14]\n",
      " [ 70  70]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 17:\n",
      "[[666  20]\n",
      " [ 54  12]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, multilabel_confusion_matrix\n",
    "\n",
    "# # 1. Convert raw scores to probabilities using the sigmoid function.\n",
    "# probabilities = 1 / (1 + np.exp(-results.values))\n",
    "\n",
    "# 2. Convert probabilities to binary predictions using a threshold.\n",
    "threshold = 0.5\n",
    "binary_predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "# 3. Extract true labels from test_data. Assuming test_data has labels in all columns except \"Text\".\n",
    "true_labels = test_data.drop(columns=\"Text\").values\n",
    "print(true_labels.shape)\n",
    "\n",
    "# Calculate accuracy (this will be a multi-label accuracy).\n",
    "accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report.\n",
    "report = classification_report(true_labels, binary_predictions, target_names=test_data.columns[1:])\n",
    "print(report)\n",
    "\n",
    "# Optionally, display the confusion matrix for each SDG (or label).\n",
    "matrices = multilabel_confusion_matrix(true_labels, binary_predictions)\n",
    "for idx, matrix in enumerate(matrices):\n",
    "    print(f\"Confusion matrix for SDG {idx+1}:\")\n",
    "    print(matrix)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d5ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e2db77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write everything to a .txt file\n",
    "with open(f\"Reports/{model_name}_2_evaluation_report.txt\", \"w\") as f:\n",
    "    f.write(f\"Overall Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "    f.write(\"\\n\\n\")\n",
    "\n",
    "    for idx, matrix in enumerate(matrices):\n",
    "        # Convert the matrix to traditional format\n",
    "        traditional_matrix = np.array([[matrix[1][1], matrix[1][0]], [matrix[0][1], matrix[0][0]]])\n",
    "        f.write(f\"Confusion matrix for SDG {idx+1}:\\n\")\n",
    "        f.write(str(traditional_matrix))\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3437200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e02c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2475d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
