{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b55607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- SPECIFY FILE LOCATIONS HERE -----------------\n",
    "\n",
    "# S3 paths\n",
    "s3_bucket = 'sdg-project'\n",
    "model_name = 'bal_model1'\n",
    "artifact_name = 'pytorch-training-2023-10-26-04-05-28-024'\n",
    "\n",
    "# Model location path\n",
    "s3_model_path = f's3://{s3_bucket}/models/{model_name}/artifacts/{artifact_name}/output/model.tar.gz'\n",
    "\n",
    "# Original test data path\n",
    "#test_data_path = 'data/old_data/test_course.csv'\n",
    "test_data_path = 'data/bal_test.csv'\n",
    "s3_test_data_path = f's3://{s3_bucket}/{test_data_path}'\n",
    "\n",
    "# Transformed (text only) test data path\n",
    "transformed_data_path = 'data/test_split/text_only_test.csv'\n",
    "s3_transformed_data_path = f's3://{s3_bucket}/{transformed_data_path}'\n",
    "\n",
    "# Prediction output path\n",
    "prediction_output_path = f's3://{s3_bucket}/models/{model_name}/predictions/'\n",
    "\n",
    "# Local paths\n",
    "local_tarball_path = 'model.tar.gz'\n",
    "local_test_data_path = 'Split_Data/text_only_test.csv'\n",
    "local_results_path = 'batch_results.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d2fb405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.18.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (4.18.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (0.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (2023.10.3)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (2.31.0)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (0.0.53)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.18.0) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (4.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.18.0) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.18.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.18.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.18.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.18.0) (2023.5.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses->transformers==4.18.0) (1.16.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses->transformers==4.18.0) (8.1.6)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses->transformers==4.18.0) (1.3.1)\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "4.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.18.0\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "import torch\n",
    "import os\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "import transformers\n",
    "import tarfile\n",
    "\n",
    "role = get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = 'sdg-project'\n",
    "\n",
    "print(transformers.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a111b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sdg-project/models/bal_model1/artifacts/pytorch-training-2023-10-26-04-05-28-024/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(s3_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0852a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the tarball from S3\n",
    "s3 = boto3.client('s3')\n",
    "s3.download_file(s3_bucket, s3_model_path.replace(f's3://{s3_bucket}/', ''), local_tarball_path)\n",
    "\n",
    "# Extract the tarball\n",
    "with tarfile.open(local_tarball_path, 'r:gz') as tar:\n",
    "    tar.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2f93eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test data\n",
    "test_data = pd.read_csv(f's3://{s3_bucket}/{test_data_path}')\n",
    "valid_rows = test_data['Text'].apply(lambda x: isinstance(x, str))\n",
    "test_data = test_data[valid_rows]\n",
    "\n",
    "os.makedirs('Split_Data', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a4eed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5de4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad10681c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Found 2 rows with unmatched double quotes!\n",
      "Warning: Found 136 rows with newlines!\n"
     ]
    }
   ],
   "source": [
    "# Check 1: Verify if any row in the 'Text' column contains unexpected double quotes\n",
    "malformed_rows = test_data['Text'].str.count('\"') % 2 != 0\n",
    "if malformed_rows.sum() > 0:\n",
    "    print(f\"Warning: Found {malformed_rows.sum()} rows with unmatched double quotes!\")\n",
    "\n",
    "# Check 2: Verify if any row in the 'Text' column contains newlines \n",
    "newline_rows = test_data['Text'].str.contains('\\n')\n",
    "if newline_rows.sum() > 0:\n",
    "    print(f\"Warning: Found {newline_rows.sum()} rows with newlines!\")\n",
    "\n",
    "# Check 3: Verify if any row in the 'Text' column exceeds a certain length\n",
    "# (Useful check if there's a MaxPayloadInMB constraint as mentioned in your logs)\n",
    "max_length = 5 * 10**6  # e.g., 5MB\n",
    "long_rows = test_data['Text'].str.len() > max_length\n",
    "if long_rows.sum() > 0:\n",
    "    print(f\"Warning: Found {long_rows.sum()} rows exceeding {max_length} characters!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "effb86bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle unmatched double quotes\n",
    "# Option 1: Remove rows with unmatched double quotes\n",
    "test_data = test_data[~malformed_rows]\n",
    "\n",
    "\n",
    "# Handle newlines\n",
    "# Replace newlines with spaces\n",
    "test_data['Text'] = test_data['Text'].str.replace('\\n', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14b79428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SDG 1</th>\n",
       "      <th>SDG 2</th>\n",
       "      <th>SDG 3</th>\n",
       "      <th>SDG 4</th>\n",
       "      <th>SDG 5</th>\n",
       "      <th>SDG 6</th>\n",
       "      <th>SDG 7</th>\n",
       "      <th>SDG 8</th>\n",
       "      <th>SDG 9</th>\n",
       "      <th>SDG 10</th>\n",
       "      <th>SDG 11</th>\n",
       "      <th>SDG 12</th>\n",
       "      <th>SDG 13</th>\n",
       "      <th>SDG 14</th>\n",
       "      <th>SDG 15</th>\n",
       "      <th>SDG 16</th>\n",
       "      <th>SDG 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SDG 1  SDG 2  SDG 3  SDG 4  SDG 5  SDG 6  SDG 7  SDG 8  SDG 9  SDG 10  \\\n",
       "0        0      0      0      0      0      0      0      0      0       0   \n",
       "1        0      0      0      0      0      0      0      0      0       0   \n",
       "2        1      0      1      0      1      0      0      0      0       1   \n",
       "3        0      0      0      0      0      0      0      1      0       0   \n",
       "4        0      0      0      0      0      0      0      0      0       0   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...     ...   \n",
       "495      0      0      1      0      0      0      0      0      0       0   \n",
       "496      0      0      0      1      0      0      0      0      0       0   \n",
       "497      0      0      0      1      0      0      0      0      0       0   \n",
       "498      0      0      0      0      0      0      0      0      0       0   \n",
       "499      0      0      0      1      0      0      0      0      0       0   \n",
       "\n",
       "     SDG 11  SDG 12  SDG 13  SDG 14  SDG 15  SDG 16  SDG 17  \n",
       "0         0       1       0       0       0       0       0  \n",
       "1         0       0       0       1       0       0       0  \n",
       "2         0       1       1       0       0       0       0  \n",
       "3         0       0       0       0       0       0       0  \n",
       "4         1       0       0       0       0       0       0  \n",
       "..      ...     ...     ...     ...     ...     ...     ...  \n",
       "495       0       0       0       0       0       0       0  \n",
       "496       0       1       0       0       0       0       0  \n",
       "497       0       0       0       0       0       0       0  \n",
       "498       0       0       0       0       0       1       0  \n",
       "499       0       0       0       0       0       0       0  \n",
       "\n",
       "[498 rows x 17 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(test_data))\n",
    "true_labels = test_data.drop(columns=['Text'])\n",
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3cdc0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a version with only the 'Text' column and save it\n",
    "test_data[[\"Text\"]].to_csv(local_test_data_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf3b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d0e6bdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the CSV\n",
    "# test_data = pd.read_csv(s3_transformed_data_path)\n",
    "\n",
    "# # Display the first few rows\n",
    "# #print(test_data.head())\n",
    "# with open(local_test_data_path, 'r') as file:\n",
    "#     content = file.read()\n",
    "#     if content.count('\"') % 2 != 0:\n",
    "#         print(\"Mismatched quotes found!\")\n",
    "#     else:\n",
    "#         print(\"Quotes seem to be okay.\")\n",
    "\n",
    "# # Check for empty or NaN rows\n",
    "# empty_rows = test_data[test_data.isnull().any(axis=1)]\n",
    "# if not empty_rows.empty:\n",
    "#     print(\"Found empty or NaN rows:\")\n",
    "#     print(empty_rows)\n",
    "# else:\n",
    "#     print(\"No empty or NaN rows found.\")\n",
    "\n",
    "# # with open(local_test_data_path, 'r') as file:\n",
    "# #     content = file.read()\n",
    "# #     line_endings = set(content.splitlines(True))\n",
    "# #     print(f\"Line endings used: {line_endings}\")\n",
    "\n",
    "# # Check if all rows have the same number of columns\n",
    "# column_counts = test_data.apply(lambda x: x.count(), axis=1)\n",
    "# if len(column_counts.unique()) > 1:\n",
    "#     print(\"Rows with varying number of columns detected!\")\n",
    "# else:\n",
    "#     print(\"All rows have the same number of columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2129778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\r\n",
      "-rw-r--r-- root/root  98841817 2023-10-26 11:26 model.pth\r\n"
     ]
    }
   ],
   "source": [
    "# Upload the text-only data to S3\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.meta.client.upload_file(local_test_data_path, s3_bucket, transformed_data_path)\n",
    "\n",
    "!tar -tzvf model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da9d8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model.pth' is in the current directory\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    tar.add('model.pth')\n",
    "    tar.add('requirements.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce93be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted files: ['model.pth', 'requirements.txt']\n",
      "All necessary files are present in the model.tar.gz.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "\n",
    "# Extract the tarball to a temp directory\n",
    "temp_dir = 'temp_model_dir'\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "\n",
    "with tarfile.open(local_tarball_path, 'r:gz') as tar:\n",
    "    tar.extractall(path=temp_dir)\n",
    "\n",
    "# List contents of the extracted directory\n",
    "extracted_files = os.listdir(temp_dir)\n",
    "print(\"Extracted files:\", extracted_files)\n",
    "\n",
    "# Define the necessary files that should be present\n",
    "required_files = ['model.pth', 'requirements.txt']\n",
    "\n",
    "# Check if the necessary files are present\n",
    "all_files_present = all(file in extracted_files for file in required_files)\n",
    "\n",
    "if all_files_present:\n",
    "    print(\"All necessary files are present in the model.tar.gz.\")\n",
    "else:\n",
    "    missing_files = [file for file in required_files if file not in extracted_files]\n",
    "    print(f\"Missing files in model.tar.gz: {missing_files}\")\n",
    "    # Raise an error or handle accordingly\n",
    "    raise RuntimeError(f\"model.tar.gz is missing the following files: {missing_files}\")\n",
    "\n",
    "# Optionally, remove the temporary directory after verification\n",
    "import shutil\n",
    "shutil.rmtree(temp_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd6f5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09bbe687",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_location = 'model.tar.gz' \n",
    "model = PyTorchModel(model_data=model_location, \n",
    "                     role=role,\n",
    "                     framework_version='1.8.0',\n",
    "                     py_version='py3',\n",
    "                     entry_point='train.py',\n",
    "                     sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a915aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = model.transformer(instance_count=1,\n",
    "                                instance_type='ml.m5.xlarge',\n",
    "                                strategy='SingleRecord',\n",
    "                                assemble_with='Line',\n",
    "                                output_path=prediction_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46e82e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: pytorch-inference-2023-10-26-13-31-37-400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[32m2023-10-26T13:36:47.914:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:45,343 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 2956 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:45,343 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[35mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[35mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[35mMax heap size: 2956 M\u001b[0m\n",
      "\u001b[35mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:45,374 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,001 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag faee83225a044eacbe9358e24f149b1e\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,011 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,040 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,225 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,230 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,231 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,231 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,241 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,241 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,243 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mInitial Models: model.mar\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 4\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[35mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[35mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[35mEnable metrics API: true\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:45,374 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,001 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag faee83225a044eacbe9358e24f149b1e\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,011 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,040 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,225 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,230 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,231 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,231 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,241 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,241 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,243 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,252 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,252 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,277 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,286 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,294 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,296 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,296 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,296 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,299 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,519 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:53274 \"GET /ping HTTP/1.1\" 200 73\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,538 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,730 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:53284 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,252 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,252 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,277 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,286 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,294 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,296 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,296 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,296 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,299 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,519 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:53274 \"GET /ping HTTP/1.1\" 200 73\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,538 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,730 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:53284 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,731 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,078 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,080 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.598567962646484|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,081 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.266563415527344|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,082 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.8|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,082 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:13958.90625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,083 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1276.03515625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,084 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,931 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,972 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:49,028 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:49,034 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,731 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,078 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,080 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.598567962646484|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,081 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.266563415527344|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,082 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.8|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,082 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:13958.90625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,083 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1276.03515625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,084 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,931 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,972 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:49,028 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:49,034 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,640 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,640 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,664 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,675 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,678 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,698 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,707 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,727 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,754 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,664 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,675 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,678 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,698 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,707 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,727 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,754 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,746 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,746 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,754 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,833 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,839 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,846 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,968 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,974 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:52,353 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:52,363 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:52,572 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:52,576 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,754 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,833 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,839 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,846 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,968 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,974 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:52,353 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:52,363 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:52,572 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:52,576 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,099 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,127 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,180 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,182 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,183 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,186 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,251 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,099 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,127 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,180 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,182 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,183 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,186 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,251 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,257 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,339 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,366 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,420 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,422 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,423 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,460 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,463 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,466 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,468 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,573 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,581 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,615 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,257 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,339 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,366 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,420 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,422 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,423 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,460 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,463 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,466 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,468 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,573 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,581 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,615 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,714 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,861 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,865 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,714 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,861 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,865 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:54,009 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:54,019 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:54,043 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:54,045 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:54,009 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:54,019 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:54,043 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:54,045 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,158 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,185 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,354 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,356 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,414 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,418 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,158 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,185 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,354 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,356 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,414 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,418 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,936 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,938 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,939 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,940 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,092 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,096 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,272 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,277 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,287 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,400 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,405 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,414 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,484 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,486 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,526 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,529 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,531 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,533 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,547 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,552 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,622 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,628 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,636 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,644 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,936 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,938 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,939 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,940 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,092 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,096 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,272 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,277 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,287 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,400 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,405 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,414 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,484 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,486 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,526 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,529 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,531 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,533 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,547 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,552 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,622 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,628 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,636 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,644 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,667 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,667 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,670 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,670 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,673 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,674 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,674 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,682 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,695 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,698 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,702 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,710 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,784 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,786 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,879 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,885 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,916 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,667 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,667 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,670 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,670 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,673 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,674 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,674 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,682 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,695 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,698 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,702 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,710 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,784 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,786 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,879 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,885 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,916 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,919 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,923 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,926 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,929 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,935 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,937 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,938 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,939 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,940 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,948 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,951 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,966 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,968 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,969 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,971 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,975 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,997 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,999 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,000 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,001 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,002 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,029 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,167 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,170 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,172 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,173 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,919 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,923 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,926 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,929 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,935 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,937 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,938 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,939 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,940 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,948 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,951 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,966 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,968 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,969 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,971 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,975 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,997 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,999 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,000 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,001 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,002 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,029 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,167 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,170 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,172 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,173 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,182 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,192 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,195 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,198 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,201 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,202 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,212 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,213 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,215 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,216 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,219 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,219 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,221 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,224 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,228 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,245 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,246 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,249 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,443 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,446 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,450 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,465 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,466 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,182 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,192 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,195 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,198 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,201 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,202 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,212 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,213 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,215 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,216 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,219 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,219 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,221 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,224 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,228 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,245 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,246 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,249 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,443 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,446 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,450 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,465 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,466 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,108 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,125 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,125 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,108 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,125 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,125 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:36:59,035 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,337 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,483 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,483 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,487 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=f277d4d2efbce297ab2fda0cdd9b52bae40642d12b91d8ef4659e9a2a60d1b6b\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,035 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,337 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,483 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,483 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,487 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=f277d4d2efbce297ab2fda0cdd9b52bae40642d12b91d8ef4659e9a2a60d1b6b\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,667 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,668 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,675 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Uninstalling packaging-20.4:\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,682 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -       Successfully uninstalled packaging-20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,542 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,617 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,633 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,667 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,668 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,675 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Uninstalling packaging-20.4:\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,682 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -       Successfully uninstalled packaging-20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,542 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,617 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,633 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,729 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,730 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,732 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,798 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,800 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,802 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,830 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,831 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,832 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,729 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,730 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,732 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,798 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,800 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,802 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,830 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,831 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,832 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:03,463 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:03,463 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,609 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,609 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,746 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,748 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,878 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,904 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,200 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,746 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,748 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,878 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,904 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,200 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,209 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,561 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,586 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,209 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,561 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,586 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,733 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,739 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,764 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,766 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,770 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,777 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,778 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,805 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,811 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,827 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,912 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,913 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,918 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,925 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,733 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,739 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,764 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,766 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,770 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,777 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,778 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,805 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,811 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,827 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,912 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,913 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,918 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,925 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,931 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,936 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,945 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:06,570 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:06,576 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,931 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,936 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,945 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:06,570 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:06,576 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:06,669 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:06,675 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,108 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,137 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,171 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,179 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,213 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,277 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,282 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,331 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,336 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:06,669 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:06,675 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,108 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,137 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,171 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,179 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,213 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,277 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,282 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,331 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,336 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,351 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,433 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,435 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,453 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,469 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,511 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,514 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,560 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,564 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,648 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,667 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,351 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,433 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,435 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,453 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,469 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,511 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,514 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,560 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,564 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,648 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,667 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:37:09,648 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,648 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,938 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,955 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,122 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,125 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,129 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,130 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,131 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,938 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,955 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,122 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,125 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,129 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,130 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,131 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,243 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,246 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,259 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,262 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,304 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,309 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,243 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,246 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,259 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,262 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,304 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,309 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,860 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,881 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,995 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,998 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,135 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,135 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,139 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,153 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,309 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,311 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,313 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,860 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,881 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,995 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,998 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,135 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,135 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,139 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,153 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,309 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,311 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,313 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,315 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,318 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,318 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,436 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,442 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,449 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,451 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,514 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,519 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,590 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,595 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,612 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,616 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,646 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,660 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,315 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,318 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,318 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,436 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,442 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,449 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,451 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,514 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,519 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,590 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,595 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,612 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,616 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,646 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,660 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,678 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,678 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,760 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,763 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,766 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,778 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,855 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,860 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,873 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,876 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,887 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,922 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,924 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,944 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,947 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,966 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,967 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,978 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,986 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,989 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,992 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,993 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,995 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,003 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,004 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,005 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,064 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,067 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,092 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,098 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,760 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,763 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,766 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,778 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,855 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,860 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,873 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,876 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,887 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,922 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,924 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,944 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,947 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,966 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,967 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,978 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,986 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,989 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,992 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,993 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,995 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,003 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,004 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,005 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,064 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,067 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,092 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,098 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,114 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,117 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,124 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,125 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,174 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,230 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,233 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,236 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,351 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,354 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,376 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,413 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,414 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,424 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,431 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,469 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,470 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,482 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,483 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,484 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,486 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,560 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,561 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,563 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,587 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,589 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,657 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,114 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,117 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,124 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,125 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,174 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,230 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,233 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,236 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,351 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,354 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,376 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,413 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,414 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,424 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,431 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,469 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,470 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,482 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,483 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,484 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,486 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,560 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,561 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,563 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,587 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,589 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,657 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,660 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,661 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,663 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,666 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,660 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,661 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,663 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,666 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,690 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,728 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,729 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,735 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,741 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,813 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,814 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,816 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,911 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,914 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,988 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:13,266 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,690 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,728 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,729 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,735 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,741 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,813 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,814 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,816 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,911 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,914 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,988 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:13,266 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:13,765 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:13,852 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:14,069 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:13,765 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:13,852 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:14,069 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:15,616 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:15,616 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,115 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,208 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,245 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,408 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,115 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,208 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,245 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,408 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,733 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,823 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:17,022 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,733 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,823 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:17,022 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:18,366 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:18,366 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:18,367 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/847 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:18,367 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/847 [00:00<?, ?B/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:37:19,132 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/140M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,236 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 35.0k/140M [00:00<07:25, 329kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,342 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 93.0k/140M [00:00<05:12, 470kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,443 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 221k/140M [00:00<02:58, 821kB/s] \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,544 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 429k/140M [00:00<01:51, 1.32MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,644 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 857k/140M [00:00<01:01, 2.39MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,132 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/140M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,236 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 35.0k/140M [00:00<07:25, 329kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,342 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 93.0k/140M [00:00<05:12, 470kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,443 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 221k/140M [00:00<02:58, 821kB/s] \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,544 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 429k/140M [00:00<01:51, 1.32MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,644 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 857k/140M [00:00<01:01, 2.39MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,744 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 1.61M/140M [00:00<00:33, 4.29MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,844 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|â–         | 3.09M/140M [00:00<00:18, 7.93MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,944 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|â–         | 5.93M/140M [00:00<00:09, 14.8MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,044 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|â–Œ         | 8.67M/140M [00:00<00:07, 19.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,144 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|â–Š         | 11.4M/140M [00:01<00:06, 21.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,246 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|â–ˆ         | 14.1M/140M [00:01<00:05, 24.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,346 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|â–ˆâ–        | 16.8M/140M [00:01<00:05, 25.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,446 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|â–ˆâ–        | 19.6M/140M [00:01<00:04, 26.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,546 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|â–ˆâ–Œ        | 22.3M/140M [00:01<00:04, 27.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,744 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 1.61M/140M [00:00<00:33, 4.29MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,844 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|â–         | 3.09M/140M [00:00<00:18, 7.93MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,944 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|â–         | 5.93M/140M [00:00<00:09, 14.8MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,044 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|â–Œ         | 8.67M/140M [00:00<00:07, 19.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,144 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|â–Š         | 11.4M/140M [00:01<00:06, 21.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,246 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|â–ˆ         | 14.1M/140M [00:01<00:05, 24.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,346 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|â–ˆâ–        | 16.8M/140M [00:01<00:05, 25.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,446 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|â–ˆâ–        | 19.6M/140M [00:01<00:04, 26.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,546 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|â–ˆâ–Œ        | 22.3M/140M [00:01<00:04, 27.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,646 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|â–ˆâ–Š        | 25.1M/140M [00:01<00:04, 27.7MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,646 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|â–ˆâ–Š        | 25.1M/140M [00:01<00:04, 27.7MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,747 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  20%|â–ˆâ–‰        | 27.9M/140M [00:01<00:04, 28.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,848 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  22%|â–ˆâ–ˆâ–       | 30.7M/140M [00:01<00:04, 28.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,948 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|â–ˆâ–ˆâ–       | 33.5M/140M [00:01<00:03, 28.7MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,049 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–Œ       | 36.3M/140M [00:01<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,149 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 39.1M/140M [00:02<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,249 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|â–ˆâ–ˆâ–‰       | 41.9M/140M [00:02<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,350 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  32%|â–ˆâ–ˆâ–ˆâ–      | 44.7M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,450 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  34%|â–ˆâ–ˆâ–ˆâ–      | 47.4M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,551 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 50.2M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,651 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 53.0M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,747 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  20%|â–ˆâ–‰        | 27.9M/140M [00:01<00:04, 28.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,848 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  22%|â–ˆâ–ˆâ–       | 30.7M/140M [00:01<00:04, 28.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,948 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|â–ˆâ–ˆâ–       | 33.5M/140M [00:01<00:03, 28.7MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,049 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–Œ       | 36.3M/140M [00:01<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,149 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 39.1M/140M [00:02<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,249 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|â–ˆâ–ˆâ–‰       | 41.9M/140M [00:02<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,350 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  32%|â–ˆâ–ˆâ–ˆâ–      | 44.7M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,450 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  34%|â–ˆâ–ˆâ–ˆâ–      | 47.4M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,551 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 50.2M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,651 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 53.0M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,751 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 55.8M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,852 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 58.6M/140M [00:02<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,952 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 61.4M/140M [00:02<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,052 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 64.2M/140M [00:02<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,153 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 67.0M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,751 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 55.8M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,852 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 58.6M/140M [00:02<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,952 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 61.4M/140M [00:02<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,052 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 64.2M/140M [00:02<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,153 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 67.0M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,253 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 69.8M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,354 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 72.5M/140M [00:03<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,455 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 75.3M/140M [00:03<00:02, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,555 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 78.1M/140M [00:03<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,656 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 81.0M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,253 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 69.8M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,354 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 72.5M/140M [00:03<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,455 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 75.3M/140M [00:03<00:02, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,555 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 78.1M/140M [00:03<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,656 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 81.0M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,757 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 83.8M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,858 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 86.6M/140M [00:03<00:01, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,958 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 89.4M/140M [00:03<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,059 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 92.1M/140M [00:03<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,159 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 94.9M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,259 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 97.7M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,360 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 101M/140M [00:04<00:01, 29.2MB/s] \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,460 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 103M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,561 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 106M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,661 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 109M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,757 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 83.8M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,858 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 86.6M/140M [00:03<00:01, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,958 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 89.4M/140M [00:03<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,059 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 92.1M/140M [00:03<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,159 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 94.9M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,259 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 97.7M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,360 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 101M/140M [00:04<00:01, 29.2MB/s] \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,460 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 103M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,561 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 106M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,661 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 109M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,762 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 112M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,762 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 112M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,862 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 114M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,963 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 117M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,065 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 120M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,165 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 123M/140M [00:05<00:00, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,265 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 126M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,366 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 128M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,466 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 131M/140M [00:05<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,568 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 134M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,669 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 137M/140M [00:05<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,862 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 114M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,963 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 117M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,065 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 120M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,165 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 123M/140M [00:05<00:00, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,265 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 126M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,366 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 128M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,466 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 131M/140M [00:05<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,568 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 134M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,669 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 137M/140M [00:05<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,683 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 140M/140M [00:05<00:00, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,683 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 140M/140M [00:05<00:00, 29.0MB/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.bias']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,764 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,799 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.bias']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,764 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,799 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,178 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,180 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,302 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140M/140M [00:05<00:00, 25.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,304 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,178 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,180 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,302 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140M/140M [00:05<00:00, 25.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,304 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,760 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,761 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:42741|#Level:Host|#hostname:c449b28b682c,timestamp:1698327449\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,762 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:86|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,038 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,038 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:43018|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,042 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:112|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42737\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:43087|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:68|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42715\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:43105|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:105|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,284 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,289 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,760 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,761 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:42741|#Level:Host|#hostname:c449b28b682c,timestamp:1698327449\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,762 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:86|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,038 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,038 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:43018|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,042 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:112|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42737\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:43087|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:68|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42715\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:43105|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:105|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,284 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,289 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2012\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 42556\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:40523|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2011.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:65095cc4-4f82-47e0-8034-78fe11bf2b19,timestamp:1698327451\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2012\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 42556\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:40523|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2011.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:65095cc4-4f82-47e0-8034-78fe11bf2b19,timestamp:1698327451\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,356 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1526\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1528\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,356 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1524.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bb0be808-fe69-45c8-a0c8-cc68dbad4b68,timestamp:1698327453\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,356 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1526\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1528\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,356 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1524.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bb0be808-fe69-45c8-a0c8-cc68dbad4b68,timestamp:1698327453\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1372\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1371.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b7772f33-47d1-4f4b-95e0-b4347ead9e25,timestamp:1698327454\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1372\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1371.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b7772f33-47d1-4f4b-95e0-b4347ead9e25,timestamp:1698327454\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cee78850-0755-4eb2-bbe2-9cba0ddc3924,timestamp:1698327456\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,400 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cee78850-0755-4eb2-bbe2-9cba0ddc3924,timestamp:1698327456\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,400 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,743 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14d45333-2b1e-4e24-9696-0d075d6d59b3,timestamp:1698327457\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,743 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14d45333-2b1e-4e24-9696-0d075d6d59b3,timestamp:1698327457\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1811\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1810.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:de9f549a-8147-4cc7-8a67-9725a6aa3524,timestamp:1698327459\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1812\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1811\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1810.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:de9f549a-8147-4cc7-8a67-9725a6aa3524,timestamp:1698327459\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1812\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4803d9ae-c908-48ee-8a86-1e662d12ebd8,timestamp:1698327462\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,551 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4803d9ae-c908-48ee-8a86-1e662d12ebd8,timestamp:1698327462\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,551 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,059 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1500\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,059 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1503.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1d3b469-bc3c-4d07-afb2-871655b4408b,timestamp:1698327464\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1506\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,059 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1500\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,059 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1503.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1d3b469-bc3c-4d07-afb2-871655b4408b,timestamp:1698327464\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1506\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,386 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:93c8d3df-6dcd-4004-a0c5-4eab6c462f31,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,386 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:93c8d3df-6dcd-4004-a0c5-4eab6c462f31,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.317108154296875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548023223876953|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12786.66015625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2448.26953125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.317108154296875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548023223876953|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12786.66015625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2448.26953125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,016 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1622\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,016 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1624.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c78f4109-8e11-4761-a804-e4f09961c203,timestamp:1698327469\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1626\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,016 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1622\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,016 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1624.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c78f4109-8e11-4761-a804-e4f09961c203,timestamp:1698327469\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1626\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f6ae57a-9d8a-4106-b917-bb1e930906b4,timestamp:1698327470\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f6ae57a-9d8a-4106-b917-bb1e930906b4,timestamp:1698327470\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,728 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1400.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3954776-80be-4968-950f-8937119fda6b,timestamp:1698327471\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,728 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1402\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,728 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1400.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3954776-80be-4968-950f-8937119fda6b,timestamp:1698327471\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,728 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1402\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14f59c17-0ed1-4a2d-8af7-0072cc7b2cda,timestamp:1698327473\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1318\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14f59c17-0ed1-4a2d-8af7-0072cc7b2cda,timestamp:1698327473\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1318\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2016\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2020.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5ab7098d-102e-4ea9-a081-6d9569492451,timestamp:1698327475\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2022\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2016\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2020.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5ab7098d-102e-4ea9-a081-6d9569492451,timestamp:1698327475\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2022\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,085 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,085 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:37:56,708 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1618.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:903e1c63-1596-4335-962d-fa54af9c33ad,timestamp:1698327476\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,708 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1618.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:903e1c63-1596-4335-962d-fa54af9c33ad,timestamp:1698327476\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1677\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1673.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a515225c-23c7-4801-8c9b-a553adfe621d,timestamp:1698327478\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1677\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1673.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a515225c-23c7-4801-8c9b-a553adfe621d,timestamp:1698327478\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1614\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1613.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dc3121ca-a424-4a36-be4f-2daf49f1c5e2,timestamp:1698327480\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1615\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1614\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1613.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dc3121ca-a424-4a36-be4f-2daf49f1c5e2,timestamp:1698327480\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1615\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1624.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9d0e02f1-03ad-4ff2-a5cf-9f925996a323,timestamp:1698327481\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1629\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,645 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,645 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,646 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1624.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9d0e02f1-03ad-4ff2-a5cf-9f925996a323,timestamp:1698327481\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1629\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,645 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,645 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,646 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f7e7b169-3386-4602-af88-27e4a2da49b5,timestamp:1698327482\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,904 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f7e7b169-3386-4602-af88-27e4a2da49b5,timestamp:1698327482\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,904 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,571 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,571 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2655.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fabc3455-d876-4ece-bdc0-c960c3635220,timestamp:1698327485\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,571 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,571 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2655.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fabc3455-d876-4ece-bdc0-c960c3635220,timestamp:1698327485\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a96cc3ea-f4fa-4e08-a86f-a303c8282b5c,timestamp:1698327487\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1621\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,198 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,198 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a96cc3ea-f4fa-4e08-a86f-a303c8282b5c,timestamp:1698327487\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1621\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,198 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,198 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1846.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:07ee51b3-2cf7-4473-af31-b97adeb39f67,timestamp:1698327490\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1848\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1848\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,738 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1846.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:07ee51b3-2cf7-4473-af31-b97adeb39f67,timestamp:1698327490\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1848\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1848\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,738 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,196 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2453\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,196 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2453.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:af37c7be-e7eb-42d0-b2a6-c06e7b886f22,timestamp:1698327493\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2455\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,196 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2453\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,196 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2453.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:af37c7be-e7eb-42d0-b2a6-c06e7b886f22,timestamp:1698327493\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2455\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,433 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,433 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:78ffcf7c-a3fc-4c6b-822c-afe250b7913f,timestamp:1698327494\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,433 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,433 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:78ffcf7c-a3fc-4c6b-822c-afe250b7913f,timestamp:1698327494\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,436 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,436 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3b8ff94-8bfa-4804-9796-1beec0b100ea,timestamp:1698327495\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,690 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,690 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3b8ff94-8bfa-4804-9796-1beec0b100ea,timestamp:1698327495\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,690 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,690 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,367 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bfa85e39-4e88-411f-a014-0af3d6c3afbc,timestamp:1698327497\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,367 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,367 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bfa85e39-4e88-411f-a014-0af3d6c3afbc,timestamp:1698327497\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,367 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,369 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,369 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e2b1c48-6d45-442c-b49c-b199677f7068,timestamp:1698327498\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,623 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,623 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e2b1c48-6d45-442c-b49c-b199677f7068,timestamp:1698327498\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,623 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,623 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1351.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bfbd700b-a66d-45a2-9112-0bef370dd348,timestamp:1698327501\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,327 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,327 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1351.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bfbd700b-a66d-45a2-9112-0bef370dd348,timestamp:1698327501\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,327 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,327 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:480050e1-5048-476b-b482-112eca0da968,timestamp:1698327502\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:480050e1-5048-476b-b482-112eca0da968,timestamp:1698327502\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1626.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a57697d1-32e5-469d-9afb-7a7de8c010d9,timestamp:1698327504\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,223 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,223 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1626.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a57697d1-32e5-469d-9afb-7a7de8c010d9,timestamp:1698327504\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,223 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,223 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1774\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1773.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:597e17dc-3ebb-4f1d-9196-57d7b5527623,timestamp:1698327512\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1775\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1774\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1773.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:597e17dc-3ebb-4f1d-9196-57d7b5527623,timestamp:1698327512\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1775\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,456 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1683.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:30f6b808-a694-48b2-a627-434950f5387d,timestamp:1698327514\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,456 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1684\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1686\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,456 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1683.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:30f6b808-a694-48b2-a627-434950f5387d,timestamp:1698327514\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,456 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1684\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1686\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,401 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1937\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,401 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1937.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:79b219d2-e8bb-4560-9fcd-b6309f78fd82,timestamp:1698327516\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,402 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1939\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,402 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,403 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,403 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,401 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1937\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,401 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1937.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:79b219d2-e8bb-4560-9fcd-b6309f78fd82,timestamp:1698327516\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,402 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1939\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,402 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,403 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,403 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,491 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2083.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b04c0c2a-e5d7-46c4-802e-5fb925b56192,timestamp:1698327518\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2085\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2086\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,491 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2083.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b04c0c2a-e5d7-46c4-802e-5fb925b56192,timestamp:1698327518\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2085\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2086\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b69c631f-9df4-46d0-a614-99fba178cbde,timestamp:1698327520\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b69c631f-9df4-46d0-a614-99fba178cbde,timestamp:1698327520\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1363\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e84ee2d-9349-48e1-b500-cc28c397e399,timestamp:1698327523\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,110 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1363\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e84ee2d-9349-48e1-b500-cc28c397e399,timestamp:1698327523\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,110 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.28|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e0f58b3-d557-4443-b619-02b614e3d420,timestamp:1698327524\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,406 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,406 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.28|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e0f58b3-d557-4443-b619-02b614e3d420,timestamp:1698327524\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,406 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,406 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,678 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f859b50-1f07-41c4-b9a6-79afa0b94784,timestamp:1698327525\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,678 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f859b50-1f07-41c4-b9a6-79afa0b94784,timestamp:1698327525\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1222\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,906 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,906 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1218.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d61d859-aeaa-4b5f-b3b7-30c4a2767b81,timestamp:1698327526\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1222\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,906 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,906 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1218.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d61d859-aeaa-4b5f-b3b7-30c4a2767b81,timestamp:1698327526\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.317012786865234|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548118591308594|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12782.28125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2452.6484375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:26303a8d-fae1-4835-b945-769ac0803b6f,timestamp:1698327528\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.317012786865234|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548118591308594|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12782.28125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2452.6484375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:26303a8d-fae1-4835-b945-769ac0803b6f,timestamp:1698327528\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1690\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1690\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1695.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:54f6fb58-e258-4bee-9fac-d2757516feb5,timestamp:1698327530\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1696\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1695.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:54f6fb58-e258-4bee-9fac-d2757516feb5,timestamp:1698327530\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1696\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1662.46|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cba66855-a814-42b3-b51e-8413d4a9b573,timestamp:1698327533\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,701 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,701 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1662.46|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cba66855-a814-42b3-b51e-8413d4a9b573,timestamp:1698327533\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,701 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,701 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1679.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b85b5b73-2e60-49b1-9fa4-eae845bf0529,timestamp:1698327535\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,386 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1679.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b85b5b73-2e60-49b1-9fa4-eae845bf0529,timestamp:1698327535\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,386 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,386 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,386 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2332.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1c11321-f28d-4cc3-89a0-01f76a3bffc0,timestamp:1698327537\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2332.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1c11321-f28d-4cc3-89a0-01f76a3bffc0,timestamp:1698327537\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2334\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2334\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8ea503a0-be07-423a-9846-75b4be6eac58,timestamp:1698327539\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,035 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,035 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8ea503a0-be07-423a-9846-75b4be6eac58,timestamp:1698327539\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,035 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,035 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2002\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2007.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:649d9b7b-3c74-4b88-8235-99c24ee8d6ed,timestamp:1698327541\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2009\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,048 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,048 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2002\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2007.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:649d9b7b-3c74-4b88-8235-99c24ee8d6ed,timestamp:1698327541\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2009\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,048 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,048 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0cbf66bd-f2cd-4704-9547-94865f9e9eb5,timestamp:1698327542\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,311 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,311 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0cbf66bd-f2cd-4704-9547-94865f9e9eb5,timestamp:1698327542\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,311 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,311 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b9de3e2-8758-4322-9914-296446393975,timestamp:1698327543\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,588 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,589 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,589 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b9de3e2-8758-4322-9914-296446393975,timestamp:1698327543\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,588 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,589 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,589 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1856\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1855.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d26b299b-1e57-4893-85fb-26b557c029a8,timestamp:1698327545\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1857\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1856\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1855.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d26b299b-1e57-4893-85fb-26b557c029a8,timestamp:1698327545\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1857\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,093 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1639\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,093 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0b287d8-cb22-475c-a8d9-f5242238033e,timestamp:1698327547\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,093 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1639\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,093 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0b287d8-cb22-475c-a8d9-f5242238033e,timestamp:1698327547\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.67|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e81597c6-d30d-49bb-8a56-3a5d889e2a4a,timestamp:1698327560\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.67|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e81597c6-d30d-49bb-8a56-3a5d889e2a4a,timestamp:1698327560\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1634\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1634\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1637.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:24a5ff2d-2797-4a11-bc3c-e860429f5bc4,timestamp:1698327562\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1637.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:24a5ff2d-2797-4a11-bc3c-e860429f5bc4,timestamp:1698327562\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1731\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1731\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1730.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:365e6e9a-2411-4df9-9256-bd33f42daf2a,timestamp:1698327563\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,964 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,964 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1731\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1731\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1730.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:365e6e9a-2411-4df9-9256-bd33f42daf2a,timestamp:1698327563\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,964 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,964 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1395\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1395.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:362913f9-6577-4227-8e99-cef13e6b86bc,timestamp:1698327565\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1396\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1395\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1395.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:362913f9-6577-4227-8e99-cef13e6b86bc,timestamp:1698327565\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1396\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1665.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:31f544d5-0123-4f6a-8c50-1f7086e1bd82,timestamp:1698327567\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1667\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,035 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1665.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:31f544d5-0123-4f6a-8c50-1f7086e1bd82,timestamp:1698327567\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1667\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,035 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1630.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4150a462-e940-4df9-9105-7d2ef61b8836,timestamp:1698327568\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1630.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4150a462-e940-4df9-9105-7d2ef61b8836,timestamp:1698327568\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:39:31,940 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,940 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2cb22d9a-c8e8-476b-a784-e79079d2b241,timestamp:1698327571\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,941 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,941 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,945 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,945 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,940 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,940 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2cb22d9a-c8e8-476b-a784-e79079d2b241,timestamp:1698327571\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,941 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,941 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,945 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,945 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1724\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1722.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e37786f9-7487-4f2e-b5fa-20d6d9d81b8f,timestamp:1698327573\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1724\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1724\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1722.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e37786f9-7487-4f2e-b5fa-20d6d9d81b8f,timestamp:1698327573\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1724\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aef6548f-ccb7-4447-a49e-b5f68ca32b23,timestamp:1698327574\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aef6548f-ccb7-4447-a49e-b5f68ca32b23,timestamp:1698327574\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1617\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1617\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1617.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f2ba15a8-2132-4e68-8a5b-8077b4bd50f7,timestamp:1698327576\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1619\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1617.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f2ba15a8-2132-4e68-8a5b-8077b4bd50f7,timestamp:1698327576\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1619\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1710\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1711\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,293 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1709.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1ebfb8d0-d785-4b02-8a22-129f7232449c,timestamp:1698327578\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,293 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1710\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1711\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,293 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1709.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1ebfb8d0-d785-4b02-8a22-129f7232449c,timestamp:1698327578\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,293 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,592 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,592 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4c9ef204-a5de-4293-8fd7-da5c0f3a5486,timestamp:1698327579\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1296\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,592 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,592 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4c9ef204-a5de-4293-8fd7-da5c0f3a5486,timestamp:1698327579\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1296\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:39:42,149 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.23|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fe64f11a-6593-44f2-937c-6d346a92b6f7,timestamp:1698327582\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,149 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.23|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fe64f11a-6593-44f2-937c-6d346a92b6f7,timestamp:1698327582\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1382\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1387.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7c49b222-55a0-45e1-ac4d-a40f0d721eec,timestamp:1698327583\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1382\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1387.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7c49b222-55a0-45e1-ac4d-a40f0d721eec,timestamp:1698327583\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,800 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,800 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.28|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9d21d4fd-50e6-4fff-840c-a0f33afc8b87,timestamp:1698327584\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,800 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,800 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.28|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9d21d4fd-50e6-4fff-840c-a0f33afc8b87,timestamp:1698327584\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1407\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c98e92d-e2b0-4175-a0ea-d7814d1a378c,timestamp:1698327586\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1407\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c98e92d-e2b0-4175-a0ea-d7814d1a378c,timestamp:1698327586\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,213 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,213 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,213 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,213 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31691360473633|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.5482177734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12780.10546875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2454.828125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2036.98|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:62872960-c435-4280-a199-d4f8efe1dcab,timestamp:1698327588\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31691360473633|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.5482177734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12780.10546875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2454.828125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2036.98|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:62872960-c435-4280-a199-d4f8efe1dcab,timestamp:1698327588\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:61675d7f-c919-4457-9cf5-52933d0f695a,timestamp:1698327589\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:61675d7f-c919-4457-9cf5-52933d0f695a,timestamp:1698327589\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2047.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f97691c7-b753-4ea2-807a-08a39551ce20,timestamp:1698327593\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2047.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f97691c7-b753-4ea2-807a-08a39551ce20,timestamp:1698327593\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1384bb49-1247-41a6-9300-048693c41303,timestamp:1698327594\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1384bb49-1247-41a6-9300-048693c41303,timestamp:1698327594\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ee312e02-41f9-4c4c-896c-dec81fced280,timestamp:1698327596\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ee312e02-41f9-4c4c-896c-dec81fced280,timestamp:1698327596\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1646.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4bae4cad-b645-4576-911e-f81a61842adf,timestamp:1698327597\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1646.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4bae4cad-b645-4576-911e-f81a61842adf,timestamp:1698327597\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:581520b1-2c26-4239-9dbd-2cde80425ec9,timestamp:1698327599\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:581520b1-2c26-4239-9dbd-2cde80425ec9,timestamp:1698327599\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50906994-cbf2-49d7-9cfd-96774b594cac,timestamp:1698327600\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50906994-cbf2-49d7-9cfd-96774b594cac,timestamp:1698327600\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:433e639c-16c7-4f01-8a84-10eeb76dcbdb,timestamp:1698327603\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,334 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,334 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:433e639c-16c7-4f01-8a84-10eeb76dcbdb,timestamp:1698327603\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,334 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,334 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1a638444-fd91-4bf0-822b-f2595d1d72a6,timestamp:1698327604\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1a638444-fd91-4bf0-822b-f2595d1d72a6,timestamp:1698327604\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,334 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,334 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1666.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8461b11a-71b0-488f-8610-e21b556d67a0,timestamp:1698327606\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,334 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,334 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1666.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8461b11a-71b0-488f-8610-e21b556d67a0,timestamp:1698327606\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2074\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2073.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c2ebda5e-c12b-424a-8118-d151b9765bba,timestamp:1698327608\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2075\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2074\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2073.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c2ebda5e-c12b-424a-8118-d151b9765bba,timestamp:1698327608\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2075\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1642\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1640.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3103aba7-cbec-47ce-bbd0-130b01fa68bf,timestamp:1698327610\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1642\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1640.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3103aba7-cbec-47ce-bbd0-130b01fa68bf,timestamp:1698327610\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,723 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6c10b451-c7e5-4789-bd25-2b75b6f88ef3,timestamp:1698327611\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1661\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,723 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6c10b451-c7e5-4789-bd25-2b75b6f88ef3,timestamp:1698327611\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1661\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1340.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a0bfa35b-8b66-4823-802f-45e39a259da1,timestamp:1698327614\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1341\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1340.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a0bfa35b-8b66-4823-802f-45e39a259da1,timestamp:1698327614\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1341\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f9556296-2ae9-438b-80fc-807fed79ccc9,timestamp:1698327616\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,034 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f9556296-2ae9-438b-80fc-807fed79ccc9,timestamp:1698327616\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,034 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2049\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2048.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e441f55f-bb7f-46ae-96d2-14508aa0551c,timestamp:1698327618\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2050\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2049\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2048.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e441f55f-bb7f-46ae-96d2-14508aa0551c,timestamp:1698327618\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2050\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:13981b08-675a-4a3e-b765-053c0c3c9489,timestamp:1698327619\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:13981b08-675a-4a3e-b765-053c0c3c9489,timestamp:1698327619\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49321dda-f4f4-4e10-b8f8-bfb22bd8fc92,timestamp:1698327620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49321dda-f4f4-4e10-b8f8-bfb22bd8fc92,timestamp:1698327620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,266 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,266 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1678.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cf9c7bde-a528-4b63-af91-f7db5419ccc5,timestamp:1698327622\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,266 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,266 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1678.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cf9c7bde-a528-4b63-af91-f7db5419ccc5,timestamp:1698327622\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:40:25,597 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,597 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:379f4205-9385-4e16-bf47-2815252e6eb8,timestamp:1698327625\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,597 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,597 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:379f4205-9385-4e16-bf47-2815252e6eb8,timestamp:1698327625\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:de19732c-ee4b-4eb7-8be6-8d9d5c58dc00,timestamp:1698327626\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:de19732c-ee4b-4eb7-8be6-8d9d5c58dc00,timestamp:1698327626\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,125 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,125 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c8768c7f-9820-41a7-9582-82ab0d6e54d9,timestamp:1698327628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,125 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,125 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c8768c7f-9820-41a7-9582-82ab0d6e54d9,timestamp:1698327628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2101\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2099.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2e2f7e29-0ac0-470e-8eac-f7bb0d625eac,timestamp:1698327630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2101\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2101\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2099.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2e2f7e29-0ac0-470e-8eac-f7bb0d625eac,timestamp:1698327630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2101\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f18a9c6-0709-49a7-97d4-291c7f965fa1,timestamp:1698327631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f18a9c6-0709-49a7-97d4-291c7f965fa1,timestamp:1698327631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3efd9850-8b09-41d8-bae0-6c8616533ff3,timestamp:1698327632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,905 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3efd9850-8b09-41d8-bae0-6c8616533ff3,timestamp:1698327632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,905 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,905 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,905 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c552f00-5dab-455d-ac4c-ae631ccdb50d,timestamp:1698327634\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,164 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,164 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c552f00-5dab-455d-ac4c-ae631ccdb50d,timestamp:1698327634\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,164 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,164 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1329\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1329\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1327.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e7fc58e-4cfa-41bf-8cae-d30c58447d7a,timestamp:1698327637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1329\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1329\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1327.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e7fc58e-4cfa-41bf-8cae-d30c58447d7a,timestamp:1698327637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,996 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1862\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1862.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c12c6616-ef22-4664-a8b0-605c7c9fcb86,timestamp:1698327638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1864\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,996 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1862\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1862.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c12c6616-ef22-4664-a8b0-605c7c9fcb86,timestamp:1698327638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1864\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,289 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2052\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,289 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2051.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e92c2c3d-e556-41a5-bd6d-9fdb72eca6db,timestamp:1698327643\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2053\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,289 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2052\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,289 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2051.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e92c2c3d-e556-41a5-bd6d-9fdb72eca6db,timestamp:1698327643\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2053\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c90d50ed-8250-4a65-8e15-85e203697cb9,timestamp:1698327645\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c90d50ed-8250-4a65-8e15-85e203697cb9,timestamp:1698327645\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:20e508ee-575c-4682-9571-afcf0a6b683b,timestamp:1698327646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:20e508ee-575c-4682-9571-afcf0a6b683b,timestamp:1698327646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31681442260742|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548316955566406|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12775.33984375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2459.58984375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2150\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2149.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dcabee6d-7325-4aa1-94aa-c77e998a8218,timestamp:1698327648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2150\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,438 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,438 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31681442260742|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548316955566406|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12775.33984375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2459.58984375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2150\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2149.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dcabee6d-7325-4aa1-94aa-c77e998a8218,timestamp:1698327648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2150\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,438 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,438 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2026\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2025.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:727620c3-2a89-4591-990f-d068cad74def,timestamp:1698327650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2027\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,470 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2026\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2025.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:727620c3-2a89-4591-990f-d068cad74def,timestamp:1698327650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2027\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,470 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:40:53,359 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,359 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:06e2162c-30de-4bac-b65f-badacf97ff39,timestamp:1698327653\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,359 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,359 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:06e2162c-30de-4bac-b65f-badacf97ff39,timestamp:1698327653\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c6a1c622-9c3b-488b-b6ef-fa686c177820,timestamp:1698327654\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c6a1c622-9c3b-488b-b6ef-fa686c177820,timestamp:1698327654\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e91db868-338f-4190-8f04-45093f8e7b75,timestamp:1698327656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e91db868-338f-4190-8f04-45093f8e7b75,timestamp:1698327656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,615 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f09eed66-bccb-4a91-a755-f40d540e7c93,timestamp:1698327657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,615 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,615 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f09eed66-bccb-4a91-a755-f40d540e7c93,timestamp:1698327657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,615 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,862 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,862 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ed74ddbf-d905-4953-8274-953503d331a5,timestamp:1698327658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,862 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,862 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ed74ddbf-d905-4953-8274-953503d331a5,timestamp:1698327658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:56ffdee5-9cfc-49db-bf49-6b7e92b7cf5f,timestamp:1698327660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:56ffdee5-9cfc-49db-bf49-6b7e92b7cf5f,timestamp:1698327660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1350.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5b8ce10e-8326-41ee-9723-4f93ca7cb771,timestamp:1698327663\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1352\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1350.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5b8ce10e-8326-41ee-9723-4f93ca7cb771,timestamp:1698327663\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1352\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:367d876c-a619-41f4-8219-08e4740a42c0,timestamp:1698327665\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:367d876c-a619-41f4-8219-08e4740a42c0,timestamp:1698327665\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1355.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c99cc994-3c95-49d3-80fe-11ccd91bd9fc,timestamp:1698327666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1353\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1355.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c99cc994-3c95-49d3-80fe-11ccd91bd9fc,timestamp:1698327666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1353\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1820\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1818.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0992444a-7ed7-4266-a2d4-f4f96aa25253,timestamp:1698327668\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1820\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1820\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1818.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0992444a-7ed7-4266-a2d4-f4f96aa25253,timestamp:1698327668\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1820\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,715 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,715 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff8955d7-0242-4c40-b2bb-bd1c9aba1761,timestamp:1698327669\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,715 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,715 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff8955d7-0242-4c40-b2bb-bd1c9aba1761,timestamp:1698327669\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,578 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2859\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,578 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2858.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8efa77f8-b529-4d62-a167-143319492f8b,timestamp:1698327672\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2860\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,578 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2859\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,578 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2858.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8efa77f8-b529-4d62-a167-143319492f8b,timestamp:1698327672\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2860\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9c1c26c4-7d82-4ccd-b12e-1fe2def27204,timestamp:1698327675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9c1c26c4-7d82-4ccd-b12e-1fe2def27204,timestamp:1698327675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1670.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:65dc6e45-3f0a-4ceb-a68a-23f40f2bb2f6,timestamp:1698327676\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1672\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1670.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:65dc6e45-3f0a-4ceb-a68a-23f40f2bb2f6,timestamp:1698327676\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1672\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,037 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2200\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,037 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2200.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50f4e11a-3422-4b5d-92bd-4337e88b1f1e,timestamp:1698327679\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2202\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,037 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2200\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,037 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2200.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50f4e11a-3422-4b5d-92bd-4337e88b1f1e,timestamp:1698327679\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2202\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1664\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a01e45fc-d31f-4df7-b4db-07dda684858a,timestamp:1698327680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1664\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a01e45fc-d31f-4df7-b4db-07dda684858a,timestamp:1698327680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,403 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1692\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,403 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1692.07|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:29100dfd-bc65-470f-bc46-920c64e7d0b2,timestamp:1698327682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1693\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,403 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1692\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,403 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1692.07|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:29100dfd-bc65-470f-bc46-920c64e7d0b2,timestamp:1698327682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1693\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,735 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,735 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1327.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1c2abeec-00b0-4bed-9af5-0dc6527d2be3,timestamp:1698327683\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1329\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,735 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,735 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1327.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1c2abeec-00b0-4bed-9af5-0dc6527d2be3,timestamp:1698327683\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1329\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:41:27,691 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2045.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c2adee7f-ba7c-47ea-a629-5b4dc3909c2a,timestamp:1698327687\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2046\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2047\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,691 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2045.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c2adee7f-ba7c-47ea-a629-5b4dc3909c2a,timestamp:1698327687\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2046\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2047\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1999\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1998.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3d25eef-e100-41a2-9249-42696fccb216,timestamp:1698327689\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1999\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,695 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,695 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1999\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1998.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3d25eef-e100-41a2-9249-42696fccb216,timestamp:1698327689\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1999\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,695 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,695 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1754\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1753.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fc7be897-2019-4fb0-a5c5-5447286fd971,timestamp:1698327691\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1755\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1754\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1753.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fc7be897-2019-4fb0-a5c5-5447286fd971,timestamp:1698327691\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1755\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,405 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1949\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1949.37|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11ec3378-a7b5-4478-837c-470a5e9808ec,timestamp:1698327693\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1951\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,405 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1949\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1949.37|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11ec3378-a7b5-4478-837c-470a5e9808ec,timestamp:1698327693\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1951\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,500 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2090\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2089.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:539c9863-2897-405f-9685-a645e0da3c3b,timestamp:1698327695\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2091\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,500 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2090\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2089.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:539c9863-2897-405f-9685-a645e0da3c3b,timestamp:1698327695\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2091\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:41:37,197 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1693\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,197 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1693\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2449.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b8d4fb05-5e47-4092-80c7-d9d5e86fcfad,timestamp:1698327699\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2449.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b8d4fb05-5e47-4092-80c7-d9d5e86fcfad,timestamp:1698327699\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,958 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,958 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5d1bb4bc-2ba4-4444-a98a-9ab62c6dce54,timestamp:1698327700\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,958 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,958 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5d1bb4bc-2ba4-4444-a98a-9ab62c6dce54,timestamp:1698327700\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a525c0d5-c7ac-410e-9a64-847d22d2ed0e,timestamp:1698327702\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a525c0d5-c7ac-410e-9a64-847d22d2ed0e,timestamp:1698327702\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2056\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2055.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:178204cb-43da-4720-b324-64b3a6f49a36,timestamp:1698327704\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2056\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2056\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2055.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:178204cb-43da-4720-b324-64b3a6f49a36,timestamp:1698327704\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2056\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1449.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45bc673e-f158-4af8-92b3-295197f7388f,timestamp:1698327705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1451\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1449.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45bc673e-f158-4af8-92b3-295197f7388f,timestamp:1698327705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1451\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:41:47,950 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31672286987305|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548408508300781|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,950 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31672286987305|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548408508300781|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12772.9140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2462.015625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12772.9140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2462.015625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1503\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e8dcdb0-7d66-47f3-8563-d52280b733fa,timestamp:1698327708\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1504\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1503\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e8dcdb0-7d66-47f3-8563-d52280b733fa,timestamp:1698327708\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1504\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,579 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:096a8701-cbd9-4e23-9c6b-f802b65f3cfc,timestamp:1698327710\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,579 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:096a8701-cbd9-4e23-9c6b-f802b65f3cfc,timestamp:1698327710\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1785\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1784.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8972a0f3-87f8-461e-94ff-f639dff89c84,timestamp:1698327712\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1786\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1785\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1784.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8972a0f3-87f8-461e-94ff-f639dff89c84,timestamp:1698327712\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1786\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,789 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,789 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e6e3cd84-c848-4db1-b96c-39c2eacd0474,timestamp:1698327713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1417\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,789 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,789 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e6e3cd84-c848-4db1-b96c-39c2eacd0474,timestamp:1698327713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1417\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1781\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1780.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3940eb3-e33f-49ab-8cfa-eed5a4132015,timestamp:1698327715\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1781\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1781\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1780.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3940eb3-e33f-49ab-8cfa-eed5a4132015,timestamp:1698327715\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1781\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9c48e623-28f2-48f6-afcc-4f88c34d2846,timestamp:1698327718\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9c48e623-28f2-48f6-afcc-4f88c34d2846,timestamp:1698327718\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3056635e-d732-40de-98bb-232330c9fa99,timestamp:1698327719\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3056635e-d732-40de-98bb-232330c9fa99,timestamp:1698327719\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,516 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1704\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,516 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1703.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11465b82-c8be-47e8-ae69-934c2856e56b,timestamp:1698327721\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,516 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1704\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,516 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1703.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11465b82-c8be-47e8-ae69-934c2856e56b,timestamp:1698327721\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,830 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1309.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d4be9f35-87fe-4a03-98c2-9fddfa164bef,timestamp:1698327722\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,901 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,901 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2066.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a38dce50-4620-4a19-b1b7-8c6956095e7d,timestamp:1698327724\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2068\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1438\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d5451a3-1a45-47b1-84b3-82c60341a90b,timestamp:1698327726\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1674.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2abac83e-f238-4fc6-a526-aef59962f37e,timestamp:1698327728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,022 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,022 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1674.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2abac83e-f238-4fc6-a526-aef59962f37e,timestamp:1698327728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,022 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,022 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f7a2b04a-44e4-4c64-9fee-a5fbc10fcfd4,timestamp:1698327729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f7a2b04a-44e4-4c64-9fee-a5fbc10fcfd4,timestamp:1698327729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:81bee4b4-3f84-4685-bdd4-8a8ce8575564,timestamp:1698327730\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:81bee4b4-3f84-4685-bdd4-8a8ce8575564,timestamp:1698327730\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3684f17c-00cd-4172-8a3f-9ca557ba5851,timestamp:1698327731\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3684f17c-00cd-4172-8a3f-9ca557ba5851,timestamp:1698327731\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:21995c74-c407-4f33-b39a-02fa4ce54d84,timestamp:1698327735\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:21995c74-c407-4f33-b39a-02fa4ce54d84,timestamp:1698327735\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,685 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,685 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:674bc574-cadd-4c4e-a128-0aba14c22ba9,timestamp:1698327736\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,685 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,685 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:674bc574-cadd-4c4e-a128-0aba14c22ba9,timestamp:1698327736\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4c56f93e-1cc7-4de2-b970-d9bf967a7c94,timestamp:1698327737\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4c56f93e-1cc7-4de2-b970-d9bf967a7c94,timestamp:1698327737\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d3d91e83-9706-4882-9147-e4d66901f8b9,timestamp:1698327739\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d3d91e83-9706-4882-9147-e4d66901f8b9,timestamp:1698327739\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1789\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1788.79|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fabe5c85-cbca-4b87-9441-38ca5c2f7f57,timestamp:1698327741\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1790\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1789\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1788.79|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fabe5c85-cbca-4b87-9441-38ca5c2f7f57,timestamp:1698327741\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1790\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1697.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52283406-3e3f-4352-a951-9ec92b3ea8e2,timestamp:1698327742\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1697.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52283406-3e3f-4352-a951-9ec92b3ea8e2,timestamp:1698327742\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1562.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4b08d76f-b890-4c2b-8fec-87404f8dc91d,timestamp:1698327745\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1563\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1563\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1562.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4b08d76f-b890-4c2b-8fec-87404f8dc91d,timestamp:1698327745\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1563\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1563\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2463\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2462.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6a970a1c-8702-4ffd-ada5-a97fbd8a314a,timestamp:1698327748\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2464\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2463\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2462.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6a970a1c-8702-4ffd-ada5-a97fbd8a314a,timestamp:1698327748\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2464\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2333\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2331.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:041496bd-6602-4ab8-a11e-690b2313259a,timestamp:1698327750\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2333\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2333\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2331.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:041496bd-6602-4ab8-a11e-690b2313259a,timestamp:1698327750\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2333\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1ab5fd63-e9ac-48d0-90cd-4ce4fedcd73a,timestamp:1698327752\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,129 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1ab5fd63-e9ac-48d0-90cd-4ce4fedcd73a,timestamp:1698327752\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,129 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2289.42|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14ec7e24-48cb-48c8-9a99-009a6353ee0f,timestamp:1698327754\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2291\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2292\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2289.42|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14ec7e24-48cb-48c8-9a99-009a6353ee0f,timestamp:1698327754\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2291\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2292\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:42:37,041 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,041 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:20948807-bf80-47b3-8d29-2a0e9ea041da,timestamp:1698327757\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,041 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,041 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:20948807-bf80-47b3-8d29-2a0e9ea041da,timestamp:1698327757\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e28f588c-a75b-4d2e-a77b-a7a542db792a,timestamp:1698327758\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,708 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e28f588c-a75b-4d2e-a77b-a7a542db792a,timestamp:1698327758\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,708 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1665\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0df33c63-ef78-44c9-9ddd-217faad7ba64,timestamp:1698327760\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1665\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0df33c63-ef78-44c9-9ddd-217faad7ba64,timestamp:1698327760\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2215\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2213.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e85acde7-0819-483a-8eb9-843b579a9f75,timestamp:1698327762\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2215\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2215\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2213.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e85acde7-0819-483a-8eb9-843b579a9f75,timestamp:1698327762\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2215\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:724b926b-abc9-4b64-9d87-85219cf80c21,timestamp:1698327763\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1326\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:724b926b-abc9-4b64-9d87-85219cf80c21,timestamp:1698327763\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1326\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1665\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97a315e4-5154-4fd1-9f04-fdac9ef1eb09,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1665\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1665\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97a315e4-5154-4fd1-9f04-fdac9ef1eb09,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1665\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31661605834961|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548515319824219|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12770.265625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2464.69140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31661605834961|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548515319824219|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12770.265625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2464.69140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:94309e0d-5b91-4a78-84b4-eec0137bc03a,timestamp:1698327768\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:94309e0d-5b91-4a78-84b4-eec0137bc03a,timestamp:1698327768\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,973 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2016\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2021.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5633b1fe-4b07-4ec5-b8c5-bc44c4bafb27,timestamp:1698327770\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2023\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,973 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2016\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2021.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5633b1fe-4b07-4ec5-b8c5-bc44c4bafb27,timestamp:1698327770\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2023\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,636 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,636 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,636 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1658.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f6b8a02e-7e3c-49d1-8a1a-8539da7c432c,timestamp:1698327772\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,636 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1658.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f6b8a02e-7e3c-49d1-8a1a-8539da7c432c,timestamp:1698327772\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2124\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2123.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b5ce46c9-3015-4110-bcdf-2f24ebe7573c,timestamp:1698327774\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2124\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,765 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,765 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2124\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2123.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b5ce46c9-3015-4110-bcdf-2f24ebe7573c,timestamp:1698327774\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2124\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,765 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,765 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2017\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2017\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2016.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:017f7422-4c5a-4c34-b34e-3f59d88d5cbf,timestamp:1698327778\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2017\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2016.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:017f7422-4c5a-4c34-b34e-3f59d88d5cbf,timestamp:1698327778\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2017\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1848\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1851.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b061f398-8a65-4f7c-ae4b-6b946ff15576,timestamp:1698327779\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1853\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1848\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1851.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b061f398-8a65-4f7c-ae4b-6b946ff15576,timestamp:1698327779\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1853\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1407\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c196776e-d92b-46df-b1b8-2008ad1497ef,timestamp:1698327781\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1407\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c196776e-d92b-46df-b1b8-2008ad1497ef,timestamp:1698327781\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,576 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,576 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14a25e13-1d4a-4097-ba95-2fe8712424c8,timestamp:1698327782\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,576 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,576 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14a25e13-1d4a-4097-ba95-2fe8712424c8,timestamp:1698327782\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1706.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5cf95cc8-5d2b-4766-a3c5-c3e2203721b7,timestamp:1698327784\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1706.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5cf95cc8-5d2b-4766-a3c5-c3e2203721b7,timestamp:1698327784\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2712.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a3fa9af0-9c49-4ad3-bcb2-f6ed012e83ff,timestamp:1698327788\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2712.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a3fa9af0-9c49-4ad3-bcb2-f6ed012e83ff,timestamp:1698327788\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49c3e498-8166-498a-8d3a-e37a783b6c16,timestamp:1698327789\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,797 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49c3e498-8166-498a-8d3a-e37a783b6c16,timestamp:1698327789\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,797 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1640\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52a9ea71-63d1-45ef-893b-89aa7d43ee54,timestamp:1698327791\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1640\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52a9ea71-63d1-45ef-893b-89aa7d43ee54,timestamp:1698327791\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,924 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1479.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:baec28fd-20d9-4990-856e-aec649a19fb1,timestamp:1698327792\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,924 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1478\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,924 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1479.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:baec28fd-20d9-4990-856e-aec649a19fb1,timestamp:1698327792\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,924 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1478\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,795 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1867\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,795 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1866.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a9c3b02d-1d80-4f5d-8bd8-c7da5ccc42c0,timestamp:1698327794\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1867\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,795 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1867\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,795 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1866.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a9c3b02d-1d80-4f5d-8bd8-c7da5ccc42c0,timestamp:1698327794\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1867\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:43:18,686 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,686 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7154ce9d-88eb-48d7-8da7-ce3c1dcc0dd7,timestamp:1698327798\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,686 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,686 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7154ce9d-88eb-48d7-8da7-ce3c1dcc0dd7,timestamp:1698327798\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:728c0000-c133-4525-b60a-c41902a78a3b,timestamp:1698327799\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:728c0000-c133-4525-b60a-c41902a78a3b,timestamp:1698327799\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,680 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1716\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,680 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1715.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8a74af8a-efa0-4457-acc1-b5d933abdaa7,timestamp:1698327801\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1717\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,680 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1716\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,680 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1715.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8a74af8a-efa0-4457-acc1-b5d933abdaa7,timestamp:1698327801\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1717\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:18ae1895-5941-4e63-83de-02711c7b04b8,timestamp:1698327802\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:18ae1895-5941-4e63-83de-02711c7b04b8,timestamp:1698327802\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,037 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2088\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,037 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2088.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a823c71b-9ba3-4041-a8a2-deeb74f123d6,timestamp:1698327805\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2090\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,037 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2088\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,037 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2088.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a823c71b-9ba3-4041-a8a2-deeb74f123d6,timestamp:1698327805\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2090\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,434 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2393\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,434 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2392.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ffed611b-593c-45ca-9643-4a4df412e292,timestamp:1698327807\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2394\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,434 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2393\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,434 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2392.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ffed611b-593c-45ca-9643-4a4df412e292,timestamp:1698327807\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2394\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:74f55f10-26c1-4c5c-821c-69b33abd3263,timestamp:1698327810\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:74f55f10-26c1-4c5c-821c-69b33abd3263,timestamp:1698327810\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1751\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1750.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f85ffefe-1405-4104-8f3a-12e9e5e29f99,timestamp:1698327812\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1751\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1751\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1750.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f85ffefe-1405-4104-8f3a-12e9e5e29f99,timestamp:1698327812\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1751\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2022\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2022.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ea44a57c-3716-466e-bc4d-4bd473ce62dd,timestamp:1698327814\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2023\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,664 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2022\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2022.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ea44a57c-3716-466e-bc4d-4bd473ce62dd,timestamp:1698327814\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2023\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,664 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,314 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1645\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,314 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:08e210a0-3803-4e83-9e48-10c86f3d6073,timestamp:1698327816\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,314 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1645\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,314 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:08e210a0-3803-4e83-9e48-10c86f3d6073,timestamp:1698327816\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0893525c-bfbd-4f92-81bb-6edaa6d17965,timestamp:1698327817\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0893525c-bfbd-4f92-81bb-6edaa6d17965,timestamp:1698327817\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0f93d46-4a69-4279-9559-1127a830bdd6,timestamp:1698327820\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0f93d46-4a69-4279-9559-1127a830bdd6,timestamp:1698327820\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f1f240f-d1a8-43f4-915d-69b74f111c70,timestamp:1698327822\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,259 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f1f240f-d1a8-43f4-915d-69b74f111c70,timestamp:1698327822\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,259 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1630.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6a308ac7-f961-4efd-86c9-1b5bf2a4567e,timestamp:1698327823\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1630.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6a308ac7-f961-4efd-86c9-1b5bf2a4567e,timestamp:1698327823\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,293 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,293 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7b5c60a0-3566-47b1-b0cb-231e1834beab,timestamp:1698327825\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,293 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,293 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7b5c60a0-3566-47b1-b0cb-231e1834beab,timestamp:1698327825\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4ce6f12a-fbf4-4ee4-92d1-4c3b80d77e39,timestamp:1698327826\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,960 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4ce6f12a-fbf4-4ee4-92d1-4c3b80d77e39,timestamp:1698327826\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,960 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.316532135009766|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548599243164062|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12768.58203125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2466.40625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b82ca32b-9dd8-400c-9e07-b81df125cd46,timestamp:1698327828\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.316532135009766|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548599243164062|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12768.58203125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2466.40625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b82ca32b-9dd8-400c-9e07-b81df125cd46,timestamp:1698327828\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1724.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:762c209c-21dd-45c7-ad3b-c8cddf52b32a,timestamp:1698327832\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1725\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1724.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:762c209c-21dd-45c7-ad3b-c8cddf52b32a,timestamp:1698327832\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1725\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:05e314ad-60e6-48c5-a12f-ebdb86d74771,timestamp:1698327834\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:05e314ad-60e6-48c5-a12f-ebdb86d74771,timestamp:1698327834\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1695\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1694.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2484db1b-9705-48fc-b709-0601bdefcc58,timestamp:1698327836\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1696\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1695\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1694.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2484db1b-9705-48fc-b709-0601bdefcc58,timestamp:1698327836\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1696\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1320.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:458a69c9-a1f8-4022-9e1c-5c58b5f394d4,timestamp:1698327837\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1320.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:458a69c9-a1f8-4022-9e1c-5c58b5f394d4,timestamp:1698327837\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,341 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,341 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:58a7fd5e-e261-4832-b6ee-3b814b602af5,timestamp:1698327841\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,341 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,341 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:58a7fd5e-e261-4832-b6ee-3b814b602af5,timestamp:1698327841\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49d41340-6514-4905-9f1f-2de74bb96278,timestamp:1698327842\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49d41340-6514-4905-9f1f-2de74bb96278,timestamp:1698327842\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28bf454a-4656-48fe-b4dd-d4768dcbc12b,timestamp:1698327844\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1629\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28bf454a-4656-48fe-b4dd-d4768dcbc12b,timestamp:1698327844\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1629\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,475 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,475 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:667d574a-623d-477c-a3ed-99ded2492669,timestamp:1698327845\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,475 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,475 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:667d574a-623d-477c-a3ed-99ded2492669,timestamp:1698327845\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1308.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:02907ff3-397b-4593-ac38-5700ab80fb8a,timestamp:1698327846\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1308.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:02907ff3-397b-4593-ac38-5700ab80fb8a,timestamp:1698327846\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1826.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:310b1623-eec3-405c-94ab-16a487ef9464,timestamp:1698327848\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1828\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1826.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:310b1623-eec3-405c-94ab-16a487ef9464,timestamp:1698327848\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1828\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7dfde606-1a7e-4728-9937-7a4034e4fcb8,timestamp:1698327851\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7dfde606-1a7e-4728-9937-7a4034e4fcb8,timestamp:1698327851\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1807\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1805.8|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5efaae40-334a-4097-ba7b-971c0cf68965,timestamp:1698327853\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1807\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1807\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1805.8|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5efaae40-334a-4097-ba7b-971c0cf68965,timestamp:1698327853\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1807\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1740.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9718c83f-168c-4055-9919-985e011ade9d,timestamp:1698327855\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1741\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1742\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1740.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9718c83f-168c-4055-9919-985e011ade9d,timestamp:1698327855\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1741\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1742\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,119 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2001\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,119 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2006.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:694bc1c3-9ab6-4f30-903f-f8769a32da83,timestamp:1698327857\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2008\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,119 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2001\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,119 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2006.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:694bc1c3-9ab6-4f30-903f-f8769a32da83,timestamp:1698327857\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2008\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:01259183-c826-448b-a28d-c8fd70af6064,timestamp:1698327858\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:01259183-c826-448b-a28d-c8fd70af6064,timestamp:1698327858\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1419\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1419\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,543 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1419\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1419\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,543 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1676\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1678.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a644f871-697d-4259-9bde-452f42ed2477,timestamp:1698327862\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1679\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1676\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1678.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a644f871-697d-4259-9bde-452f42ed2477,timestamp:1698327862\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1679\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,758 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1520\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1523.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:48de9a19-245a-40fc-954d-20449de069d3,timestamp:1698327863\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1525\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,758 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1520\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1523.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:48de9a19-245a-40fc-954d-20449de069d3,timestamp:1698327863\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1525\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e360d3be-1500-4b8d-9767-5f0e97158f32,timestamp:1698327865\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,070 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e360d3be-1500-4b8d-9767-5f0e97158f32,timestamp:1698327865\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,070 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:10983be5-4d5b-48b4-8120-a8daea9062dd,timestamp:1698327866\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,725 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:10983be5-4d5b-48b4-8120-a8daea9062dd,timestamp:1698327866\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,725 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2022\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2028.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3768b1d0-7fd9-4f47-9f83-69e91b0b888f,timestamp:1698327868\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2030\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2022\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2028.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3768b1d0-7fd9-4f47-9f83-69e91b0b888f,timestamp:1698327868\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2030\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c31d1019-3381-44c2-a608-b0a64ff74b40,timestamp:1698327871\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c31d1019-3381-44c2-a608-b0a64ff74b40,timestamp:1698327871\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:215a128a-852c-4daf-949d-f0e90060ba16,timestamp:1698327872\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:215a128a-852c-4daf-949d-f0e90060ba16,timestamp:1698327872\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2e0b9dc9-0960-4227-9704-73626b9188df,timestamp:1698327873\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2e0b9dc9-0960-4227-9704-73626b9188df,timestamp:1698327873\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e9a8be8-bc96-4533-b2a7-9f0c5b080cc5,timestamp:1698327875\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e9a8be8-bc96-4533-b2a7-9f0c5b080cc5,timestamp:1698327875\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2097\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2096.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9676d859-8480-4314-ad71-090bc12d58b6,timestamp:1698327877\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2097\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2097\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2096.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9676d859-8480-4314-ad71-090bc12d58b6,timestamp:1698327877\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2097\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50f21bc7-35ed-44a0-b2aa-18847e690876,timestamp:1698327879\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50f21bc7-35ed-44a0-b2aa-18847e690876,timestamp:1698327879\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,006 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,006 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,006 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,006 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1801\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1801\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1652\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1651.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c6ed6abb-8b06-48f6-ad60-4705132e776c,timestamp:1698327882\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1652\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,470 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,470 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1652\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1651.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c6ed6abb-8b06-48f6-ad60-4705132e776c,timestamp:1698327882\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1652\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,470 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,470 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3b9f848a-8114-4f7b-aee5-1486359ae701,timestamp:1698327883\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,884 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3b9f848a-8114-4f7b-aee5-1486359ae701,timestamp:1698327883\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,884 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2434\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2434.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d120211-1921-4f46-9ee2-c4a5fe69d8cf,timestamp:1698327886\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2435\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2434\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2434.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d120211-1921-4f46-9ee2-c4a5fe69d8cf,timestamp:1698327886\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2435\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,951 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31644058227539|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548690795898438|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12761.84765625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1709\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1708.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ba96ed03-0158-4322-8dbc-d0b091191d4c,timestamp:1698327888\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1709\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,951 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31644058227539|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548690795898438|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12761.84765625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1709\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1708.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ba96ed03-0158-4322-8dbc-d0b091191d4c,timestamp:1698327888\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1709\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1652\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff506ec9-8f4d-43af-b1a1-5e18a84c651e,timestamp:1698327889\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1652\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff506ec9-8f4d-43af-b1a1-5e18a84c651e,timestamp:1698327889\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:71bac16b-adee-47fa-8d92-a90b223becbc,timestamp:1698327892\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:71bac16b-adee-47fa-8d92-a90b223becbc,timestamp:1698327892\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1949\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1948.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:72ed463e-eadd-4a55-9e1c-286f963e662d,timestamp:1698327894\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1950\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1949\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1948.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:72ed463e-eadd-4a55-9e1c-286f963e662d,timestamp:1698327894\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1950\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,556 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1371\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1370.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ae784124-bc2d-4be6-b9e7-aa541c8244cb,timestamp:1698327895\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1372\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,556 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1371\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1370.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ae784124-bc2d-4be6-b9e7-aa541c8244cb,timestamp:1698327895\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1372\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1683\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1683\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1683.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:17649f45-32a6-4a62-8759-df86ab0ed3fc,timestamp:1698327897\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1683\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1683.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:17649f45-32a6-4a62-8759-df86ab0ed3fc,timestamp:1698327897\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1683\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,857 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1610\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1611\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,857 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1609.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:831faf89-9c78-4177-a6a0-91925ce76335,timestamp:1698327898\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,857 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1610\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1611\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,857 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1609.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:831faf89-9c78-4177-a6a0-91925ce76335,timestamp:1698327898\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b622a182-dfa4-401a-9cfa-a7ae4469bfa5,timestamp:1698327900\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b622a182-dfa4-401a-9cfa-a7ae4469bfa5,timestamp:1698327900\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,383 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,383 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9a65b04c-1368-4c4f-8efc-761d8d6f5665,timestamp:1698327901\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,383 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,383 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9a65b04c-1368-4c4f-8efc-761d8d6f5665,timestamp:1698327901\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1313.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:948ff0c3-80b8-4f19-b4df-9aebdccd0a60,timestamp:1698327904\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1314\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1313.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:948ff0c3-80b8-4f19-b4df-9aebdccd0a60,timestamp:1698327904\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1314\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1221\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1219.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b930f99-4ecb-432e-95de-1b04f0649fb8,timestamp:1698327905\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1221\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1221\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1219.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b930f99-4ecb-432e-95de-1b04f0649fb8,timestamp:1698327905\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1221\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9ba5e415-625b-4762-9a31-7e3de34a79c4,timestamp:1698327906\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9ba5e415-625b-4762-9a31-7e3de34a79c4,timestamp:1698327906\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1839\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1842\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1840.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bc78a0a9-a721-48d5-a1c9-f30521c6411d,timestamp:1698327908\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1839\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1842\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1840.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bc78a0a9-a721-48d5-a1c9-f30521c6411d,timestamp:1698327908\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8887d500-b324-4564-89ae-e2e3e3d8fbd5,timestamp:1698327910\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8887d500-b324-4564-89ae-e2e3e3d8fbd5,timestamp:1698327910\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2102\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2100.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d148bdc5-2e7b-4183-a114-4c133ae38b62,timestamp:1698327912\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2102\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2102\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2100.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d148bdc5-2e7b-4183-a114-4c133ae38b62,timestamp:1698327912\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2102\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,473 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,473 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1764\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1764\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,891 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1649\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,891 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0cc37087-1aae-4370-96d0-f121f5830a03,timestamp:1698327915\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,891 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1649\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,891 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0cc37087-1aae-4370-96d0-f121f5830a03,timestamp:1698327915\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7b21813a-0f58-4d04-9dd2-a8622743219d,timestamp:1698327917\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7b21813a-0f58-4d04-9dd2-a8622743219d,timestamp:1698327917\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:467f808c-a992-429e-9373-3473c0e7248b,timestamp:1698327920\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:467f808c-a992-429e-9373-3473c0e7248b,timestamp:1698327920\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,480 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,480 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:68e67ae0-3828-4246-b3f0-8004409a7547,timestamp:1698327921\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:68e67ae0-3828-4246-b3f0-8004409a7547,timestamp:1698327921\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a46be4fb-fcfd-4aec-b5a2-2d9d4d841d8c,timestamp:1698327923\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a46be4fb-fcfd-4aec-b5a2-2d9d4d841d8c,timestamp:1698327923\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1432\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1432\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1431.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:90dbc4f5-9943-4850-818c-8917da386bd4,timestamp:1698327924\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1432\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1432\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1431.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:90dbc4f5-9943-4850-818c-8917da386bd4,timestamp:1698327924\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1376.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:afbe553c-e7f4-4488-9993-ff80df21b7d4,timestamp:1698327925\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1377\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1376.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:afbe553c-e7f4-4488-9993-ff80df21b7d4,timestamp:1698327925\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1377\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1472\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1471.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d95b2e69-e21e-4e9b-b2b7-1e85c9ba9b29,timestamp:1698327927\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1473\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1472\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1471.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d95b2e69-e21e-4e9b-b2b7-1e85c9ba9b29,timestamp:1698327927\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1473\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,687 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,687 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c746094b-3350-49c9-9d75-a375836e0860,timestamp:1698327928\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,687 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,687 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c746094b-3350-49c9-9d75-a375836e0860,timestamp:1698327928\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:45:31,705 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1706\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1706.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e9497759-ffdc-466b-946f-1cca45be1856,timestamp:1698327931\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1708\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,705 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1706\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1706.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e9497759-ffdc-466b-946f-1cca45be1856,timestamp:1698327931\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1708\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1979\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1978.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2573ad1b-f816-44dc-a520-a00bb6dff4bc,timestamp:1698327933\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1980\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1979\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1978.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2573ad1b-f816-44dc-a520-a00bb6dff4bc,timestamp:1698327933\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1980\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a9fd7cc6-e237-4afa-bc95-e2d00710ec2c,timestamp:1698327935\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a9fd7cc6-e237-4afa-bc95-e2d00710ec2c,timestamp:1698327935\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,438 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1335.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5df395f8-16c4-40b7-ad3e-639d1f47fca7,timestamp:1698327936\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1337\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,438 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1335.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5df395f8-16c4-40b7-ad3e-639d1f47fca7,timestamp:1698327936\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1337\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1405\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1404.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3bb0ea3-74dc-41f9-896e-f186e1eeb347,timestamp:1698327937\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1406\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,849 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1405\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1404.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3bb0ea3-74dc-41f9-896e-f186e1eeb347,timestamp:1698327937\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1406\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,849 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,849 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,849 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1809\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1808.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cbdd7cf4-3ae6-48ca-abf7-6e16c2c58a32,timestamp:1698327939\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1809\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1809\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1808.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cbdd7cf4-3ae6-48ca-abf7-6e16c2c58a32,timestamp:1698327939\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1809\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:45:43,725 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1875\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1876\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1874.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d36f38d-ea8b-46c7-ba64-5029db298a2b,timestamp:1698327943\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,725 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1875\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1876\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1874.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d36f38d-ea8b-46c7-ba64-5029db298a2b,timestamp:1698327943\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2514\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2514.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a2c658a0-15b6-46c9-9a41-af2e8ee6b384,timestamp:1698327946\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2516\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2514\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2514.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a2c658a0-15b6-46c9-9a41-af2e8ee6b384,timestamp:1698327946\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2516\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1704.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ad67cfe1-e024-4944-8d60-906ff6bd63db,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,953 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31633377075195|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548797607421875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12761.95703125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.02734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1704.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ad67cfe1-e024-4944-8d60-906ff6bd63db,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,953 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31633377075195|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548797607421875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12761.95703125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.02734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d96bbf3-a9b7-4455-af5e-5889f0bfa362,timestamp:1698327949\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d96bbf3-a9b7-4455-af5e-5889f0bfa362,timestamp:1698327949\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,716 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1480\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,716 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1479.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f9e2def-ac16-4b4b-bf2a-e85bc0c0008a,timestamp:1698327950\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,716 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1480\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,716 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1479.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f9e2def-ac16-4b4b-bf2a-e85bc0c0008a,timestamp:1698327950\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eed3fbbb-71d6-4e3c-a25b-343c11ee0151,timestamp:1698327953\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eed3fbbb-71d6-4e3c-a25b-343c11ee0151,timestamp:1698327953\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1728.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45a17be7-a81c-4664-a411-384b1274998d,timestamp:1698327955\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1728.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45a17be7-a81c-4664-a411-384b1274998d,timestamp:1698327955\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2490\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2489.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c51105cc-a84b-4db0-a5be-9bf10d10c8ed,timestamp:1698327958\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2491\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2490\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2489.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c51105cc-a84b-4db0-a5be-9bf10d10c8ed,timestamp:1698327958\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2491\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1645.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0ac4f379-61bb-44f9-8043-7e652b585c37,timestamp:1698327959\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1645.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0ac4f379-61bb-44f9-8043-7e652b585c37,timestamp:1698327959\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,865 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,865 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,671 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1803\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,671 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1803.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2a093a39-d7d1-4909-a91f-f0cfced85551,timestamp:1698327961\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1805\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,671 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1803\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,671 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1803.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2a093a39-d7d1-4909-a91f-f0cfced85551,timestamp:1698327961\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1805\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:46:04,958 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,958 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cae178c8-f000-4367-b900-9e5e8ae23e2b,timestamp:1698327964\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,958 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,958 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cae178c8-f000-4367-b900-9e5e8ae23e2b,timestamp:1698327964\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1082b815-9c31-4301-ae6b-112ff8f8fea7,timestamp:1698327966\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1082b815-9c31-4301-ae6b-112ff8f8fea7,timestamp:1698327966\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1424\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1423.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a65c50c7-e738-4d2c-a48d-7d630fece047,timestamp:1698327967\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1425\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,799 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,800 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1424\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1423.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a65c50c7-e738-4d2c-a48d-7d630fece047,timestamp:1698327967\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1425\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,799 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,800 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:522ba232-192d-46be-b621-f25e54a062a5,timestamp:1698327969\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:522ba232-192d-46be-b621-f25e54a062a5,timestamp:1698327969\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1644\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1642.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:632341bc-8ed5-4da9-b20d-5d4ab3324ac2,timestamp:1698327970\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1644\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1644\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1642.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:632341bc-8ed5-4da9-b20d-5d4ab3324ac2,timestamp:1698327970\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1644\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:efbec117-5397-4824-8f98-59042ca9a3a4,timestamp:1698327972\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:efbec117-5397-4824-8f98-59042ca9a3a4,timestamp:1698327972\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff0c2855-e93c-48a1-b92b-e27240e87928,timestamp:1698327973\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,341 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,341 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff0c2855-e93c-48a1-b92b-e27240e87928,timestamp:1698327973\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,341 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,341 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1347\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:847423d8-5eb7-46a7-bf90-05d13c132bec,timestamp:1698327975\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1347\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1347\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:847423d8-5eb7-46a7-bf90-05d13c132bec,timestamp:1698327975\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1347\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1712.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1a29813-24ec-4bfa-b558-536ea0b7a375,timestamp:1698327977\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1712.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1a29813-24ec-4bfa-b558-536ea0b7a375,timestamp:1698327977\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,983 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6100ba07-f012-4999-93ee-32c789225771,timestamp:1698327978\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,983 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,983 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6100ba07-f012-4999-93ee-32c789225771,timestamp:1698327978\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,983 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1688\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1687.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b9c96e1-7660-4d75-b7ae-3927c90104fd,timestamp:1698327980\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1688\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1687.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b9c96e1-7660-4d75-b7ae-3927c90104fd,timestamp:1698327980\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,110 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1431\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1431.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aff042f3-6adc-4027-a341-80753ca56f95,timestamp:1698327982\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1433\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,110 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1431\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1431.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aff042f3-6adc-4027-a341-80753ca56f95,timestamp:1698327982\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1433\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,775 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1661\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,775 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b068d87-f920-40f9-a8d7-5e0581991122,timestamp:1698327983\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,775 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1661\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,775 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b068d87-f920-40f9-a8d7-5e0581991122,timestamp:1698327983\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1436\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:df6b44fd-98c1-4f8b-bd20-de9ba00c91a2,timestamp:1698327986\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1436\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:df6b44fd-98c1-4f8b-bd20-de9ba00c91a2,timestamp:1698327986\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,323 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1361\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,323 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1360.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cda953a3-c6fe-4bea-bd6b-4c05cc66453e,timestamp:1698327988\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1362\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,323 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1361\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,323 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1360.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cda953a3-c6fe-4bea-bd6b-4c05cc66453e,timestamp:1698327988\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1362\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1791\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1791.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fad758a8-6123-4328-b67f-ceaa198f6b41,timestamp:1698327990\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1792\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1791\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1791.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fad758a8-6123-4328-b67f-ceaa198f6b41,timestamp:1698327990\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1792\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:79a91ad3-950f-490e-8edf-61a12d6803b7,timestamp:1698327991\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,363 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:79a91ad3-950f-490e-8edf-61a12d6803b7,timestamp:1698327991\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,363 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1669.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c71aa92c-f0eb-45f1-9c09-01a1a9625845,timestamp:1698327993\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1671\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1669.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c71aa92c-f0eb-45f1-9c09-01a1a9625845,timestamp:1698327993\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1671\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:88230441-fd7b-435e-b074-5afee69b6f98,timestamp:1698327996\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1393\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:88230441-fd7b-435e-b074-5afee69b6f98,timestamp:1698327996\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1393\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1692\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1691.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f09790d-00c6-490d-8b8a-0261fc8afbaf,timestamp:1698327998\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1692\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1692\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1691.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f09790d-00c6-490d-8b8a-0261fc8afbaf,timestamp:1698327998\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1692\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53cf8b49-d7dc-4d0c-83b8-d1c6ee577590,timestamp:1698327999\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53cf8b49-d7dc-4d0c-83b8-d1c6ee577590,timestamp:1698327999\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,860 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,860 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,860 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,860 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1761\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1760.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c129478f-300d-45d8-8c8f-ae6865e12456,timestamp:1698328002\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1761\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1761\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1760.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c129478f-300d-45d8-8c8f-ae6865e12456,timestamp:1698328002\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1761\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2218.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2b363583-4d32-4b02-9cb6-8fa3e57f38e5,timestamp:1698328005\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2218.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2b363583-4d32-4b02-9cb6-8fa3e57f38e5,timestamp:1698328005\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f08aaf3-59a6-4d9e-b867-f3e6103552d6,timestamp:1698328006\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,633 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,633 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f08aaf3-59a6-4d9e-b867-f3e6103552d6,timestamp:1698328006\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,633 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,633 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31623458862305|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548896789550781|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12759.296875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2475.66796875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,366 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,366 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1727.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:34172272-d91c-4223-b424-ca9721c92582,timestamp:1698328008\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31623458862305|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548896789550781|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12759.296875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2475.66796875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,366 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,366 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1727.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:34172272-d91c-4223-b424-ca9721c92582,timestamp:1698328008\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2485\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2485.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bb9e5c91-df21-495b-9681-e6601f7c35c5,timestamp:1698328010\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2486\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2485\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2485.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bb9e5c91-df21-495b-9681-e6601f7c35c5,timestamp:1698328010\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2486\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:03ad77c2-68ce-41a7-8d4c-e414c6326339,timestamp:1698328013\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:03ad77c2-68ce-41a7-8d4c-e414c6326339,timestamp:1698328013\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2082\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2081.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d5002e1-ba94-444b-8029-68085bcdcb80,timestamp:1698328015\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2082\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2082\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2081.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d5002e1-ba94-444b-8029-68085bcdcb80,timestamp:1698328015\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2082\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28515402-0967-43c5-be26-c6a76c9f14b0,timestamp:1698328017\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28515402-0967-43c5-be26-c6a76c9f14b0,timestamp:1698328017\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,762 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9a430ee7-d6c3-4618-818f-e6baacbf06e4,timestamp:1698328018\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,762 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9a430ee7-d6c3-4618-818f-e6baacbf06e4,timestamp:1698328018\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,762 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,762 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1776\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1776.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7f1a63c0-1a67-4456-9a0b-834eb5254fa9,timestamp:1698328020\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1777\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,543 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1776\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1776.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7f1a63c0-1a67-4456-9a0b-834eb5254fa9,timestamp:1698328020\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1777\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,543 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1652.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1a645e24-2837-4b85-a1ca-8706f906917a,timestamp:1698328024\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1653\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1652.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1a645e24-2837-4b85-a1ca-8706f906917a,timestamp:1698328024\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1653\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b9dc79cd-c6b5-46ea-adb3-da695785528d,timestamp:1698328025\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b9dc79cd-c6b5-46ea-adb3-da695785528d,timestamp:1698328025\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,909 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,909 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,909 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,909 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.46|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c0677412-46c8-4a1d-bcea-67683f6a5bf2,timestamp:1698328027\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.46|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c0677412-46c8-4a1d-bcea-67683f6a5bf2,timestamp:1698328027\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.42|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c431ba7-71fa-40c2-9deb-4c6be0a6957a,timestamp:1698328028\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.42|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c431ba7-71fa-40c2-9deb-4c6be0a6957a,timestamp:1698328028\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:306575b1-1b81-48c7-97ae-61ae94d44a09,timestamp:1698328030\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:306575b1-1b81-48c7-97ae-61ae94d44a09,timestamp:1698328030\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1398\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1397.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:41fc8ca7-bdae-4d58-8ae9-f8e93c4b8ab6,timestamp:1698328031\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1398\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1397.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:41fc8ca7-bdae-4d58-8ae9-f8e93c4b8ab6,timestamp:1698328031\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.98|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:462816c7-2c02-41ad-80a7-b195708f2bfc,timestamp:1698328032\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1359\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1359\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,894 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.98|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:462816c7-2c02-41ad-80a7-b195708f2bfc,timestamp:1698328032\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1359\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1359\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,894 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,969 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2072.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d3e12233-bb37-4500-b49d-ea6ed69f3765,timestamp:1698328034\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,969 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2073\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2074\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,969 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2072.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d3e12233-bb37-4500-b49d-ea6ed69f3765,timestamp:1698328034\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,969 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2073\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2074\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3be41809-2898-4a3c-a72b-46b4b2388abc,timestamp:1698328036\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,248 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,248 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3be41809-2898-4a3c-a72b-46b4b2388abc,timestamp:1698328036\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,248 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,248 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a5ffc720-defe-47f6-9b01-a50a7f3c3b1c,timestamp:1698328040\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1654\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a5ffc720-defe-47f6-9b01-a50a7f3c3b1c,timestamp:1698328040\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1654\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1336.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ca6a36b7-b7d0-4570-84a7-efac4051879e,timestamp:1698328041\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1336.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ca6a36b7-b7d0-4570-84a7-efac4051879e,timestamp:1698328041\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6bfbdd85-d207-483d-8700-65306b3d5374,timestamp:1698328045\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6bfbdd85-d207-483d-8700-65306b3d5374,timestamp:1698328045\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1696.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:95b4ad59-0b82-4d3c-ac1c-47b16e852469,timestamp:1698328046\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1696.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:95b4ad59-0b82-4d3c-ac1c-47b16e852469,timestamp:1698328046\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2025\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2028.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ce9abb94-3a95-41dc-baa0-1b8a34716249,timestamp:1698328048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2029\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2025\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2028.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ce9abb94-3a95-41dc-baa0-1b8a34716249,timestamp:1698328048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2029\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1310.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3674ad6a-998a-44e7-a159-7f1e513f3430,timestamp:1698328050\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1310.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3674ad6a-998a-44e7-a159-7f1e513f3430,timestamp:1698328050\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d9e3f92c-1390-475f-aa2c-9b3b4d8ed64f,timestamp:1698328051\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d9e3f92c-1390-475f-aa2c-9b3b4d8ed64f,timestamp:1698328051\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1665.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:38a89644-6bed-407d-b775-d28fce74b633,timestamp:1698328053\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1667\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1665.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:38a89644-6bed-407d-b775-d28fce74b633,timestamp:1698328053\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1667\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2025\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2024.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:411a8d01-ddcf-4a31-bcd0-5e37ff88f619,timestamp:1698328056\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2026\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2025\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2024.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:411a8d01-ddcf-4a31-bcd0-5e37ff88f619,timestamp:1698328056\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2026\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1760\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1759.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1647af25-7c5b-4089-ad77-ab4e083f6628,timestamp:1698328058\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1760\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1760\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1759.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1647af25-7c5b-4089-ad77-ab4e083f6628,timestamp:1698328058\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1760\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1644\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1644.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:87b132e8-c347-491b-a36d-cbbfe4f65061,timestamp:1698328060\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1644\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1644.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:87b132e8-c347-491b-a36d-cbbfe4f65061,timestamp:1698328060\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1725\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:43e62af7-d04b-4677-ad6f-4fedd851f608,timestamp:1698328062\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1727\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1725\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:43e62af7-d04b-4677-ad6f-4fedd851f608,timestamp:1698328062\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1727\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1627.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:166e63fe-93ce-441f-966a-86258febea99,timestamp:1698328063\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,669 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,669 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1627.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:166e63fe-93ce-441f-966a-86258febea99,timestamp:1698328063\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,669 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,669 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0a2c78a0-dd1f-4155-b7e5-6b9c8e70747d,timestamp:1698328066\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0a2c78a0-dd1f-4155-b7e5-6b9c8e70747d,timestamp:1698328066\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.3161506652832|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548980712890625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12754.734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,958 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2480.26171875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,958 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1721\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1722.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97fff8af-fbd3-4d40-a2a5-101e1110d388,timestamp:1698328068\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1723\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.3161506652832|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548980712890625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12754.734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,958 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2480.26171875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,958 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1721\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1722.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97fff8af-fbd3-4d40-a2a5-101e1110d388,timestamp:1698328068\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1723\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0fd44ff0-4483-4ba3-a1e6-acefb24b3d0d,timestamp:1698328069\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,557 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0fd44ff0-4483-4ba3-a1e6-acefb24b3d0d,timestamp:1698328069\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,557 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1621\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1621.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5111199b-ccba-4568-8042-8f125491b3ec,timestamp:1698328071\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1621\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1621.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5111199b-ccba-4568-8042-8f125491b3ec,timestamp:1698328071\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1625\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1625\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1679\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:06b6e261-5c20-425d-8bdf-85e85ce2c5a3,timestamp:1698328072\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1679\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:06b6e261-5c20-425d-8bdf-85e85ce2c5a3,timestamp:1698328072\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,157 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,157 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0fb382f8-3721-4070-9b9c-b84c956ddeb3,timestamp:1698328074\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,157 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,157 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0fb382f8-3721-4070-9b9c-b84c956ddeb3,timestamp:1698328074\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1502\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9307db9a-0417-4cfa-b6df-a37bdbdb6a2c,timestamp:1698328075\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1503\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1502\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9307db9a-0417-4cfa-b6df-a37bdbdb6a2c,timestamp:1698328075\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1503\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2117\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2117\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2116.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:05886aa8-e3c0-4778-9748-e4f338f937ec,timestamp:1698328079\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2117\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2116.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:05886aa8-e3c0-4778-9748-e4f338f937ec,timestamp:1698328079\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2117\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1763\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1762.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cd684da6-b0dc-49eb-998b-fa79773685cb,timestamp:1698328081\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1763\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1763\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1762.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cd684da6-b0dc-49eb-998b-fa79773685cb,timestamp:1698328081\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1763\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,613 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,613 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1312.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4aabfbad-5f34-46f1-ac5e-f6649ff0ab10,timestamp:1698328084\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1314\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,613 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,613 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1312.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4aabfbad-5f34-46f1-ac5e-f6649ff0ab10,timestamp:1698328084\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1314\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d0b6ad65-c62d-433a-b3fd-393967784381,timestamp:1698328086\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,258 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d0b6ad65-c62d-433a-b3fd-393967784381,timestamp:1698328086\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,258 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:85a25488-8a50-4726-a4fa-c04945cc6131,timestamp:1698328087\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:85a25488-8a50-4726-a4fa-c04945cc6131,timestamp:1698328087\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:da9c29dd-1ebe-4771-82c0-abf4db848320,timestamp:1698328088\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,810 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,810 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:da9c29dd-1ebe-4771-82c0-abf4db848320,timestamp:1698328088\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,810 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,810 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1804\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1802.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c82bd738-0feb-462f-a296-55f5f8b52e53,timestamp:1698328090\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1804\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1804\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1802.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c82bd738-0feb-462f-a296-55f5f8b52e53,timestamp:1698328090\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1804\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1340.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:71dc37ee-8e42-4797-ac8b-0a1295ad0378,timestamp:1698328091\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1342\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1340.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:71dc37ee-8e42-4797-ac8b-0a1295ad0378,timestamp:1698328091\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1342\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff2d9a01-bcd1-4761-8e5e-fdcc37fdd82c,timestamp:1698328093\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,263 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,263 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff2d9a01-bcd1-4761-8e5e-fdcc37fdd82c,timestamp:1698328093\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,263 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,263 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.4|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eac6a4eb-37f8-45a8-ba82-d695fef8e7a2,timestamp:1698328094\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.4|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eac6a4eb-37f8-45a8-ba82-d695fef8e7a2,timestamp:1698328094\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1843\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1841.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:38fb106f-f452-4ea4-9ff3-5f60c0a86049,timestamp:1698328096\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1843\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1843\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1841.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:38fb106f-f452-4ea4-9ff3-5f60c0a86049,timestamp:1698328096\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1843\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1925\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1925\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1924.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:906eba8d-454b-4afa-a1b7-a124e043e116,timestamp:1698328099\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1925\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1925\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1924.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:906eba8d-454b-4afa-a1b7-a124e043e116,timestamp:1698328099\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:24f5a470-da46-452e-9521-ec995ea1dca4,timestamp:1698328101\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:24f5a470-da46-452e-9521-ec995ea1dca4,timestamp:1698328101\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f8375d1c-a009-4f67-8c9c-150f14d8c450,timestamp:1698328102\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f8375d1c-a009-4f67-8c9c-150f14d8c450,timestamp:1698328102\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ee0bfd69-0284-4ff5-9318-8bd087717b17,timestamp:1698328103\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,742 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ee0bfd69-0284-4ff5-9318-8bd087717b17,timestamp:1698328103\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,742 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1325.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6b75fd1b-332f-43f2-afbf-5871a66d8de2,timestamp:1698328105\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1325.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6b75fd1b-332f-43f2-afbf-5871a66d8de2,timestamp:1698328105\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1633\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1632.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0dc05e73-a210-49c0-8d4d-20c6e0e0395c,timestamp:1698328106\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1633\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1633\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1632.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0dc05e73-a210-49c0-8d4d-20c6e0e0395c,timestamp:1698328106\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1633\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ba48cf02-d0f2-4065-a282-240680945afb,timestamp:1698328109\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ba48cf02-d0f2-4065-a282-240680945afb,timestamp:1698328109\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f8e8b54e-4384-4bf4-ad1f-6c2d80628ff5,timestamp:1698328110\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f8e8b54e-4384-4bf4-ad1f-6c2d80628ff5,timestamp:1698328110\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2560\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2559.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7e970ab-1a2f-4bbf-95a7-1d0276b30037,timestamp:1698328113\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2560\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2560\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2559.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7e970ab-1a2f-4bbf-95a7-1d0276b30037,timestamp:1698328113\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2560\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2124\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2124.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fe0389e3-2390-451c-a937-f6a682c7d1c2,timestamp:1698328115\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2125\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2124\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2124.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fe0389e3-2390-451c-a937-f6a682c7d1c2,timestamp:1698328115\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2125\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f63fdc4-ab4c-46dd-ac7a-e42aee46269a,timestamp:1698328117\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f63fdc4-ab4c-46dd-ac7a-e42aee46269a,timestamp:1698328117\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1696.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5a289724-1e19-4edf-819d-02ff1cd72f48,timestamp:1698328120\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1696.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5a289724-1e19-4edf-819d-02ff1cd72f48,timestamp:1698328120\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2037.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d884646-0e5e-4160-8e6a-5cd2dcb8a3d1,timestamp:1698328123\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2037.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d884646-0e5e-4160-8e6a-5cd2dcb8a3d1,timestamp:1698328123\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:13bb89e0-27fb-42fe-960e-0baa9f90f456,timestamp:1698328124\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:13bb89e0-27fb-42fe-960e-0baa9f90f456,timestamp:1698328124\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1403\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1401.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2d909855-9787-469d-86c6-b075d81d42ed,timestamp:1698328125\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1403\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1403\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1401.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2d909855-9787-469d-86c6-b075d81d42ed,timestamp:1698328125\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1403\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2326\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2325.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ec9fa40f-c2bd-47a9-8b3b-af731d4341ce,timestamp:1698328127\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,002 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3160514831543|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2326\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2325.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ec9fa40f-c2bd-47a9-8b3b-af731d4341ce,timestamp:1698328127\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,002 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3160514831543|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.549079895019531|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12750.0546875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2484.9453125|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,004 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.549079895019531|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12750.0546875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2484.9453125|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,004 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2059\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2062.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f6406dd-a5c7-473b-beec-1ac0ec942496,timestamp:1698328131\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2064\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2059\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2062.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f6406dd-a5c7-473b-beec-1ac0ec942496,timestamp:1698328131\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2064\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2069\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2070.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eed8cf8d-3c28-4aec-b96d-828421f156ff,timestamp:1698328133\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2072\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2069\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2070.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eed8cf8d-3c28-4aec-b96d-828421f156ff,timestamp:1698328133\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2072\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1627.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ce1ad4b5-8cd0-42d7-8d3a-b469d22d5bec,timestamp:1698328136\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,797 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,797 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1627.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ce1ad4b5-8cd0-42d7-8d3a-b469d22d5bec,timestamp:1698328136\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,797 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,797 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2429\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2428.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b655e281-0061-40cc-a14d-c6f02179b60f,timestamp:1698328139\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2429\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2428.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b655e281-0061-40cc-a14d-c6f02179b60f,timestamp:1698328139\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2429\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,229 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,229 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2429\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,229 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,229 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52aa3cfe-bd27-401c-88ec-8bd5699b3fc3,timestamp:1698328140\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,582 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52aa3cfe-bd27-401c-88ec-8bd5699b3fc3,timestamp:1698328140\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,582 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2114\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2112.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:846ee9b5-2cd1-45a1-bf48-27b303f64133,timestamp:1698328142\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2114\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2114\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2112.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:846ee9b5-2cd1-45a1-bf48-27b303f64133,timestamp:1698328142\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2114\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2002cef4-fa14-4f36-9bd3-fd082324adee,timestamp:1698328143\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2002cef4-fa14-4f36-9bd3-fd082324adee,timestamp:1698328143\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e00cba96-4bc3-4bf6-9204-29842b1f2ef8,timestamp:1698328145\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e00cba96-4bc3-4bf6-9204-29842b1f2ef8,timestamp:1698328145\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2092\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2093\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2092\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2093\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2091.8|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5f339fa5-7c8d-439a-91d7-7fd8d885e8bf,timestamp:1698328147\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2091.8|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5f339fa5-7c8d-439a-91d7-7fd8d885e8bf,timestamp:1698328147\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2105\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2105\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2104.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1c44814f-ddfa-4a8d-865e-6f685a2bd269,timestamp:1698328149\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2105\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2105\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2104.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1c44814f-ddfa-4a8d-865e-6f685a2bd269,timestamp:1698328149\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1364\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e1a7de69-da04-41b7-ba33-983fef97a9e9,timestamp:1698328153\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1364\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e1a7de69-da04-41b7-ba33-983fef97a9e9,timestamp:1698328153\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1362\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1362\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1361.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9dcfeda0-0292-47d5-83cf-dfc64c4a6c0c,timestamp:1698328154\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1362\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1362\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1361.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9dcfeda0-0292-47d5-83cf-dfc64c4a6c0c,timestamp:1698328154\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1808\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1807.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:649c5068-0a79-4cfe-957d-e61ae309ef7c,timestamp:1698328158\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1808\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1808\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1807.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:649c5068-0a79-4cfe-957d-e61ae309ef7c,timestamp:1698328158\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1808\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2139\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2138.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cb579f91-2955-443c-a564-1d6194d9894b,timestamp:1698328160\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2139\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,654 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2139\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2138.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cb579f91-2955-443c-a564-1d6194d9894b,timestamp:1698328160\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2139\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,654 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2806\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2805.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6b1550ec-8e96-4df5-98dd-04dd0f851604,timestamp:1698328163\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2806\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2806\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2805.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6b1550ec-8e96-4df5-98dd-04dd0f851604,timestamp:1698328163\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2806\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2538\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2537.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:47ca7921-0f09-430e-8628-d3748131ed12,timestamp:1698328166\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2539\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,004 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2538\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2537.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:47ca7921-0f09-430e-8628-d3748131ed12,timestamp:1698328166\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2539\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,004 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8da55ed8-b346-4404-9ffb-ae6f2b2e966c,timestamp:1698328167\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8da55ed8-b346-4404-9ffb-ae6f2b2e966c,timestamp:1698328167\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1703\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1702.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3fddbbb5-9340-42bd-8799-65674ea04d2e,timestamp:1698328170\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1704\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1703\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1702.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3fddbbb5-9340-42bd-8799-65674ea04d2e,timestamp:1698328170\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1704\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1710\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1711\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1709.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53d22a03-0eb7-4f45-b50a-32580f3d358e,timestamp:1698328171\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1710\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1711\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1709.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53d22a03-0eb7-4f45-b50a-32580f3d358e,timestamp:1698328171\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:202190b7-b1c5-41ca-9826-1e0c79a8262e,timestamp:1698328173\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:202190b7-b1c5-41ca-9826-1e0c79a8262e,timestamp:1698328173\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1390\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1390\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,973 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,973 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1389.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d27f0dd-6743-4cd9-8d35-7f7c73e18e77,timestamp:1698328174\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1390\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1390\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,973 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,973 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1389.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d27f0dd-6743-4cd9-8d35-7f7c73e18e77,timestamp:1698328174\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1668.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45e61b9c-6f75-49ab-9836-f9f4d9db15bc,timestamp:1698328176\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1670\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1668.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45e61b9c-6f75-49ab-9836-f9f4d9db15bc,timestamp:1698328176\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1670\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:49:40,596 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2263\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2262.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ecdc8fe5-1dda-4bb0-9097-1d392acb5fe0,timestamp:1698328180\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,596 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2263\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2262.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ecdc8fe5-1dda-4bb0-9097-1d392acb5fe0,timestamp:1698328180\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2037\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2035.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cacc8370-6203-4a7f-9ef6-b446b5eedf37,timestamp:1698328182\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2037\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2037\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2035.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cacc8370-6203-4a7f-9ef6-b446b5eedf37,timestamp:1698328182\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2037\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1704.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:32c74dcb-09d8-45e1-b1f9-c636e48d0ea8,timestamp:1698328184\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,346 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,346 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1704.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:32c74dcb-09d8-45e1-b1f9-c636e48d0ea8,timestamp:1698328184\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,346 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,346 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,223 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1873\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,223 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1873.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:26bb799a-efda-40d8-b167-7170de2e5c3d,timestamp:1698328186\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1875\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,223 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1873\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,223 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1873.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:26bb799a-efda-40d8-b167-7170de2e5c3d,timestamp:1698328186\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1875\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31596374511719|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.54916763305664|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12735.97265625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2499.0234375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31596374511719|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.54916763305664|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12735.97265625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2499.0234375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1728.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7fb1ea8-1d57-40f1-a099-547dc0ba668b,timestamp:1698328190\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1728.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7fb1ea8-1d57-40f1-a099-547dc0ba668b,timestamp:1698328190\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1790\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1788.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2b4bbbad-9ebd-46d2-a04d-b24c117a7ae4,timestamp:1698328192\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1790\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1790\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1788.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2b4bbbad-9ebd-46d2-a04d-b24c117a7ae4,timestamp:1698328192\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1790\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c14a4872-658f-4b59-af62-65f608674603,timestamp:1698328193\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c14a4872-658f-4b59-af62-65f608674603,timestamp:1698328193\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1688.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3777e91-a09a-47ca-aa1e-4d9ff18442c0,timestamp:1698328195\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1688.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3777e91-a09a-47ca-aa1e-4d9ff18442c0,timestamp:1698328195\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1878\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1878\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1877.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0398488-6466-4eae-856f-adb7d43e2875,timestamp:1698328197\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1878\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1878\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1877.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0398488-6466-4eae-856f-adb7d43e2875,timestamp:1698328197\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1389\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1389\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1388.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b4b1e17e-e4d3-47b7-9a2d-d9baaee9752a,timestamp:1698328198\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,814 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1388.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b4b1e17e-e4d3-47b7-9a2d-d9baaee9752a,timestamp:1698328198\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,814 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1828\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1827.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d07da1fd-a6be-4dc1-9d65-5435e129a960,timestamp:1698328202\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1828\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1827.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d07da1fd-a6be-4dc1-9d65-5435e129a960,timestamp:1698328202\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1415\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1414.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f02c62b6-8073-49e6-b792-998ba1c79bb7,timestamp:1698328203\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1415\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1415\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1414.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f02c62b6-8073-49e6-b792-998ba1c79bb7,timestamp:1698328203\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1415\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,830 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,830 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,830 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,830 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,137 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,137 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:85148d89-56e2-4914-ae11-8079cb1c6130,timestamp:1698328205\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,137 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,137 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:85148d89-56e2-4914-ae11-8079cb1c6130,timestamp:1698328205\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4d0eb647-941d-43fe-a4c4-386acca2448b,timestamp:1698328206\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4d0eb647-941d-43fe-a4c4-386acca2448b,timestamp:1698328206\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1679.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:325df290-6bf3-40ce-97de-b8b9c2cbbe71,timestamp:1698328208\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1679.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:325df290-6bf3-40ce-97de-b8b9c2cbbe71,timestamp:1698328208\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6c3cdfbc-9dac-476e-922c-1cecae788361,timestamp:1698328209\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6c3cdfbc-9dac-476e-922c-1cecae788361,timestamp:1698328209\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11c21136-ed57-4d0a-bbfe-00292654bfc7,timestamp:1698328213\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11c21136-ed57-4d0a-bbfe-00292654bfc7,timestamp:1698328213\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5c496906-b8f6-4442-9b14-3888734e7cc5,timestamp:1698328215\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5c496906-b8f6-4442-9b14-3888734e7cc5,timestamp:1698328215\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1642\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1641.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cdeb90ca-e393-4156-92a2-ae875d05324a,timestamp:1698328216\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1642\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1642\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1641.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cdeb90ca-e393-4156-92a2-ae875d05324a,timestamp:1698328216\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1642\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,138 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e82ec88-8982-4c5e-8be6-93a162ede205,timestamp:1698328218\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,138 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e82ec88-8982-4c5e-8be6-93a162ede205,timestamp:1698328218\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d76239f1-837e-474f-835f-85e0e85841c2,timestamp:1698328219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d76239f1-837e-474f-835f-85e0e85841c2,timestamp:1698328219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1317\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1318\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1316.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:897bb7b6-a14d-4ea1-a4e6-e026559e892c,timestamp:1698328220\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1317\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1318\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1316.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:897bb7b6-a14d-4ea1-a4e6-e026559e892c,timestamp:1698328220\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1802\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1800.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e82318b9-e1b1-4e34-a852-e00fbade6cce,timestamp:1698328222\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1802\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1802\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1800.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e82318b9-e1b1-4e34-a852-e00fbade6cce,timestamp:1698328222\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1802\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1667\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1667\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1666.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52639262-3eb0-492f-be5b-498f298d7ba6,timestamp:1698328224\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1666.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52639262-3eb0-492f-be5b-498f298d7ba6,timestamp:1698328224\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53ac1e23-316d-4fa3-8eb4-108322ad3ef2,timestamp:1698328225\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53ac1e23-316d-4fa3-8eb4-108322ad3ef2,timestamp:1698328225\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2325\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2323.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28a9f142-4e12-4580-83e6-fd12c59680c6,timestamp:1698328228\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2325\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2325\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2323.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28a9f142-4e12-4580-83e6-fd12c59680c6,timestamp:1698328228\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2325\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1370\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1368.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9fa11cba-0a3e-4bfb-bca3-3d6037826b2d,timestamp:1698328230\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1370\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1370\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1368.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9fa11cba-0a3e-4bfb-bca3-3d6037826b2d,timestamp:1698328230\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1370\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2586.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:258d792b-94f9-420f-b8f3-eb2cf89268f5,timestamp:1698328233\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2586.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:258d792b-94f9-420f-b8f3-eb2cf89268f5,timestamp:1698328233\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1718\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1718\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1717.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d2943e5e-d8bd-4da3-a66e-1d4d3675e222,timestamp:1698328235\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1718\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1717.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d2943e5e-d8bd-4da3-a66e-1d4d3675e222,timestamp:1698328235\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1718\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1637.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c0a4a8b9-5335-43d1-a370-8322579297d9,timestamp:1698328236\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1637.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c0a4a8b9-5335-43d1-a370-8322579297d9,timestamp:1698328236\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1612\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1611.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3c684abc-d4b5-449a-87e6-2cc9c3927f4c,timestamp:1698328238\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1612\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,453 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,453 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1612\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1611.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3c684abc-d4b5-449a-87e6-2cc9c3927f4c,timestamp:1698328238\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1612\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,453 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,453 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1491\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1489.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:662f8d95-118d-4463-8d39-6b16bdf7f685,timestamp:1698328239\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1491\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1489.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:662f8d95-118d-4463-8d39-6b16bdf7f685,timestamp:1698328239\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aadda497-54a6-451d-9b61-595ba243bebd,timestamp:1698328242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aadda497-54a6-451d-9b61-595ba243bebd,timestamp:1698328242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,069 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1639\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1297698d-9e29-48d1-9698-47bb3d66035b,timestamp:1698328244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,069 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1639\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1297698d-9e29-48d1-9698-47bb3d66035b,timestamp:1698328244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:960a71e3-2d69-4b03-98e8-15e59e2e943b,timestamp:1698328245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:960a71e3-2d69-4b03-98e8-15e59e2e943b,timestamp:1698328245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2035\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2034.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:abbd144f-29e4-4f92-a916-e5ec52563657,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2036\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31587600708008|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.54925537109375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12745.15625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2489.84375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2035\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2034.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:abbd144f-29e4-4f92-a916-e5ec52563657,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2036\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31587600708008|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.54925537109375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12745.15625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2489.84375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1635.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d5620729-5139-47b6-9dfb-5d8e137aefeb,timestamp:1698328248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1636\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,988 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,988 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1635.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d5620729-5139-47b6-9dfb-5d8e137aefeb,timestamp:1698328248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1636\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,988 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,988 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1315\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d6dbb9fb-8540-4860-a54d-c6404f68ef00,timestamp:1698328250\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1315\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d6dbb9fb-8540-4860-a54d-c6404f68ef00,timestamp:1698328250\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2023-10-26 13:50:53,666 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,666 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fbccf36f-aafc-4160-bb65-a25faa16ec21,timestamp:1698328253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,666 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,666 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fbccf36f-aafc-4160-bb65-a25faa16ec21,timestamp:1698328253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3aa64ed-d147-4ec9-a5e0-15115ea7e814,timestamp:1698328254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3aa64ed-d147-4ec9-a5e0-15115ea7e814,timestamp:1698328254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1792\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1790.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:09f31605-b1f0-457f-8bd3-aee341444baf,timestamp:1698328256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1792\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1792\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1790.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:09f31605-b1f0-457f-8bd3-aee341444baf,timestamp:1698328256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1792\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1715\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1715\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1714.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:57c4235b-f91e-40ca-aaf1-b61503ec54ed,timestamp:1698328261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1715\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1714.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:57c4235b-f91e-40ca-aaf1-b61503ec54ed,timestamp:1698328261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1715\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1670\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1669.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8d056155-c919-424d-b703-03c66bdc576c,timestamp:1698328262\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1670\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1669.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8d056155-c919-424d-b703-03c66bdc576c,timestamp:1698328262\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2037\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2036.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a2d98886-ea7b-40db-988d-dcfcd58a0c2a,timestamp:1698328264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2037\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2037\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2036.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a2d98886-ea7b-40db-988d-dcfcd58a0c2a,timestamp:1698328264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2037\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[32m2023-10-26T13:36:47.914:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=SINGLE_RECORD\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:45,343 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[34mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[34mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mCurrent directory: /\u001b[0m\n",
      "\u001b[34mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[34mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[34mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[34mMax heap size: 2956 M\u001b[0m\n",
      "\u001b[34mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[34mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[34mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:45,343 [INFO ] main org.pytorch.serve.ModelServer - \u001b[0m\n",
      "\u001b[35mTorchserve version: 0.3.0\u001b[0m\n",
      "\u001b[35mTS Home: /opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[35mCurrent directory: /\u001b[0m\n",
      "\u001b[35mTemp directory: /home/model-server/tmp\u001b[0m\n",
      "\u001b[35mNumber of GPUs: 0\u001b[0m\n",
      "\u001b[35mNumber of CPUs: 4\u001b[0m\n",
      "\u001b[35mMax heap size: 2956 M\u001b[0m\n",
      "\u001b[35mPython executable: /opt/conda/bin/python3.6\u001b[0m\n",
      "\u001b[35mConfig file: /etc/sagemaker-ts.properties\u001b[0m\n",
      "\u001b[35mInference address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35mManagement address: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[34mInitial Models: model.mar\u001b[0m\n",
      "\u001b[34mLog dir: /logs\u001b[0m\n",
      "\u001b[34mMetrics dir: /logs\u001b[0m\n",
      "\u001b[34mNetty threads: 0\u001b[0m\n",
      "\u001b[34mNetty client threads: 0\u001b[0m\n",
      "\u001b[34mDefault workers per model: 4\u001b[0m\n",
      "\u001b[34mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[34mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[34mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[34mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[34mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[34mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[34mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[34mEnable metrics API: true\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:45,374 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,001 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag faee83225a044eacbe9358e24f149b1e\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,011 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,040 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,225 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,230 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,231 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,231 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,241 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,241 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,243 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35mMetrics address: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35mModel Store: /.sagemaker/ts/models\u001b[0m\n",
      "\u001b[35mInitial Models: model.mar\u001b[0m\n",
      "\u001b[35mLog dir: /logs\u001b[0m\n",
      "\u001b[35mMetrics dir: /logs\u001b[0m\n",
      "\u001b[35mNetty threads: 0\u001b[0m\n",
      "\u001b[35mNetty client threads: 0\u001b[0m\n",
      "\u001b[35mDefault workers per model: 4\u001b[0m\n",
      "\u001b[35mBlacklist Regex: N/A\u001b[0m\n",
      "\u001b[35mMaximum Response Size: 6553500\u001b[0m\n",
      "\u001b[35mMaximum Request Size: 6553500\u001b[0m\n",
      "\u001b[35mPrefer direct buffer: false\u001b[0m\n",
      "\u001b[35mAllowed Urls: [file://.*|http(s)?://.*]\u001b[0m\n",
      "\u001b[35mCustom python dependency for model allowed: false\u001b[0m\n",
      "\u001b[35mMetrics report format: prometheus\u001b[0m\n",
      "\u001b[35mEnable metrics API: true\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:45,374 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: model.mar\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,001 [INFO ] main org.pytorch.serve.archive.ModelArchive - eTag faee83225a044eacbe9358e24f149b1e\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,011 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model model loaded.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,040 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,225 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,230 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]45\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,231 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,231 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,241 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,241 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: EpollServerSocketChannel.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,243 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9003\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,252 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,252 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,277 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,286 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,294 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,296 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,296 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,296 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,299 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,519 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:53274 \"GET /ping HTTP/1.1\" 200 73\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,538 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,730 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:53284 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,252 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,252 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]48\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,253 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9001\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,277 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]47\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,280 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9002\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,286 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9001.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,294 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9003.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,296 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Listening on port: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,296 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - [PID]46\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,296 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9002.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Torch worker started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Connecting to: /home/model-server/tmp/.ts.sock.9000\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,297 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Python runtime: 3.6.13\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,299 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Connection accepted: /home/model-server/tmp/.ts.sock.9000.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,519 [INFO ] pool-1-thread-5 ACCESS_LOG - /169.254.255.130:53274 \"GET /ping HTTP/1.1\" 200 73\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,538 [INFO ] pool-1-thread-5 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,730 [INFO ] epollEventLoopGroup-3-2 ACCESS_LOG - /169.254.255.130:53284 \"GET /execution-parameters HTTP/1.1\" 404 2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:47,731 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34mModel server started.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,078 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,080 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.598567962646484|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,081 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.266563415527344|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,082 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.8|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,082 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:13958.90625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,083 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1276.03515625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,084 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,931 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:48,972 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:49,028 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:49,034 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:47,731 [INFO ] epollEventLoopGroup-3-2 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35mModel server started.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,078 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,080 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.598567962646484|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,081 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.266563415527344|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,082 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:14.8|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,082 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:13958.90625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,083 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:1276.03515625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,084 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:10.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,931 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:48,972 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:49,028 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:49,034 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Generating new fontManager, this may take some time...\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,640 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,640 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,664 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,675 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,678 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,698 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,707 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,727 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:50,754 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,664 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,675 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,678 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,698 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,707 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,727 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting transformers==4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:50,754 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,746 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,746 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,754 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,833 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,839 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,846 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,968 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:51,974 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:52,353 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:52,363 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:52,572 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:52,576 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,754 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,833 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,839 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,846 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,968 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:51,974 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:52,353 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:52,363 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:52,572 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:52,576 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,099 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,127 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,180 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,182 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,183 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,186 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,251 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,099 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,127 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,180 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,182 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,183 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,186 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,251 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,257 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,339 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,366 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,420 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,422 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,423 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,460 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,463 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,466 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,468 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,573 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,581 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,615 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,257 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,339 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,366 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,420 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,422 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,423 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,460 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,463 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,466 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,468 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,573 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,581 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,613 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,615 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,714 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,861 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:53,865 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,714 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,861 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:53,865 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:54,009 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:54,019 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:54,043 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:54,045 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:54,009 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:54,019 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:54,043 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:54,045 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,158 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,185 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,354 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,356 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,414 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,418 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,158 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,185 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tokenizers-0.12.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,354 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,356 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,414 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,418 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached sacremoses-0.0.53.tar.gz (880 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,936 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,938 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,939 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:55,940 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,092 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,096 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,272 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,277 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,287 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,400 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,405 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,414 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,484 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,486 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,526 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,529 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,531 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,533 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,547 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,552 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,622 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,628 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,636 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,644 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,936 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,938 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,939 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:55,940 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,092 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting huggingface-hub<1.0,>=0.1.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,096 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,272 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,277 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,287 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,400 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,405 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,414 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,484 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,486 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,526 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,529 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,531 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,533 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (5.4.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,547 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting regex!=2019.12.17\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,552 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached regex-2023.8.8-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (759 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,622 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,628 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,636 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,644 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,667 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,667 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,670 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,670 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,673 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,674 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,674 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,682 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,695 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,698 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,702 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,710 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,784 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,786 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,879 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,885 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,916 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,667 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting importlib-metadata\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,667 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,670 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,670 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,673 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (4.59.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,674 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,674 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.6/site-packages (from transformers==4.18.0) (20.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,682 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,695 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,698 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,702 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,710 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,784 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting filelock\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,786 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,879 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,885 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,916 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,919 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,923 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,926 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,929 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,935 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,937 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,938 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,939 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,940 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,948 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,951 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,966 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,968 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,969 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,971 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,975 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,997 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:56,999 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,000 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,001 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,002 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,029 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,167 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,170 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,172 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,173 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,919 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,923 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting packaging>=20.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,926 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached packaging-21.3-py3-none-any.whl (40 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,929 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.6/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.18.0) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,935 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,937 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,938 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging>=20.0->transformers==4.18.0) (2.4.7)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,939 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,940 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,948 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,951 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,966 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,968 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,969 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,971 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,975 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,997 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:56,999 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,000 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,001 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,002 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,029 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,167 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,170 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting zipp>=0.5\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,172 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,173 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,182 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,192 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,195 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,198 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,201 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,202 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,212 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,213 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,215 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,216 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,219 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,219 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,221 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,224 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,228 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,245 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,246 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,249 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,443 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,446 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,450 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,465 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:57,466 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,182 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,192 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,195 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,198 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,201 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,202 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,212 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,213 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,215 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,216 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==4.18.0) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,219 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,219 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,221 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,224 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,228 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,245 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,246 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,249 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,443 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting click\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,446 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached click-8.0.4-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,450 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==4.18.0) (1.0.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,465 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Building wheels for collected packages: sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:57,466 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): started\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,108 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,125 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,125 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,108 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,125 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,125 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,706 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,706 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:58,710 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,035 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,337 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,483 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,483 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,487 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=f277d4d2efbce297ab2fda0cdd9b52bae40642d12b91d8ef4659e9a2a60d1b6b\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,706 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,706 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:58,710 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,035 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Building wheel for sacremoses (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,337 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,483 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,483 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,487 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=d106e57678cf77c2a37972608e7f18a43840470af87efa7dae30b78b444f2373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,488 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895254 sha256=f277d4d2efbce297ab2fda0cdd9b52bae40642d12b91d8ef4659e9a2a60d1b6b\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Stored in directory: /root/.cache/pip/wheels/4c/64/31/e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,490 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully built sacremoses\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,667 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,668 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,675 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Uninstalling packaging-20.4:\u001b[0m\n",
      "\u001b[34m2023-10-26 13:36:59,682 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -       Successfully uninstalled packaging-20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,542 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,617 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,633 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,667 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,668 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,675 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Uninstalling packaging-20.4:\u001b[0m\n",
      "\u001b[35m2023-10-26 13:36:59,682 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -       Successfully uninstalled packaging-20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,542 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,617 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,633 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: zipp, importlib-metadata, regex, packaging, filelock, click, tokenizers, sacremoses, huggingface-hub, transformers\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,729 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,730 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,732 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,798 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,800 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,802 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,830 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,831 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:00,832 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,729 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,730 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,732 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,798 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,800 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,802 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,830 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Attempting uninstall: packaging\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,831 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Found existing installation: packaging 20.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:00,832 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -     Can't uninstall 'packaging'. No files were found to uninstall.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:03,463 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:03,463 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,609 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,609 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,746 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,748 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,878 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:04,904 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,200 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,746 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,748 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed click-8.0.4 filelock-3.4.1 huggingface-hub-0.4.0 importlib-metadata-4.8.3 packaging-21.3 regex-2023.8.8 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 zipp-3.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,878 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:04,904 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,200 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,209 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,561 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,586 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,209 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,561 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,586 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,733 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,739 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,764 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,766 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,770 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,777 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,778 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,805 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,811 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,827 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,912 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,913 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,918 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,925 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,733 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,739 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,764 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,766 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,770 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,773 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,777 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,778 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,805 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,811 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,827 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,912 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,913 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,918 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,925 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,931 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,936 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:05,945 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:06,570 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:06,576 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,931 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,936 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:05,945 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:06,570 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:06,576 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:06,669 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:06,675 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,108 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,137 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,171 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,179 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,213 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,277 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,282 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,331 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,336 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:06,669 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:06,675 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,108 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,137 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,171 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,179 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,213 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,277 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,282 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,331 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,336 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,351 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,433 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,435 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,453 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,469 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,511 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,514 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,560 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,564 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,648 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:07,667 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,351 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,433 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,435 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,453 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,469 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,511 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,514 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,560 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,564 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,648 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:07,667 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,097 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,124 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,097 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,124 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,380 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,384 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,474 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,478 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,533 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,552 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,593 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,633 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,639 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,648 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,380 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,384 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,474 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,478 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,533 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,552 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,593 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,633 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,639 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,648 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,938 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:09,955 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,122 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,125 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,129 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,130 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,131 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,938 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:09,955 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,122 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,125 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,129 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,130 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (2.22.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,131 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,243 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,246 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,259 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,262 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,304 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,309 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,243 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,246 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,259 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,262 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,304 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,309 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,860 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,881 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,995 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:10,998 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,135 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,135 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,139 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,153 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,309 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,311 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,313 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,860 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,881 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,995 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:10,998 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,135 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting werkzeug>=1.0.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,135 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting grpcio>=1.24.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,139 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,153 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached grpcio-1.48.2-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,304 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,309 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,311 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,313 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,315 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,318 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,318 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,436 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,442 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,449 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,451 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,514 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,519 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,590 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,595 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,612 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,616 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,646 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,660 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,315 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (1.19.1)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,318 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (0.36.2)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,318 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.6/site-packages (from tensorboard) (49.6.0.post20210108)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,436 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,442 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,449 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,450 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,451 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,514 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,519 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,590 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting protobuf<3.20,>=3.9.2\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,595 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached protobuf-3.19.6-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,612 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,616 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,646 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,660 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting tensorboard-data-server<0.7.0,>=0.6.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,678 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,678 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,760 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,763 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,766 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,778 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,855 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,860 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,873 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,876 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,887 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,922 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,924 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,944 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,947 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,966 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,967 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,978 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,986 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,989 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,992 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,993 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:11,995 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,003 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,004 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,005 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,064 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,067 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,092 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,098 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,760 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,763 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,766 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,778 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,855 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,860 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,873 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,876 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,887 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,922 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,924 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,944 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,947 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,966 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,967 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,978 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,986 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,989 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,992 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,993 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:11,995 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,003 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,004 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,005 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,064 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,067 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,092 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,098 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,114 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,117 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,124 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,125 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,174 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,230 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,233 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,236 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,351 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,354 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,376 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,413 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,414 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,424 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,431 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,469 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,470 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,482 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,483 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,484 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,486 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,560 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,561 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,563 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,587 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,589 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,657 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,114 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,117 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,124 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,125 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: urllib3<2.0 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (1.25.11)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,174 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,230 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,233 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached cachetools-4.2.4-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,236 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,351 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,354 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,376 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,413 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,414 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,424 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,431 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,469 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,470 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,482 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,483 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,484 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,486 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,560 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,561 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,563 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,587 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,589 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,657 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,660 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,661 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,663 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,666 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,660 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,661 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,663 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,666 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,690 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,728 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,729 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,735 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,741 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,813 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,814 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,816 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,911 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,914 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:12,988 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:13,266 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,690 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.6/site-packages (from markdown>=2.6.8->tensorboard) (4.8.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,728 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.7.4.3)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,729 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.6.0)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,735 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,741 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,813 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,814 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,816 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,911 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Collecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,914 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle -   Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:12,988 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Requirement already satisfied: dataclasses in /opt/conda/lib/python3.6/site-packages (from werkzeug>=1.0.1->tensorboard) (0.8)\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:13,266 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:13,765 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:13,852 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:14,069 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:13,765 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:13,852 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:14,069 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Installing collected packages: pyasn1-modules, oauthlib, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tensorboard\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:15,616 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:15,616 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,115 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,208 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,245 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,408 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,115 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,208 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,245 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,408 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Successfully installed absl-py-1.4.0 cachetools-4.2.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.48.2 markdown-3.3.7 oauthlib-3.2.2 protobuf-3.19.6 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.0.3\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,733 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:16,823 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:17,022 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,733 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:16,823 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:17,022 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Transformers module imported successfully!\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:18,366 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:18,366 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:18,367 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/847 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:18,367 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/847 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,023 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,132 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/140M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,236 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 35.0k/140M [00:00<07:25, 329kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,342 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 93.0k/140M [00:00<05:12, 470kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,443 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 221k/140M [00:00<02:58, 821kB/s] \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,544 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 429k/140M [00:00<01:51, 1.32MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,644 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 857k/140M [00:00<01:01, 2.39MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,023 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,132 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/140M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,236 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 35.0k/140M [00:00<07:25, 329kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,342 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 93.0k/140M [00:00<05:12, 470kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,443 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 221k/140M [00:00<02:58, 821kB/s] \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,544 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 429k/140M [00:00<01:51, 1.32MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,644 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 857k/140M [00:00<01:01, 2.39MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,744 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 1.61M/140M [00:00<00:33, 4.29MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,844 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|â–         | 3.09M/140M [00:00<00:18, 7.93MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:19,944 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|â–         | 5.93M/140M [00:00<00:09, 14.8MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,044 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|â–Œ         | 8.67M/140M [00:00<00:07, 19.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,144 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|â–Š         | 11.4M/140M [00:01<00:06, 21.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,246 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|â–ˆ         | 14.1M/140M [00:01<00:05, 24.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,346 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|â–ˆâ–        | 16.8M/140M [00:01<00:05, 25.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,446 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|â–ˆâ–        | 19.6M/140M [00:01<00:04, 26.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,546 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|â–ˆâ–Œ        | 22.3M/140M [00:01<00:04, 27.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,744 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   1%|          | 1.61M/140M [00:00<00:33, 4.29MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,844 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   2%|â–         | 3.09M/140M [00:00<00:18, 7.93MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:19,944 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   4%|â–         | 5.93M/140M [00:00<00:09, 14.8MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,044 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   6%|â–Œ         | 8.67M/140M [00:00<00:07, 19.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,144 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   8%|â–Š         | 11.4M/140M [00:01<00:06, 21.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,246 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  10%|â–ˆ         | 14.1M/140M [00:01<00:05, 24.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,346 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  12%|â–ˆâ–        | 16.8M/140M [00:01<00:05, 25.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,446 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  14%|â–ˆâ–        | 19.6M/140M [00:01<00:04, 26.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,546 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  16%|â–ˆâ–Œ        | 22.3M/140M [00:01<00:04, 27.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,646 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|â–ˆâ–Š        | 25.1M/140M [00:01<00:04, 27.7MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,646 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  18%|â–ˆâ–Š        | 25.1M/140M [00:01<00:04, 27.7MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,747 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  20%|â–ˆâ–‰        | 27.9M/140M [00:01<00:04, 28.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,848 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  22%|â–ˆâ–ˆâ–       | 30.7M/140M [00:01<00:04, 28.5MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:20,948 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|â–ˆâ–ˆâ–       | 33.5M/140M [00:01<00:03, 28.7MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,049 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–Œ       | 36.3M/140M [00:01<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,149 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 39.1M/140M [00:02<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,249 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|â–ˆâ–ˆâ–‰       | 41.9M/140M [00:02<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,350 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  32%|â–ˆâ–ˆâ–ˆâ–      | 44.7M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,450 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  34%|â–ˆâ–ˆâ–ˆâ–      | 47.4M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,551 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 50.2M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,651 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 53.0M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,747 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  20%|â–ˆâ–‰        | 27.9M/140M [00:01<00:04, 28.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,848 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  22%|â–ˆâ–ˆâ–       | 30.7M/140M [00:01<00:04, 28.5MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:20,948 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  24%|â–ˆâ–ˆâ–       | 33.5M/140M [00:01<00:03, 28.7MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,049 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  26%|â–ˆâ–ˆâ–Œ       | 36.3M/140M [00:01<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,149 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  28%|â–ˆâ–ˆâ–Š       | 39.1M/140M [00:02<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,249 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  30%|â–ˆâ–ˆâ–‰       | 41.9M/140M [00:02<00:03, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,350 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  32%|â–ˆâ–ˆâ–ˆâ–      | 44.7M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,450 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  34%|â–ˆâ–ˆâ–ˆâ–      | 47.4M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,551 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 50.2M/140M [00:02<00:03, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,651 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 53.0M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,751 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 55.8M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,852 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 58.6M/140M [00:02<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:21,952 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 61.4M/140M [00:02<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,052 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 64.2M/140M [00:02<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,153 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 67.0M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,751 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 55.8M/140M [00:02<00:03, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,852 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 58.6M/140M [00:02<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:21,952 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 61.4M/140M [00:02<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,052 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 64.2M/140M [00:02<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,153 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 67.0M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,253 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 69.8M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,354 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 72.5M/140M [00:03<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,455 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 75.3M/140M [00:03<00:02, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,555 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 78.1M/140M [00:03<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,656 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 81.0M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,253 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 69.8M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,354 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 72.5M/140M [00:03<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,455 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 75.3M/140M [00:03<00:02, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,555 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 78.1M/140M [00:03<00:02, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,656 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 81.0M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,757 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 83.8M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,858 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 86.6M/140M [00:03<00:01, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:22,958 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 89.4M/140M [00:03<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,059 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 92.1M/140M [00:03<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,159 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 94.9M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,259 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 97.7M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,360 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 101M/140M [00:04<00:01, 29.2MB/s] \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,460 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 103M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,561 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 106M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,661 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 109M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,757 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 83.8M/140M [00:03<00:02, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,858 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 86.6M/140M [00:03<00:01, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:22,958 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 89.4M/140M [00:03<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,059 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 92.1M/140M [00:03<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,159 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 94.9M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,259 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 97.7M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,360 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 101M/140M [00:04<00:01, 29.2MB/s] \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,460 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 103M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,561 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 106M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,661 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 109M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,762 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 112M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,762 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 112M/140M [00:04<00:01, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,862 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 114M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:23,963 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 117M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,065 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 120M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,165 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 123M/140M [00:05<00:00, 28.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,265 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 126M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,366 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 128M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,466 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 131M/140M [00:05<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,568 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 134M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,669 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 137M/140M [00:05<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,862 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 114M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:23,963 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 117M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,065 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 120M/140M [00:04<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,165 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 123M/140M [00:05<00:00, 28.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,265 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 126M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,366 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 128M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,466 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 131M/140M [00:05<00:00, 29.3MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,568 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 134M/140M [00:05<00:00, 29.2MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,669 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 137M/140M [00:05<00:00, 29.1MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:24,683 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 140M/140M [00:05<00:00, 29.0MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:24,683 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 140M/140M [00:05<00:00, 29.0MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,762 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 847/847 [00:00<00:00, 636kB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.bias']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,764 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,799 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,762 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 847/847 [00:00<00:00, 636kB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.dense.weight', 'cls.predictions.bias']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,763 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,764 [WARN ] W-9002-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,799 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:28,800 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,178 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,180 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,302 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140M/140M [00:05<00:00, 25.9MB/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,304 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,178 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,179 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,180 [WARN ] W-9000-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,302 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 140M/140M [00:05<00:00, 25.9MB/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - - This IS NOT expected if you are initializing MobileBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,303 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Some weights of MobileBertForSequenceClassification were not initialized from the model checkpoint at google/mobilebert-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,304 [WARN ] W-9003-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,760 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,761 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:42741|#Level:Host|#hostname:c449b28b682c,timestamp:1698327449\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:29,762 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:86|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,038 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,038 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:43018|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,042 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:112|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42737\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:43087|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:68|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42715\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:43105|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:105|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,284 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:30,289 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,760 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,761 [INFO ] W-9001-model_1 TS_METRICS - W-9001-model_1.ms:42741|#Level:Host|#hostname:c449b28b682c,timestamp:1698327449\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:29,762 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:86|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,038 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,038 [INFO ] W-9002-model_1 TS_METRICS - W-9002-model_1.ms:43018|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,042 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:112|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42737\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 TS_METRICS - W-9003-model_1.ms:43087|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,107 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:68|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 42715\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 TS_METRICS - W-9000-model_1.ms:43105|#Level:Host|#hostname:c449b28b682c,timestamp:1698327450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,122 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:105|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,284 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - \u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:30,289 [WARN ] W-9001-model_1-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2012\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 42556\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:40523|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2011.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:65095cc4-4f82-47e0-8034-78fe11bf2b19,timestamp:1698327451\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2012\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 42556\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,776 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:40523|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:31,777 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2011.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:65095cc4-4f82-47e0-8034-78fe11bf2b19,timestamp:1698327451\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,356 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1526\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1528\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,356 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1524.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bb0be808-fe69-45c8-a0c8-cc68dbad4b68,timestamp:1698327453\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,356 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1526\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1528\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,356 [INFO ] W-9002-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1524.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bb0be808-fe69-45c8-a0c8-cc68dbad4b68,timestamp:1698327453\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:33,357 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1372\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1371.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b7772f33-47d1-4f4b-95e0-b4347ead9e25,timestamp:1698327454\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1372\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1371.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b7772f33-47d1-4f4b-95e0-b4347ead9e25,timestamp:1698327454\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,734 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:34,735 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cee78850-0755-4eb2-bbe2-9cba0ddc3924,timestamp:1698327456\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,400 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:36,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1-stdout org.pytorch.serve.wlm.WorkerLifeCycle - transformers Version: 4.18.0\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cee78850-0755-4eb2-bbe2-9cba0ddc3924,timestamp:1698327456\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,399 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,400 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:36,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,743 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14d45333-2b1e-4e24-9696-0d075d6d59b3,timestamp:1698327457\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,743 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1338.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14d45333-2b1e-4e24-9696-0d075d6d59b3,timestamp:1698327457\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1340\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:37,744 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1811\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1810.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:de9f549a-8147-4cc7-8a67-9725a6aa3524,timestamp:1698327459\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1812\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1811\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1810.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:de9f549a-8147-4cc7-8a67-9725a6aa3524,timestamp:1698327459\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1812\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:39,561 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:41,326 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1758.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:61c9e01a-4c52-43e0-83df-c83b3739db02,timestamp:1698327461\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:41,326 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1759\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:41,327 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1762\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:41,327 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:41,327 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:41,327 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:41,326 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1758.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:61c9e01a-4c52-43e0-83df-c83b3739db02,timestamp:1698327461\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:41,326 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1759\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:41,327 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1762\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:41,327 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:41,327 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:41,327 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4803d9ae-c908-48ee-8a86-1e662d12ebd8,timestamp:1698327462\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:42,551 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1217.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4803d9ae-c908-48ee-8a86-1e662d12ebd8,timestamp:1698327462\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1218\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,550 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:42,551 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,059 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1500\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,059 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1503.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1d3b469-bc3c-4d07-afb2-871655b4408b,timestamp:1698327464\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1506\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,059 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1500\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,059 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1503.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1d3b469-bc3c-4d07-afb2-871655b4408b,timestamp:1698327464\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1506\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:44,060 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:46,116 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:46,117 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2052\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:46,117 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:46,117 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:46,117 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:46,116 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2050.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:739310e8-7a96-4ffc-a505-72c9a4f5387e,timestamp:1698327466\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:46,116 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:46,117 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2052\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:46,117 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:46,117 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:46,117 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:46,116 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2050.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:739310e8-7a96-4ffc-a505-72c9a4f5387e,timestamp:1698327466\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,386 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:93c8d3df-6dcd-4004-a0c5-4eab6c462f31,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,386 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:93c8d3df-6dcd-4004-a0c5-4eab6c462f31,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,387 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.317108154296875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548023223876953|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12786.66015625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2448.26953125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.317108154296875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,952 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548023223876953|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12786.66015625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2448.26953125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.8|#Level:Host|#hostname:c449b28b682c,timestamp:1698327467\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,016 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1622\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,016 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1624.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c78f4109-8e11-4761-a804-e4f09961c203,timestamp:1698327469\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1626\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,016 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1622\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,016 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1624.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c78f4109-8e11-4761-a804-e4f09961c203,timestamp:1698327469\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1626\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:49,017 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f6ae57a-9d8a-4106-b917-bb1e930906b4,timestamp:1698327470\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f6ae57a-9d8a-4106-b917-bb1e930906b4,timestamp:1698327470\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,320 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:50,321 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,728 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1400.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3954776-80be-4968-950f-8937119fda6b,timestamp:1698327471\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,728 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1402\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,728 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1400.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3954776-80be-4968-950f-8937119fda6b,timestamp:1698327471\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,728 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1399\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1402\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:51,729 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14f59c17-0ed1-4a2d-8af7-0072cc7b2cda,timestamp:1698327473\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1318\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1322.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14f59c17-0ed1-4a2d-8af7-0072cc7b2cda,timestamp:1698327473\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1318\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,057 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1324\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:53,058 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2016\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2020.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5ab7098d-102e-4ea9-a081-6d9569492451,timestamp:1698327475\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2022\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2016\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2020.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5ab7098d-102e-4ea9-a081-6d9569492451,timestamp:1698327475\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2022\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,084 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:55,085 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:55,085 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,708 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1618\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,708 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1618.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:903e1c63-1596-4335-962d-fa54af9c33ad,timestamp:1698327476\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,708 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1618\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,708 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1618.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:903e1c63-1596-4335-962d-fa54af9c33ad,timestamp:1698327476\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:56,709 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1677\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1673.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a515225c-23c7-4801-8c9b-a553adfe621d,timestamp:1698327478\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1677\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1673.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a515225c-23c7-4801-8c9b-a553adfe621d,timestamp:1698327478\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:37:58,391 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1614\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1613.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dc3121ca-a424-4a36-be4f-2daf49f1c5e2,timestamp:1698327480\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1615\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1614\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1613.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dc3121ca-a424-4a36-be4f-2daf49f1c5e2,timestamp:1698327480\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1615\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:00,010 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1624.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9d0e02f1-03ad-4ff2-a5cf-9f925996a323,timestamp:1698327481\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1629\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,645 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,645 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:01,646 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1624.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9d0e02f1-03ad-4ff2-a5cf-9f925996a323,timestamp:1698327481\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,644 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1629\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,645 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,645 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:01,646 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f7e7b169-3386-4602-af88-27e4a2da49b5,timestamp:1698327482\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:02,904 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f7e7b169-3386-4602-af88-27e4a2da49b5,timestamp:1698327482\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,903 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:02,904 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,571 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,571 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2655.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fabc3455-d876-4ece-bdc0-c960c3635220,timestamp:1698327485\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,571 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,571 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2655.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fabc3455-d876-4ece-bdc0-c960c3635220,timestamp:1698327485\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:05,572 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a96cc3ea-f4fa-4e08-a86f-a303c8282b5c,timestamp:1698327487\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1621\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,198 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:07,198 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a96cc3ea-f4fa-4e08-a86f-a303c8282b5c,timestamp:1698327487\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1621\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,197 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,198 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:07,198 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:08,883 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:08,883 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1e905e46-729a-4919-9936-bc09a7bd6344,timestamp:1698327488\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:08,884 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1683\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:08,885 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:08,885 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:08,885 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:08,883 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:08,883 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1e905e46-729a-4919-9936-bc09a7bd6344,timestamp:1698327488\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:08,884 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1683\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:08,885 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:08,885 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:08,885 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1846.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:07ee51b3-2cf7-4473-af31-b97adeb39f67,timestamp:1698327490\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1848\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1848\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:10,738 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1846.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:07ee51b3-2cf7-4473-af31-b97adeb39f67,timestamp:1698327490\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1848\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1848\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:10,738 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,196 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2453\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,196 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2453.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:af37c7be-e7eb-42d0-b2a6-c06e7b886f22,timestamp:1698327493\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2455\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,196 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2453\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,196 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2453.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:af37c7be-e7eb-42d0-b2a6-c06e7b886f22,timestamp:1698327493\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2455\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:13,197 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,433 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,433 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:78ffcf7c-a3fc-4c6b-822c-afe250b7913f,timestamp:1698327494\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,433 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,433 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:78ffcf7c-a3fc-4c6b-822c-afe250b7913f,timestamp:1698327494\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:14,436 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,434 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:14,436 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3b8ff94-8bfa-4804-9796-1beec0b100ea,timestamp:1698327495\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,690 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:15,690 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3b8ff94-8bfa-4804-9796-1beec0b100ea,timestamp:1698327495\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1249\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,689 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,690 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:15,690 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,367 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bfa85e39-4e88-411f-a014-0af3d6c3afbc,timestamp:1698327497\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,367 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,367 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bfa85e39-4e88-411f-a014-0af3d6c3afbc,timestamp:1698327497\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,367 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:17,369 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,368 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:17,369 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e2b1c48-6d45-442c-b49c-b199677f7068,timestamp:1698327498\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,623 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:18,623 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1246.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e2b1c48-6d45-442c-b49c-b199677f7068,timestamp:1698327498\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,622 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,623 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:18,623 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1342\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1341.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:036ad7a3-9fcd-45a9-832e-e67571f9fa62,timestamp:1698327499\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1343\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:19,970 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1342\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1341.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:036ad7a3-9fcd-45a9-832e-e67571f9fa62,timestamp:1698327499\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1343\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:19,969 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:19,970 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1351.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bfbd700b-a66d-45a2-9112-0bef370dd348,timestamp:1698327501\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,327 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:21,327 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1351.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bfbd700b-a66d-45a2-9112-0bef370dd348,timestamp:1698327501\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1353\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,326 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,327 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:21,327 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:480050e1-5048-476b-b482-112eca0da968,timestamp:1698327502\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:480050e1-5048-476b-b482-112eca0da968,timestamp:1698327502\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:22,590 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1626.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a57697d1-32e5-469d-9afb-7a7de8c010d9,timestamp:1698327504\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,223 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:24,223 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1626.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a57697d1-32e5-469d-9afb-7a7de8c010d9,timestamp:1698327504\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,222 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,223 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:24,223 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:25,886 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:25,886 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:048ca2fe-894b-4b71-afd5-b5c08c563b77,timestamp:1698327505\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:25,886 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1659\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:25,887 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:25,887 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:25,887 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:25,886 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:25,886 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:048ca2fe-894b-4b71-afd5-b5c08c563b77,timestamp:1698327505\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:25,886 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1659\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:25,887 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:25,887 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:25,887 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:27,596 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1702.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:761d6881-c122-420e-870e-4d5dab518c18,timestamp:1698327507\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:27,596 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:27,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:27,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:27,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:27,598 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:27,596 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1702.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:761d6881-c122-420e-870e-4d5dab518c18,timestamp:1698327507\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:27,596 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:27,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:27,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:27,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:27,598 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:28,974 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1365\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:28,974 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1371.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c02df509-1abc-4aa9-ae94-e44aec6bd620,timestamp:1698327508\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:28,974 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:28,974 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:28,975 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:28,975 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:28,974 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1365\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:28,974 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1371.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c02df509-1abc-4aa9-ae94-e44aec6bd620,timestamp:1698327508\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:28,974 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:28,974 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:28,975 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:28,975 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:30,989 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2010\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:30,989 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2009.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a937254a-5a2d-4fbf-ac39-0f04d4c1add8,timestamp:1698327510\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:30,990 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2012\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:30,990 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:30,990 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:30,990 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:30,989 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2010\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:30,989 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2009.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a937254a-5a2d-4fbf-ac39-0f04d4c1add8,timestamp:1698327510\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:30,990 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2012\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:30,990 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:30,990 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:30,990 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1774\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1773.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:597e17dc-3ebb-4f1d-9196-57d7b5527623,timestamp:1698327512\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1775\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1774\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1773.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:597e17dc-3ebb-4f1d-9196-57d7b5527623,timestamp:1698327512\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1775\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:32,768 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,456 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1683.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:30f6b808-a694-48b2-a627-434950f5387d,timestamp:1698327514\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,456 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1684\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1686\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,456 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1683.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:30f6b808-a694-48b2-a627-434950f5387d,timestamp:1698327514\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,456 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1684\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1686\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:34,457 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,401 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1937\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,401 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1937.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:79b219d2-e8bb-4560-9fcd-b6309f78fd82,timestamp:1698327516\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,402 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1939\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,402 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,403 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:36,403 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,401 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1937\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,401 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1937.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:79b219d2-e8bb-4560-9fcd-b6309f78fd82,timestamp:1698327516\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,402 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1939\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,402 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,403 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:36,403 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,491 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2083.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b04c0c2a-e5d7-46c4-802e-5fb925b56192,timestamp:1698327518\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2085\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2086\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,491 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2083.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b04c0c2a-e5d7-46c4-802e-5fb925b56192,timestamp:1698327518\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2085\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2086\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:38,492 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b69c631f-9df4-46d0-a614-99fba178cbde,timestamp:1698327520\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b69c631f-9df4-46d0-a614-99fba178cbde,timestamp:1698327520\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:40,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1511\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1511.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3bf21e7-faad-4797-8fa2-09eee9b66a29,timestamp:1698327521\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1513\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1511\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1511.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3bf21e7-faad-4797-8fa2-09eee9b66a29,timestamp:1698327521\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1513\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:41,741 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1363\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e84ee2d-9349-48e1-b500-cc28c397e399,timestamp:1698327523\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:43,110 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1363\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e84ee2d-9349-48e1-b500-cc28c397e399,timestamp:1698327523\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,109 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:43,110 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.28|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e0f58b3-d557-4443-b619-02b614e3d420,timestamp:1698327524\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,406 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:44,406 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1289.28|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e0f58b3-d557-4443-b619-02b614e3d420,timestamp:1698327524\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1292\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,405 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,406 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:44,406 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,678 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f859b50-1f07-41c4-b9a6-79afa0b94784,timestamp:1698327525\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,678 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,678 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f859b50-1f07-41c4-b9a6-79afa0b94784,timestamp:1698327525\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:45,679 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1222\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,906 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,906 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1218.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d61d859-aeaa-4b5f-b3b7-30c4a2767b81,timestamp:1698327526\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1222\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,906 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,906 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:46,905 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1218.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d61d859-aeaa-4b5f-b3b7-30c4a2767b81,timestamp:1698327526\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.317012786865234|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548118591308594|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12782.28125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2452.6484375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:26303a8d-fae1-4835-b945-769ac0803b6f,timestamp:1698327528\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.317012786865234|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548118591308594|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12782.28125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2452.6484375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:47,951 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327527\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:26303a8d-fae1-4835-b945-769ac0803b6f,timestamp:1698327528\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:48,541 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1690\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1690\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1695.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:54f6fb58-e258-4bee-9fac-d2757516feb5,timestamp:1698327530\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1696\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1695.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:54f6fb58-e258-4bee-9fac-d2757516feb5,timestamp:1698327530\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1696\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:50,242 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1786\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1785.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53b799c6-612c-4a32-ba18-50cac4681ff6,timestamp:1698327532\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1787\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1786\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1785.29|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53b799c6-612c-4a32-ba18-50cac4681ff6,timestamp:1698327532\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1787\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:52,033 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1662.46|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cba66855-a814-42b3-b51e-8413d4a9b573,timestamp:1698327533\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,701 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:53,701 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1662.46|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cba66855-a814-42b3-b51e-8413d4a9b573,timestamp:1698327533\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,700 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,701 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:53,701 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1679.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b85b5b73-2e60-49b1-9fa4-eae845bf0529,timestamp:1698327535\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,386 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,385 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1679.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b85b5b73-2e60-49b1-9fa4-eae845bf0529,timestamp:1698327535\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,386 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:55,386 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:55,386 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2329\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2332.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1c11321-f28d-4cc3-89a0-01f76a3bffc0,timestamp:1698327537\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2329\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2332.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1c11321-f28d-4cc3-89a0-01f76a3bffc0,timestamp:1698327537\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2334\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2334\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:57,723 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8ea503a0-be07-423a-9846-75b4be6eac58,timestamp:1698327539\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,035 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:38:59,035 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8ea503a0-be07-423a-9846-75b4be6eac58,timestamp:1698327539\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,034 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,035 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:38:59,035 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2002\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2007.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:649d9b7b-3c74-4b88-8235-99c24ee8d6ed,timestamp:1698327541\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2009\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,048 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:01,048 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2002\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2007.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:649d9b7b-3c74-4b88-8235-99c24ee8d6ed,timestamp:1698327541\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2009\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,047 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,048 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:01,048 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0cbf66bd-f2cd-4704-9547-94865f9e9eb5,timestamp:1698327542\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,311 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:02,311 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0cbf66bd-f2cd-4704-9547-94865f9e9eb5,timestamp:1698327542\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,310 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,311 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:02,311 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b9de3e2-8758-4322-9914-296446393975,timestamp:1698327543\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,588 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,589 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:03,589 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b9de3e2-8758-4322-9914-296446393975,timestamp:1698327543\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,587 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1273\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,588 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,589 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:03,589 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1856\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1855.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d26b299b-1e57-4893-85fb-26b557c029a8,timestamp:1698327545\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1857\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1856\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1855.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d26b299b-1e57-4893-85fb-26b557c029a8,timestamp:1698327545\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1857\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:05,449 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,093 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1639\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,093 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0b287d8-cb22-475c-a8d9-f5242238033e,timestamp:1698327547\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,093 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1639\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,093 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0b287d8-cb22-475c-a8d9-f5242238033e,timestamp:1698327547\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:07,094 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1640.08|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dc1b7b86-a0e5-4f1e-b464-719e51f78147,timestamp:1698327548\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1640.08|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dc1b7b86-a0e5-4f1e-b464-719e51f78147,timestamp:1698327548\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:08,739 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:10,498 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1755\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:10,498 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1754.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6d0f1f8c-b5a9-4a41-87e5-4907324d4053,timestamp:1698327550\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:10,499 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1757\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:10,499 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:10,499 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:10,499 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:10,498 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1755\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:10,498 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1754.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6d0f1f8c-b5a9-4a41-87e5-4907324d4053,timestamp:1698327550\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:10,499 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1757\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:10,499 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:10,499 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:10,499 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:12,165 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:12,165 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1662.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:291744b6-2bdf-4aa9-969b-18cda2d982f2,timestamp:1698327552\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:12,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1664\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:12,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:12,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:12,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:12,165 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:12,165 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1662.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:291744b6-2bdf-4aa9-969b-18cda2d982f2,timestamp:1698327552\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:12,166 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1664\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:12,166 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:12,166 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:12,166 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:13,474 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:13,474 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:13,474 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3c037587-7ffd-4f97-8f3b-43a78bc9cdd2,timestamp:1698327553\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:13,475 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:13,475 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:13,475 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:13,474 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:13,474 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:13,474 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3c037587-7ffd-4f97-8f3b-43a78bc9cdd2,timestamp:1698327553\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:13,475 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:13,475 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:13,475 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:14,705 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1226\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:14,705 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1225.4|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fa3ec512-7257-49dd-a540-5cc8758807c6,timestamp:1698327554\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:14,705 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:14,706 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:14,706 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:14,706 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:14,705 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1226\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:14,705 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1225.4|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fa3ec512-7257-49dd-a540-5cc8758807c6,timestamp:1698327554\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:14,705 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1227\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:14,706 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:14,706 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:14,706 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1280\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1015daec-59e2-4562-a2d7-7b887bd509d1,timestamp:1698327555\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1015daec-59e2-4562-a2d7-7b887bd509d1,timestamp:1698327555\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1280\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:15,990 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:17,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:17,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1f85dbf9-b49e-4ec1-ba3e-0ac3f1596a42,timestamp:1698327557\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:17,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:17,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:17,247 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:17,247 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:17,246 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:17,246 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1f85dbf9-b49e-4ec1-ba3e-0ac3f1596a42,timestamp:1698327557\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:17,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:17,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:17,247 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:17,247 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:19,314 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2063\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:19,314 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2063.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b01ec0b3-c419-4d31-85e1-7ccc0c960dc0,timestamp:1698327559\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:19,315 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2065\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:19,314 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2063\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:19,314 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2063.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b01ec0b3-c419-4d31-85e1-7ccc0c960dc0,timestamp:1698327559\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:19,315 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2065\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:19,315 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:19,315 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:19,315 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:19,315 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:19,315 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:19,315 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.67|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e81597c6-d30d-49bb-8a56-3a5d889e2a4a,timestamp:1698327560\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1265\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.67|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e81597c6-d30d-49bb-8a56-3a5d889e2a4a,timestamp:1698327560\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:20,585 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1634\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1634\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1637.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:24a5ff2d-2797-4a11-bc3c-e860429f5bc4,timestamp:1698327562\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1637.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:24a5ff2d-2797-4a11-bc3c-e860429f5bc4,timestamp:1698327562\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:22,228 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1731\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1731\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1730.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:365e6e9a-2411-4df9-9256-bd33f42daf2a,timestamp:1698327563\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,964 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:23,964 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1731\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1731\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,963 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1730.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:365e6e9a-2411-4df9-9256-bd33f42daf2a,timestamp:1698327563\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,964 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:23,964 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1395\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1395.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:362913f9-6577-4227-8e99-cef13e6b86bc,timestamp:1698327565\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1396\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1395\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1395.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:362913f9-6577-4227-8e99-cef13e6b86bc,timestamp:1698327565\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,363 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1396\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:25,364 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1665.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:31f544d5-0123-4f6a-8c50-1f7086e1bd82,timestamp:1698327567\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1667\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:27,035 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1665.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:31f544d5-0123-4f6a-8c50-1f7086e1bd82,timestamp:1698327567\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1667\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,034 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:27,035 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1630.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4150a462-e940-4df9-9105-7d2ef61b8836,timestamp:1698327568\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:28,670 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1630.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4150a462-e940-4df9-9105-7d2ef61b8836,timestamp:1698327568\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:30,683 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2009\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:30,683 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2008.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aac91623-ae7f-4065-a98c-beb8e45a722c,timestamp:1698327570\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:30,683 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2009\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:30,683 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:30,684 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:30,684 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:30,683 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2009\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:30,683 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2008.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aac91623-ae7f-4065-a98c-beb8e45a722c,timestamp:1698327570\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:30,683 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2009\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:30,683 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:30,684 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:30,684 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,940 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,940 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2cb22d9a-c8e8-476b-a784-e79079d2b241,timestamp:1698327571\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,941 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,941 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,945 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:31,945 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,940 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,940 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2cb22d9a-c8e8-476b-a784-e79079d2b241,timestamp:1698327571\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,941 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,941 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,945 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:31,945 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1724\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1722.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e37786f9-7487-4f2e-b5fa-20d6d9d81b8f,timestamp:1698327573\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1724\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1724\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1722.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e37786f9-7487-4f2e-b5fa-20d6d9d81b8f,timestamp:1698327573\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1724\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:33,673 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aef6548f-ccb7-4447-a49e-b5f68ca32b23,timestamp:1698327574\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1278\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1277.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aef6548f-ccb7-4447-a49e-b5f68ca32b23,timestamp:1698327574\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1278\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:34,955 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1617\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1617\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1617.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f2ba15a8-2132-4e68-8a5b-8077b4bd50f7,timestamp:1698327576\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1619\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1617.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f2ba15a8-2132-4e68-8a5b-8077b4bd50f7,timestamp:1698327576\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1619\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:36,578 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1710\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1711\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,293 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1709.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1ebfb8d0-d785-4b02-8a22-129f7232449c,timestamp:1698327578\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:38,293 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1710\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1711\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,293 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,292 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1709.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1ebfb8d0-d785-4b02-8a22-129f7232449c,timestamp:1698327578\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:38,293 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,592 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,592 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4c9ef204-a5de-4293-8fd7-da5c0f3a5486,timestamp:1698327579\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1296\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,592 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1295\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,592 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1294.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4c9ef204-a5de-4293-8fd7-da5c0f3a5486,timestamp:1698327579\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1296\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:39,593 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:70c4d0b7-57bb-45de-bdfc-89930e8eb966,timestamp:1698327580\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1282\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:70c4d0b7-57bb-45de-bdfc-89930e8eb966,timestamp:1698327580\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:40,880 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:40,879 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:40,880 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,149 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.23|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fe64f11a-6593-44f2-937c-6d346a92b6f7,timestamp:1698327582\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,149 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.23|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fe64f11a-6593-44f2-937c-6d346a92b6f7,timestamp:1698327582\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:42,150 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1382\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1387.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7c49b222-55a0-45e1-ac4d-a40f0d721eec,timestamp:1698327583\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1382\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1387.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7c49b222-55a0-45e1-ac4d-a40f0d721eec,timestamp:1698327583\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:43,543 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,800 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,800 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.28|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9d21d4fd-50e6-4fff-840c-a0f33afc8b87,timestamp:1698327584\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,800 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,800 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1249.28|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9d21d4fd-50e6-4fff-840c-a0f33afc8b87,timestamp:1698327584\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:44,801 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1407\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c98e92d-e2b0-4175-a0ea-d7814d1a378c,timestamp:1698327586\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1407\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c98e92d-e2b0-4175-a0ea-d7814d1a378c,timestamp:1698327586\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,213 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:46,213 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,212 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,213 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:46,213 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31691360473633|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.5482177734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12780.10546875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2454.828125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2036.98|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:62872960-c435-4280-a199-d4f8efe1dcab,timestamp:1698327588\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31691360473633|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.5482177734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12780.10546875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2454.828125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:47,955 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:48,254 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2036.98|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:62872960-c435-4280-a199-d4f8efe1dcab,timestamp:1698327588\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:61675d7f-c919-4457-9cf5-52933d0f695a,timestamp:1698327589\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1228\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1227.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:61675d7f-c919-4457-9cf5-52933d0f695a,timestamp:1698327589\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:49,488 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:51,190 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:51,190 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1697.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c7fa4b51-ed38-4c29-8df7-21d816dd8005,timestamp:1698327591\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:51,191 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1700\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:51,191 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:51,191 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:51,191 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:51,190 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:51,190 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1697.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c7fa4b51-ed38-4c29-8df7-21d816dd8005,timestamp:1698327591\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:51,191 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1700\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:51,191 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:51,191 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:51,191 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2047.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f97691c7-b753-4ea2-807a-08a39551ce20,timestamp:1698327593\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2047.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f97691c7-b753-4ea2-807a-08a39551ce20,timestamp:1698327593\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:53,243 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1384bb49-1247-41a6-9300-048693c41303,timestamp:1698327594\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1297\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1296.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1384bb49-1247-41a6-9300-048693c41303,timestamp:1698327594\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:54,545 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ee312e02-41f9-4c4c-896c-dec81fced280,timestamp:1698327596\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ee312e02-41f9-4c4c-896c-dec81fced280,timestamp:1698327596\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:56,209 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1646.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4bae4cad-b645-4576-911e-f81a61842adf,timestamp:1698327597\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1646.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4bae4cad-b645-4576-911e-f81a61842adf,timestamp:1698327597\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:57,860 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:581520b1-2c26-4239-9dbd-2cde80425ec9,timestamp:1698327599\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:581520b1-2c26-4239-9dbd-2cde80425ec9,timestamp:1698327599\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,109 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:39:59,110 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50906994-cbf2-49d7-9cfd-96774b594cac,timestamp:1698327600\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50906994-cbf2-49d7-9cfd-96774b594cac,timestamp:1698327600\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:00,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:02,063 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:02,063 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1646.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8460d49a-6d33-4d1c-adef-7ffe2a044092,timestamp:1698327602\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:02,064 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:02,064 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:02,064 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:02,064 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:02,063 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:02,063 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1646.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8460d49a-6d33-4d1c-adef-7ffe2a044092,timestamp:1698327602\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:02,064 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:02,064 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:02,064 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:02,064 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:433e639c-16c7-4f01-8a84-10eeb76dcbdb,timestamp:1698327603\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,334 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:03,334 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1265.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:433e639c-16c7-4f01-8a84-10eeb76dcbdb,timestamp:1698327603\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,333 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,334 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:03,334 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1a638444-fd91-4bf0-822b-f2595d1d72a6,timestamp:1698327604\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1326.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1a638444-fd91-4bf0-822b-f2595d1d72a6,timestamp:1698327604\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:04,664 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,334 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,334 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1666.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8461b11a-71b0-488f-8610-e21b556d67a0,timestamp:1698327606\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,334 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,334 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1666.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8461b11a-71b0-488f-8610-e21b556d67a0,timestamp:1698327606\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:06,335 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2074\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2073.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c2ebda5e-c12b-424a-8118-d151b9765bba,timestamp:1698327608\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2075\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2074\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2073.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c2ebda5e-c12b-424a-8118-d151b9765bba,timestamp:1698327608\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,413 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2075\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:08,414 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1642\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1640.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3103aba7-cbec-47ce-bbd0-130b01fa68bf,timestamp:1698327610\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1642\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1640.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3103aba7-cbec-47ce-bbd0-130b01fa68bf,timestamp:1698327610\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:10,059 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,723 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6c10b451-c7e5-4789-bd25-2b75b6f88ef3,timestamp:1698327611\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1661\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,723 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,723 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6c10b451-c7e5-4789-bd25-2b75b6f88ef3,timestamp:1698327611\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1661\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:11,724 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1669\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1668.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2510b30e-3727-4bec-9d60-7bd616f4ac0f,timestamp:1698327613\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1669\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1669\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1668.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2510b30e-3727-4bec-9d60-7bd616f4ac0f,timestamp:1698327613\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1669\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:13,396 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1340.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a0bfa35b-8b66-4823-802f-45e39a259da1,timestamp:1698327614\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1341\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1340.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a0bfa35b-8b66-4823-802f-45e39a259da1,timestamp:1698327614\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1341\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:14,741 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f9556296-2ae9-438b-80fc-807fed79ccc9,timestamp:1698327616\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:16,034 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f9556296-2ae9-438b-80fc-807fed79ccc9,timestamp:1698327616\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,033 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:16,034 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2049\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2048.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e441f55f-bb7f-46ae-96d2-14508aa0551c,timestamp:1698327618\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2050\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2049\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2048.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e441f55f-bb7f-46ae-96d2-14508aa0551c,timestamp:1698327618\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2050\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:18,087 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:13981b08-675a-4a3e-b765-053c0c3c9489,timestamp:1698327619\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1230.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:13981b08-675a-4a3e-b765-053c0c3c9489,timestamp:1698327619\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:19,321 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49321dda-f4f4-4e10-b8f8-bfb22bd8fc92,timestamp:1698327620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49321dda-f4f4-4e10-b8f8-bfb22bd8fc92,timestamp:1698327620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:20,584 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,266 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,266 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1678.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cf9c7bde-a528-4b63-af91-f7db5419ccc5,timestamp:1698327622\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,266 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,266 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1678.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cf9c7bde-a528-4b63-af91-f7db5419ccc5,timestamp:1698327622\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:22,267 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2030\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2032.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:30232690-f292-4b0b-9e32-96b02d98df7b,timestamp:1698327624\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2034\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2030\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2032.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:30232690-f292-4b0b-9e32-96b02d98df7b,timestamp:1698327624\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2034\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:24,304 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,597 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,597 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:379f4205-9385-4e16-bf47-2815252e6eb8,timestamp:1698327625\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,597 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,597 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:379f4205-9385-4e16-bf47-2815252e6eb8,timestamp:1698327625\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1290\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:25,598 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:de19732c-ee4b-4eb7-8be6-8d9d5c58dc00,timestamp:1698327626\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1264.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:de19732c-ee4b-4eb7-8be6-8d9d5c58dc00,timestamp:1698327626\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:26,867 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,125 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,125 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c8768c7f-9820-41a7-9582-82ab0d6e54d9,timestamp:1698327628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,125 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,125 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c8768c7f-9820-41a7-9582-82ab0d6e54d9,timestamp:1698327628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:28,126 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2101\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2099.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2e2f7e29-0ac0-470e-8eac-f7bb0d625eac,timestamp:1698327630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2101\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2101\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2099.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2e2f7e29-0ac0-470e-8eac-f7bb0d625eac,timestamp:1698327630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2101\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:30,230 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f18a9c6-0709-49a7-97d4-291c7f965fa1,timestamp:1698327631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1292\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1292.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f18a9c6-0709-49a7-97d4-291c7f965fa1,timestamp:1698327631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:31,527 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3efd9850-8b09-41d8-bae0-6c8616533ff3,timestamp:1698327632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,905 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3efd9850-8b09-41d8-bae0-6c8616533ff3,timestamp:1698327632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,904 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,905 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:32,905 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:32,905 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c552f00-5dab-455d-ac4c-ae631ccdb50d,timestamp:1698327634\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,164 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:34,164 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c552f00-5dab-455d-ac4c-ae631ccdb50d,timestamp:1698327634\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,163 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,164 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:34,164 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d74dbbfb-edf9-4052-bb1a-0c2ed7931855,timestamp:1698327635\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d74dbbfb-edf9-4052-bb1a-0c2ed7931855,timestamp:1698327635\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:35,798 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1329\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1329\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1327.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e7fc58e-4cfa-41bf-8cae-d30c58447d7a,timestamp:1698327637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1329\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1329\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:37,130 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1327.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e7fc58e-4cfa-41bf-8cae-d30c58447d7a,timestamp:1698327637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,996 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1862\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1862.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c12c6616-ef22-4664-a8b0-605c7c9fcb86,timestamp:1698327638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1864\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,996 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1862\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1862.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c12c6616-ef22-4664-a8b0-605c7c9fcb86,timestamp:1698327638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1864\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:38,997 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:41,232 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:41,232 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2230.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:76c242f6-c764-4f19-8936-f1fa830c2a74,timestamp:1698327641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:41,232 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:41,232 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2230.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:76c242f6-c764-4f19-8936-f1fa830c2a74,timestamp:1698327641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:41,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2232\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:41,234 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:41,234 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:41,234 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:41,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2232\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:41,234 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:41,234 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:41,234 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,289 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2052\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,289 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2051.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e92c2c3d-e556-41a5-bd6d-9fdb72eca6db,timestamp:1698327643\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2053\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,289 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2052\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,289 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2051.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e92c2c3d-e556-41a5-bd6d-9fdb72eca6db,timestamp:1698327643\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2053\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:43,290 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c90d50ed-8250-4a65-8e15-85e203697cb9,timestamp:1698327645\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c90d50ed-8250-4a65-8e15-85e203697cb9,timestamp:1698327645\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:45,021 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:20e508ee-575c-4682-9571-afcf0a6b683b,timestamp:1698327646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,283 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:20e508ee-575c-4682-9571-afcf0a6b683b,timestamp:1698327646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:46,284 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31681442260742|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548316955566406|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12775.33984375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2459.58984375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2150\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2149.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dcabee6d-7325-4aa1-94aa-c77e998a8218,timestamp:1698327648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2150\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,438 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:48,438 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31681442260742|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548316955566406|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12775.33984375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2459.58984375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2150\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2149.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dcabee6d-7325-4aa1-94aa-c77e998a8218,timestamp:1698327648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2150\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,437 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,438 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:48,438 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2026\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2025.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:727620c3-2a89-4591-990f-d068cad74def,timestamp:1698327650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2027\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:50,470 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2026\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2025.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:727620c3-2a89-4591-990f-d068cad74def,timestamp:1698327650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2027\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,469 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:50,470 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:52,094 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1613\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:52,094 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1613\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:52,094 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ad81f51c-a6a7-4648-942d-299f950d238f,timestamp:1698327652\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:52,094 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:52,094 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:52,095 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:52,095 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:52,094 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ad81f51c-a6a7-4648-942d-299f950d238f,timestamp:1698327652\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:52,094 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:52,094 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:52,095 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:52,095 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,359 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,359 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:06e2162c-30de-4bac-b65f-badacf97ff39,timestamp:1698327653\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,359 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,359 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:06e2162c-30de-4bac-b65f-badacf97ff39,timestamp:1698327653\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:53,360 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c6a1c622-9c3b-488b-b6ef-fa686c177820,timestamp:1698327654\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1250\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c6a1c622-9c3b-488b-b6ef-fa686c177820,timestamp:1698327654\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:54,616 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e91db868-338f-4190-8f04-45093f8e7b75,timestamp:1698327656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e91db868-338f-4190-8f04-45093f8e7b75,timestamp:1698327656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:56,257 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,615 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f09eed66-bccb-4a91-a755-f40d540e7c93,timestamp:1698327657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,615 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,615 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f09eed66-bccb-4a91-a755-f40d540e7c93,timestamp:1698327657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,615 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1354\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1356\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:57,616 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,862 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,862 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ed74ddbf-d905-4953-8274-953503d331a5,timestamp:1698327658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,862 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,862 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ed74ddbf-d905-4953-8274-953503d331a5,timestamp:1698327658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:40:58,863 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:56ffdee5-9cfc-49db-bf49-6b7e92b7cf5f,timestamp:1698327660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:56ffdee5-9cfc-49db-bf49-6b7e92b7cf5f,timestamp:1698327660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:00,524 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:02,164 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:31c5a664-1b5d-40e9-ab31-14c274889966,timestamp:1698327662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:02,164 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:31c5a664-1b5d-40e9-ab31-14c274889966,timestamp:1698327662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:02,165 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1350.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5b8ce10e-8326-41ee-9723-4f93ca7cb771,timestamp:1698327663\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1352\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1350.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5b8ce10e-8326-41ee-9723-4f93ca7cb771,timestamp:1698327663\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1352\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1352\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:03,520 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:367d876c-a619-41f4-8219-08e4740a42c0,timestamp:1698327665\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:367d876c-a619-41f4-8219-08e4740a42c0,timestamp:1698327665\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:05,153 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1355.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c99cc994-3c95-49d3-80fe-11ccd91bd9fc,timestamp:1698327666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1353\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1355.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c99cc994-3c95-49d3-80fe-11ccd91bd9fc,timestamp:1698327666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1353\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:06,514 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1820\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1818.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0992444a-7ed7-4266-a2d4-f4f96aa25253,timestamp:1698327668\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1820\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1820\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1818.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0992444a-7ed7-4266-a2d4-f4f96aa25253,timestamp:1698327668\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1820\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:08,337 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,715 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,715 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff8955d7-0242-4c40-b2bb-bd1c9aba1761,timestamp:1698327669\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,715 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,715 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1374.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff8955d7-0242-4c40-b2bb-bd1c9aba1761,timestamp:1698327669\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:09,716 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,578 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2859\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,578 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2858.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8efa77f8-b529-4d62-a167-143319492f8b,timestamp:1698327672\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2860\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,578 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2859\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,578 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2858.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8efa77f8-b529-4d62-a167-143319492f8b,timestamp:1698327672\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2860\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:12,579 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:13,880 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:13,880 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.15|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3a57f692-97fc-4a49-8676-cd72b15db3e9,timestamp:1698327673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:13,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:13,881 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:13,881 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:13,881 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:13,880 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:13,880 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.15|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3a57f692-97fc-4a49-8676-cd72b15db3e9,timestamp:1698327673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:13,880 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:13,881 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:13,881 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:13,881 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9c1c26c4-7d82-4ccd-b12e-1fe2def27204,timestamp:1698327675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9c1c26c4-7d82-4ccd-b12e-1fe2def27204,timestamp:1698327675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:15,155 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1670.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:65dc6e45-3f0a-4ceb-a68a-23f40f2bb2f6,timestamp:1698327676\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1672\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1670.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:65dc6e45-3f0a-4ceb-a68a-23f40f2bb2f6,timestamp:1698327676\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1672\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:16,833 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,037 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2200\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,037 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2200.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50f4e11a-3422-4b5d-92bd-4337e88b1f1e,timestamp:1698327679\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2202\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,037 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2200\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,037 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2200.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50f4e11a-3422-4b5d-92bd-4337e88b1f1e,timestamp:1698327679\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2202\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:19,038 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1664\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a01e45fc-d31f-4df7-b4db-07dda684858a,timestamp:1698327680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1664\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a01e45fc-d31f-4df7-b4db-07dda684858a,timestamp:1698327680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:20,707 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,403 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1692\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,403 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1692.07|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:29100dfd-bc65-470f-bc46-920c64e7d0b2,timestamp:1698327682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1693\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,403 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1692\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,403 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1692.07|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:29100dfd-bc65-470f-bc46-920c64e7d0b2,timestamp:1698327682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1693\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:22,404 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,735 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,735 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1327.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1c2abeec-00b0-4bed-9af5-0dc6527d2be3,timestamp:1698327683\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1329\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,735 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,735 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1327.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1c2abeec-00b0-4bed-9af5-0dc6527d2be3,timestamp:1698327683\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1329\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:23,736 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:25,641 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1902\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:25,641 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1901.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dea8ef46-03c1-4e3c-baa6-4726bc9a1432,timestamp:1698327685\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:25,641 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1902\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:25,642 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:25,642 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:25,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:25,641 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1902\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:25,641 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1901.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dea8ef46-03c1-4e3c-baa6-4726bc9a1432,timestamp:1698327685\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:25,641 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1902\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:25,642 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:25,642 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:25,642 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,691 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2045.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c2adee7f-ba7c-47ea-a629-5b4dc3909c2a,timestamp:1698327687\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2046\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2047\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,691 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2045.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c2adee7f-ba7c-47ea-a629-5b4dc3909c2a,timestamp:1698327687\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2046\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2047\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:27,692 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1999\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1998.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3d25eef-e100-41a2-9249-42696fccb216,timestamp:1698327689\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1999\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,695 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:29,695 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1999\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1998.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3d25eef-e100-41a2-9249-42696fccb216,timestamp:1698327689\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1999\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,694 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,695 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:29,695 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1754\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1753.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fc7be897-2019-4fb0-a5c5-5447286fd971,timestamp:1698327691\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1755\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1754\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1753.73|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fc7be897-2019-4fb0-a5c5-5447286fd971,timestamp:1698327691\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1755\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:31,452 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,405 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1949\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1949.37|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11ec3378-a7b5-4478-837c-470a5e9808ec,timestamp:1698327693\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1951\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,405 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1949\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1949.37|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11ec3378-a7b5-4478-837c-470a5e9808ec,timestamp:1698327693\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1951\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:33,406 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,500 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2090\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2089.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:539c9863-2897-405f-9685-a645e0da3c3b,timestamp:1698327695\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2091\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,500 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2090\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2089.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:539c9863-2897-405f-9685-a645e0da3c3b,timestamp:1698327695\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2091\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:35,501 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,197 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1691.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5219d18c-5253-4868-b86e-6dcb1f1b2666,timestamp:1698327697\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,197 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1689\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,197 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1693\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,197 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1691.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5219d18c-5253-4868-b86e-6dcb1f1b2666,timestamp:1698327697\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,197 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1689\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,197 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1693\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:37,198 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2449.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b8d4fb05-5e47-4092-80c7-d9d5e86fcfad,timestamp:1698327699\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2449.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b8d4fb05-5e47-4092-80c7-d9d5e86fcfad,timestamp:1698327699\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,651 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:39,652 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,958 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,958 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5d1bb4bc-2ba4-4444-a98a-9ab62c6dce54,timestamp:1698327700\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,958 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,958 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1302.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5d1bb4bc-2ba4-4444-a98a-9ab62c6dce54,timestamp:1698327700\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:40,959 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a525c0d5-c7ac-410e-9a64-847d22d2ed0e,timestamp:1698327702\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,262 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,262 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a525c0d5-c7ac-410e-9a64-847d22d2ed0e,timestamp:1698327702\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:42,263 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2056\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2055.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:178204cb-43da-4720-b324-64b3a6f49a36,timestamp:1698327704\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2056\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2056\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2055.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:178204cb-43da-4720-b324-64b3a6f49a36,timestamp:1698327704\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2056\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:44,322 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1450\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1449.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45bc673e-f158-4af8-92b3-295197f7388f,timestamp:1698327705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1451\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1450\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1449.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45bc673e-f158-4af8-92b3-295197f7388f,timestamp:1698327705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1451\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:45,776 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,438 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1658.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bebf978f-fc9c-4a5b-a1b6-5f44837ded8d,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,438 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1658.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bebf978f-fc9c-4a5b-a1b6-5f44837ded8d,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,439 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,950 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31672286987305|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548408508300781|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,950 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,950 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31672286987305|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548408508300781|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12772.9140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2462.015625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12772.9140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2462.015625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1503\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e8dcdb0-7d66-47f3-8563-d52280b733fa,timestamp:1698327708\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1504\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1503\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e8dcdb0-7d66-47f3-8563-d52280b733fa,timestamp:1698327708\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1504\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:48,946 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,579 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:096a8701-cbd9-4e23-9c6b-f802b65f3cfc,timestamp:1698327710\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,579 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:096a8701-cbd9-4e23-9c6b-f802b65f3cfc,timestamp:1698327710\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:50,580 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1785\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1784.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8972a0f3-87f8-461e-94ff-f639dff89c84,timestamp:1698327712\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1786\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1785\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1784.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8972a0f3-87f8-461e-94ff-f639dff89c84,timestamp:1698327712\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,369 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1786\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:52,370 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,789 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,789 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e6e3cd84-c848-4db1-b96c-39c2eacd0474,timestamp:1698327713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1417\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,789 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1416\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,789 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1415.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e6e3cd84-c848-4db1-b96c-39c2eacd0474,timestamp:1698327713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1417\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:53,790 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1781\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1780.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3940eb3-e33f-49ab-8cfa-eed5a4132015,timestamp:1698327715\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1781\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,575 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1781\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,575 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1780.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b3940eb3-e33f-49ab-8cfa-eed5a4132015,timestamp:1698327715\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1781\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:55,576 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1717\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1715.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:60898991-912a-4707-9abf-43743ab2f1ae,timestamp:1698327717\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1717\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1717\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1715.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:60898991-912a-4707-9abf-43743ab2f1ae,timestamp:1698327717\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1717\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:57,296 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9c48e623-28f2-48f6-afcc-4f88c34d2846,timestamp:1698327718\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1260\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1259.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9c48e623-28f2-48f6-afcc-4f88c34d2846,timestamp:1698327718\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1260\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:58,559 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3056635e-d732-40de-98bb-232330c9fa99,timestamp:1698327719\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3056635e-d732-40de-98bb-232330c9fa99,timestamp:1698327719\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:41:59,809 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,516 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1704\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,516 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1703.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11465b82-c8be-47e8-ae69-934c2856e56b,timestamp:1698327721\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,516 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1704\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,516 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1703.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11465b82-c8be-47e8-ae69-934c2856e56b,timestamp:1698327721\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:01,517 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:02,830 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1309.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d4be9f35-87fe-4a03-98c2-9fddfa164bef,timestamp:1698327722\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,830 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1309.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d4be9f35-87fe-4a03-98c2-9fddfa164bef,timestamp:1698327722\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:02,831 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:04,901 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:04,901 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2066.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a38dce50-4620-4a19-b1b7-8c6956095e7d,timestamp:1698327724\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2068\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,901 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,901 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2066.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a38dce50-4620-4a19-b1b7-8c6956095e7d,timestamp:1698327724\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2068\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:04,902 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1438\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d5451a3-1a45-47b1-84b3-82c60341a90b,timestamp:1698327726\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1438\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d5451a3-1a45-47b1-84b3-82c60341a90b,timestamp:1698327726\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:06,343 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1674.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2abac83e-f238-4fc6-a526-aef59962f37e,timestamp:1698327728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,022 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:08,022 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1674.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2abac83e-f238-4fc6-a526-aef59962f37e,timestamp:1698327728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,021 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,022 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:08,022 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f7a2b04a-44e4-4c64-9fee-a5fbc10fcfd4,timestamp:1698327729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f7a2b04a-44e4-4c64-9fee-a5fbc10fcfd4,timestamp:1698327729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:09,271 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:81bee4b4-3f84-4685-bdd4-8a8ce8575564,timestamp:1698327730\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:81bee4b4-3f84-4685-bdd4-8a8ce8575564,timestamp:1698327730\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:10,527 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3684f17c-00cd-4172-8a3f-9ca557ba5851,timestamp:1698327731\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,787 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,787 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3684f17c-00cd-4172-8a3f-9ca557ba5851,timestamp:1698327731\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:11,788 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2310\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2309.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:578c7e86-815c-464a-ab5a-f9c73437e468,timestamp:1698327734\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2310\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2310\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2309.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:578c7e86-815c-464a-ab5a-f9c73437e468,timestamp:1698327734\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2310\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:14,103 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:21995c74-c407-4f33-b39a-02fa4ce54d84,timestamp:1698327735\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1268.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:21995c74-c407-4f33-b39a-02fa4ce54d84,timestamp:1698327735\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:15,376 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,685 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,685 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:674bc574-cadd-4c4e-a128-0aba14c22ba9,timestamp:1698327736\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,685 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,685 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:674bc574-cadd-4c4e-a128-0aba14c22ba9,timestamp:1698327736\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:16,686 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4c56f93e-1cc7-4de2-b970-d9bf967a7c94,timestamp:1698327737\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1301\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1301\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4c56f93e-1cc7-4de2-b970-d9bf967a7c94,timestamp:1698327737\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:17,990 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d3d91e83-9706-4882-9147-e4d66901f8b9,timestamp:1698327739\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d3d91e83-9706-4882-9147-e4d66901f8b9,timestamp:1698327739\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:19,251 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1789\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1788.79|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fabe5c85-cbca-4b87-9441-38ca5c2f7f57,timestamp:1698327741\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1790\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1789\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1788.79|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fabe5c85-cbca-4b87-9441-38ca5c2f7f57,timestamp:1698327741\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1790\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:21,044 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1697.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52283406-3e3f-4352-a951-9ec92b3ea8e2,timestamp:1698327742\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1697.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52283406-3e3f-4352-a951-9ec92b3ea8e2,timestamp:1698327742\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:22,745 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:24,124 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1376\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:24,124 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1376\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:24,124 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1375.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5d5ab5e0-214d-431e-8681-ff66146daf74,timestamp:1698327744\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:24,124 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:24,125 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:24,125 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:24,125 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:24,124 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1375.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5d5ab5e0-214d-431e-8681-ff66146daf74,timestamp:1698327744\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:24,124 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1376\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:24,125 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:24,125 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:24,125 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1562.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4b08d76f-b890-4c2b-8fec-87404f8dc91d,timestamp:1698327745\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1563\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1563\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1562.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4b08d76f-b890-4c2b-8fec-87404f8dc91d,timestamp:1698327745\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1563\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1563\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:25,691 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2463\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2462.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6a970a1c-8702-4ffd-ada5-a97fbd8a314a,timestamp:1698327748\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2464\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2463\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2462.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6a970a1c-8702-4ffd-ada5-a97fbd8a314a,timestamp:1698327748\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2464\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:28,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2333\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2331.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:041496bd-6602-4ab8-a11e-690b2313259a,timestamp:1698327750\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2333\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2333\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2331.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:041496bd-6602-4ab8-a11e-690b2313259a,timestamp:1698327750\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,494 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2333\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:30,495 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1ab5fd63-e9ac-48d0-90cd-4ce4fedcd73a,timestamp:1698327752\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:32,129 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1ab5fd63-e9ac-48d0-90cd-4ce4fedcd73a,timestamp:1698327752\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,128 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:32,129 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2289.42|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14ec7e24-48cb-48c8-9a99-009a6353ee0f,timestamp:1698327754\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2291\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2292\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,422 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2289.42|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14ec7e24-48cb-48c8-9a99-009a6353ee0f,timestamp:1698327754\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2291\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2292\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:34,423 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:35,782 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1355\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:35,782 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d2381cf1-60d5-4630-9cf1-bfe96e4e0bd6,timestamp:1698327755\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:35,782 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:35,783 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:35,783 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:35,782 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1355\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:35,782 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1353.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d2381cf1-60d5-4630-9cf1-bfe96e4e0bd6,timestamp:1698327755\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:35,782 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1355\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:35,783 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:35,783 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:35,783 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:35,783 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,041 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,041 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:20948807-bf80-47b3-8d29-2a0e9ea041da,timestamp:1698327757\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,041 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,041 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:20948807-bf80-47b3-8d29-2a0e9ea041da,timestamp:1698327757\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:37,042 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e28f588c-a75b-4d2e-a77b-a7a542db792a,timestamp:1698327758\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:38,708 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1659.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e28f588c-a75b-4d2e-a77b-a7a542db792a,timestamp:1698327758\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,707 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:38,708 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1665\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0df33c63-ef78-44c9-9ddd-217faad7ba64,timestamp:1698327760\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1665\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0df33c63-ef78-44c9-9ddd-217faad7ba64,timestamp:1698327760\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:40,377 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2215\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2213.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e85acde7-0819-483a-8eb9-843b579a9f75,timestamp:1698327762\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2215\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2215\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2213.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e85acde7-0819-483a-8eb9-843b579a9f75,timestamp:1698327762\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2215\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:42,595 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:724b926b-abc9-4b64-9d87-85219cf80c21,timestamp:1698327763\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1326\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1325\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1324.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:724b926b-abc9-4b64-9d87-85219cf80c21,timestamp:1698327763\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1326\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:43,925 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1675\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1674.67|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:37c24a1b-b542-4862-aaf1-506fc3bd1d04,timestamp:1698327765\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1676\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1675\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1674.67|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:37c24a1b-b542-4862-aaf1-506fc3bd1d04,timestamp:1698327765\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1676\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:45,604 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1665\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97a315e4-5154-4fd1-9f04-fdac9ef1eb09,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1665\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1665\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1664.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97a315e4-5154-4fd1-9f04-fdac9ef1eb09,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1665\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,272 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31661605834961|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548515319824219|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12770.265625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2464.69140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31661605834961|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548515319824219|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12770.265625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2464.69140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:17.9|#Level:Host|#hostname:c449b28b682c,timestamp:1698327767\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1666\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:94309e0d-5b91-4a78-84b4-eec0137bc03a,timestamp:1698327768\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:94309e0d-5b91-4a78-84b4-eec0137bc03a,timestamp:1698327768\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:48,948 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,973 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2016\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2021.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5633b1fe-4b07-4ec5-b8c5-bc44c4bafb27,timestamp:1698327770\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2023\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,973 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2016\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2021.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5633b1fe-4b07-4ec5-b8c5-bc44c4bafb27,timestamp:1698327770\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2023\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:50,974 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,636 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,636 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1659\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,636 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1658.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f6b8a02e-7e3c-49d1-8a1a-8539da7c432c,timestamp:1698327772\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,636 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1658.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f6b8a02e-7e3c-49d1-8a1a-8539da7c432c,timestamp:1698327772\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1660\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:52,637 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2124\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2123.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b5ce46c9-3015-4110-bcdf-2f24ebe7573c,timestamp:1698327774\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2124\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,765 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:54,765 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2124\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2123.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b5ce46c9-3015-4110-bcdf-2f24ebe7573c,timestamp:1698327774\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2124\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,765 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:54,765 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fa48b04e-3cd9-4811-ba94-129b7d2f764f,timestamp:1698327776\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fa48b04e-3cd9-4811-ba94-129b7d2f764f,timestamp:1698327776\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1240\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:56,009 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2017\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2017\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2016.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:017f7422-4c5a-4c34-b34e-3f59d88d5cbf,timestamp:1698327778\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2017\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2016.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:017f7422-4c5a-4c34-b34e-3f59d88d5cbf,timestamp:1698327778\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,029 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2017\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:58,030 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1848\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1851.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b061f398-8a65-4f7c-ae4b-6b946ff15576,timestamp:1698327779\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1853\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1848\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1851.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b061f398-8a65-4f7c-ae4b-6b946ff15576,timestamp:1698327779\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,886 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1853\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:42:59,887 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1407\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c196776e-d92b-46df-b1b8-2008ad1497ef,timestamp:1698327781\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1407\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c196776e-d92b-46df-b1b8-2008ad1497ef,timestamp:1698327781\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:01,297 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,576 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,576 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14a25e13-1d4a-4097-ba95-2fe8712424c8,timestamp:1698327782\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,576 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,576 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:14a25e13-1d4a-4097-ba95-2fe8712424c8,timestamp:1698327782\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:02,577 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1706.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5cf95cc8-5d2b-4766-a3c5-c3e2203721b7,timestamp:1698327784\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1707\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1706.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5cf95cc8-5d2b-4766-a3c5-c3e2203721b7,timestamp:1698327784\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1707\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:04,287 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:05,828 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1537\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1537.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d01e19a-9c29-45f7-ab60-670e9c5607f5,timestamp:1698327785\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1539\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:05,828 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1537\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1537.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d01e19a-9c29-45f7-ab60-670e9c5607f5,timestamp:1698327785\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1539\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:05,829 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2712.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a3fa9af0-9c49-4ad3-bcb2-f6ed012e83ff,timestamp:1698327788\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:08,545 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2712.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a3fa9af0-9c49-4ad3-bcb2-f6ed012e83ff,timestamp:1698327788\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49c3e498-8166-498a-8d3a-e37a783b6c16,timestamp:1698327789\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:09,797 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1247.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49c3e498-8166-498a-8d3a-e37a783b6c16,timestamp:1698327789\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,796 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:09,797 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1640\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52a9ea71-63d1-45ef-893b-89aa7d43ee54,timestamp:1698327791\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1640\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52a9ea71-63d1-45ef-893b-89aa7d43ee54,timestamp:1698327791\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,440 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1641\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:11,441 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,924 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1479.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:baec28fd-20d9-4990-856e-aec649a19fb1,timestamp:1698327792\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,924 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1478\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,924 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1479.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:baec28fd-20d9-4990-856e-aec649a19fb1,timestamp:1698327792\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,924 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1478\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:12,925 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,795 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1867\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,795 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1866.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a9c3b02d-1d80-4f5d-8bd8-c7da5ccc42c0,timestamp:1698327794\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1867\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,795 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1867\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,795 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1866.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a9c3b02d-1d80-4f5d-8bd8-c7da5ccc42c0,timestamp:1698327794\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1867\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:14,796 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:17,045 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2241\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:17,046 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:17,045 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2245.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4bacc04b-8d97-40e7-96f6-49e789f910c8,timestamp:1698327797\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:17,046 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:17,046 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:17,046 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:17,045 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2241\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:17,046 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:17,045 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2245.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4bacc04b-8d97-40e7-96f6-49e789f910c8,timestamp:1698327797\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:17,046 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:17,046 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:17,046 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,686 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,686 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7154ce9d-88eb-48d7-8da7-ce3c1dcc0dd7,timestamp:1698327798\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,686 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,686 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7154ce9d-88eb-48d7-8da7-ce3c1dcc0dd7,timestamp:1698327798\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:18,687 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:728c0000-c133-4525-b60a-c41902a78a3b,timestamp:1698327799\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:728c0000-c133-4525-b60a-c41902a78a3b,timestamp:1698327799\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:19,961 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,680 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1716\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,680 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1715.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8a74af8a-efa0-4457-acc1-b5d933abdaa7,timestamp:1698327801\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1717\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,680 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1716\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,680 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1715.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8a74af8a-efa0-4457-acc1-b5d933abdaa7,timestamp:1698327801\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1717\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:21,681 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:18ae1895-5941-4e63-83de-02711c7b04b8,timestamp:1698327802\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:18ae1895-5941-4e63-83de-02711c7b04b8,timestamp:1698327802\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:22,945 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,037 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2088\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,037 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2088.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a823c71b-9ba3-4041-a8a2-deeb74f123d6,timestamp:1698327805\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2090\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,037 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2088\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,037 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2088.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a823c71b-9ba3-4041-a8a2-deeb74f123d6,timestamp:1698327805\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2090\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:25,038 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,434 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2393\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,434 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2392.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ffed611b-593c-45ca-9643-4a4df412e292,timestamp:1698327807\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2394\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,434 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2393\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,434 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2392.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ffed611b-593c-45ca-9643-4a4df412e292,timestamp:1698327807\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2394\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:27,435 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2204\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2203.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4aff87fa-2dce-42df-be27-a65a97a55835,timestamp:1698327809\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2205\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2204\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2203.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4aff87fa-2dce-42df-be27-a65a97a55835,timestamp:1698327809\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2205\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:29,643 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:74f55f10-26c1-4c5c-821c-69b33abd3263,timestamp:1698327810\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1236\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1234.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:74f55f10-26c1-4c5c-821c-69b33abd3263,timestamp:1698327810\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1236\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:30,883 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1751\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1750.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f85ffefe-1405-4104-8f3a-12e9e5e29f99,timestamp:1698327812\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1751\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1751\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1750.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f85ffefe-1405-4104-8f3a-12e9e5e29f99,timestamp:1698327812\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1751\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:32,637 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2022\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2022.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ea44a57c-3716-466e-bc4d-4bd473ce62dd,timestamp:1698327814\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2023\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:34,664 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2022\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2022.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ea44a57c-3716-466e-bc4d-4bd473ce62dd,timestamp:1698327814\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2023\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,663 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:34,664 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,314 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1645\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,314 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:08e210a0-3803-4e83-9e48-10c86f3d6073,timestamp:1698327816\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,314 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1645\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,314 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:08e210a0-3803-4e83-9e48-10c86f3d6073,timestamp:1698327816\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:36,315 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0893525c-bfbd-4f92-81bb-6edaa6d17965,timestamp:1698327817\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1281.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0893525c-bfbd-4f92-81bb-6edaa6d17965,timestamp:1698327817\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:37,601 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1332\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1331.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:366c114f-fffd-4971-94ca-30aa81723ce8,timestamp:1698327818\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1332\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1331.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:366c114f-fffd-4971-94ca-30aa81723ce8,timestamp:1698327818\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1332\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:38,936 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0f93d46-4a69-4279-9559-1127a830bdd6,timestamp:1698327820\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0f93d46-4a69-4279-9559-1127a830bdd6,timestamp:1698327820\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:40,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f1f240f-d1a8-43f4-915d-69b74f111c70,timestamp:1698327822\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:42,259 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f1f240f-d1a8-43f4-915d-69b74f111c70,timestamp:1698327822\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:42,259 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1630.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6a308ac7-f961-4efd-86c9-1b5bf2a4567e,timestamp:1698327823\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1630.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6a308ac7-f961-4efd-86c9-1b5bf2a4567e,timestamp:1698327823\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:43,893 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,293 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,293 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7b5c60a0-3566-47b1-b0cb-231e1834beab,timestamp:1698327825\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,293 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1397\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,293 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1396.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7b5c60a0-3566-47b1-b0cb-231e1834beab,timestamp:1698327825\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:45,294 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4ce6f12a-fbf4-4ee4-92d1-4c3b80d77e39,timestamp:1698327826\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:46,960 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4ce6f12a-fbf4-4ee4-92d1-4c3b80d77e39,timestamp:1698327826\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,959 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:46,960 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.316532135009766|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548599243164062|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12768.58203125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2466.40625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b82ca32b-9dd8-400c-9e07-b81df125cd46,timestamp:1698327828\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.316532135009766|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548599243164062|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12768.58203125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2466.40625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:47,956 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1303\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1303.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b82ca32b-9dd8-400c-9e07-b81df125cd46,timestamp:1698327828\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,266 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1304\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:48,267 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ea6ffa2b-5a56-4394-90af-f64e48b44b41,timestamp:1698327829\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ea6ffa2b-5a56-4394-90af-f64e48b44b41,timestamp:1698327829\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:49,537 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fc4386f7-b728-407e-acaf-5c5a4d330167,timestamp:1698327831\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fc4386f7-b728-407e-acaf-5c5a4d330167,timestamp:1698327831\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:51,189 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1725\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1724.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:762c209c-21dd-45c7-ad3b-c8cddf52b32a,timestamp:1698327832\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1725\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1725\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1724.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:762c209c-21dd-45c7-ad3b-c8cddf52b32a,timestamp:1698327832\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1725\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:52,921 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:05e314ad-60e6-48c5-a12f-ebdb86d74771,timestamp:1698327834\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:05e314ad-60e6-48c5-a12f-ebdb86d74771,timestamp:1698327834\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:54,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1695\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1694.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2484db1b-9705-48fc-b709-0601bdefcc58,timestamp:1698327836\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1696\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1695\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1694.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2484db1b-9705-48fc-b709-0601bdefcc58,timestamp:1698327836\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1696\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:56,306 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1320.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:458a69c9-a1f8-4022-9e1c-5c58b5f394d4,timestamp:1698327837\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1321\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1320.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:458a69c9-a1f8-4022-9e1c-5c58b5f394d4,timestamp:1698327837\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:57,631 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2047.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:af199ec0-78c5-456c-a02b-657a8e1f88f4,timestamp:1698327839\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2047.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:af199ec0-78c5-456c-a02b-657a8e1f88f4,timestamp:1698327839\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:43:59,683 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,341 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,341 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:58a7fd5e-e261-4832-b6ee-3b814b602af5,timestamp:1698327841\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,341 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,341 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:58a7fd5e-e261-4832-b6ee-3b814b602af5,timestamp:1698327841\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:01,342 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49d41340-6514-4905-9f1f-2de74bb96278,timestamp:1698327842\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1252.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:49d41340-6514-4905-9f1f-2de74bb96278,timestamp:1698327842\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:02,598 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28bf454a-4656-48fe-b4dd-d4768dcbc12b,timestamp:1698327844\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1629\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1628.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28bf454a-4656-48fe-b4dd-d4768dcbc12b,timestamp:1698327844\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1629\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:04,231 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,475 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,475 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:667d574a-623d-477c-a3ed-99ded2492669,timestamp:1698327845\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,475 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1241\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,475 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1240.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:667d574a-623d-477c-a3ed-99ded2492669,timestamp:1698327845\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:05,476 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1308.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:02907ff3-397b-4593-ac38-5700ab80fb8a,timestamp:1698327846\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1302\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1308.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:02907ff3-397b-4593-ac38-5700ab80fb8a,timestamp:1698327846\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1309\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:06,788 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1826.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:310b1623-eec3-405c-94ab-16a487ef9464,timestamp:1698327848\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1828\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1826.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:310b1623-eec3-405c-94ab-16a487ef9464,timestamp:1698327848\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1828\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:08,619 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.08|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bc97019e-a16c-493a-95c3-62a49ef5efe7,timestamp:1698327849\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.08|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bc97019e-a16c-493a-95c3-62a49ef5efe7,timestamp:1698327849\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1288\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:09,910 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7dfde606-1a7e-4728-9937-7a4034e4fcb8,timestamp:1698327851\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7dfde606-1a7e-4728-9937-7a4034e4fcb8,timestamp:1698327851\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:11,553 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1807\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1805.8|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5efaae40-334a-4097-ba7b-971c0cf68965,timestamp:1698327853\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1807\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1807\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1805.8|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5efaae40-334a-4097-ba7b-971c0cf68965,timestamp:1698327853\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1807\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:13,363 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1740.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9718c83f-168c-4055-9919-985e011ade9d,timestamp:1698327855\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1741\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1742\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1740.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9718c83f-168c-4055-9919-985e011ade9d,timestamp:1698327855\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1741\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1742\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:15,108 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,119 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2001\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,119 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2006.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:694bc1c3-9ab6-4f30-903f-f8769a32da83,timestamp:1698327857\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2008\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,119 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2001\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,119 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2006.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:694bc1c3-9ab6-4f30-903f-f8769a32da83,timestamp:1698327857\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2008\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:17,120 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:01259183-c826-448b-a28d-c8fd70af6064,timestamp:1698327858\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1417.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:01259183-c826-448b-a28d-c8fd70af6064,timestamp:1698327858\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1419\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1419\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:18,543 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1419\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1419\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,542 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:18,543 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1998\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2000.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bd8fba4d-84f5-4d08-898c-e7764e763a57,timestamp:1698327860\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2001\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1998\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2000.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bd8fba4d-84f5-4d08-898c-e7764e763a57,timestamp:1698327860\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2001\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:20,547 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1676\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1678.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a644f871-697d-4259-9bde-452f42ed2477,timestamp:1698327862\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1679\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1676\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1678.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a644f871-697d-4259-9bde-452f42ed2477,timestamp:1698327862\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1679\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:22,230 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,758 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1520\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1523.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:48de9a19-245a-40fc-954d-20449de069d3,timestamp:1698327863\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1525\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,758 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1520\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1523.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:48de9a19-245a-40fc-954d-20449de069d3,timestamp:1698327863\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1525\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:23,759 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e360d3be-1500-4b8d-9767-5f0e97158f32,timestamp:1698327865\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:25,070 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1306\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1305.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e360d3be-1500-4b8d-9767-5f0e97158f32,timestamp:1698327865\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1307\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,069 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:25,070 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:10983be5-4d5b-48b4-8120-a8daea9062dd,timestamp:1698327866\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:26,725 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:10983be5-4d5b-48b4-8120-a8daea9062dd,timestamp:1698327866\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,724 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:26,725 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2022\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2028.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3768b1d0-7fd9-4f47-9f83-69e91b0b888f,timestamp:1698327868\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2030\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2022\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2028.39|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3768b1d0-7fd9-4f47-9f83-69e91b0b888f,timestamp:1698327868\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2030\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:28,757 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:30,116 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:30,116 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1356.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97c8aab8-4897-41c0-af09-793a3a4ec19a,timestamp:1698327870\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:30,117 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:30,117 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:30,117 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:30,117 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:30,116 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1356\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:30,116 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1356.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97c8aab8-4897-41c0-af09-793a3a4ec19a,timestamp:1698327870\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:30,117 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1358\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:30,117 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:30,117 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:30,117 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c31d1019-3381-44c2-a608-b0a64ff74b40,timestamp:1698327871\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:31,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1279\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1278.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c31d1019-3381-44c2-a608-b0a64ff74b40,timestamp:1698327871\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1279\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,399 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:31,400 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:215a128a-852c-4daf-949d-f0e90060ba16,timestamp:1698327872\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1286\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1285.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:215a128a-852c-4daf-949d-f0e90060ba16,timestamp:1698327872\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:32,689 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2e0b9dc9-0960-4227-9704-73626b9188df,timestamp:1698327873\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1297.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2e0b9dc9-0960-4227-9704-73626b9188df,timestamp:1698327873\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1298\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:33,990 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e9a8be8-bc96-4533-b2a7-9f0c5b080cc5,timestamp:1698327875\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6e9a8be8-bc96-4533-b2a7-9f0c5b080cc5,timestamp:1698327875\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:35,265 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2097\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2096.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9676d859-8480-4314-ad71-090bc12d58b6,timestamp:1698327877\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2097\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2097\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2096.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9676d859-8480-4314-ad71-090bc12d58b6,timestamp:1698327877\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2097\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:37,365 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50f21bc7-35ed-44a0-b2aa-18847e690876,timestamp:1698327879\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1637\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:50f21bc7-35ed-44a0-b2aa-18847e690876,timestamp:1698327879\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1637\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,005 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,006 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:39,006 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,006 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:39,006 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1800\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1799.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:654a7d04-be64-4ead-a689-0ffb4e27df24,timestamp:1698327880\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1801\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1800\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1799.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:654a7d04-be64-4ead-a689-0ffb4e27df24,timestamp:1698327880\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1801\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:40,809 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1652\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1651.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c6ed6abb-8b06-48f6-ad60-4705132e776c,timestamp:1698327882\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1652\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,470 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:42,470 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1652\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1651.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c6ed6abb-8b06-48f6-ad60-4705132e776c,timestamp:1698327882\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1652\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,469 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,470 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:42,470 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3b9f848a-8114-4f7b-aee5-1486359ae701,timestamp:1698327883\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:43,884 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1404\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1409.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3b9f848a-8114-4f7b-aee5-1486359ae701,timestamp:1698327883\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1410\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,883 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:43,884 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2434\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2434.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d120211-1921-4f46-9ee2-c4a5fe69d8cf,timestamp:1698327886\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2435\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2434\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2434.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d120211-1921-4f46-9ee2-c4a5fe69d8cf,timestamp:1698327886\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2435\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:46,322 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,951 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31644058227539|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548690795898438|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12761.84765625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1709\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1708.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ba96ed03-0158-4322-8dbc-d0b091191d4c,timestamp:1698327888\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1709\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,951 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31644058227539|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548690795898438|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12761.84765625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.140625|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327887\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1709\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1708.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ba96ed03-0158-4322-8dbc-d0b091191d4c,timestamp:1698327888\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1709\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:48,035 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1652\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff506ec9-8f4d-43af-b1a1-5e18a84c651e,timestamp:1698327889\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1652\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff506ec9-8f4d-43af-b1a1-5e18a84c651e,timestamp:1698327889\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:49,694 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c92fe9e2-b835-4d7c-b9a4-e6c9824e3552,timestamp:1698327890\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1286.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c92fe9e2-b835-4d7c-b9a4-e6c9824e3552,timestamp:1698327890\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1287\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1287\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:50,984 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:71bac16b-adee-47fa-8d92-a90b223becbc,timestamp:1698327892\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1241.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:71bac16b-adee-47fa-8d92-a90b223becbc,timestamp:1698327892\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:52,229 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1949\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1948.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:72ed463e-eadd-4a55-9e1c-286f963e662d,timestamp:1698327894\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1950\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1949\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1948.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:72ed463e-eadd-4a55-9e1c-286f963e662d,timestamp:1698327894\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1950\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:54,182 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,556 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1371\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1370.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ae784124-bc2d-4be6-b9e7-aa541c8244cb,timestamp:1698327895\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1372\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,556 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1371\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1370.71|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ae784124-bc2d-4be6-b9e7-aa541c8244cb,timestamp:1698327895\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1372\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:55,557 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1683\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1683\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1683.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:17649f45-32a6-4a62-8759-df86ab0ed3fc,timestamp:1698327897\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1683\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1683.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:17649f45-32a6-4a62-8759-df86ab0ed3fc,timestamp:1698327897\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,243 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1683\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:57,244 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,857 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1610\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1611\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,857 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1609.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:831faf89-9c78-4177-a6a0-91925ce76335,timestamp:1698327898\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,857 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1610\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1611\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,857 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1609.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:831faf89-9c78-4177-a6a0-91925ce76335,timestamp:1698327898\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:44:58,858 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b622a182-dfa4-401a-9cfa-a7ae4469bfa5,timestamp:1698327900\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1246\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1254.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b622a182-dfa4-401a-9cfa-a7ae4469bfa5,timestamp:1698327900\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:00,116 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,383 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,383 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9a65b04c-1368-4c4f-8efc-761d8d6f5665,timestamp:1698327901\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,383 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,383 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1263.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9a65b04c-1368-4c4f-8efc-761d8d6f5665,timestamp:1698327901\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1265\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:01,384 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:03,017 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97299a1e-ce4f-4640-9b70-5d52ec723ca7,timestamp:1698327903\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:03,017 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:03,017 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1631\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:03,018 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:03,018 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:03,018 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:03,017 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97299a1e-ce4f-4640-9b70-5d52ec723ca7,timestamp:1698327903\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:03,017 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:03,017 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1631\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:03,018 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:03,018 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:03,018 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1313.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:948ff0c3-80b8-4f19-b4df-9aebdccd0a60,timestamp:1698327904\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1314\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1313.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:948ff0c3-80b8-4f19-b4df-9aebdccd0a60,timestamp:1698327904\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,335 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1314\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:04,336 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1221\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1219.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b930f99-4ecb-432e-95de-1b04f0649fb8,timestamp:1698327905\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1221\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1221\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1219.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b930f99-4ecb-432e-95de-1b04f0649fb8,timestamp:1698327905\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1221\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:05,560 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9ba5e415-625b-4762-9a31-7e3de34a79c4,timestamp:1698327906\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1298.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9ba5e415-625b-4762-9a31-7e3de34a79c4,timestamp:1698327906\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1299\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:06,862 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1839\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1842\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1840.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bc78a0a9-a721-48d5-a1c9-f30521c6411d,timestamp:1698327908\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1839\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1842\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:08,707 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1840.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bc78a0a9-a721-48d5-a1c9-f30521c6411d,timestamp:1698327908\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8887d500-b324-4564-89ae-e2e3e3d8fbd5,timestamp:1698327910\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1655.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8887d500-b324-4564-89ae-e2e3e3d8fbd5,timestamp:1698327910\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:10,367 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2102\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2100.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d148bdc5-2e7b-4183-a114-4c133ae38b62,timestamp:1698327912\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2102\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2102\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2100.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d148bdc5-2e7b-4183-a114-4c133ae38b62,timestamp:1698327912\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2102\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:12,473 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,472 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:12,473 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1763\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1762.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b77466c-b116-43e2-8592-ac21ca83e288,timestamp:1698327914\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1764\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1763\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1762.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b77466c-b116-43e2-8592-ac21ca83e288,timestamp:1698327914\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1764\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:14,239 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,891 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1649\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,891 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0cc37087-1aae-4370-96d0-f121f5830a03,timestamp:1698327915\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,891 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1649\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,891 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1648.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0cc37087-1aae-4370-96d0-f121f5830a03,timestamp:1698327915\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:15,892 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7b21813a-0f58-4d04-9dd2-a8622743219d,timestamp:1698327917\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1255\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1253.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7b21813a-0f58-4d04-9dd2-a8622743219d,timestamp:1698327917\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:17,149 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:19,193 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2041\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:19,193 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2041\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:19,193 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:19,194 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:19,194 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:19,194 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2040.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1cb3dbc9-11e7-4ede-9ec0-a62777554f52,timestamp:1698327919\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:19,193 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2041\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:19,193 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2041\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:19,193 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:19,194 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:19,194 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:19,194 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2040.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1cb3dbc9-11e7-4ede-9ec0-a62777554f52,timestamp:1698327919\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:467f808c-a992-429e-9373-3473c0e7248b,timestamp:1698327920\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.2|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:467f808c-a992-429e-9373-3473c0e7248b,timestamp:1698327920\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:20,480 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,479 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:20,480 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:68e67ae0-3828-4246-b3f0-8004409a7547,timestamp:1698327921\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:68e67ae0-3828-4246-b3f0-8004409a7547,timestamp:1698327921\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:21,857 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a46be4fb-fcfd-4aec-b5a2-2d9d4d841d8c,timestamp:1698327923\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1249\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a46be4fb-fcfd-4aec-b5a2-2d9d4d841d8c,timestamp:1698327923\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:23,118 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1432\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1432\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1431.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:90dbc4f5-9943-4850-818c-8917da386bd4,timestamp:1698327924\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1432\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1432\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:24,553 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1431.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:90dbc4f5-9943-4850-818c-8917da386bd4,timestamp:1698327924\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1376.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:afbe553c-e7f4-4488-9993-ff80df21b7d4,timestamp:1698327925\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1377\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1377\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1376.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:afbe553c-e7f4-4488-9993-ff80df21b7d4,timestamp:1698327925\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1377\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:25,933 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1472\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1471.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d95b2e69-e21e-4e9b-b2b7-1e85c9ba9b29,timestamp:1698327927\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1473\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,408 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1472\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,408 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1471.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d95b2e69-e21e-4e9b-b2b7-1e85c9ba9b29,timestamp:1698327927\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1473\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:27,409 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,687 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,687 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c746094b-3350-49c9-9d75-a375836e0860,timestamp:1698327928\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,687 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,687 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.0|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c746094b-3350-49c9-9d75-a375836e0860,timestamp:1698327928\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:28,688 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:29,995 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:29,995 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1304\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:29,995 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:42a3abbc-ea6c-46ee-aa91-44c47b53bcc4,timestamp:1698327929\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:29,995 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:29,995 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:29,996 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:29,996 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:29,995 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.05|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:42a3abbc-ea6c-46ee-aa91-44c47b53bcc4,timestamp:1698327929\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:29,995 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:29,995 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:29,996 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:29,996 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,705 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1706\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1706.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e9497759-ffdc-466b-946f-1cca45be1856,timestamp:1698327931\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1708\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,705 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1706\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1706.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e9497759-ffdc-466b-946f-1cca45be1856,timestamp:1698327931\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1708\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:31,706 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1979\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1978.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2573ad1b-f816-44dc-a520-a00bb6dff4bc,timestamp:1698327933\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1980\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1979\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1978.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2573ad1b-f816-44dc-a520-a00bb6dff4bc,timestamp:1698327933\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1980\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:33,688 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a9fd7cc6-e237-4afa-bc95-e2d00710ec2c,timestamp:1698327935\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a9fd7cc6-e237-4afa-bc95-e2d00710ec2c,timestamp:1698327935\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:35,099 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,438 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1335.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5df395f8-16c4-40b7-ad3e-639d1f47fca7,timestamp:1698327936\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1337\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,438 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1335.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5df395f8-16c4-40b7-ad3e-639d1f47fca7,timestamp:1698327936\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1337\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:36,439 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1405\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1404.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3bb0ea3-74dc-41f9-896e-f186e1eeb347,timestamp:1698327937\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1406\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,849 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1405\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1404.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3bb0ea3-74dc-41f9-896e-f186e1eeb347,timestamp:1698327937\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1406\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,848 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,849 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:37,849 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:37,849 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1809\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1808.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cbdd7cf4-3ae6-48ca-abf7-6e16c2c58a32,timestamp:1698327939\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1809\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1809\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1808.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cbdd7cf4-3ae6-48ca-abf7-6e16c2c58a32,timestamp:1698327939\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1809\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:39,661 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2182\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2181.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ae03150e-f3f7-44e7-bea8-da1834d947f6,timestamp:1698327941\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2182\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2182\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2181.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ae03150e-f3f7-44e7-bea8-da1834d947f6,timestamp:1698327941\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2182\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:41,846 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,725 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1875\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1876\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1874.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d36f38d-ea8b-46c7-ba64-5029db298a2b,timestamp:1698327943\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,725 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1875\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1876\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1874.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d36f38d-ea8b-46c7-ba64-5029db298a2b,timestamp:1698327943\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:43,726 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2514\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2514.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a2c658a0-15b6-46c9-9a41-af2e8ee6b384,timestamp:1698327946\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2516\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2514\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2514.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a2c658a0-15b6-46c9-9a41-af2e8ee6b384,timestamp:1698327946\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2516\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:46,244 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1704.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ad67cfe1-e024-4944-8d60-906ff6bd63db,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,953 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31633377075195|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548797607421875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12761.95703125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.02734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1704.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ad67cfe1-e024-4944-8d60-906ff6bd63db,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,952 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,953 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31633377075195|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.548797607421875|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12761.95703125|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2473.02734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:47,992 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698327947\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d96bbf3-a9b7-4455-af5e-5889f0bfa362,timestamp:1698327949\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1277\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:49,233 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7d96bbf3-a9b7-4455-af5e-5889f0bfa362,timestamp:1698327949\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,716 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1480\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,716 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1479.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f9e2def-ac16-4b4b-bf2a-e85bc0c0008a,timestamp:1698327950\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,716 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1480\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,716 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1479.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f9e2def-ac16-4b4b-bf2a-e85bc0c0008a,timestamp:1698327950\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1481\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:50,717 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1647\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1646.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e0855fe7-b5cb-40bc-a08c-88f300be3038,timestamp:1698327952\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1647\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1646.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e0855fe7-b5cb-40bc-a08c-88f300be3038,timestamp:1698327952\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:52,367 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eed3fbbb-71d6-4e3c-a25b-343c11ee0151,timestamp:1698327953\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1619.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eed3fbbb-71d6-4e3c-a25b-343c11ee0151,timestamp:1698327953\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1620\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:53,990 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1728.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45a17be7-a81c-4664-a411-384b1274998d,timestamp:1698327955\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1728.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45a17be7-a81c-4664-a411-384b1274998d,timestamp:1698327955\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:55,722 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2490\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2489.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c51105cc-a84b-4db0-a5be-9bf10d10c8ed,timestamp:1698327958\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2491\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2490\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2489.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c51105cc-a84b-4db0-a5be-9bf10d10c8ed,timestamp:1698327958\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2491\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:58,215 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1645.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0ac4f379-61bb-44f9-8043-7e652b585c37,timestamp:1698327959\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1645.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0ac4f379-61bb-44f9-8043-7e652b585c37,timestamp:1698327959\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:45:59,865 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,864 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:45:59,865 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,671 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1803\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,671 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1803.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2a093a39-d7d1-4909-a91f-f0cfced85551,timestamp:1698327961\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1805\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,671 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1803\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,671 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1803.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2a093a39-d7d1-4909-a91f-f0cfced85551,timestamp:1698327961\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1805\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:01,672 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:03,727 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2052\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:03,727 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2051.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:96cc0bed-e547-4f36-9518-1a3afd748242,timestamp:1698327963\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:03,727 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2052\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:03,728 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:03,729 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:03,729 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:03,727 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2052\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:03,727 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2051.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:96cc0bed-e547-4f36-9518-1a3afd748242,timestamp:1698327963\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:03,727 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2052\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:03,728 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:03,729 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:03,729 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,958 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,958 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cae178c8-f000-4367-b900-9e5e8ae23e2b,timestamp:1698327964\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,958 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1224\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,958 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1226.04|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cae178c8-f000-4367-b900-9e5e8ae23e2b,timestamp:1698327964\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1228\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:04,959 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1082b815-9c31-4301-ae6b-112ff8f8fea7,timestamp:1698327966\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1406.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1082b815-9c31-4301-ae6b-112ff8f8fea7,timestamp:1698327966\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:06,370 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1424\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1423.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a65c50c7-e738-4d2c-a48d-7d630fece047,timestamp:1698327967\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1425\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,799 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:07,800 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1424\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1423.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a65c50c7-e738-4d2c-a48d-7d630fece047,timestamp:1698327967\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1425\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,798 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,799 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:07,800 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:522ba232-192d-46be-b621-f25e54a062a5,timestamp:1698327969\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1335\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1334.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:522ba232-192d-46be-b621-f25e54a062a5,timestamp:1698327969\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1336\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:09,137 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1644\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1642.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:632341bc-8ed5-4da9-b20d-5d4ab3324ac2,timestamp:1698327970\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1644\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1644\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1642.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:632341bc-8ed5-4da9-b20d-5d4ab3324ac2,timestamp:1698327970\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1644\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:10,784 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:efbec117-5397-4824-8f98-59042ca9a3a4,timestamp:1698327972\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1294\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1293.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:efbec117-5397-4824-8f98-59042ca9a3a4,timestamp:1698327972\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1294\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:12,081 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff0c2855-e93c-48a1-b92b-e27240e87928,timestamp:1698327973\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,341 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:13,341 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1255.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff0c2855-e93c-48a1-b92b-e27240e87928,timestamp:1698327973\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,340 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,341 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:13,341 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:14,594 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:14,594 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:14,594 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5dfa7a13-ade3-415b-bdcd-5f2703d75f54,timestamp:1698327974\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:14,594 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:14,595 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:14,595 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:14,594 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:14,594 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:14,594 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5dfa7a13-ade3-415b-bdcd-5f2703d75f54,timestamp:1698327974\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:14,594 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:14,595 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:14,595 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1347\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:847423d8-5eb7-46a7-bf90-05d13c132bec,timestamp:1698327975\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1347\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1347\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1345.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:847423d8-5eb7-46a7-bf90-05d13c132bec,timestamp:1698327975\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1347\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:15,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1712.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1a29813-24ec-4bfa-b558-536ea0b7a375,timestamp:1698327977\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1712.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d1a29813-24ec-4bfa-b558-536ea0b7a375,timestamp:1698327977\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:17,660 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,983 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6100ba07-f012-4999-93ee-32c789225771,timestamp:1698327978\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,983 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,983 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1319.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6100ba07-f012-4999-93ee-32c789225771,timestamp:1698327978\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,983 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1320\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1321\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:18,984 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1688\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1687.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b9c96e1-7660-4d75-b7ae-3927c90104fd,timestamp:1698327980\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1688\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1687.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b9c96e1-7660-4d75-b7ae-3927c90104fd,timestamp:1698327980\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,675 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:20,676 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,110 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1431\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1431.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aff042f3-6adc-4027-a341-80753ca56f95,timestamp:1698327982\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1433\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,110 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1431\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1431.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aff042f3-6adc-4027-a341-80753ca56f95,timestamp:1698327982\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1433\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:22,111 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,775 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1661\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,775 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b068d87-f920-40f9-a8d7-5e0581991122,timestamp:1698327983\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,775 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1661\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,775 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1661.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0b068d87-f920-40f9-a8d7-5e0581991122,timestamp:1698327983\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1663\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:23,776 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1739\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1738.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4691a9c4-c5e4-4459-b697-efb296fd2ce1,timestamp:1698327985\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1740\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1739\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1738.62|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4691a9c4-c5e4-4459-b697-efb296fd2ce1,timestamp:1698327985\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1740\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:25,518 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1436\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:df6b44fd-98c1-4f8b-bd20-de9ba00c91a2,timestamp:1698327986\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1436\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1436.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:df6b44fd-98c1-4f8b-bd20-de9ba00c91a2,timestamp:1698327986\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1438\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:26,959 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,323 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1361\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,323 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1360.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cda953a3-c6fe-4bea-bd6b-4c05cc66453e,timestamp:1698327988\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1362\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,323 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1361\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,323 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1360.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cda953a3-c6fe-4bea-bd6b-4c05cc66453e,timestamp:1698327988\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1362\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:28,324 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1791\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1791.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fad758a8-6123-4328-b67f-ceaa198f6b41,timestamp:1698327990\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1792\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1791\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1791.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fad758a8-6123-4328-b67f-ceaa198f6b41,timestamp:1698327990\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1792\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:30,118 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:79a91ad3-950f-490e-8edf-61a12d6803b7,timestamp:1698327991\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:31,363 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1240\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1241\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1239.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:79a91ad3-950f-490e-8edf-61a12d6803b7,timestamp:1698327991\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,362 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:31,363 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1669.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c71aa92c-f0eb-45f1-9c09-01a1a9625845,timestamp:1698327993\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1671\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1669.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c71aa92c-f0eb-45f1-9c09-01a1a9625845,timestamp:1698327993\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1671\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1671\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:33,036 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2076\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2074.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8e6817cc-f5f4-4045-a439-fedf6a033e01,timestamp:1698327995\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2076\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2076\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2074.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8e6817cc-f5f4-4045-a439-fedf6a033e01,timestamp:1698327995\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2076\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:35,115 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:88230441-fd7b-435e-b074-5afee69b6f98,timestamp:1698327996\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1393\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1393\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1392.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:88230441-fd7b-435e-b074-5afee69b6f98,timestamp:1698327996\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1393\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:36,511 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1692\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1691.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f09790d-00c6-490d-8b8a-0261fc8afbaf,timestamp:1698327998\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1692\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1692\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1691.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3f09790d-00c6-490d-8b8a-0261fc8afbaf,timestamp:1698327998\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1692\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:38,206 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53cf8b49-d7dc-4d0c-83b8-d1c6ee577590,timestamp:1698327999\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1649.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53cf8b49-d7dc-4d0c-83b8-d1c6ee577590,timestamp:1698327999\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1650\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,859 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,860 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:39,860 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,860 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:39,860 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1372.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:29406f05-92e2-419e-ad15-f598ae314145,timestamp:1698328001\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1372.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:29406f05-92e2-419e-ad15-f598ae314145,timestamp:1698328001\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1373\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:41,235 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1761\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1760.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c129478f-300d-45d8-8c8f-ae6865e12456,timestamp:1698328002\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1761\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1761\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1760.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c129478f-300d-45d8-8c8f-ae6865e12456,timestamp:1698328002\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1761\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:42,999 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2218.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2b363583-4d32-4b02-9cb6-8fa3e57f38e5,timestamp:1698328005\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2218.17|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2b363583-4d32-4b02-9cb6-8fa3e57f38e5,timestamp:1698328005\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:45,221 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f08aaf3-59a6-4d9e-b867-f3e6103552d6,timestamp:1698328006\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,633 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:46,633 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1407.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f08aaf3-59a6-4d9e-b867-f3e6103552d6,timestamp:1698328006\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1408\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,632 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,633 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:46,633 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31623458862305|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548896789550781|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12759.296875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2475.66796875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,366 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,366 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1727.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:34172272-d91c-4223-b424-ca9721c92582,timestamp:1698328008\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.31623458862305|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548896789550781|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12759.296875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2475.66796875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:47,953 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328007\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,366 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1728\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,366 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1727.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:34172272-d91c-4223-b424-ca9721c92582,timestamp:1698328008\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:48,367 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2485\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2485.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bb9e5c91-df21-495b-9681-e6601f7c35c5,timestamp:1698328010\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2486\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2485\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2485.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bb9e5c91-df21-495b-9681-e6601f7c35c5,timestamp:1698328010\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2486\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:50,855 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d5ba71de-a7b3-455b-bb72-2443c3a04278,timestamp:1698328012\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:52,517 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1657.33|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d5ba71de-a7b3-455b-bb72-2443c3a04278,timestamp:1698328012\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:52,516 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:52,517 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:03ad77c2-68ce-41a7-8d4c-e414c6326339,timestamp:1698328013\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1257\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1256.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:03ad77c2-68ce-41a7-8d4c-e414c6326339,timestamp:1698328013\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:53,777 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2082\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2081.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d5002e1-ba94-444b-8029-68085bcdcb80,timestamp:1698328015\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2082\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2082\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2081.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3d5002e1-ba94-444b-8029-68085bcdcb80,timestamp:1698328015\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2082\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:55,862 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28515402-0967-43c5-be26-c6a76c9f14b0,timestamp:1698328017\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1631.38|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28515402-0967-43c5-be26-c6a76c9f14b0,timestamp:1698328017\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:57,497 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,762 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9a430ee7-d6c3-4618-818f-e6baacbf06e4,timestamp:1698328018\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,762 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1261.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9a430ee7-d6c3-4618-818f-e6baacbf06e4,timestamp:1698328018\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,762 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,762 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1262\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1262\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:46:58,763 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1776\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1776.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7f1a63c0-1a67-4456-9a0b-834eb5254fa9,timestamp:1698328020\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1777\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:00,543 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1776\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1776.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7f1a63c0-1a67-4456-9a0b-834eb5254fa9,timestamp:1698328020\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1777\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,542 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:00,543 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2021\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2020.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3bfaa217-dfa6-44ce-8e93-2c2b8948cd98,timestamp:1698328022\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2021\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2021\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2020.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3bfaa217-dfa6-44ce-8e93-2c2b8948cd98,timestamp:1698328022\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2021\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:02,567 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1652.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1a645e24-2837-4b85-a1ca-8706f906917a,timestamp:1698328024\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1653\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:04,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1653\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1652.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1a645e24-2837-4b85-a1ca-8706f906917a,timestamp:1698328024\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1653\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,223 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:04,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b9dc79cd-c6b5-46ea-adb3-da695785528d,timestamp:1698328025\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b9dc79cd-c6b5-46ea-adb3-da695785528d,timestamp:1698328025\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,909 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:05,909 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,908 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,909 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:05,909 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.46|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c0677412-46c8-4a1d-bcea-67683f6a5bf2,timestamp:1698328027\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1268\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.46|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c0677412-46c8-4a1d-bcea-67683f6a5bf2,timestamp:1698328027\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1269\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:07,180 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.42|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c431ba7-71fa-40c2-9deb-4c6be0a6957a,timestamp:1698328028\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.42|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8c431ba7-71fa-40c2-9deb-4c6be0a6957a,timestamp:1698328028\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:08,454 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:306575b1-1b81-48c7-97ae-61ae94d44a09,timestamp:1698328030\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1672.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:306575b1-1b81-48c7-97ae-61ae94d44a09,timestamp:1698328030\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1673\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:10,130 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1398\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1397.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:41fc8ca7-bdae-4d58-8ae9-f8e93c4b8ab6,timestamp:1698328031\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:11,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1398\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1397.87|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:41fc8ca7-bdae-4d58-8ae9-f8e93c4b8ab6,timestamp:1698328031\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1398\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,531 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,532 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:11,532 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.98|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:462816c7-2c02-41ad-80a7-b195708f2bfc,timestamp:1698328032\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1359\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1359\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:12,894 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1357.98|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:462816c7-2c02-41ad-80a7-b195708f2bfc,timestamp:1698328032\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1359\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1359\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,893 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:12,894 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,969 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2072.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d3e12233-bb37-4500-b49d-ea6ed69f3765,timestamp:1698328034\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,969 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2073\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2074\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,969 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2072.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d3e12233-bb37-4500-b49d-ea6ed69f3765,timestamp:1698328034\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,969 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2073\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2074\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:14,970 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3be41809-2898-4a3c-a72b-46b4b2388abc,timestamp:1698328036\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,248 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:16,248 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1274\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1273.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3be41809-2898-4a3c-a72b-46b4b2388abc,timestamp:1698328036\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,247 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,248 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:16,248 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2133\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2132.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a5992371-3688-4329-87a2-456fe24155cb,timestamp:1698328038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2133\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2133\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2132.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a5992371-3688-4329-87a2-456fe24155cb,timestamp:1698328038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2133\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:18,383 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a5ffc720-defe-47f6-9b01-a50a7f3c3b1c,timestamp:1698328040\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1654\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1654\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1653.26|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a5ffc720-defe-47f6-9b01-a50a7f3c3b1c,timestamp:1698328040\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1654\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:20,040 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1336.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ca6a36b7-b7d0-4570-84a7-efac4051879e,timestamp:1698328041\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1336.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ca6a36b7-b7d0-4570-84a7-efac4051879e,timestamp:1698328041\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:21,381 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:23,565 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2172\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:23,565 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2175.79|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:42b8a862-e220-49a7-b8f5-5cbca6d8bf59,timestamp:1698328043\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:23,566 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2177\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:23,567 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:23,565 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2172\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:23,565 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2175.79|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:42b8a862-e220-49a7-b8f5-5cbca6d8bf59,timestamp:1698328043\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:23,566 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2177\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:23,567 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:23,567 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:23,567 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:23,567 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:23,567 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6bfbdd85-d207-483d-8700-65306b3d5374,timestamp:1698328045\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.84|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6bfbdd85-d207-483d-8700-65306b3d5374,timestamp:1698328045\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1649\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:25,219 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1696.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:95b4ad59-0b82-4d3c-ac1c-47b16e852469,timestamp:1698328046\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1696.55|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:95b4ad59-0b82-4d3c-ac1c-47b16e852469,timestamp:1698328046\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:26,920 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2025\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2028.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ce9abb94-3a95-41dc-baa0-1b8a34716249,timestamp:1698328048\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2029\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2025\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2028.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ce9abb94-3a95-41dc-baa0-1b8a34716249,timestamp:1698328048\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2029\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:28,952 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1310.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3674ad6a-998a-44e7-a159-7f1e513f3430,timestamp:1698328050\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,265 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1309\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1310.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3674ad6a-998a-44e7-a159-7f1e513f3430,timestamp:1698328050\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1311\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:30,266 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d9e3f92c-1390-475f-aa2c-9b3b4d8ed64f,timestamp:1698328051\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1244.35|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d9e3f92c-1390-475f-aa2c-9b3b4d8ed64f,timestamp:1698328051\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1246\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:31,514 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1665.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:38a89644-6bed-407d-b775-d28fce74b633,timestamp:1698328053\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1667\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1662\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1665.85|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:38a89644-6bed-407d-b775-d28fce74b633,timestamp:1698328053\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1667\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:33,183 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:34,864 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:34,864 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1677.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e5a6dbca-e3ad-486e-b0c5-e733d0ced63c,timestamp:1698328054\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:34,864 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:34,866 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:34,866 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:34,866 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:34,864 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1678\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:34,864 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1677.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e5a6dbca-e3ad-486e-b0c5-e733d0ced63c,timestamp:1698328054\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:34,864 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1678\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:34,866 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:34,866 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:34,866 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2025\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2024.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:411a8d01-ddcf-4a31-bcd0-5e37ff88f619,timestamp:1698328056\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2026\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2025\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2024.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:411a8d01-ddcf-4a31-bcd0-5e37ff88f619,timestamp:1698328056\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2026\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:36,894 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1760\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1759.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1647af25-7c5b-4089-ad77-ab4e083f6628,timestamp:1698328058\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1760\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1760\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1759.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1647af25-7c5b-4089-ad77-ab4e083f6628,timestamp:1698328058\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1760\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:38,658 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1644\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1644.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:87b132e8-c347-491b-a36d-cbbfe4f65061,timestamp:1698328060\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1646\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1644\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1644.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:87b132e8-c347-491b-a36d-cbbfe4f65061,timestamp:1698328060\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,307 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1646\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:40,308 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1725\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:43e62af7-d04b-4677-ad6f-4fedd851f608,timestamp:1698328062\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1727\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1725\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1726.03|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:43e62af7-d04b-4677-ad6f-4fedd851f608,timestamp:1698328062\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1727\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:42,037 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1627.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:166e63fe-93ce-441f-966a-86258febea99,timestamp:1698328063\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,669 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:43,669 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1627.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:166e63fe-93ce-441f-966a-86258febea99,timestamp:1698328063\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,668 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,669 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:43,669 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:45,310 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:45,310 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:91152279-e254-4b4e-96d9-5443a0c97c53,timestamp:1698328065\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:45,310 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:45,310 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:45,311 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:45,311 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:45,310 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:45,310 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1636.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:91152279-e254-4b4e-96d9-5443a0c97c53,timestamp:1698328065\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:45,310 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1639\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:45,310 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:45,311 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:45,311 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0a2c78a0-dd1f-4155-b7e5-6b9c8e70747d,timestamp:1698328066\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1283\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1282.36|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0a2c78a0-dd1f-4155-b7e5-6b9c8e70747d,timestamp:1698328066\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1284\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:46,597 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.3161506652832|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548980712890625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12754.734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,958 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2480.26171875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:47,958 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1721\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1722.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97fff8af-fbd3-4d40-a2a5-101e1110d388,timestamp:1698328068\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1723\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskAvailable.Gigabytes:47.3161506652832|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskUsage.Gigabytes:8.548980712890625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,957 [INFO ] pool-2-thread-1 TS_METRICS - MemoryAvailable.Megabytes:12754.734375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,958 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUsed.Megabytes:2480.26171875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:47,958 [INFO ] pool-2-thread-1 TS_METRICS - MemoryUtilization.Percent:18.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328067\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1721\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1722.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:97fff8af-fbd3-4d40-a2a5-101e1110d388,timestamp:1698328068\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1723\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:48,323 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0fd44ff0-4483-4ba3-a1e6-acefb24b3d0d,timestamp:1698328069\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:49,557 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1230\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1229.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0fd44ff0-4483-4ba3-a1e6-acefb24b3d0d,timestamp:1698328069\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1230\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,556 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:49,557 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1621\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1621.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5111199b-ccba-4568-8042-8f125491b3ec,timestamp:1698328071\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1621\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1621.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5111199b-ccba-4568-8042-8f125491b3ec,timestamp:1698328071\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1625\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1625\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:51,184 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1679\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:06b6e261-5c20-425d-8bdf-85e85ce2c5a3,timestamp:1698328072\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1681\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1679\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1680.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:06b6e261-5c20-425d-8bdf-85e85ce2c5a3,timestamp:1698328072\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1681\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:52,869 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,157 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,157 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0fb382f8-3721-4070-9b9c-b84c956ddeb3,timestamp:1698328074\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,157 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1285\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,157 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1284.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0fb382f8-3721-4070-9b9c-b84c956ddeb3,timestamp:1698328074\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1286\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:54,158 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1502\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9307db9a-0417-4cfa-b6df-a37bdbdb6a2c,timestamp:1698328075\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1503\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1502\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1502.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9307db9a-0417-4cfa-b6df-a37bdbdb6a2c,timestamp:1698328075\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,663 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1503\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:55,664 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1617\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1616.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5789fc61-dff2-4789-be53-d9b12fc516c4,timestamp:1698328077\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1617\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1617\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1616.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5789fc61-dff2-4789-be53-d9b12fc516c4,timestamp:1698328077\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1617\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:57,283 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2117\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2117\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2116.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:05886aa8-e3c0-4778-9748-e4f338f937ec,timestamp:1698328079\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2117\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2116.51|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:05886aa8-e3c0-4778-9748-e4f338f937ec,timestamp:1698328079\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2117\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:47:59,403 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1763\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1762.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cd684da6-b0dc-49eb-998b-fa79773685cb,timestamp:1698328081\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1763\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1763\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1762.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cd684da6-b0dc-49eb-998b-fa79773685cb,timestamp:1698328081\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1763\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:01,169 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2126\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2125.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a4293816-5ccb-4f62-9e10-f057efc4ceb7,timestamp:1698328083\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2126\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2126\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2125.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a4293816-5ccb-4f62-9e10-f057efc4ceb7,timestamp:1698328083\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2126\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:03,298 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,613 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,613 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1312.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4aabfbad-5f34-46f1-ac5e-f6649ff0ab10,timestamp:1698328084\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1314\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,613 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1312\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,613 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1312.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4aabfbad-5f34-46f1-ac5e-f6649ff0ab10,timestamp:1698328084\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1314\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:04,614 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d0b6ad65-c62d-433a-b3fd-393967784381,timestamp:1698328086\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:06,258 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1632\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1639.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d0b6ad65-c62d-433a-b3fd-393967784381,timestamp:1698328086\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,257 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:06,258 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:9|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:85a25488-8a50-4726-a4fa-c04945cc6131,timestamp:1698328087\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1276\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1275.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:85a25488-8a50-4726-a4fa-c04945cc6131,timestamp:1698328087\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1276\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:07,536 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:da9c29dd-1ebe-4771-82c0-abf4db848320,timestamp:1698328088\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,810 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:08,810 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1269.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:da9c29dd-1ebe-4771-82c0-abf4db848320,timestamp:1698328088\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1270\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,809 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,810 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:08,810 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1804\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1802.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c82bd738-0feb-462f-a296-55f5f8b52e53,timestamp:1698328090\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1804\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1804\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1802.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c82bd738-0feb-462f-a296-55f5f8b52e53,timestamp:1698328090\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1804\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:10,616 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1340.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:71dc37ee-8e42-4797-ac8b-0a1295ad0378,timestamp:1698328091\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1342\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1340\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1340.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:71dc37ee-8e42-4797-ac8b-0a1295ad0378,timestamp:1698328091\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1342\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:11,960 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff2d9a01-bcd1-4761-8e5e-fdcc37fdd82c,timestamp:1698328093\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,263 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:13,263 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1300\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1299.41|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ff2d9a01-bcd1-4761-8e5e-fdcc37fdd82c,timestamp:1698328093\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1300\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,262 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,263 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:13,263 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1648\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.4|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eac6a4eb-37f8-45a8-ba82-d695fef8e7a2,timestamp:1698328094\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1648\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:14,913 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1647.4|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eac6a4eb-37f8-45a8-ba82-d695fef8e7a2,timestamp:1698328094\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1843\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1841.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:38fb106f-f452-4ea4-9ff3-5f60c0a86049,timestamp:1698328096\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1843\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1843\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1841.93|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:38fb106f-f452-4ea4-9ff3-5f60c0a86049,timestamp:1698328096\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1843\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:16,759 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a7a2bdf0-e14a-404d-b17c-0f6092937f8a,timestamp:1698328098\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1252\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1251.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a7a2bdf0-e14a-404d-b17c-0f6092937f8a,timestamp:1698328098\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:18,014 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1925\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1925\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1924.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:906eba8d-454b-4afa-a1b7-a124e043e116,timestamp:1698328099\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1925\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1925\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1924.47|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:906eba8d-454b-4afa-a1b7-a124e043e116,timestamp:1698328099\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:19,944 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:24f5a470-da46-452e-9521-ec995ea1dca4,timestamp:1698328101\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1260.49|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:24f5a470-da46-452e-9521-ec995ea1dca4,timestamp:1698328101\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:21,208 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f8375d1c-a009-4f67-8c9c-150f14d8c450,timestamp:1698328102\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1258.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f8375d1c-a009-4f67-8c9c-150f14d8c450,timestamp:1698328102\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,470 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:22,471 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ee0bfd69-0284-4ff5-9318-8bd087717b17,timestamp:1698328103\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:23,742 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1267\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1267.11|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ee0bfd69-0284-4ff5-9318-8bd087717b17,timestamp:1698328103\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1268\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,741 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:23,742 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1325.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6b75fd1b-332f-43f2-afbf-5871a66d8de2,timestamp:1698328105\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:25,071 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1325.81|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6b75fd1b-332f-43f2-afbf-5871a66d8de2,timestamp:1698328105\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1633\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1632.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0dc05e73-a210-49c0-8d4d-20c6e0e0395c,timestamp:1698328106\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1633\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1633\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1632.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0dc05e73-a210-49c0-8d4d-20c6e0e0395c,timestamp:1698328106\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1633\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:26,707 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e2b3c58f-297a-4de9-b093-ae24f5c46639,timestamp:1698328108\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1291\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1291\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1290.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e2b3c58f-297a-4de9-b093-ae24f5c46639,timestamp:1698328108\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1291\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:28,001 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ba48cf02-d0f2-4065-a282-240680945afb,timestamp:1698328109\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ba48cf02-d0f2-4065-a282-240680945afb,timestamp:1698328109\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:29,309 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f8e8b54e-4384-4bf4-ad1f-6c2d80628ff5,timestamp:1698328110\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.52|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f8e8b54e-4384-4bf4-ad1f-6c2d80628ff5,timestamp:1698328110\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:30,969 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2560\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2559.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7e970ab-1a2f-4bbf-95a7-1d0276b30037,timestamp:1698328113\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2560\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2560\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2559.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7e970ab-1a2f-4bbf-95a7-1d0276b30037,timestamp:1698328113\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2560\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:33,532 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2124\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2124.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fe0389e3-2390-451c-a937-f6a682c7d1c2,timestamp:1698328115\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2125\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2124\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2124.12|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fe0389e3-2390-451c-a937-f6a682c7d1c2,timestamp:1698328115\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2125\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:35,660 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f63fdc4-ab4c-46dd-ac7a-e42aee46269a,timestamp:1698328117\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1374\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1373.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4f63fdc4-ab4c-46dd-ac7a-e42aee46269a,timestamp:1698328117\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1375\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:37,037 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:39,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2230\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:39,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2230.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:86e679ce-4494-456f-85a4-43eb6ff96bcd,timestamp:1698328119\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:39,270 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2230\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:39,271 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:39,271 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:39,271 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:39,270 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2230\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:39,270 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2230.06|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:86e679ce-4494-456f-85a4-43eb6ff96bcd,timestamp:1698328119\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:39,270 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2230\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:39,271 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:39,271 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:39,271 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1696.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5a289724-1e19-4edf-819d-02ff1cd72f48,timestamp:1698328120\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1697\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1696.82|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5a289724-1e19-4edf-819d-02ff1cd72f48,timestamp:1698328120\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1698\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:40,971 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2037.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d884646-0e5e-4160-8e6a-5cd2dcb8a3d1,timestamp:1698328123\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2038\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2037.94|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d884646-0e5e-4160-8e6a-5cd2dcb8a3d1,timestamp:1698328123\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2038\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:43,012 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:13bb89e0-27fb-42fe-960e-0baa9f90f456,timestamp:1698328124\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1243\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1242.19|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:13bb89e0-27fb-42fe-960e-0baa9f90f456,timestamp:1698328124\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1243\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:44,258 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1403\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1401.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2d909855-9787-469d-86c6-b075d81d42ed,timestamp:1698328125\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1403\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1403\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1401.91|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2d909855-9787-469d-86c6-b075d81d42ed,timestamp:1698328125\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1403\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:45,665 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2326\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2325.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ec9fa40f-c2bd-47a9-8b3b-af731d4341ce,timestamp:1698328127\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2327\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,002 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3160514831543|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2326\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2325.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ec9fa40f-c2bd-47a9-8b3b-af731d4341ce,timestamp:1698328127\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2327\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:47,994 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,002 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.3160514831543|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.549079895019531|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12750.0546875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2484.9453125|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:48,004 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.549079895019531|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12750.0546875|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,003 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2484.9453125|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:48,004 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:c449b28b682c,timestamp:1698328128\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1672\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:067a0130-863e-4c17-a27b-ec0cd7e63808,timestamp:1698328129\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1672\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1672\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1671.3|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:067a0130-863e-4c17-a27b-ec0cd7e63808,timestamp:1698328129\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1672\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:49,669 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2059\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2062.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f6406dd-a5c7-473b-beec-1ac0ec942496,timestamp:1698328131\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2064\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2059\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2062.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0f6406dd-a5c7-473b-beec-1ac0ec942496,timestamp:1698328131\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2064\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:51,737 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2069\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2070.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eed8cf8d-3c28-4aec-b96d-828421f156ff,timestamp:1698328133\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2072\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2069\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2070.65|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:eed8cf8d-3c28-4aec-b96d-828421f156ff,timestamp:1698328133\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2072\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:53,811 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:55,164 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:55,164 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c4232acc-db5a-44b8-8178-1a0be9a45486,timestamp:1698328135\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:55,164 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:55,165 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:55,165 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:55,165 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:55,164 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:55,164 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c4232acc-db5a-44b8-8178-1a0be9a45486,timestamp:1698328135\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:55,164 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:55,165 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:55,165 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:55,165 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1627\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1627.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ce1ad4b5-8cd0-42d7-8d3a-b469d22d5bec,timestamp:1698328136\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,797 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:56,797 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1627.1|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ce1ad4b5-8cd0-42d7-8d3a-b469d22d5bec,timestamp:1698328136\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1628\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,796 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,797 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:56,797 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2429\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2428.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b655e281-0061-40cc-a14d-c6f02179b60f,timestamp:1698328139\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2429\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2428.57|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b655e281-0061-40cc-a14d-c6f02179b60f,timestamp:1698328139\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2429\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,229 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:48:59,229 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2429\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,229 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:48:59,229 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52aa3cfe-bd27-401c-88ec-8bd5699b3fc3,timestamp:1698328140\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,582 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,581 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1350\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,581 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1349.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52aa3cfe-bd27-401c-88ec-8bd5699b3fc3,timestamp:1698328140\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,582 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1351\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:00,583 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2114\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2112.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:846ee9b5-2cd1-45a1-bf48-27b303f64133,timestamp:1698328142\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2114\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2114\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2112.96|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:846ee9b5-2cd1-45a1-bf48-27b303f64133,timestamp:1698328142\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2114\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:02,700 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2002cef4-fa14-4f36-9bd3-fd082324adee,timestamp:1698328143\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2002cef4-fa14-4f36-9bd3-fd082324adee,timestamp:1698328143\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:03,947 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e00cba96-4bc3-4bf6-9204-29842b1f2ef8,timestamp:1698328145\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1655\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1654.7|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e00cba96-4bc3-4bf6-9204-29842b1f2ef8,timestamp:1698328145\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1656\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:05,606 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2092\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2093\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2092\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2093\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2091.8|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5f339fa5-7c8d-439a-91d7-7fd8d885e8bf,timestamp:1698328147\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2091.8|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5f339fa5-7c8d-439a-91d7-7fd8d885e8bf,timestamp:1698328147\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:07,701 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2105\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2105\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2104.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1c44814f-ddfa-4a8d-865e-6f685a2bd269,timestamp:1698328149\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2105\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2105\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2104.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1c44814f-ddfa-4a8d-865e-6f685a2bd269,timestamp:1698328149\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:09,810 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2039\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2039\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2038.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7a0d2cf8-c62e-45c1-9448-a66268d91f24,timestamp:1698328151\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2039\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2039\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2038.21|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:7a0d2cf8-c62e-45c1-9448-a66268d91f24,timestamp:1698328151\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:11,857 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1364\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e1a7de69-da04-41b7-ba33-983fef97a9e9,timestamp:1698328153\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1364\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1362.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e1a7de69-da04-41b7-ba33-983fef97a9e9,timestamp:1698328153\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1364\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:13,228 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1362\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1362\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1361.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9dcfeda0-0292-47d5-83cf-dfc64c4a6c0c,timestamp:1698328154\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1362\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1362\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1361.92|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9dcfeda0-0292-47d5-83cf-dfc64c4a6c0c,timestamp:1698328154\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:14,593 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2105\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2105\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2103.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dd0f1728-2241-4464-9394-82d6c311c1d6,timestamp:1698328156\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2105\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2105\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2103.89|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dd0f1728-2241-4464-9394-82d6c311c1d6,timestamp:1698328156\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:16,701 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1808\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1807.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:649c5068-0a79-4cfe-957d-e61ae309ef7c,timestamp:1698328158\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1808\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1808\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1807.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:649c5068-0a79-4cfe-957d-e61ae309ef7c,timestamp:1698328158\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1808\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:18,512 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2139\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2138.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cb579f91-2955-443c-a564-1d6194d9894b,timestamp:1698328160\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2139\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:20,654 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2139\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2138.25|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cb579f91-2955-443c-a564-1d6194d9894b,timestamp:1698328160\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2139\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,653 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:20,654 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2806\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2805.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6b1550ec-8e96-4df5-98dd-04dd0f851604,timestamp:1698328163\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2806\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2806\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2805.16|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6b1550ec-8e96-4df5-98dd-04dd0f851604,timestamp:1698328163\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2806\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:23,462 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2538\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2537.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:47ca7921-0f09-430e-8628-d3748131ed12,timestamp:1698328166\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2539\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:26,004 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2538\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2537.61|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:47ca7921-0f09-430e-8628-d3748131ed12,timestamp:1698328166\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2539\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,003 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:26,004 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8da55ed8-b346-4404-9ffb-ae6f2b2e966c,timestamp:1698328167\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1245.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8da55ed8-b346-4404-9ffb-ae6f2b2e966c,timestamp:1698328167\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:27,253 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:28,527 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:28,527 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:61bffbfc-3a08-4ea1-bfe2-6c1a9839791f,timestamp:1698328168\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:28,527 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:28,527 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:28,528 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:28,528 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:28,527 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:28,527 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1271.22|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:61bffbfc-3a08-4ea1-bfe2-6c1a9839791f,timestamp:1698328168\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:28,527 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:28,527 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:28,528 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:28,528 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1703\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1702.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3fddbbb5-9340-42bd-8799-65674ea04d2e,timestamp:1698328170\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1704\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1703\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1702.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3fddbbb5-9340-42bd-8799-65674ea04d2e,timestamp:1698328170\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1704\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:30,234 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1710\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1711\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1709.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53d22a03-0eb7-4f45-b50a-32580f3d358e,timestamp:1698328171\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1710\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1711\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1709.44|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53d22a03-0eb7-4f45-b50a-32580f3d358e,timestamp:1698328171\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:31,947 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:202190b7-b1c5-41ca-9826-1e0c79a8262e,timestamp:1698328173\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1629\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1630\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,579 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1629.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:202190b7-b1c5-41ca-9826-1e0c79a8262e,timestamp:1698328173\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:33,580 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1390\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1390\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,973 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,973 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1389.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d27f0dd-6743-4cd9-8d35-7f7c73e18e77,timestamp:1698328174\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1390\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1390\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,973 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,973 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:34,972 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1389.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:0d27f0dd-6743-4cd9-8d35-7f7c73e18e77,timestamp:1698328174\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1668.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45e61b9c-6f75-49ab-9836-f9f4d9db15bc,timestamp:1698328176\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1670\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1668.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:45e61b9c-6f75-49ab-9836-f9f4d9db15bc,timestamp:1698328176\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1670\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:36,645 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:38,330 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:38,330 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1682.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:376674a3-f425-4679-80ca-15a33f87cd94,timestamp:1698328178\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:38,331 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1684\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:38,331 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:38,331 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:38,331 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:38,330 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:38,330 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1682.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:376674a3-f425-4679-80ca-15a33f87cd94,timestamp:1698328178\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:38,331 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1684\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:38,331 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:38,331 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:38,331 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,596 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2263\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2262.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ecdc8fe5-1dda-4bb0-9097-1d392acb5fe0,timestamp:1698328180\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,596 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2263\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2262.53|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:ecdc8fe5-1dda-4bb0-9097-1d392acb5fe0,timestamp:1698328180\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:40,597 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2037\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2035.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cacc8370-6203-4a7f-9ef6-b446b5eedf37,timestamp:1698328182\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2037\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2037\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2035.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cacc8370-6203-4a7f-9ef6-b446b5eedf37,timestamp:1698328182\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2037\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:42,636 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1704.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:32c74dcb-09d8-45e1-b1f9-c636e48d0ea8,timestamp:1698328184\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,346 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:44,346 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1704.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:32c74dcb-09d8-45e1-b1f9-c636e48d0ea8,timestamp:1698328184\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1705\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,343 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,346 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:44,346 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,223 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1873\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,223 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1873.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:26bb799a-efda-40d8-b167-7170de2e5c3d,timestamp:1698328186\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1875\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,223 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1873\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,223 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1873.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:26bb799a-efda-40d8-b167-7170de2e5c3d,timestamp:1698328186\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1875\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:46,224 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31596374511719|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.54916763305664|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12735.97265625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2499.0234375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31596374511719|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.54916763305664|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12735.97265625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,951 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2499.0234375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:47,952 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.2|#Level:Host|#hostname:c449b28b682c,timestamp:1698328187\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2806\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2805.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:952665de-6b3c-43ae-82fe-ec3fe5b57d0e,timestamp:1698328189\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2806\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2806\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2805.18|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:952665de-6b3c-43ae-82fe-ec3fe5b57d0e,timestamp:1698328189\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2806\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:49,032 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1728.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7fb1ea8-1d57-40f1-a099-547dc0ba668b,timestamp:1698328190\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1728.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7fb1ea8-1d57-40f1-a099-547dc0ba668b,timestamp:1698328190\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1729\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:50,764 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1790\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1788.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2b4bbbad-9ebd-46d2-a04d-b24c117a7ae4,timestamp:1698328192\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1790\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1790\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1788.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:2b4bbbad-9ebd-46d2-a04d-b24c117a7ae4,timestamp:1698328192\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1790\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:52,557 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c14a4872-658f-4b59-af62-65f608674603,timestamp:1698328193\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1288\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1287.78|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c14a4872-658f-4b59-af62-65f608674603,timestamp:1698328193\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1289\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:53,848 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1682\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1688.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3777e91-a09a-47ca-aa1e-4d9ff18442c0,timestamp:1698328195\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1682\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1688.43|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3777e91-a09a-47ca-aa1e-4d9ff18442c0,timestamp:1698328195\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1689\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:55,540 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1878\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1878\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1877.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0398488-6466-4eae-856f-adb7d43e2875,timestamp:1698328197\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1878\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1878\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1877.77|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f0398488-6466-4eae-856f-adb7d43e2875,timestamp:1698328197\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:57,421 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1389\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1389\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1388.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b4b1e17e-e4d3-47b7-9a2d-d9baaee9752a,timestamp:1698328198\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:49:58,814 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1389\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1388.56|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:b4b1e17e-e4d3-47b7-9a2d-d9baaee9752a,timestamp:1698328198\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,813 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:49:58,814 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:00,580 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1763\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:00,580 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1762.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bade810c-d4df-4e00-a8b9-63ec260569e8,timestamp:1698328200\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1764\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:00,580 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1763\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:00,580 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1762.95|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:bade810c-d4df-4e00-a8b9-63ec260569e8,timestamp:1698328200\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1764\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:00,581 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1827\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1828\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1827.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d07da1fd-a6be-4dc1-9d65-5435e129a960,timestamp:1698328202\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1827\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1828\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1827.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d07da1fd-a6be-4dc1-9d65-5435e129a960,timestamp:1698328202\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:02,411 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1415\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1414.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f02c62b6-8073-49e6-b792-998ba1c79bb7,timestamp:1698328203\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1415\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1415\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1414.54|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:f02c62b6-8073-49e6-b792-998ba1c79bb7,timestamp:1698328203\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1415\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,829 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,830 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:03,830 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,830 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:03,830 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,137 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,137 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:85148d89-56e2-4914-ae11-8079cb1c6130,timestamp:1698328205\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,137 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,137 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1304.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:85148d89-56e2-4914-ae11-8079cb1c6130,timestamp:1698328205\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1305\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:05,138 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4d0eb647-941d-43fe-a4c4-386acca2448b,timestamp:1698328206\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.13|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4d0eb647-941d-43fe-a4c4-386acca2448b,timestamp:1698328206\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:06,797 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1679.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:325df290-6bf3-40ce-97de-b8b9c2cbbe71,timestamp:1698328208\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1680\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1679.5|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:325df290-6bf3-40ce-97de-b8b9c2cbbe71,timestamp:1698328208\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1680\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:08,480 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6c3cdfbc-9dac-476e-922c-1cecae788361,timestamp:1698328209\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1275\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1274.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:6c3cdfbc-9dac-476e-922c-1cecae788361,timestamp:1698328209\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:09,758 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2805\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2804.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a51db57d-c4f1-4084-97d1-9bebbfb06c41,timestamp:1698328212\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2806\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2805\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2804.74|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a51db57d-c4f1-4084-97d1-9bebbfb06c41,timestamp:1698328212\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2806\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:12,566 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11c21136-ed57-4d0a-bbfe-00292654bfc7,timestamp:1698328213\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1337.31|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:11c21136-ed57-4d0a-bbfe-00292654bfc7,timestamp:1698328213\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1338\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:13,907 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5c496906-b8f6-4442-9b14-3888734e7cc5,timestamp:1698328215\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1258\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1257.9|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:5c496906-b8f6-4442-9b14-3888734e7cc5,timestamp:1698328215\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:15,168 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1642\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1641.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cdeb90ca-e393-4156-92a2-ae875d05324a,timestamp:1698328216\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1642\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1642\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1641.59|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:cdeb90ca-e393-4156-92a2-ae875d05324a,timestamp:1698328216\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1642\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:16,813 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,138 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1318\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,138 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e82ec88-8982-4c5e-8be6-93a162ede205,timestamp:1698328218\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,138 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1318\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1322\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,138 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1321.83|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:4e82ec88-8982-4c5e-8be6-93a162ede205,timestamp:1698328218\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:18,139 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d76239f1-837e-474f-835f-85e0e85841c2,timestamp:1698328219\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1271\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1270.45|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d76239f1-837e-474f-835f-85e0e85841c2,timestamp:1698328219\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1272\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:19,413 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1317\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1318\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1316.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:897bb7b6-a14d-4ea1-a4e6-e026559e892c,timestamp:1698328220\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1317\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1318\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:20,733 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1316.34|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:897bb7b6-a14d-4ea1-a4e6-e026559e892c,timestamp:1698328220\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1802\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1800.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e82318b9-e1b1-4e34-a852-e00fbade6cce,timestamp:1698328222\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1802\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1802\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1800.6|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e82318b9-e1b1-4e34-a852-e00fbade6cce,timestamp:1698328222\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1802\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:22,537 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1667\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1667\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1666.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52639262-3eb0-492f-be5b-498f298d7ba6,timestamp:1698328224\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1666.75|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:52639262-3eb0-492f-be5b-498f298d7ba6,timestamp:1698328224\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1668\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:24,207 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53ac1e23-316d-4fa3-8eb4-108322ad3ef2,timestamp:1698328225\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1657\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1656.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:53ac1e23-316d-4fa3-8eb4-108322ad3ef2,timestamp:1698328225\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1658\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:25,867 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2325\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2323.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28a9f142-4e12-4580-83e6-fd12c59680c6,timestamp:1698328228\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2325\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2325\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2323.97|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:28a9f142-4e12-4580-83e6-fd12c59680c6,timestamp:1698328228\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2325\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:28,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1316\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7dd0c0d-72b9-415b-a7c6-1bbbd5b07c8f,timestamp:1698328229\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1316\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d7dd0c0d-72b9-415b-a7c6-1bbbd5b07c8f,timestamp:1698328229\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1316\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:29,513 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1370\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1368.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9fa11cba-0a3e-4bfb-bca3-3d6037826b2d,timestamp:1698328230\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1370\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1370\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1368.76|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:9fa11cba-0a3e-4bfb-bca3-3d6037826b2d,timestamp:1698328230\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1370\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:30,885 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2587\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2586.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:258d792b-94f9-420f-b8f3-eb2cf89268f5,timestamp:1698328233\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2587\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2586.27|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:258d792b-94f9-420f-b8f3-eb2cf89268f5,timestamp:1698328233\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:33,474 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1718\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1718\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1717.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d2943e5e-d8bd-4da3-a66e-1d4d3675e222,timestamp:1698328235\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1718\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1717.68|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d2943e5e-d8bd-4da3-a66e-1d4d3675e222,timestamp:1698328235\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1718\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:35,195 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1637.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c0a4a8b9-5335-43d1-a370-8322579297d9,timestamp:1698328236\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1637.58|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:c0a4a8b9-5335-43d1-a370-8322579297d9,timestamp:1698328236\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1638\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:36,836 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1612\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1611.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3c684abc-d4b5-449a-87e6-2cc9c3927f4c,timestamp:1698328238\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1612\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,453 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:38,453 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1612\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1611.69|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:3c684abc-d4b5-449a-87e6-2cc9c3927f4c,timestamp:1698328238\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1612\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,451 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,453 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:38,453 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:2|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1491\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1489.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:662f8d95-118d-4463-8d39-6b16bdf7f685,timestamp:1698328239\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1491\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1491\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:39,946 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1489.63|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:662f8d95-118d-4463-8d39-6b16bdf7f685,timestamp:1698328239\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:41,192 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:41,192 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:41,192 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:41,192 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:245a6270-b4df-4938-95e6-f5d4ebfc4e80,timestamp:1698328241\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:41,193 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:41,193 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:41,192 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:41,192 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:41,192 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:41,192 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1243.09|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:245a6270-b4df-4938-95e6-f5d4ebfc4e80,timestamp:1698328241\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:41,193 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:41,193 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aadda497-54a6-451d-9b61-595ba243bebd,timestamp:1698328242\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1231\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1231.01|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:aadda497-54a6-451d-9b61-595ba243bebd,timestamp:1698328242\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1232\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:42,428 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,069 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1639\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1297698d-9e29-48d1-9698-47bb3d66035b,timestamp:1698328244\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,069 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1639\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1638.72|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:1297698d-9e29-48d1-9698-47bb3d66035b,timestamp:1698328244\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1640\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:44,070 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:960a71e3-2d69-4b03-98e8-15e59e2e943b,timestamp:1698328245\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1239\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1239\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1237.99|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:960a71e3-2d69-4b03-98e8-15e59e2e943b,timestamp:1698328245\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:45,311 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2035\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2034.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:abbd144f-29e4-4f92-a916-e5ec52563657,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2036\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31587600708008|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.54925537109375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12745.15625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2489.84375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2035\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2034.48|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:abbd144f-29e4-4f92-a916-e5ec52563657,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2036\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,349 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskAvailable.Gigabytes:47.31587600708008|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUsage.Gigabytes:8.54925537109375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - DiskUtilization.Percent:15.3|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryAvailable.Megabytes:12745.15625|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,949 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUsed.Megabytes:2489.84375|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:47,950 [INFO ] pool-2-thread-2 TS_METRICS - MemoryUtilization.Percent:18.1|#Level:Host|#hostname:c449b28b682c,timestamp:1698328247\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1635.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d5620729-5139-47b6-9dfb-5d8e137aefeb,timestamp:1698328248\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1636\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,988 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:48,988 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1636\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1635.32|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d5620729-5139-47b6-9dfb-5d8e137aefeb,timestamp:1698328248\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1636\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,987 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,988 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:48,988 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1315\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d6dbb9fb-8540-4860-a54d-c6404f68ef00,timestamp:1698328250\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1314\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1315\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1314.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:d6dbb9fb-8540-4860-a54d-c6404f68ef00,timestamp:1698328250\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:50,305 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2086\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2085.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dfb6656a-b62a-40d1-a137-bf9827b7333d,timestamp:1698328252\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2086\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2086\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2085.64|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:dfb6656a-b62a-40d1-a137-bf9827b7333d,timestamp:1698328252\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2086\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:52,397 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,666 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,666 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fbccf36f-aafc-4160-bb65-a25faa16ec21,timestamp:1698328253\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,666 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1266\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,666 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1266.24|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:fbccf36f-aafc-4160-bb65-a25faa16ec21,timestamp:1698328253\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1267\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:53,667 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3aa64ed-d147-4ec9-a5e0-15115ea7e814,timestamp:1698328254\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1251\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1250.02|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:e3aa64ed-d147-4ec9-a5e0-15115ea7e814,timestamp:1698328254\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:54,920 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1792\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1790.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:09f31605-b1f0-457f-8bd3-aee341444baf,timestamp:1698328256\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1792\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1792\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1790.86|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:09f31605-b1f0-457f-8bd3-aee341444baf,timestamp:1698328256\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1792\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:56,714 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2713\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2719\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2717.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:903dda07-2341-40d2-9cbf-f0022335c780,timestamp:1698328259\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2713\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2719\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2717.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:903dda07-2341-40d2-9cbf-f0022335c780,timestamp:1698328259\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:50:59,435 [INFO ] W-9003-model_1 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1715\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1715\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1714.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:57c4235b-f91e-40ca-aaf1-b61503ec54ed,timestamp:1698328261\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1715\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1714.14|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:57c4235b-f91e-40ca-aaf1-b61503ec54ed,timestamp:1698328261\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1715\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:01,153 [INFO ] W-9000-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1670\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1669.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8d056155-c919-424d-b703-03c66bdc576c,timestamp:1698328262\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1670\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 1670\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,826 [INFO ] W-9001-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:1669.88|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:8d056155-c919-424d-b703-03c66bdc576c,timestamp:1698328262\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:02,827 [INFO ] W-9001-model_1 TS_METRICS - WorkerThreadTime.ms:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2037\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2036.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a2d98886-ea7b-40db-988d-dcfcd58a0c2a,timestamp:1698328264\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2037\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[34m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 org.pytorch.serve.wlm.WorkerThread - Backend response time: 2037\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1-stdout MODEL_METRICS - PredictionTime.Milliseconds:2036.66|#ModelName:model,Level:Model|#hostname:c449b28b682c,requestID:a2d98886-ea7b-40db-988d-dcfcd58a0c2a,timestamp:1698328264\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 ACCESS_LOG - /169.254.255.130:53288 \"POST /invocations HTTP/1.1\" 200 2037\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n",
      "\u001b[35m2023-10-26 13:51:04,867 [INFO ] W-9002-model_1 TS_METRICS - WorkerThreadTime.ms:0|#Level:Host|#hostname:c449b28b682c,timestamp:null\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(s3_transformed_data_path, content_type='text/csv', split_type='Line')\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad06ab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3://sdg-project/models/wed_11_10_model2/predictions/text_only_test.csv.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "17a45809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[-6.7427802085876465</td>\n",
       "      <td>-3.526881</td>\n",
       "      <td>-3.840098</td>\n",
       "      <td>-3.456978</td>\n",
       "      <td>-5.653651</td>\n",
       "      <td>-1.463233</td>\n",
       "      <td>-2.125176</td>\n",
       "      <td>-3.038805</td>\n",
       "      <td>-3.900960</td>\n",
       "      <td>-3.875421</td>\n",
       "      <td>-1.577592</td>\n",
       "      <td>-2.332674</td>\n",
       "      <td>1.505961</td>\n",
       "      <td>-1.963717</td>\n",
       "      <td>0.101850</td>\n",
       "      <td>-3.057724</td>\n",
       "      <td>-1.632241129875183]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[-11.403116226196289</td>\n",
       "      <td>-2.582178</td>\n",
       "      <td>-0.190443</td>\n",
       "      <td>-8.382274</td>\n",
       "      <td>-7.121809</td>\n",
       "      <td>-4.422887</td>\n",
       "      <td>-6.666330</td>\n",
       "      <td>-6.831847</td>\n",
       "      <td>-4.508859</td>\n",
       "      <td>-6.143005</td>\n",
       "      <td>-6.224436</td>\n",
       "      <td>-4.360418</td>\n",
       "      <td>-5.629896</td>\n",
       "      <td>-4.777306</td>\n",
       "      <td>-4.434818</td>\n",
       "      <td>-7.283071</td>\n",
       "      <td>-4.2934393882751465]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[-5.668707370758057</td>\n",
       "      <td>-0.109197</td>\n",
       "      <td>-1.049971</td>\n",
       "      <td>-5.457737</td>\n",
       "      <td>-8.217352</td>\n",
       "      <td>0.283350</td>\n",
       "      <td>-4.905684</td>\n",
       "      <td>-2.088828</td>\n",
       "      <td>-2.284471</td>\n",
       "      <td>-4.620093</td>\n",
       "      <td>-2.468168</td>\n",
       "      <td>-1.632369</td>\n",
       "      <td>-1.389243</td>\n",
       "      <td>-3.849088</td>\n",
       "      <td>-2.307996</td>\n",
       "      <td>-3.758041</td>\n",
       "      <td>-0.7262153029441833]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[-6.214212417602539</td>\n",
       "      <td>-2.695269</td>\n",
       "      <td>-5.482683</td>\n",
       "      <td>-2.395831</td>\n",
       "      <td>-5.196604</td>\n",
       "      <td>-6.662023</td>\n",
       "      <td>-1.982881</td>\n",
       "      <td>0.704692</td>\n",
       "      <td>1.944795</td>\n",
       "      <td>-4.072114</td>\n",
       "      <td>-5.606999</td>\n",
       "      <td>1.248887</td>\n",
       "      <td>-2.856170</td>\n",
       "      <td>-4.680631</td>\n",
       "      <td>-5.028345</td>\n",
       "      <td>-3.648393</td>\n",
       "      <td>-1.4624660015106201]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[-3.8930087089538574</td>\n",
       "      <td>-2.324404</td>\n",
       "      <td>-4.818657</td>\n",
       "      <td>-2.718109</td>\n",
       "      <td>-1.324449</td>\n",
       "      <td>-6.733837</td>\n",
       "      <td>-4.226032</td>\n",
       "      <td>0.729391</td>\n",
       "      <td>-1.175744</td>\n",
       "      <td>-0.215925</td>\n",
       "      <td>-3.743657</td>\n",
       "      <td>-1.756615</td>\n",
       "      <td>-1.544684</td>\n",
       "      <td>-3.934689</td>\n",
       "      <td>-4.756916</td>\n",
       "      <td>-3.421002</td>\n",
       "      <td>1.5194090604782104]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0         1         2         3         4         5   \\\n",
       "0  [[-6.7427802085876465 -3.526881 -3.840098 -3.456978 -5.653651 -1.463233   \n",
       "1  [[-11.403116226196289 -2.582178 -0.190443 -8.382274 -7.121809 -4.422887   \n",
       "2   [[-5.668707370758057 -0.109197 -1.049971 -5.457737 -8.217352  0.283350   \n",
       "3   [[-6.214212417602539 -2.695269 -5.482683 -2.395831 -5.196604 -6.662023   \n",
       "4  [[-3.8930087089538574 -2.324404 -4.818657 -2.718109 -1.324449 -6.733837   \n",
       "\n",
       "         6         7         8         9         10        11        12  \\\n",
       "0 -2.125176 -3.038805 -3.900960 -3.875421 -1.577592 -2.332674  1.505961   \n",
       "1 -6.666330 -6.831847 -4.508859 -6.143005 -6.224436 -4.360418 -5.629896   \n",
       "2 -4.905684 -2.088828 -2.284471 -4.620093 -2.468168 -1.632369 -1.389243   \n",
       "3 -1.982881  0.704692  1.944795 -4.072114 -5.606999  1.248887 -2.856170   \n",
       "4 -4.226032  0.729391 -1.175744 -0.215925 -3.743657 -1.756615 -1.544684   \n",
       "\n",
       "         13        14        15                      16  \n",
       "0 -1.963717  0.101850 -3.057724    -1.632241129875183]]  \n",
       "1 -4.777306 -4.434818 -7.283071   -4.2934393882751465]]  \n",
       "2 -3.849088 -2.307996 -3.758041   -0.7262153029441833]]  \n",
       "3 -4.680631 -5.028345 -3.648393   -1.4624660015106201]]  \n",
       "4 -3.934689 -4.756916 -3.421002    1.5194090604782104]]  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_output_key = os.path.join(prediction_output_path, 'text_only_test.csv.out')\n",
    "\n",
    "s3_client = boto3.client('s3')\n",
    "s3_client.download_file(s3_bucket, f'models/{model_name}/predictions/text_only_test.csv.out', local_results_path)\n",
    "\n",
    "results = pd.read_csv(local_results_path, header=None)\n",
    "print(results.shape)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "214cb99f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9344/2297004454.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  results[0] = results[0].str.replace(\"\\\\[\\\\[\", \"\").str.replace(\"\\\\]\\\\]\", \"\").astype(float)\n",
      "/tmp/ipykernel_9344/2297004454.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  results[16] = results[16].str.replace(\"\\\\[\\\\[\", \"\").str.replace(\"\\\\]\\\\]\", \"\").astype(float)\n"
     ]
    }
   ],
   "source": [
    "results[0] = results[0].str.replace(\"\\\\[\\\\[\", \"\").str.replace(\"\\\\]\\\\]\", \"\").astype(float)\n",
    "results[16] = results[16].str.replace(\"\\\\[\\\\[\", \"\").str.replace(\"\\\\]\\\\]\", \"\").astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9244cfd",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "886d4c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.742780</td>\n",
       "      <td>-3.526881</td>\n",
       "      <td>-3.840098</td>\n",
       "      <td>-3.456978</td>\n",
       "      <td>-5.653651</td>\n",
       "      <td>-1.463233</td>\n",
       "      <td>-2.125176</td>\n",
       "      <td>-3.038805</td>\n",
       "      <td>-3.900960</td>\n",
       "      <td>-3.875421</td>\n",
       "      <td>-1.577592</td>\n",
       "      <td>-2.332674</td>\n",
       "      <td>1.505961</td>\n",
       "      <td>-1.963717</td>\n",
       "      <td>0.101850</td>\n",
       "      <td>-3.057724</td>\n",
       "      <td>-1.632241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-11.403116</td>\n",
       "      <td>-2.582178</td>\n",
       "      <td>-0.190443</td>\n",
       "      <td>-8.382274</td>\n",
       "      <td>-7.121809</td>\n",
       "      <td>-4.422887</td>\n",
       "      <td>-6.666330</td>\n",
       "      <td>-6.831847</td>\n",
       "      <td>-4.508859</td>\n",
       "      <td>-6.143005</td>\n",
       "      <td>-6.224436</td>\n",
       "      <td>-4.360418</td>\n",
       "      <td>-5.629896</td>\n",
       "      <td>-4.777306</td>\n",
       "      <td>-4.434818</td>\n",
       "      <td>-7.283071</td>\n",
       "      <td>-4.293439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.668707</td>\n",
       "      <td>-0.109197</td>\n",
       "      <td>-1.049971</td>\n",
       "      <td>-5.457737</td>\n",
       "      <td>-8.217352</td>\n",
       "      <td>0.283350</td>\n",
       "      <td>-4.905684</td>\n",
       "      <td>-2.088828</td>\n",
       "      <td>-2.284471</td>\n",
       "      <td>-4.620093</td>\n",
       "      <td>-2.468168</td>\n",
       "      <td>-1.632369</td>\n",
       "      <td>-1.389243</td>\n",
       "      <td>-3.849088</td>\n",
       "      <td>-2.307996</td>\n",
       "      <td>-3.758041</td>\n",
       "      <td>-0.726215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.214212</td>\n",
       "      <td>-2.695269</td>\n",
       "      <td>-5.482683</td>\n",
       "      <td>-2.395831</td>\n",
       "      <td>-5.196604</td>\n",
       "      <td>-6.662023</td>\n",
       "      <td>-1.982881</td>\n",
       "      <td>0.704692</td>\n",
       "      <td>1.944795</td>\n",
       "      <td>-4.072114</td>\n",
       "      <td>-5.606999</td>\n",
       "      <td>1.248887</td>\n",
       "      <td>-2.856170</td>\n",
       "      <td>-4.680631</td>\n",
       "      <td>-5.028345</td>\n",
       "      <td>-3.648393</td>\n",
       "      <td>-1.462466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.893009</td>\n",
       "      <td>-2.324404</td>\n",
       "      <td>-4.818657</td>\n",
       "      <td>-2.718109</td>\n",
       "      <td>-1.324449</td>\n",
       "      <td>-6.733837</td>\n",
       "      <td>-4.226032</td>\n",
       "      <td>0.729391</td>\n",
       "      <td>-1.175744</td>\n",
       "      <td>-0.215925</td>\n",
       "      <td>-3.743657</td>\n",
       "      <td>-1.756615</td>\n",
       "      <td>-1.544684</td>\n",
       "      <td>-3.934689</td>\n",
       "      <td>-4.756916</td>\n",
       "      <td>-3.421002</td>\n",
       "      <td>1.519409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>-4.586705</td>\n",
       "      <td>-9.756909</td>\n",
       "      <td>0.140676</td>\n",
       "      <td>0.927643</td>\n",
       "      <td>-5.052139</td>\n",
       "      <td>-12.516607</td>\n",
       "      <td>-9.832187</td>\n",
       "      <td>-3.127861</td>\n",
       "      <td>-7.149845</td>\n",
       "      <td>-2.605274</td>\n",
       "      <td>-4.543658</td>\n",
       "      <td>-6.353708</td>\n",
       "      <td>-9.456362</td>\n",
       "      <td>-12.584826</td>\n",
       "      <td>-10.690624</td>\n",
       "      <td>-5.809613</td>\n",
       "      <td>-6.874060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>-7.734004</td>\n",
       "      <td>-2.911306</td>\n",
       "      <td>0.590839</td>\n",
       "      <td>-4.380599</td>\n",
       "      <td>-7.777104</td>\n",
       "      <td>-3.627806</td>\n",
       "      <td>-6.414397</td>\n",
       "      <td>-3.614635</td>\n",
       "      <td>-5.237248</td>\n",
       "      <td>-5.653421</td>\n",
       "      <td>-3.726418</td>\n",
       "      <td>-2.770887</td>\n",
       "      <td>-4.075782</td>\n",
       "      <td>-3.607900</td>\n",
       "      <td>-0.467346</td>\n",
       "      <td>-6.568101</td>\n",
       "      <td>-3.438507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-6.219999</td>\n",
       "      <td>-6.429441</td>\n",
       "      <td>-2.165011</td>\n",
       "      <td>1.170356</td>\n",
       "      <td>-4.077498</td>\n",
       "      <td>-10.660872</td>\n",
       "      <td>-9.727581</td>\n",
       "      <td>-3.798720</td>\n",
       "      <td>-4.490309</td>\n",
       "      <td>-1.494787</td>\n",
       "      <td>-5.584704</td>\n",
       "      <td>-5.379607</td>\n",
       "      <td>-7.168537</td>\n",
       "      <td>-9.609615</td>\n",
       "      <td>-6.910304</td>\n",
       "      <td>-7.182022</td>\n",
       "      <td>-4.257317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>-6.512262</td>\n",
       "      <td>-5.133459</td>\n",
       "      <td>-8.045794</td>\n",
       "      <td>-2.658935</td>\n",
       "      <td>-0.647907</td>\n",
       "      <td>-10.426758</td>\n",
       "      <td>-6.103676</td>\n",
       "      <td>0.025853</td>\n",
       "      <td>-0.088539</td>\n",
       "      <td>-2.700311</td>\n",
       "      <td>-6.036829</td>\n",
       "      <td>-2.192528</td>\n",
       "      <td>-8.765369</td>\n",
       "      <td>-7.485864</td>\n",
       "      <td>-8.334633</td>\n",
       "      <td>-1.796827</td>\n",
       "      <td>-2.810197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-3.950134</td>\n",
       "      <td>-6.312482</td>\n",
       "      <td>-5.225931</td>\n",
       "      <td>1.178059</td>\n",
       "      <td>-4.132321</td>\n",
       "      <td>-10.341725</td>\n",
       "      <td>-8.356134</td>\n",
       "      <td>-0.990261</td>\n",
       "      <td>-4.547494</td>\n",
       "      <td>-1.462593</td>\n",
       "      <td>-6.662718</td>\n",
       "      <td>-4.423824</td>\n",
       "      <td>-7.440042</td>\n",
       "      <td>-10.354132</td>\n",
       "      <td>-7.011350</td>\n",
       "      <td>-3.546985</td>\n",
       "      <td>-4.311428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4          5         6   \\\n",
       "0    -6.742780 -3.526881 -3.840098 -3.456978 -5.653651  -1.463233 -2.125176   \n",
       "1   -11.403116 -2.582178 -0.190443 -8.382274 -7.121809  -4.422887 -6.666330   \n",
       "2    -5.668707 -0.109197 -1.049971 -5.457737 -8.217352   0.283350 -4.905684   \n",
       "3    -6.214212 -2.695269 -5.482683 -2.395831 -5.196604  -6.662023 -1.982881   \n",
       "4    -3.893009 -2.324404 -4.818657 -2.718109 -1.324449  -6.733837 -4.226032   \n",
       "..         ...       ...       ...       ...       ...        ...       ...   \n",
       "493  -4.586705 -9.756909  0.140676  0.927643 -5.052139 -12.516607 -9.832187   \n",
       "494  -7.734004 -2.911306  0.590839 -4.380599 -7.777104  -3.627806 -6.414397   \n",
       "495  -6.219999 -6.429441 -2.165011  1.170356 -4.077498 -10.660872 -9.727581   \n",
       "496  -6.512262 -5.133459 -8.045794 -2.658935 -0.647907 -10.426758 -6.103676   \n",
       "497  -3.950134 -6.312482 -5.225931  1.178059 -4.132321 -10.341725 -8.356134   \n",
       "\n",
       "           7         8         9         10        11        12         13  \\\n",
       "0   -3.038805 -3.900960 -3.875421 -1.577592 -2.332674  1.505961  -1.963717   \n",
       "1   -6.831847 -4.508859 -6.143005 -6.224436 -4.360418 -5.629896  -4.777306   \n",
       "2   -2.088828 -2.284471 -4.620093 -2.468168 -1.632369 -1.389243  -3.849088   \n",
       "3    0.704692  1.944795 -4.072114 -5.606999  1.248887 -2.856170  -4.680631   \n",
       "4    0.729391 -1.175744 -0.215925 -3.743657 -1.756615 -1.544684  -3.934689   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "493 -3.127861 -7.149845 -2.605274 -4.543658 -6.353708 -9.456362 -12.584826   \n",
       "494 -3.614635 -5.237248 -5.653421 -3.726418 -2.770887 -4.075782  -3.607900   \n",
       "495 -3.798720 -4.490309 -1.494787 -5.584704 -5.379607 -7.168537  -9.609615   \n",
       "496  0.025853 -0.088539 -2.700311 -6.036829 -2.192528 -8.765369  -7.485864   \n",
       "497 -0.990261 -4.547494 -1.462593 -6.662718 -4.423824 -7.440042 -10.354132   \n",
       "\n",
       "            14        15        16  \n",
       "0     0.101850 -3.057724 -1.632241  \n",
       "1    -4.434818 -7.283071 -4.293439  \n",
       "2    -2.307996 -3.758041 -0.726215  \n",
       "3    -5.028345 -3.648393 -1.462466  \n",
       "4    -4.756916 -3.421002  1.519409  \n",
       "..         ...       ...       ...  \n",
       "493 -10.690624 -5.809613 -6.874060  \n",
       "494  -0.467346 -6.568101 -3.438507  \n",
       "495  -6.910304 -7.182022 -4.257317  \n",
       "496  -8.334633 -1.796827 -2.810197  \n",
       "497  -7.011350 -3.546985 -4.311428  \n",
       "\n",
       "[498 rows x 17 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the content from the file\n",
    "with open(local_results_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Process each line to remove the outer brackets and split numbers\n",
    "processed_lines = [list(map(float, line.strip()[2:-2].split(','))) for line in lines]\n",
    "\n",
    "# Convert the processed data into a dataframe\n",
    "results_df = pd.DataFrame(processed_lines)\n",
    "\n",
    "# print(results_df.shape)\n",
    "# print(results_df.head())\n",
    "\n",
    "#processed_lines\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7f5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "eee1d50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total non-float values: 0\n"
     ]
    }
   ],
   "source": [
    "# def is_not_float(value):\n",
    "#     try:\n",
    "#         float(value)\n",
    "#         return False\n",
    "#     except ValueError:\n",
    "#         return True\n",
    "\n",
    "# non_float_mask = results_df.applymap(is_not_float)\n",
    "# non_float_counts = non_float_mask.sum().sum()\n",
    "# print(f\"Total non-float values: {non_float_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "65083af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ValueError: could not convert string to float: '[[-4.270998001098633'\n",
      "Problematic values in column 0: ['[[-4.270998001098633' '[[-5.848301410675049' '[[-3.6253974437713623'\n",
      " '[[-5.789789199829102' '[[-4.9356889724731445' '[[-4.165139198303223'\n",
      " '[[-5.735708236694336' '[[-4.352252006530762' '[[-7.999675750732422'\n",
      " '[[-6.6009602546691895' '[[-5.733427047729492' '[[-1.9372594356536865'\n",
      " '[[-3.4978535175323486' '[[-3.7069549560546875' '[[-3.7345829010009766'\n",
      " '[[-1.9820735454559326' '[[-6.994397163391113' '[[-2.0526175498962402'\n",
      " '[[-6.503925323486328' '[[-6.751236915588379' '[[-6.309639930725098'\n",
      " '[[-6.890380859375' '[[-3.9773223400115967' '[[-5.833578109741211'\n",
      " '[[-0.6642332673072815' '[[-4.762781143188477' '[[-4.65572452545166'\n",
      " '[[-4.783189296722412' '[[-4.987717628479004' '[[-4.2865519523620605'\n",
      " '[[-2.311419725418091' '[[-6.700862884521484' '[[-4.510231971740723'\n",
      " '[[-4.784397602081299' '[[-3.649338483810425' '[[-8.45500373840332'\n",
      " '[[-4.41664457321167' '[[-7.919408321380615' '[[-4.279530048370361'\n",
      " '[[-6.4008612632751465' '[[-7.768404960632324' '[[-3.017246723175049'\n",
      " '[[-4.791778087615967' '[[-7.279993057250977' '[[-5.430228233337402'\n",
      " '[[-3.846734046936035' '[[-4.479381084442139' '[[-5.389325141906738'\n",
      " '[[-5.995251178741455' '[[-4.722029685974121' '[[-4.107876300811768'\n",
      " '[[-2.7630510330200195' '[[-4.634404182434082' '[[-7.99796199798584'\n",
      " '[[-4.861922264099121' '[[-7.345458030700684' '[[-4.459059715270996'\n",
      " '[[-3.8399007320404053' '[[-4.537997722625732' '[[-1.7690033912658691'\n",
      " '[[-3.9344658851623535' '[[-3.4597928524017334' '[[-5.870385646820068'\n",
      " '[[-8.29948902130127' '[[-2.4515902996063232' '[[-1.368767499923706'\n",
      " '[[-5.237713813781738' '[[-2.7439992427825928' '[[-5.61875581741333'\n",
      " '[[-6.692437648773193' '[[-5.1142449378967285' '[[-2.17236328125'\n",
      " '[[-5.692722797393799' '[[-6.572370529174805' '[[-1.4175344705581665'\n",
      " '[[-4.7130351066589355' '[[-6.419593334197998' '[[-1.6166529655456543'\n",
      " '[[-6.631838798522949' '[[-6.498128890991211' '[[0.07610491663217545'\n",
      " '[[-3.526338815689087' '[[-4.736580848693848' '[[-5.8521270751953125'\n",
      " '[[-5.123577117919922' '[[-7.083866119384766' '[[-6.172067165374756'\n",
      " '[[-5.817145347595215' '[[-3.7486612796783447' '[[-6.82302188873291'\n",
      " '[[-2.962092399597168' '[[-2.0126824378967285' '[[-6.057424545288086'\n",
      " '[[-6.477544784545898' '[[-4.837697505950928' '[[-5.366683006286621'\n",
      " '[[-3.1899237632751465' '[[-4.090327739715576' '[[-5.591009140014648'\n",
      " '[[-4.2640204429626465' '[[-5.32175350189209' '[[-5.710052490234375'\n",
      " '[[-5.587062358856201' '[[-3.7767555713653564' '[[-8.431769371032715'\n",
      " '[[-5.467952251434326' '[[-2.091221332550049' '[[-4.450705528259277'\n",
      " '[[-6.665023326873779' '[[-7.0799174308776855' '[[-5.718772888183594'\n",
      " '[[-3.9141433238983154' '[[-3.7481908798217773' '[[-4.816321849822998'\n",
      " '[[-4.280367374420166' '[[0.9280763268470764' '[[-6.477004528045654'\n",
      " '[[-4.974255561828613' '[[-4.773140907287598' '[[-5.046452522277832'\n",
      " '[[-1.700165033340454' '[[-3.9124836921691895' '[[-3.3591508865356445'\n",
      " '[[-6.996191024780273' '[[-5.343505859375' '[[-5.380788803100586'\n",
      " '[[-6.370486259460449' '[[-2.91574764251709' '[[-4.710172176361084'\n",
      " '[[-5.569311141967773' '[[-4.160952091217041' '[[-4.875958442687988'\n",
      " '[[-2.0132479667663574' '[[-8.64792537689209' '[[-4.119390964508057'\n",
      " '[[-4.365232944488525' '[[-5.0460052490234375' '[[-7.004826545715332'\n",
      " '[[-5.548510551452637' '[[-5.041693687438965' '[[-4.740142822265625'\n",
      " '[[-4.692351818084717' '[[-1.878982663154602' '[[-4.6676177978515625'\n",
      " '[[-4.241215705871582' '[[-3.62968111038208' '[[-2.9548678398132324'\n",
      " '[[-5.605595111846924' '[[-3.2311835289001465' '[[-5.939365386962891'\n",
      " '[[-8.940662384033203' '[[-6.273449897766113' '[[-3.775285482406616'\n",
      " '[[-5.973952293395996' '[[-0.8098955154418945' '[[-3.5686731338500977'\n",
      " '[[-3.714031219482422' '[[-0.9034291505813599' '[[-5.714405059814453'\n",
      " '[[-6.0754241943359375' '[[-5.1328277587890625' '[[-5.379660606384277'\n",
      " '[[-5.787384510040283' '[[-4.448546409606934' '[[-1.4407403469085693'\n",
      " '[[-3.2012155055999756' '[[-6.5137739181518555' '[[-4.679378986358643'\n",
      " '[[-3.6754343509674072' '[[-4.003420352935791' '[[-5.7266340255737305'\n",
      " '[[-8.587189674377441' '[[-7.672964572906494' '[[-7.611868381500244'\n",
      " '[[-6.487873554229736' '[[-5.301342964172363' '[[-3.3126723766326904'\n",
      " '[[-5.968382835388184' '[[-4.007821559906006' '[[-2.335181474685669'\n",
      " '[[-2.3653345108032227' '[[-5.9046149253845215' '[[-5.0061869621276855'\n",
      " '[[-4.8347697257995605' '[[-6.1842803955078125' '[[-2.953808546066284'\n",
      " '[[-5.854979515075684' '[[-6.801987171173096' '[[-6.563516139984131'\n",
      " '[[-1.3828668594360352' '[[-5.5038838386535645' '[[-5.40177583694458'\n",
      " '[[-6.483630180358887' '[[-6.982141971588135' '[[-7.168542385101318'\n",
      " '[[-2.5040948390960693' '[[-6.672826766967773' '[[-5.659997463226318'\n",
      " '[[-5.558443069458008' '[[-1.3902666568756104' '[[-7.608665943145752'\n",
      " '[[-5.425466060638428' '[[-6.708422660827637' '[[-5.56894063949585'\n",
      " '[[-2.941833734512329' '[[-6.347183704376221' '[[-6.006344318389893'\n",
      " '[[-3.8046019077301025' '[[-6.56972074508667' '[[-3.565425157546997'\n",
      " '[[-3.4408464431762695' '[[-1.0765087604522705' '[[-4.361710548400879'\n",
      " '[[-3.9646124839782715' '[[-5.222179889678955' '[[-4.40587043762207'\n",
      " '[[-2.912177801132202' '[[-6.016870975494385' '[[-3.361686944961548'\n",
      " '[[-5.734943866729736' '[[-5.604926586151123' '[[-3.48110032081604'\n",
      " '[[-2.357630968093872' '[[-4.118932723999023' '[[-4.143310070037842'\n",
      " '[[-7.801636695861816' '[[-5.505824565887451' '[[0.8643921613693237'\n",
      " '[[-3.113901138305664' '[[-4.944943428039551' '[[-6.021580219268799'\n",
      " '[[-3.797197103500366' '[[-6.600115776062012' '[[-6.63611364364624'\n",
      " '[[-5.6557512283325195' '[[-4.145737648010254' '[[-4.805609703063965'\n",
      " '[[-5.541276454925537' '[[-6.478823661804199' '[[-5.375845909118652'\n",
      " '[[-4.061093807220459' '[[-6.179139137268066' '[[-5.307809829711914'\n",
      " '[[-5.487459182739258' '[[-6.994748115539551' '[[-4.619502067565918'\n",
      " '[[-3.651249647140503' '[[-1.9259825944900513' '[[-4.6077470779418945'\n",
      " '[[-6.165499210357666' '[[-2.3225879669189453' '[[-6.689328193664551'\n",
      " '[[-6.339290618896484' '[[-7.813665866851807' '[[-6.010757923126221'\n",
      " '[[-5.066398620605469' '[[-3.466932535171509' '[[-7.379141807556152'\n",
      " '[[-5.313528537750244' '[[-4.692902565002441' '[[-2.961777687072754'\n",
      " '[[-6.19164514541626' '[[-2.2033956050872803' '[[0.14547301828861237'\n",
      " '[[-5.510660648345947' '[[-3.653075933456421' '[[-8.550785064697266'\n",
      " '[[-4.631887912750244' '[[-3.1264631748199463' '[[-5.630372047424316'\n",
      " '[[-3.782899856567383' '[[-5.387683868408203' '[[-5.896790504455566'\n",
      " '[[-5.988796234130859' '[[-2.4586880207061768' '[[-2.5005266666412354'\n",
      " '[[-3.625706195831299' '[[-5.961203575134277' '[[-6.94019889831543'\n",
      " '[[-0.5808588266372681' '[[-5.255492687225342' '[[-2.6192739009857178'\n",
      " '[[-7.455284118652344' '[[-6.271507740020752' '[[-5.806990623474121'\n",
      " '[[-2.6612603664398193' '[[-9.529141426086426' '[[-4.78518533706665'\n",
      " '[[-3.7911272048950195' '[[-7.15983772277832' '[[-7.83031702041626'\n",
      " '[[-5.825016021728516' '[[-6.101943492889404' '[[-3.9908387660980225'\n",
      " '[[-8.684142112731934' '[[0.4238269031047821' '[[-7.620768070220947'\n",
      " '[[-4.780109882354736' '[[-5.936419486999512' '[[-5.703969955444336'\n",
      " '[[-4.823014259338379' '[[-4.79155158996582' '[[-5.587526321411133'\n",
      " '[[-6.187087535858154' '[[-5.167657852172852' '[[-8.95258903503418'\n",
      " '[[-6.231843948364258' '[[-5.781871318817139' '[[-8.001091957092285'\n",
      " '[[-4.631852149963379' '[[-5.57232666015625' '[[-5.108728408813477'\n",
      " '[[-1.4166083335876465' '[[-3.7572693824768066' '[[-5.3421783447265625'\n",
      " '[[-5.946556091308594' '[[-5.117170333862305' '[[-2.7476699352264404'\n",
      " '[[-5.847308158874512' '[[-9.116772651672363' '[[-5.797512531280518'\n",
      " '[[-8.261754989624023' '[[-5.3266096115112305' '[[-4.386322975158691'\n",
      " '[[-2.995614528656006' '[[-6.731037616729736' '[[-7.707945823669434'\n",
      " '[[-6.550980091094971' '[[-4.897706031799316' '[[-4.016783237457275'\n",
      " '[[-6.119298934936523' '[[-5.5898213386535645' '[[-4.227860450744629'\n",
      " '[[-5.321651458740234' '[[-2.534195899963379' '[[-2.728288173675537'\n",
      " '[[-5.114403247833252' '[[-4.455225944519043' '[[-5.4297356605529785'\n",
      " '[[-5.140987873077393' '[[-5.77651309967041' '[[-5.889935493469238'\n",
      " '[[-6.3275628089904785' '[[-4.966085433959961' '[[-5.545265197753906'\n",
      " '[[-1.1682554483413696' '[[-3.5361883640289307' '[[-3.5492329597473145'\n",
      " '[[-3.5784647464752197' '[[-3.1947519779205322' '[[-9.055496215820312'\n",
      " '[[-4.348100185394287' '[[-1.5010576248168945' '[[-3.0636627674102783'\n",
      " '[[-3.335378885269165' '[[-4.390470504760742' '[[-4.493508338928223'\n",
      " '[[-6.1434478759765625' '[[-2.3342015743255615' '[[-5.718344688415527'\n",
      " '[[-5.729135513305664' '[[-5.994870185852051' '[[-3.8849709033966064'\n",
      " '[[-3.2785871028900146' '[[-5.580801486968994' '[[-4.560722827911377'\n",
      " '[[-5.7806572914123535' '[[-5.754079818725586' '[[-4.305576801300049'\n",
      " '[[-5.361231327056885' '[[-7.063699722290039' '[[-4.96148681640625'\n",
      " '[[-3.817495107650757' '[[-3.966622829437256' '[[-4.425762176513672'\n",
      " '[[-6.719507217407227' '[[-3.15559458732605' '[[-4.428043365478516'\n",
      " '[[-3.8854284286499023' '[[-4.738144397735596' '[[-5.530954360961914'\n",
      " '[[-3.3426952362060547' '[[-4.652134418487549' '[[-4.610793113708496'\n",
      " '[[-7.742284297943115' '[[-6.31239652633667' '[[-3.870204448699951'\n",
      " '[[-5.765317916870117' '[[-8.70518684387207' '[[-6.626724720001221'\n",
      " '[[-5.995110511779785' '[[-6.76685905456543' '[[-4.826569080352783'\n",
      " '[[-5.556296348571777' '[[-7.22824239730835' '[[-3.082526445388794'\n",
      " '[[-2.7107951641082764' '[[-1.3860024213790894' '[[-6.852410793304443'\n",
      " '[[-4.160278797149658' '[[-7.687325477600098' '[[-5.318034648895264'\n",
      " '[[-6.708049297332764' '[[-3.453803539276123' '[[-7.236001968383789'\n",
      " '[[-8.375969886779785' '[[-6.079710483551025' '[[-2.397895574569702'\n",
      " '[[-6.191354274749756' '[[-5.644113540649414' '[[-5.801248073577881'\n",
      " '[[-5.535896301269531' '[[-3.767343521118164' '[[-4.704610824584961'\n",
      " '[[-5.469988822937012' '[[-6.033780097961426' '[[-2.8845698833465576'\n",
      " '[[-5.280240535736084' '[[-3.3217873573303223' '[[-6.607647895812988'\n",
      " '[[-4.512389183044434' '[[-7.345453262329102' '[[-4.797182559967041'\n",
      " '[[-2.57914137840271' '[[-5.973613262176514' '[[-2.600466012954712'\n",
      " '[[-4.597878456115723' '[[-8.671058654785156' '[[-8.744098663330078'\n",
      " '[[-7.291845321655273' '[[0.422991007566452' '[[-6.225528717041016'\n",
      " '[[-4.6409382820129395' '[[-2.3431005477905273' '[[-5.9334330558776855'\n",
      " '[[-6.689553737640381' '[[-5.787444591522217' '[[-6.369288921356201'\n",
      " '[[-5.484178066253662' '[[-3.7551658153533936' '[[-5.966455459594727'\n",
      " '[[-2.9316165447235107' '[[-5.033529281616211' '[[-5.907320976257324'\n",
      " '[[-4.991513252258301' '[[-4.724883079528809' '[[-5.763137340545654'\n",
      " '[[-2.919759750366211' '[[-6.472010135650635' '[[-8.673083305358887']\n",
      "Problematic values in column 16: [' -2.411789894104004]]' ' -4.90162992477417]]' ' -4.285671234130859]]'\n",
      " ' -4.235047817230225]]' ' -3.2427642345428467]]' ' -3.1834208965301514]]'\n",
      " ' -3.113049030303955]]' ' -5.068012714385986]]' ' -3.7628467082977295]]'\n",
      " ' -4.706387519836426]]' ' -4.4276838302612305]]' ' -3.95478892326355]]'\n",
      " ' -1.9074912071228027]]' ' -5.069089889526367]]' ' -1.8667556047439575]]'\n",
      " ' -1.2592673301696777]]' ' -3.984602212905884]]' ' -3.385497570037842]]'\n",
      " ' -4.081240177154541]]' ' -4.9255805015563965]]' ' -2.654729127883911]]'\n",
      " ' -3.4753079414367676]]' ' -2.338461399078369]]' ' -4.31494140625]]'\n",
      " ' -2.0936338901519775]]' ' -3.2603821754455566]]' ' -2.501283645629883]]'\n",
      " ' -3.870305061340332]]' ' -4.8662824630737305]]' ' -2.7935330867767334]]'\n",
      " ' -2.5155093669891357]]' ' -5.215130805969238]]' ' -5.423437595367432]]'\n",
      " ' -2.3286850452423096]]' ' -0.9817500114440918]]'\n",
      " ' -5.3355326652526855]]' ' -2.741992473602295]]' ' -4.61313533782959]]'\n",
      " ' -3.4939823150634766]]' ' -2.037372350692749]]' ' -4.603734493255615]]'\n",
      " ' -2.0427141189575195]]' ' -2.4466452598571777]]' ' -6.751229763031006]]'\n",
      " ' -3.0755820274353027]]' ' -2.2106170654296875]]'\n",
      " ' -4.0190815925598145]]' ' -1.643007755279541]]' ' -4.21401309967041]]'\n",
      " ' -3.8679087162017822]]' ' -1.4555035829544067]]'\n",
      " ' -0.5862162709236145]]' ' -3.9358880519866943]]' ' -5.800942420959473]]'\n",
      " ' -3.8259599208831787]]' ' -3.286799907684326]]' ' -4.181628704071045]]'\n",
      " ' -3.066842555999756]]' ' -1.7833938598632812]]' ' -0.9616491198539734]]'\n",
      " ' -1.1686904430389404]]' ' -2.9391181468963623]]' ' -5.507752895355225]]'\n",
      " ' -6.386477470397949]]' ' -3.10770583152771]]' ' -1.731967568397522]]'\n",
      " ' -2.009371519088745]]' ' -2.1743180751800537]]' ' -2.7778496742248535]]'\n",
      " ' -5.8499321937561035]]' ' -3.825944662094116]]' ' -0.6319689750671387]]'\n",
      " ' -3.4515957832336426]]' ' -3.685096263885498]]' ' -2.3808722496032715]]'\n",
      " ' -3.9543254375457764]]' ' -4.844970226287842]]' ' -3.616299629211426]]'\n",
      " ' -3.4867794513702393]]' ' -3.0850257873535156]]'\n",
      " ' -1.5023407936096191]]' ' -1.8204143047332764]]' ' -2.492077350616455]]'\n",
      " ' -3.846574306488037]]' ' -2.8019683361053467]]' ' -4.111722469329834]]'\n",
      " ' -3.1864829063415527]]' ' -3.1667072772979736]]'\n",
      " ' -1.8923120498657227]]' ' -5.414554119110107]]' ' -3.2389299869537354]]'\n",
      " ' -1.9756557941436768]]' ' -3.008629322052002]]' ' -5.777274131774902]]'\n",
      " ' -1.8324323892593384]]' ' -2.3243815898895264]]'\n",
      " ' -2.1848278045654297]]' ' -2.5174407958984375]]' ' -1.596683382987976]]'\n",
      " ' -2.997745990753174]]' ' -3.572429656982422]]' ' -4.215400218963623]]'\n",
      " ' -4.2247090339660645]]' ' -2.568106174468994]]' ' -5.431025981903076]]'\n",
      " ' -3.5495288372039795]]' ' -3.206819772720337]]' ' -4.368980884552002]]'\n",
      " ' -4.350738525390625]]' ' -5.083254814147949]]' ' -2.7178165912628174]]'\n",
      " ' -2.275135040283203]]' ' -1.3044532537460327]]' ' -3.9445908069610596]]'\n",
      " ' -0.36066997051239014]]' ' 0.5571898221969604]]'\n",
      " ' -2.8305583000183105]]' ' -2.206820011138916]]' ' -1.0165029764175415]]'\n",
      " ' -3.5855979919433594]]' ' -0.7546042203903198]]'\n",
      " ' -3.5691070556640625]]' ' -2.6818695068359375]]' ' -4.565008163452148]]'\n",
      " ' -1.6426657438278198]]' ' -2.7152981758117676]]'\n",
      " ' -2.2112817764282227]]' ' -0.9858162999153137]]' ' -2.201411008834839]]'\n",
      " ' -2.8077738285064697]]' ' -3.188744306564331]]' ' -1.6604137420654297]]'\n",
      " ' 0.5933783650398254]]' ' -4.997603893280029]]' ' -3.2111096382141113]]'\n",
      " ' -3.790771722793579]]' ' -4.235046863555908]]' ' -3.6604182720184326]]'\n",
      " ' -3.348104476928711]]' ' -3.4219675064086914]]' ' -3.842773675918579]]'\n",
      " ' -1.59884512424469]]' ' -0.00011832825839519501]]'\n",
      " ' -2.995797872543335]]' ' -3.8438351154327393]]' ' -1.8729968070983887]]'\n",
      " ' -0.5599997639656067]]' ' -3.6102993488311768]]' ' -2.29268217086792]]'\n",
      " ' -4.5227837562561035]]' ' -4.004417896270752]]' ' -3.8073413372039795]]'\n",
      " ' -2.4989278316497803]]' ' -3.7453672885894775]]'\n",
      " ' -0.24009059369564056]]' ' -5.109797954559326]]' ' -2.359685182571411]]'\n",
      " ' -3.736198663711548]]' ' -3.2041149139404297]]' ' -2.688418388366699]]'\n",
      " ' -3.5791780948638916]]' ' -2.267134666442871]]' ' -1.9989018440246582]]'\n",
      " ' -0.6588733196258545]]' ' -1.867866039276123]]' ' -4.017880439758301]]'\n",
      " ' -2.6203911304473877]]' ' -4.36458158493042]]' ' -3.542682409286499]]'\n",
      " ' -3.2635838985443115]]' ' -3.293215274810791]]' ' -4.655296325683594]]'\n",
      " ' -4.517385482788086]]' ' -4.712741851806641]]' ' -4.030580043792725]]'\n",
      " ' -3.2601988315582275]]' ' -2.146728992462158]]' ' -2.7488927841186523]]'\n",
      " ' -3.39298152923584]]' ' -1.0263843536376953]]' ' -1.6598838567733765]]'\n",
      " ' -3.648145914077759]]' ' -4.275416374206543]]' ' -1.4077532291412354]]'\n",
      " ' -3.0134496688842773]]' ' -2.8423330783843994]]' ' -2.01196026802063]]'\n",
      " ' -3.628089666366577]]' ' -3.4144582748413086]]'\n",
      " ' -0.27613791823387146]]' ' -3.750725746154785]]' ' -2.684837818145752]]'\n",
      " ' -3.686220407485962]]' ' -4.545592308044434]]' ' -4.856088161468506]]'\n",
      " ' -4.173131942749023]]' ' -4.434253215789795]]' ' -3.250117301940918]]'\n",
      " ' -3.923464775085449]]' ' -1.4078480005264282]]' ' -3.31941294670105]]'\n",
      " ' -3.2948367595672607]]' ' -2.498900890350342]]' ' -3.27038311958313]]'\n",
      " ' -0.030868813395500183]]' ' -2.474393606185913]]'\n",
      " ' -7.124360084533691]]' ' -3.2834203243255615]]' ' -4.686707019805908]]'\n",
      " ' -2.7114803791046143]]' ' -3.1825952529907227]]'\n",
      " ' -2.0882186889648438]]' ' -5.292680740356445]]' ' -3.275984048843384]]'\n",
      " ' -2.452791929244995]]' ' -3.9688005447387695]]' ' 0.22207574546337128]]'\n",
      " ' -1.5545053482055664]]' ' -4.585343837738037]]' ' -3.6080520153045654]]'\n",
      " ' -4.962360382080078]]' ' -4.1783766746521]]' ' -2.0025060176849365]]'\n",
      " ' -1.154394268989563]]' ' -1.3027116060256958]]' ' -3.85491681098938]]'\n",
      " ' -2.0364115238189697]]' ' -2.7451295852661133]]' ' 0.3367653489112854]]'\n",
      " ' -0.8370624780654907]]' ' -2.4203593730926514]]'\n",
      " ' -1.1042166948318481]]' ' -3.4636905193328857]]' ' -4.570224285125732]]'\n",
      " ' -2.3416693210601807]]' ' -4.119032859802246]]' ' -2.2301013469696045]]'\n",
      " ' -4.374665260314941]]' ' -4.642807960510254]]' ' -3.228518009185791]]'\n",
      " ' -3.0981533527374268]]' ' -3.9750218391418457]]'\n",
      " ' -3.8516807556152344]]' ' -2.167846918106079]]' ' -4.098718643188477]]'\n",
      " ' -3.8681564331054688]]' ' -0.8198809027671814]]'\n",
      " ' -0.8106769919395447]]' ' -2.8663361072540283]]' ' -3.336184501647949]]'\n",
      " ' -4.3904829025268555]]' ' -4.262539863586426]]' ' -3.468301773071289]]'\n",
      " ' -6.008208751678467]]' ' -3.831693649291992]]' ' -1.0837435722351074]]'\n",
      " ' -1.8366765975952148]]' ' -4.923182964324951]]' ' -5.298861503601074]]'\n",
      " ' -4.7211761474609375]]' ' 0.13960571587085724]]' ' -4.684608459472656]]'\n",
      " ' -2.754545211791992]]' ' -0.26065608859062195]]'\n",
      " ' -1.5221480131149292]]' ' -0.011447612196207047]]'\n",
      " ' -3.7710256576538086]]' ' -1.6181762218475342]]' ' -4.80336856842041]]'\n",
      " ' -3.085770606994629]]' ' -2.649907350540161]]' ' -2.583897352218628]]'\n",
      " ' -3.6814939975738525]]' ' -3.403106451034546]]' ' -1.99936842918396]]'\n",
      " ' -2.079286575317383]]' ' -4.005592346191406]]' ' -2.409872055053711]]'\n",
      " ' -3.7286834716796875]]' ' -1.5825005769729614]]'\n",
      " ' -4.8425750732421875]]' ' -0.5083723068237305]]' ' -4.027437210083008]]'\n",
      " ' -2.7276971340179443]]' ' -4.38789176940918]]' ' -4.206116199493408]]'\n",
      " ' -7.066463947296143]]' ' -3.2375354766845703]]' ' -1.1227929592132568]]'\n",
      " ' -5.050883769989014]]' ' -5.188840389251709]]' ' -3.005007028579712]]'\n",
      " ' -4.561613082885742]]' ' -5.190718650817871]]' ' -4.679150104522705]]'\n",
      " ' -1.7742793560028076]]' ' -4.372599124908447]]' ' -1.0380381345748901]]'\n",
      " ' -4.733107089996338]]' ' -2.9967126846313477]]' ' -1.846756935119629]]'\n",
      " ' -1.990729570388794]]' ' -1.5336322784423828]]' ' -4.156888961791992]]'\n",
      " ' -1.864392876625061]]' ' -5.000377178192139]]' ' -2.943495750427246]]'\n",
      " ' -3.3661065101623535]]' ' -4.259222030639648]]' ' -3.985671043395996]]'\n",
      " ' -5.688442230224609]]' ' -3.80098295211792]]' ' -1.549653172492981]]'\n",
      " ' -4.894168853759766]]' ' -2.8517932891845703]]' ' -3.7830467224121094]]'\n",
      " ' -4.764583587646484]]' ' -2.5323569774627686]]' ' -2.195155620574951]]'\n",
      " ' -6.169323921203613]]' ' -5.577847003936768]]' ' -3.61602783203125]]'\n",
      " ' -1.5229777097702026]]' ' -4.7752156257629395]]'\n",
      " ' -2.6215920448303223]]' ' -2.4635164737701416]]' ' -4.732386112213135]]'\n",
      " ' -5.407302379608154]]' ' -4.114917278289795]]' ' -4.049795627593994]]'\n",
      " ' -4.250216484069824]]' ' -4.332235336303711]]' ' -5.922981262207031]]'\n",
      " ' -2.557770013809204]]' ' -2.5445809364318848]]' ' -1.2971346378326416]]'\n",
      " ' -2.4107730388641357]]' ' -1.496495246887207]]' ' -2.9963207244873047]]'\n",
      " ' -3.126842975616455]]' ' -5.999183177947998]]' ' -4.705254077911377]]'\n",
      " ' -4.426768779754639]]' ' -3.6955490112304688]]' ' -3.344949245452881]]'\n",
      " ' -0.5292964577674866]]' ' -3.612473726272583]]' ' 0.35578811168670654]]'\n",
      " ' -1.0447230339050293]]' ' -1.2989423274993896]]' ' -4.800961971282959]]'\n",
      " ' -1.784598708152771]]' ' -3.1876373291015625]]' ' -2.1558330059051514]]'\n",
      " ' -1.3308693170547485]]' ' -4.950798034667969]]' ' -4.438485145568848]]'\n",
      " ' -2.640958070755005]]' ' -4.097568511962891]]' ' -3.0741896629333496]]'\n",
      " ' -5.318958759307861]]' ' -2.989046335220337]]' ' -3.0019383430480957]]'\n",
      " ' -0.7098928689956665]]' ' -5.121471405029297]]' ' -3.9984841346740723]]'\n",
      " ' -3.245696783065796]]' ' -4.360482692718506]]' ' -2.2319133281707764]]'\n",
      " ' -2.3954546451568604]]' ' -4.519279479980469]]' ' -4.9908366203308105]]'\n",
      " ' -4.840426445007324]]' ' -3.26540470123291]]' ' -4.558743953704834]]'\n",
      " ' -4.7465128898620605]]' ' -4.016281604766846]]' ' -5.132882118225098]]'\n",
      " ' -3.2739005088806152]]' ' -0.7887281179428101]]'\n",
      " ' -3.6827712059020996]]' ' -4.10449743270874]]' ' -3.7071645259857178]]'\n",
      " ' -3.0699503421783447]]' ' -4.443276882171631]]' ' -3.665156602859497]]'\n",
      " ' -2.241121768951416]]' ' -1.8066513538360596]]' ' -6.658191680908203]]'\n",
      " ' -4.766071319580078]]' ' -4.480902671813965]]' ' -4.678241729736328]]'\n",
      " ' -2.6836140155792236]]' ' -3.368800163269043]]' ' -5.07719612121582]]'\n",
      " ' -3.7572076320648193]]' ' -1.5032709836959839]]'\n",
      " ' -1.5593903064727783]]' ' -4.296601295471191]]' ' -2.7493486404418945]]'\n",
      " ' -7.5750813484191895]]' ' -3.70607590675354]]' ' -3.439490795135498]]'\n",
      " ' -0.05410213768482208]]' ' -5.20222806930542]]' ' -5.91343355178833]]'\n",
      " ' -5.6220293045043945]]' ' -0.35088759660720825]]'\n",
      " ' -4.699073314666748]]' ' -3.9134132862091064]]' ' -1.9231369495391846]]'\n",
      " ' -3.364075183868408]]' ' -3.260552167892456]]' ' -4.843420028686523]]'\n",
      " ' -3.090649127960205]]' ' -3.910783529281616]]' ' -2.591770887374878]]'\n",
      " ' -3.0365824699401855]]' ' -1.311159372329712]]' ' -4.405313491821289]]'\n",
      " ' -1.6301437616348267]]' ' -3.9103829860687256]]'\n",
      " ' -3.8664395809173584]]' ' -2.7294392585754395]]' ' -2.960381269454956]]'\n",
      " ' -2.7181293964385986]]' ' -2.3668439388275146]]'\n",
      " ' -3.9513604640960693]]' ' -4.137397766113281]]' ' -4.974609375]]'\n",
      " ' -1.7924796342849731]]' ' -3.157588243484497]]' ' -1.8431823253631592]]'\n",
      " ' -2.4162099361419678]]' ' -3.1252596378326416]]' ' -4.185220718383789]]'\n",
      " ' -4.157343864440918]]' ' -4.33369779586792]]' ' -5.8868088722229]]'\n",
      " ' -2.2471160888671875]]' ' -3.434082269668579]]' ' -0.7572959661483765]]'\n",
      " ' -3.2689461708068848]]' ' -3.0942022800445557]]' ' -4.592566967010498]]'\n",
      " ' -3.8006174564361572]]' ' -3.5147039890289307]]' ' -4.149692535400391]]'\n",
      " ' -3.01823353767395]]' ' -5.183454513549805]]']\n"
     ]
    }
   ],
   "source": [
    "# def is_float(value):\n",
    "#     \"\"\"Check if the value can be converted to float\"\"\"\n",
    "#     try:\n",
    "#         float(value)\n",
    "#         return True\n",
    "#     except:\n",
    "#         return False\n",
    "\n",
    "# # Now proceed to convert and check for problematic values\n",
    "# try:\n",
    "#     results[0] = results[0].astype(float)\n",
    "#     results[16] = results[16].astype(float)\n",
    "# except ValueError as e:\n",
    "#     print(f\"ValueError: {e}\")\n",
    "#     problematic_values_0 = results[~results[0].apply(lambda x: is_float(x))][0]\n",
    "#     problematic_values_16 = results[~results[16].apply(lambda x: is_float(x))][16]\n",
    "#     print(\"Problematic values in column 0:\", problematic_values_0.unique())\n",
    "#     print(\"Problematic values in column 16:\", problematic_values_16.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddea1117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     float64\n",
      "1     float64\n",
      "2     float64\n",
      "3     float64\n",
      "4     float64\n",
      "5     float64\n",
      "6     float64\n",
      "7     float64\n",
      "8     float64\n",
      "9     float64\n",
      "10    float64\n",
      "11    float64\n",
      "12    float64\n",
      "13    float64\n",
      "14    float64\n",
      "15    float64\n",
      "16    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(results.dtypes)\n",
    "# 1. Convert raw scores to probabilities using the sigmoid function.\n",
    "probabilities = 1 / (1 + np.exp(-results.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a00ee6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.028557</td>\n",
       "      <td>0.021039</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.187973</td>\n",
       "      <td>0.106674</td>\n",
       "      <td>0.045703</td>\n",
       "      <td>0.019822</td>\n",
       "      <td>0.020324</td>\n",
       "      <td>0.171137</td>\n",
       "      <td>0.088453</td>\n",
       "      <td>0.818462</td>\n",
       "      <td>0.123065</td>\n",
       "      <td>0.525440</td>\n",
       "      <td>0.044885</td>\n",
       "      <td>0.163524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.070294</td>\n",
       "      <td>0.452533</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>0.011857</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.010891</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.012612</td>\n",
       "      <td>0.003576</td>\n",
       "      <td>0.008348</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.013474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003440</td>\n",
       "      <td>0.472728</td>\n",
       "      <td>0.259231</td>\n",
       "      <td>0.004245</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.570367</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.110187</td>\n",
       "      <td>0.092417</td>\n",
       "      <td>0.009756</td>\n",
       "      <td>0.078120</td>\n",
       "      <td>0.163506</td>\n",
       "      <td>0.199529</td>\n",
       "      <td>0.020855</td>\n",
       "      <td>0.090463</td>\n",
       "      <td>0.022798</td>\n",
       "      <td>0.326026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.063253</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.083491</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.121012</td>\n",
       "      <td>0.669227</td>\n",
       "      <td>0.874878</td>\n",
       "      <td>0.016756</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>0.777107</td>\n",
       "      <td>0.054363</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>0.006507</td>\n",
       "      <td>0.025372</td>\n",
       "      <td>0.188090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.019977</td>\n",
       "      <td>0.089122</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.061913</td>\n",
       "      <td>0.210079</td>\n",
       "      <td>0.001189</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>0.674672</td>\n",
       "      <td>0.235818</td>\n",
       "      <td>0.446227</td>\n",
       "      <td>0.023120</td>\n",
       "      <td>0.147215</td>\n",
       "      <td>0.175855</td>\n",
       "      <td>0.019177</td>\n",
       "      <td>0.008519</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.820451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.010084</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.535111</td>\n",
       "      <td>0.716597</td>\n",
       "      <td>0.006355</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.041973</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.068800</td>\n",
       "      <td>0.010523</td>\n",
       "      <td>0.001737</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.051597</td>\n",
       "      <td>0.643558</td>\n",
       "      <td>0.012363</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.025887</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.026221</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>0.023513</td>\n",
       "      <td>0.058918</td>\n",
       "      <td>0.016695</td>\n",
       "      <td>0.026393</td>\n",
       "      <td>0.385245</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.031113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.001611</td>\n",
       "      <td>0.102937</td>\n",
       "      <td>0.763209</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.021909</td>\n",
       "      <td>0.011093</td>\n",
       "      <td>0.183204</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.013963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.065440</td>\n",
       "      <td>0.343461</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.506463</td>\n",
       "      <td>0.477880</td>\n",
       "      <td>0.062955</td>\n",
       "      <td>0.002383</td>\n",
       "      <td>0.100423</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.142238</td>\n",
       "      <td>0.056776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.018888</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.764599</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.270861</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.188071</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.028005</td>\n",
       "      <td>0.013237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6   \\\n",
       "0    0.001178  0.028557  0.021039  0.030561  0.003492  0.187973  0.106674   \n",
       "1    0.000011  0.070294  0.452533  0.000229  0.000807  0.011857  0.001271   \n",
       "2    0.003440  0.472728  0.259231  0.004245  0.000270  0.570367  0.007350   \n",
       "3    0.001997  0.063253  0.004141  0.083491  0.005505  0.001277  0.121012   \n",
       "4    0.019977  0.089122  0.008013  0.061913  0.210079  0.001189  0.014400   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "493  0.010084  0.000058  0.535111  0.716597  0.006355  0.000004  0.000054   \n",
       "494  0.000437  0.051597  0.643558  0.012363  0.000419  0.025887  0.001635   \n",
       "495  0.001985  0.001611  0.102937  0.763209  0.016667  0.000023  0.000060   \n",
       "496  0.001483  0.005862  0.000320  0.065440  0.343461  0.000030  0.002230   \n",
       "497  0.018888  0.001810  0.005347  0.764599  0.015792  0.000032  0.000235   \n",
       "\n",
       "           7         8         9         10        11        12        13  \\\n",
       "0    0.045703  0.019822  0.020324  0.171137  0.088453  0.818462  0.123065   \n",
       "1    0.001078  0.010891  0.002144  0.001977  0.012612  0.003576  0.008348   \n",
       "2    0.110187  0.092417  0.009756  0.078120  0.163506  0.199529  0.020855   \n",
       "3    0.669227  0.874878  0.016756  0.003659  0.777107  0.054363  0.009188   \n",
       "4    0.674672  0.235818  0.446227  0.023120  0.147215  0.175855  0.019177   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "493  0.041973  0.000784  0.068800  0.010523  0.001737  0.000078  0.000003   \n",
       "494  0.026221  0.005287  0.003493  0.023513  0.058918  0.016695  0.026393   \n",
       "495  0.021909  0.011093  0.183204  0.003741  0.004588  0.000770  0.000067   \n",
       "496  0.506463  0.477880  0.062955  0.002383  0.100423  0.000156  0.000561   \n",
       "497  0.270861  0.010483  0.188071  0.001276  0.011846  0.000587  0.000032   \n",
       "\n",
       "           14        15        16  \n",
       "0    0.525440  0.044885  0.163524  \n",
       "1    0.011718  0.000687  0.013474  \n",
       "2    0.090463  0.022798  0.326026  \n",
       "3    0.006507  0.025372  0.188090  \n",
       "4    0.008519  0.031646  0.820451  \n",
       "..        ...       ...       ...  \n",
       "493  0.000023  0.002990  0.001033  \n",
       "494  0.385245  0.001402  0.031113  \n",
       "495  0.000996  0.000760  0.013963  \n",
       "496  0.000240  0.142238  0.056776  \n",
       "497  0.000901  0.028005  0.013237  \n",
       "\n",
       "[498 rows x 17 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities = 1 / (1 + np.exp(-results.values))\n",
    "probs = pd.DataFrame(probabilities)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "628203c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of true_labels: (498, 17)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'binary_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of true_labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, true_labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of binary_predictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mbinary_predictions\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'binary_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Shape of true_labels:\", true_labels.shape)\n",
    "print(\"Shape of binary_predictions:\", binary_predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1ad229e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>SDG 1</th>\n",
       "      <th>SDG 2</th>\n",
       "      <th>SDG 3</th>\n",
       "      <th>SDG 4</th>\n",
       "      <th>SDG 5</th>\n",
       "      <th>SDG 6</th>\n",
       "      <th>SDG 7</th>\n",
       "      <th>SDG 8</th>\n",
       "      <th>SDG 9</th>\n",
       "      <th>SDG 10</th>\n",
       "      <th>SDG 11</th>\n",
       "      <th>SDG 12</th>\n",
       "      <th>SDG 13</th>\n",
       "      <th>SDG 14</th>\n",
       "      <th>SDG 15</th>\n",
       "      <th>SDG 16</th>\n",
       "      <th>SDG 17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shape, Built Enviro Projects the built environ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PEP 5 this course is identified by rmit univer...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comm Skills for Health Prof this course will e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SW Field Education A in this course you will u...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LSC Work Integrated Learning 2 in this course ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>755</th>\n",
       "      <td>Policy analysis for growth prospects in region...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>Building an understanding of liveability acros...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>Stage 2 - Latrobe Valley Smart Specialisation ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>Balance Victoria:Â  Potential Impacts of a Form...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>Development of culturing procedures and molecu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  SDG 1  SDG 2  SDG 3  \\\n",
       "0    Shape, Built Enviro Projects the built environ...    0.0    0.0    0.0   \n",
       "1    PEP 5 this course is identified by rmit univer...    0.0    0.0    1.0   \n",
       "2    Comm Skills for Health Prof this course will e...    0.0    0.0    1.0   \n",
       "3    SW Field Education A in this course you will u...    0.0    0.0    0.0   \n",
       "4    LSC Work Integrated Learning 2 in this course ...    0.0    0.0    0.0   \n",
       "..                                                 ...    ...    ...    ...   \n",
       "755  Policy analysis for growth prospects in region...    0.0    0.0    0.0   \n",
       "756  Building an understanding of liveability acros...    0.0    0.0    0.0   \n",
       "757  Stage 2 - Latrobe Valley Smart Specialisation ...    0.0    1.0    0.0   \n",
       "758  Balance Victoria:Â  Potential Impacts of a Form...    0.0    0.0    0.0   \n",
       "759  Development of culturing procedures and molecu...    0.0    0.0    0.0   \n",
       "\n",
       "     SDG 4  SDG 5  SDG 6  SDG 7  SDG 8  SDG 9  SDG 10  SDG 11  SDG 12  SDG 13  \\\n",
       "0      1.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "1      1.0    0.0    0.0    0.0    1.0    0.0     1.0     0.0     0.0     0.0   \n",
       "2      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "3      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "4      1.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "..     ...    ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       "755    0.0    0.0    0.0    0.0    1.0    1.0     0.0     0.0     0.0     0.0   \n",
       "756    0.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "757    0.0    0.0    0.0    1.0    1.0    0.0     0.0     0.0     0.0     0.0   \n",
       "758    0.0    0.0    0.0    0.0    0.0    0.0     0.0     1.0     0.0     0.0   \n",
       "759    0.0    0.0    0.0    0.0    0.0    0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "     SDG 14  SDG 15  SDG 16  SDG 17  \n",
       "0       0.0     0.0     0.0     1.0  \n",
       "1       0.0     0.0     0.0     0.0  \n",
       "2       0.0     0.0     0.0     0.0  \n",
       "3       0.0     0.0     0.0     0.0  \n",
       "4       0.0     0.0     0.0     0.0  \n",
       "..      ...     ...     ...     ...  \n",
       "755     0.0     0.0     0.0     0.0  \n",
       "756     0.0     0.0     0.0     0.0  \n",
       "757     0.0     0.0     0.0     1.0  \n",
       "758     0.0     0.0     0.0     0.0  \n",
       "759     0.0     1.0     0.0     0.0  \n",
       "\n",
       "[752 rows x 18 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2d14a9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(498, 17)\n",
      "Overall Accuracy: 0.2831\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       SDG 1       0.50      0.20      0.29        25\n",
      "       SDG 2       0.80      0.48      0.60        25\n",
      "       SDG 3       0.82      0.64      0.72       126\n",
      "       SDG 4       0.68      0.58      0.62       125\n",
      "       SDG 5       0.60      0.27      0.37        22\n",
      "       SDG 6       0.68      0.62      0.65        24\n",
      "       SDG 7       0.75      0.54      0.63        39\n",
      "       SDG 8       0.57      0.50      0.53        66\n",
      "       SDG 9       0.50      0.35      0.41        74\n",
      "      SDG 10       0.49      0.26      0.34        66\n",
      "      SDG 11       0.71      0.55      0.62        73\n",
      "      SDG 12       0.62      0.32      0.42        75\n",
      "      SDG 13       0.47      0.42      0.44        48\n",
      "      SDG 14       0.60      0.14      0.23        21\n",
      "      SDG 15       0.59      0.54      0.57        24\n",
      "      SDG 16       0.65      0.39      0.49        77\n",
      "      SDG 17       0.43      0.34      0.38        53\n",
      "\n",
      "   micro avg       0.63      0.45      0.53       963\n",
      "   macro avg       0.61      0.42      0.49       963\n",
      "weighted avg       0.63      0.45      0.52       963\n",
      " samples avg       0.59      0.54      0.53       963\n",
      "\n",
      "Confusion matrix for SDG 1:\n",
      "[[468   5]\n",
      " [ 20   5]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 2:\n",
      "[[470   3]\n",
      " [ 13  12]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 3:\n",
      "[[354  18]\n",
      " [ 45  81]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 4:\n",
      "[[339  34]\n",
      " [ 53  72]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 5:\n",
      "[[472   4]\n",
      " [ 16   6]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 6:\n",
      "[[467   7]\n",
      " [  9  15]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 7:\n",
      "[[452   7]\n",
      " [ 18  21]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 8:\n",
      "[[407  25]\n",
      " [ 33  33]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 9:\n",
      "[[398  26]\n",
      " [ 48  26]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 10:\n",
      "[[414  18]\n",
      " [ 49  17]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 11:\n",
      "[[409  16]\n",
      " [ 33  40]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 12:\n",
      "[[408  15]\n",
      " [ 51  24]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 13:\n",
      "[[427  23]\n",
      " [ 28  20]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 14:\n",
      "[[475   2]\n",
      " [ 18   3]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 15:\n",
      "[[465   9]\n",
      " [ 11  13]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 16:\n",
      "[[405  16]\n",
      " [ 47  30]]\n",
      "\n",
      "\n",
      "Confusion matrix for SDG 17:\n",
      "[[421  24]\n",
      " [ 35  18]]\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, multilabel_confusion_matrix\n",
    "\n",
    "# # 1. Convert raw scores to probabilities using the sigmoid function.\n",
    "# probabilities = 1 / (1 + np.exp(-results.values))\n",
    "\n",
    "# 2. Convert probabilities to binary predictions using a threshold.\n",
    "threshold = 0.4\n",
    "binary_predictions = (probabilities > threshold).astype(int)\n",
    "\n",
    "# 3. Extract true labels from test_data. Assuming test_data has labels in all columns except \"Text\".\n",
    "true_labels = test_data.drop(columns=\"Text\").values\n",
    "print(true_labels.shape)\n",
    "\n",
    "# Calculate accuracy (this will be a multi-label accuracy).\n",
    "accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "print(f\"Overall Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report.\n",
    "report = classification_report(true_labels, binary_predictions, target_names=test_data.columns[1:])\n",
    "print(report)\n",
    "\n",
    "# Optionally, display the confusion matrix for each SDG (or label).\n",
    "matrices = multilabel_confusion_matrix(true_labels, binary_predictions)\n",
    "for idx, matrix in enumerate(matrices):\n",
    "    print(f\"Confusion matrix for SDG {idx+1}:\")\n",
    "    print(matrix)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1d5ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2db77a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write everything to a .txt file\n",
    "with open(f\"Reports/{model_name}_evaluation_report.txt\", \"w\") as f:\n",
    "    f.write(f\"Overall Accuracy: {accuracy:.4f}\\n\\n\")\n",
    "    f.write(\"Classification Report:\\n\")\n",
    "    f.write(report)\n",
    "    f.write(\"\\n\\n\")\n",
    "\n",
    "    for idx, matrix in enumerate(matrices):\n",
    "        # Convert the matrix to traditional format\n",
    "        traditional_matrix = np.array([[matrix[1][1], matrix[1][0]], [matrix[0][1], matrix[0][0]]])\n",
    "        f.write(f\"Confusion matrix for SDG {idx+1}:\\n\")\n",
    "        f.write(str(traditional_matrix))\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3437200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e02c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2475d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
